topic,paper_ID,sentence_ID,info-unit,sub,pred,obj,triplets,pred_weights
Blogs,0,15,ablation-analysis,emotion label,of,happy,emotion label of happy,0.5507864356040955
Blogs,0,43,ablation-analysis,ablation analysis,effectiveness of,pair filtering phase,ablation analysis effectiveness of pair filtering phase,0.6372940540313721
Blogs,0,8,experiments,fourth clause,considered,emotion clause,fourth clause considered emotion clause,0.624242901802063
Blogs,0,8,experiments,emotion clause,conveying,emotion of happiness,emotion clause conveying emotion of happiness,0.6981871128082275
Blogs,0,9,experiments,clauses,that contain,causes ( cause clause ),clauses that contain causes ( cause clause ),0.6335076093673706
Blogs,0,9,experiments,causes ( cause clause ),are,second clause and the third clause,causes ( cause clause ) are second clause and the third clause,0.5258371829986572
Blogs,0,14,experiments,pairs,of,emotion - cause clauses,pairs of emotion - cause clauses,0.5950623750686646
Blogs,0,35,experiments,benchmark emotion - cause dataset,by,"gui et al. , 2016","benchmark emotion - cause dataset by gui et al. , 2016",0.499880850315094
Blogs,0,33,hyperparameters,pairs,that,output 1,pairs that output 1,0.6917052865028381
Blogs,0,33,hyperparameters,pairs,used for,evaluation,pairs used for evaluation,0.6487993597984314
Blogs,0,33,hyperparameters,output 1,final set of,emotion - cause pairs,output 1 final set of emotion - cause pairs,0.6502988934516907
Blogs,0,33,hyperparameters,hyperparameters,has,pairs,hyperparameters has pairs,0.5769965648651123
Blogs,0,4,model,deep learning method,to extract,causes behind emotions in a document,deep learning method to extract causes behind emotions in a document,0.700550377368927
Blogs,0,4,model,model,develop,deep learning method,model develop deep learning method,0.5707491636276245
Blogs,0,6,model,emotion and causes,from,text,emotion and causes from text,0.6132484078407288
Blogs,0,6,model,emotion and causes,using,multi-task learning,emotion and causes using multi-task learning,0.6272367238998413
Blogs,0,6,model,emotion and causes,conducts,emotion - cause pairing and filtering,emotion and causes conducts emotion - cause pairing and filtering,0.718244731426239
Blogs,0,6,model,emotion - cause pairing and filtering,using,improved version of the multi-task learning model,emotion - cause pairing and filtering using improved version of the multi-task learning model,0.6330638527870178
Blogs,0,6,model,model,separately extract,emotion and causes,model separately extract emotion and causes,0.7445849776268005
Blogs,0,18,model,two parts,conduct,emotion - cause pairing and filtering,two parts conduct emotion - cause pairing and filtering,0.6878167986869812
Blogs,0,18,model,extract sets,of,emotion and cause clauses,extract sets of emotion and cause clauses,0.5743988156318665
Blogs,0,18,model,emotion and cause clauses,from,each document,emotion and cause clauses from each document,0.5786283612251282
Blogs,0,18,model,each document,via,two kinds of multi-task learning networks,each document via two kinds of multi-task learning networks,0.6144724488258362
Blogs,0,19,model,pairing,done via,cartesian product,pairing done via cartesian product,0.7035505175590515
Blogs,0,19,model,cartesian product,applied to,set of emotion and cause clauses,cartesian product applied to set of emotion and cause clauses,0.704578161239624
Blogs,0,19,model,model,has,pairing,model has pairing,0.6097388863563538
Blogs,0,20,model,candidate emotion - cause pairs,on which,filter,candidate emotion - cause pairs on which filter,0.5215123295783997
Blogs,0,20,model,filter,applied to remove,clause pairs,filter applied to remove clause pairs,0.7009819746017456
Blogs,0,20,model,clause pairs,do n't contain,causal relationship,clause pairs do n't contain causal relationship,0.6689996719360352
Blogs,0,21,model,emotion and cause clauses,are,mutually independent,emotion and cause clauses are mutually independent,0.5932605266571045
Blogs,0,21,model,emotion and cause clauses,not,mutually independent,emotion and cause clauses not mutually independent,0.7066947817802429
Blogs,0,21,model,model,propose,interactive multi,model propose interactive multi,0.7110477089881897
Blogs,0,23,model,prediction,for,each type of clause,prediction for each type of clause,0.6243258118629456
Blogs,0,23,model,prediction,performed via,bi-lstm hidden representations,prediction performed via bi-lstm hidden representations,0.568273663520813
Blogs,0,23,model,bi-lstm hidden representations,consist of,context - aware representations,bi-lstm hidden representations consist of context - aware representations,0.6180837154388428
Blogs,0,23,model,context - aware representations,of,each clause,context - aware representations of each clause,0.5606902241706848
Blogs,0,23,model,model,shows how,prediction,model shows how prediction,0.727959394454956
Blogs,0,25,model,model,has,task learning network,model has task learning network,0.5185685753822327
Blogs,0,27,model,improved model,performs,few extra steps,improved model performs few extra steps,0.5751604437828064
Blogs,0,27,model,few extra steps,in,upper layers,few extra steps in upper layers,0.5167784094810486
Blogs,0,27,model,few extra steps,allows,prediction,few extra steps allows prediction,0.717065155506134
Blogs,0,27,model,prediction,based on,interaction,prediction based on interaction,0.7232909798622131
Blogs,0,27,model,interaction,of,two types of representations,interaction of two types of representations,0.5927369594573975
Blogs,0,28,model,enhancing emotion extraction,based on,cause extraction,enhancing emotion extraction based on cause extraction,0.6315200924873352
Blogs,0,28,model,enhancing cause extraction,based on,emotion extraction,enhancing cause extraction based on emotion extraction,0.6495480537414551
Blogs,0,28,model,cause extraction,has,inter ce ),cause extraction has inter ce ),0.5566367506980896
Blogs,0,28,model,emotion extraction,has,inter ec ),emotion extraction has inter ec ),0.5833645462989807
Blogs,0,29,model,model,has,output,model has output,0.5534584522247314
Blogs,0,30,model,objective,pair,two sets,objective pair two sets,0.7253853678703308
Blogs,0,30,model,two sets,to form,emotion - cause pairs,two sets to form emotion - cause pairs,0.6195940971374512
Blogs,0,30,model,emotion - cause pairs,that form,causal relationships,emotion - cause pairs that form causal relationships,0.6714186072349548
Blogs,0,30,model,model,pair,two sets,model pair two sets,0.7699059844017029
Blogs,0,30,model,model,has,objective,model has objective,0.5278581380844116
Blogs,0,32,model,cause relationship,determined via,logistic regression model,cause relationship determined via logistic regression model,0.6475850939750671
Blogs,0,32,model,cause relationship,outputs,1 or 0,cause relationship outputs 1 or 0,0.6932185292243958
Blogs,0,32,model,logistic regression model,takes as input,emotion - cause candidate pair features,logistic regression model takes as input emotion - cause candidate pair features,0.666215717792511
Blogs,0,32,model,emotion - cause candidate pair features,applied,sigmoid operation,emotion - cause candidate pair features applied sigmoid operation,0.7031797170639038
Blogs,0,32,model,1 or 0,to indicate,relationship,1 or 0 to indicate relationship,0.6498304605484009
Blogs,0,32,model,relationship,exists for,each pair,relationship exists for each pair,0.7822946310043335
Blogs,0,32,model,model,has,cause relationship,model has cause relationship,0.5528054237365723
Blogs,0,46,model,both sub-tasks,to improve,ecpe,both sub-tasks to improve ecpe,0.72708660364151
Blogs,0,46,model,model,has,both sub-tasks,model has both sub-tasks,0.5616645216941833
Blogs,0,16,results,results,has,identifying causes,results has identifying causes,0.502836287021637
Blogs,0,36,results,"precision , recall , and f1 scores",used as,evaluation metrics,"precision , recall , and f1 scores used as evaluation metrics",0.5960737466812134
Blogs,0,36,results,results,has,"precision , recall , and f1 scores","results has precision , recall , and f1 scores",0.5121526122093201
Blogs,0,37,results,all the separate tasks,using,three proposed models,all the separate tasks using three proposed models,0.6921016573905945
Blogs,0,37,results,three proposed models,based on,multi-task learning,three proposed models based on multi-task learning,0.6646591424942017
Blogs,0,37,results,results,for,all the separate tasks,results for all the separate tasks,0.5702933073043823
Blogs,0,38,results,inter -ec,produced,better results,inter -ec produced better results,0.7014036774635315
Blogs,0,38,results,results,has,inter -ec,results has inter -ec,0.5254148244857788
Blogs,0,39,results,each other,in,individual tasks,each other in individual tasks,0.5149672627449036
Blogs,0,39,results,cause extraction,has,improve,cause extraction has improve,0.6159001588821411
Blogs,0,39,results,improve,has,each other,improve has each other,0.5885810256004333
Blogs,0,39,results,results,observe,emotion extraction,results observe emotion extraction,0.5516524314880371
Blogs,0,40,results,results,consistent with,intuition,results consistent with intuition,0.7009450197219849
Blogs,0,40,results,intuition,that,emotion and cause,intuition that emotion and cause,0.6884469985961914
Blogs,0,40,results,emotion and cause,are,mutually indicative,emotion and cause are mutually indicative,0.6007224917411804
Blogs,0,40,results,results,consistent with,intuition,results consistent with intuition,0.7009450197219849
Blogs,0,40,results,results,has,results,results has results,0.48582205176353455
Blogs,0,41,results,other variations,of,models,other variations of models,0.6139609217643738
Blogs,0,41,results,models,leverage,dataset available annotations,models leverage dataset available annotations,0.7213553786277771
Blogs,0,41,results,improvements,use,additional information,improvements use additional information,0.6701399087905884
Blogs,0,41,results,additional information,to improve,predictions,additional information to improve predictions,0.6780760884284973
Blogs,0,41,results,predictions,of,different tasks,predictions of different tasks,0.5617614984512329
Blogs,0,41,results,results,has,other variations,results has other variations,0.5894997715950012
Blogs,0,44,results,results,using,rule-based and machine learning methods,results using rule-based and machine learning methods,0.6178726553916931
Blogs,0,45,results,emotion extraction,helps to improve,cause extraction,emotion extraction helps to improve cause extraction,0.6734552979469299
Blogs,0,45,results,emotion extraction,helps to enhance,emotion extraction,emotion extraction helps to enhance emotion extraction,0.668796956539154
Blogs,0,45,results,cause extraction,helps to enhance,emotion extraction,cause extraction helps to enhance emotion extraction,0.6932584643363953
Blogs,0,45,results,results,indicate,emotion extraction,results indicate emotion extraction,0.527232825756073
Blogs,1,33,ablation-analysis,listener component,does n't improve,model 's performance,listener component does n't improve model 's performance,0.6879196166992188
Blogs,1,38,ablation-analysis,important ablation study,to observe,importance,important ablation study to observe importance,0.6925708055496216
Blogs,1,38,ablation-analysis,importance,of,emotion gru,importance of emotion gru,0.595393717288971
Blogs,1,38,ablation-analysis,importance,of,party state components,importance of party state components,0.6038255095481873
Blogs,1,38,ablation-analysis,ablation analysis,to observe,importance,ablation analysis to observe importance,0.7435649633407593
Blogs,1,38,ablation-analysis,ablation analysis,has,important ablation study,ablation analysis has important ablation study,0.5495229959487915
Blogs,1,39,ablation-analysis,absence of part state,has,decreases,absence of part state has decreases,0.6393998265266418
Blogs,1,39,ablation-analysis,decreases,has,performance,decreases has performance,0.5981842875480652
Blogs,1,40,ablation-analysis,party state,seems to be,more important,party state seems to be more important,0.6736662983894348
Blogs,1,40,ablation-analysis,more important,than,emotion gru,more important than emotion gru,0.5635390281677246
Blogs,1,40,ablation-analysis,ablation analysis,observed,party state,ablation analysis observed party state,0.7450900673866272
Blogs,1,26,baselines,dialoguernn_l,considers,extra listener state,dialoguernn_l considers extra listener state,0.6862413883209229
Blogs,1,26,baselines,extra listener state,while,speaker utters,extra listener state while speaker utters,0.6142972707748413
Blogs,1,27,baselines,bidirectional rnn architecture,used instead,dialoguernn + att,bidirectional rnn architecture used instead dialoguernn + att,0.6635504961013794
Blogs,1,27,baselines,attention,applied over,all surrounding emotion representations,attention applied over all surrounding emotion representations,0.676108717918396
Blogs,1,27,baselines,bidialoguernn,has,bidirectional rnn architecture,bidialoguernn has bidirectional rnn architecture,0.5558146834373474
Blogs,1,27,baselines,bidialoguernn,has,attention,bidialoguernn has attention,0.6520428657531738
Blogs,1,27,baselines,dialoguernn + att,has,attention,dialoguernn + att has attention,0.6746917366981506
Blogs,1,27,baselines,baselines,has,bidialoguernn,baselines has bidialoguernn,0.6008725762367249
Blogs,1,2,experiments,dialoguernn,has,emotion classification in conversation,dialoguernn has emotion classification in conversation,0.5574272274971008
Blogs,1,11,experiments,utterances,come in,multimodal setting,utterances come in multimodal setting,0.6792281270027161
Blogs,1,11,experiments,audio and visual features,extracted using,3d - cnn and opensmile,audio and visual features extracted using 3d - cnn and opensmile,0.6752485036849976
Blogs,1,11,experiments,utterances,has,audio and visual features,utterances has audio and visual features,0.6075478196144104
Blogs,1,11,experiments,multimodal setting,has,audio and visual features,multimodal setting has audio and visual features,0.5729479789733887
Blogs,1,30,experiments,interactions,has,between multiple parties,interactions has between multiple parties,0.5848863124847412
Blogs,1,36,experiments,dialoguernn,correctly anticipates,emotion of frustration,dialoguernn correctly anticipates emotion of frustration,0.776240885257721
Blogs,1,36,experiments,emotion of frustration,using,preceding context ( 41 and 42 ),emotion of frustration using preceding context ( 41 and 42 ),0.6668176651000977
Blogs,1,8,model,emotion detection model,considers,individual speakers,emotion detection model considers individual speakers,0.5852567553520203
Blogs,1,8,model,individual speakers,by focusing on,three different aspects,individual speakers by focusing on three different aspects,0.7036144137382507
Blogs,1,9,model,accurately predict,has,emotion of the utterance,accurately predict has emotion of the utterance,0.5762471556663513
Blogs,1,10,model,model utterances,for,"party ( i.e. , individual )","model utterances for party ( i.e. , individual )",0.5958413481712341
Blogs,1,10,model,model utterances,represented through,textual features,model utterances represented through textual features,0.6755050420761108
Blogs,1,10,model,"party ( i.e. , individual )",represented through,textual features,"party ( i.e. , individual ) represented through textual features",0.653810977935791
Blogs,1,10,model,textual features,obtained from,convolutional neural network,textual features obtained from convolutional neural network,0.49926242232322693
Blogs,1,10,model,model,for,"party ( i.e. , individual )","model for party ( i.e. , individual )",0.5815820097923279
Blogs,1,10,model,model,has,model utterances,model has model utterances,0.615445077419281
Blogs,1,12,model,network,trained at,utterance level,network trained at utterance level,0.7146084308624268
Blogs,1,12,model,utterance level,with,target emotion labels,utterance level with target emotion labels,0.6133215427398682
Blogs,1,12,model,model,has,network,model has network,0.6001628041267395
Blogs,1,13,model,final emotion,of,utterance,final emotion of utterance,0.5606814622879028
Blogs,1,13,model,party state,models,parties ' emotion dynamics,party state models parties ' emotion dynamics,0.6945584416389465
Blogs,1,13,model,parties ' emotion dynamics,through,conversations,parties ' emotion dynamics through conversations,0.6051538586616516
Blogs,1,13,model,model,called,dialoguernn,model called dialoguernn,0.7069957256317139
Blogs,1,13,model,model,determines,final emotion,model determines final emotion,0.6763166785240173
Blogs,1,14,model,party state,to ensure,model,party state to ensure model,0.710176408290863
Blogs,1,14,model,model,is aware of,speaker,model is aware of speaker,0.662198543548584
Blogs,1,14,model,speaker,of,each utterance,speaker of each utterance,0.5979385375976562
Blogs,1,14,model,each utterance,in,conversation,each utterance in conversation,0.5550758242607117
Blogs,1,14,model,model,behind,party state,model behind party state,0.7644451856613159
Blogs,1,15,model,global state,jointly encoding,preceding utterances and the party state,global state jointly encoding preceding utterances and the party state,0.772458553314209
Blogs,1,15,model,model,has,global state,model has global state,0.5588717460632324
Blogs,1,16,model,attention mechanism,applied to,global state,attention mechanism applied to global state,0.6791937947273254
Blogs,1,16,model,global state,to provide,improved context representation,global state to provide improved context representation,0.6399850845336914
Blogs,1,16,model,model,Note,attention mechanism,model Note attention mechanism,0.5826944708824158
Blogs,1,18,model,emotion representation,inferred through,party state,emotion representation inferred through party state,0.6552603840827942
Blogs,1,18,model,emotion representation,inferred through,preceding speaker 's states,emotion representation inferred through preceding speaker 's states,0.7038466334342957
Blogs,1,18,model,preceding speaker 's states,as,context ( global state ),preceding speaker 's states as context ( global state ),0.48751577734947205
Blogs,1,18,model,model,has,emotion representation,model has emotion representation,0.5130464434623718
Blogs,1,19,model,final emotion classification,via,softmax layer,final emotion classification via softmax layer,0.6529698967933655
Blogs,1,20,model,each component,of,architecture,each component of architecture,0.6097907423973083
Blogs,1,20,model,model,has,each component,model has each component,0.5446574687957764
Blogs,1,21,model,speaker state,updated using,current utterance,speaker state updated using current utterance,0.6449137330055237
Blogs,1,21,model,current utterance,along with,context,current utterance along with context,0.6096916794776917
Blogs,1,21,model,training,has,speaker state,training has speaker state,0.554023802280426
Blogs,1,21,model,model,during,training,model during training,0.714866042137146
Blogs,1,22,model,role,of,attention mechanism,role of attention mechanism,0.5628481507301331
Blogs,1,22,model,role,assigns,higher attention scores,role assigns higher attention scores,0.6616792678833008
Blogs,1,22,model,attention mechanism,assigns,higher attention scores,attention mechanism assigns higher attention scores,0.6617770791053772
Blogs,1,22,model,higher attention scores,to,utterances,higher attention scores to utterances,0.5878247618675232
Blogs,1,22,model,emotionally relevant,to,current utterance,emotionally relevant to current utterance,0.5719427466392517
Blogs,1,22,model,model,has,role,model has role,0.5706759095191956
Blogs,1,23,model,information,on,current utterance,information on current utterance,0.5315257906913757
Blogs,1,23,model,current utterance,along with,context,current utterance along with context,0.6096916794776917
Blogs,1,23,model,context,from,global gru,context from global gru,0.572843074798584
Blogs,1,23,model,speaker update,has,information,speaker update has information,0.570763349533081
Blogs,1,23,model,party gru,has,information,party gru has information,0.5755640864372253
Blogs,1,23,model,model,has,speaker update,model has speaker update,0.5395891070365906
Blogs,1,24,model,information,important for performing,final emotion classification,information important for performing final emotion classification,0.6878631711006165
Blogs,1,24,model,final emotion classification,performed by,emotion gru,final emotion classification performed by emotion gru,0.5560413002967834
Blogs,1,24,model,model,has,information,model has information,0.5741810202598572
Blogs,1,25,model,current emotion classification,relies on,previous emotion - relevant information,current emotion classification relies on previous emotion - relevant information,0.6772748827934265
Blogs,1,41,model,state of the listener,based on,current speaker utterance,state of the listener based on current speaker utterance,0.623270571231842
Blogs,1,41,model,listener update,has,changes,listener update has changes,0.5939376950263977
Blogs,1,41,model,changes,has,state of the listener,changes has state of the listener,0.6029415130615234
Blogs,1,41,model,model,has,listener update,model has listener update,0.5752775073051453
Blogs,1,42,model,visual cues,represent,information,visual cues represent information,0.6006354093551636
Blogs,1,42,model,model,has,visual cues,model has visual cues,0.5611539483070374
Blogs,1,4,results,results,Welcome to,another paper review,results Welcome to another paper review,0.6140130758285522
Blogs,1,31,results,dialoguernn,has,outperforms,dialoguernn has outperforms,0.6265738606452942
Blogs,1,31,results,outperforms,has,all baselines,outperforms has all baselines,0.5888515114784241
Blogs,1,31,results,results,observe that,dialoguernn,results observe that dialoguernn,0.5961147546768188
Blogs,1,32,results,results,using,text modality,results using text modality,0.6397952437400818
Blogs,1,34,results,other variants,found to perform,well,other variants found to perform well,0.6505361199378967
Blogs,1,34,results,well,especially,bidialoguernn + att,well especially bidialoguernn + att,0.6646565794944763
Blogs,1,34,results,well,produced,better results,well produced better results,0.682063102722168
Blogs,1,34,results,bidialoguernn + att,produced,better results,bidialoguernn + att produced better results,0.6935274004936218
Blogs,1,34,results,results,has,other variants,results has other variants,0.5616840720176697
Blogs,1,35,results,other models,in,multimodal setting,other models in multimodal setting,0.5403384566307068
Blogs,1,35,results,proposed model,has,dialoguernn,proposed model has dialoguernn,0.6512309908866882
Blogs,1,35,results,proposed model,has,significantly outperforms,proposed model has significantly outperforms,0.6167242527008057
Blogs,1,35,results,significantly outperforms,has,other models,significantly outperforms has other models,0.5646228790283203
Blogs,1,37,results,results,For,cmn model,results For cmn model,0.5983672142028809
Blogs,2,14,ablation-analysis,answers,predicted by,mrc model,answers predicted by mrc model,0.8120583891868591
Blogs,2,14,ablation-analysis,answers,considered to be,key entities,answers considered to be key entities,0.6060514450073242
Blogs,2,14,ablation-analysis,mrc model,considered to be,key entities,mrc model considered to be key entities,0.6499802470207214
Blogs,2,14,ablation-analysis,ablation analysis,has,answers,ablation analysis has answers,0.6071295142173767
Blogs,2,7,experiments,key entity detection,in,uni ed approach,key entity detection in uni ed approach,0.5384505391120911
Blogs,2,7,experiments,uni ed approach,based on,roberta,uni ed approach based on roberta,0.6638772487640381
Blogs,2,8,experiments,roberta,using,different methods,roberta using different methods,0.6578120589256287
Blogs,2,8,experiments,different methods,to implement,sentiment analysis,different methods to implement sentiment analysis,0.6424089670181274
Blogs,2,8,experiments,different methods,to implement,key entity detection,different methods to implement key entity detection,0.6493719816207886
Blogs,2,9,experiments,sentiment analysis,focus speci cally on,negative emotion information,sentiment analysis focus speci cally on negative emotion information,0.6979243755340576
Blogs,2,12,experiments,tags,can be,corruption,tags can be corruption,0.659091055393219
Blogs,2,12,experiments,tags,can be,fraud,tags can be fraud,0.6621938347816467
Blogs,2,20,experiments,sentiment,of,text,sentiment of text,0.5802077651023865
Blogs,2,20,experiments,text,using,roberta ( classic ),text using roberta ( classic ),0.7094247937202454
Blogs,2,20,experiments,roberta ( classic ),Get,nancial entity list,roberta ( classic ) Get nancial entity list,0.5776929259300232
Blogs,2,20,experiments,roberta ( classic ),select,key entities,roberta ( classic ) select key entities,0.7103607058525085
Blogs,2,20,experiments,nancial entity list,select,key entities,nancial entity list select key entities,0.6653046607971191
Blogs,2,20,experiments,key entities,with,tags,key entities with tags,0.6509701013565063
Blogs,2,20,experiments,key entity,with,tags,key entity with tags,0.6393309235572815
Blogs,2,24,experiments,number of models,determined by,number of entities,number of models determined by number of entities,0.6323094367980957
Blogs,2,27,experiments,two datasets,for,financial field,two datasets for financial field,0.5490359663963318
Blogs,2,27,experiments,event subject extraction,for,financial field,event subject extraction for financial field,0.5324844121932983
Blogs,2,21,hyperparameters,each piece,of,nancial data,each piece of nancial data,0.5673916935920715
Blogs,2,21,hyperparameters,each piece,use,ner,each piece use ner,0.6432386636734009
Blogs,2,21,hyperparameters,ner,to get,list of entities,ner to get list of entities,0.5607660412788391
Blogs,2,21,hyperparameters,hyperparameters,for,each piece,hyperparameters for each piece,0.5842301845550537
Blogs,2,6,model,outperformed,for,two nancial sentiment analysis and key entity detection datasets,outperformed for two nancial sentiment analysis and key entity detection datasets,0.5783656239509583
Blogs,2,6,model,bert,for,two nancial sentiment analysis and key entity detection datasets,bert for two nancial sentiment analysis and key entity detection datasets,0.5619734525680542
Blogs,2,6,model,outperformed,has,svm,outperformed has svm,0.621993362903595
Blogs,2,6,model,outperformed,has,lr,outperformed has lr,0.6233335733413696
Blogs,2,6,model,outperformed,has,nbm,outperformed has nbm,0.6326287388801575
Blogs,2,6,model,outperformed,has,bert,outperformed has bert,0.710383415222168
Blogs,2,6,model,model,proposed,ensemble learning,model proposed ensemble learning,0.7193567752838135
Blogs,2,11,model,most relevant key entities,tags of,nancial text,most relevant key entities tags of nancial text,0.7263724207878113
Blogs,2,19,model,key entity detection approach,for,online nancial texts,key entity detection approach for online nancial texts,0.5414386987686157
Blogs,2,19,model,model,propose,roberta based sentiment analysis,model propose roberta based sentiment analysis,0.65773606300354
Blogs,2,22,model,coarse- grained task,detected,some key entities,coarse- grained task detected some key entities,0.6720006465911865
Blogs,2,22,model,some key entities,related to,nancial text,some key entities related to nancial text,0.7047407031059265
Blogs,2,22,model,nancial text,from,entity list,nancial text from entity list,0.5296038389205933
Blogs,2,22,model,model,In,coarse- grained task,model In coarse- grained task,0.5563156008720398
Blogs,2,23,model,each entity and the nancial text,into,roberta,each entity and the nancial text into roberta,0.5399251580238342
Blogs,2,23,model,each entity and the nancial text,into,roberta,each entity and the nancial text into roberta,0.5399251580238342
Blogs,2,23,model,each entity and the nancial text,use,roberta,each entity and the nancial text use roberta,0.5731348395347595
Blogs,2,23,model,roberta,as,sentence matching model,roberta as sentence matching model,0.5154786705970764
Blogs,2,23,model,roberta,as,sentence matching model,roberta as sentence matching model,0.5154786705970764
Blogs,2,23,model,sentence matching model,to determine,each entity,sentence matching model to determine each entity,0.5911142826080322
Blogs,2,23,model,model,feed,each entity and the nancial text,model feed each entity and the nancial text,0.6174605488777161
Blogs,2,25,model,key entities,predicted as,key,key entities predicted as key,0.6498883366584778
Blogs,2,25,model,key entities,by,roberta,key entities by roberta,0.583401083946228
Blogs,2,25,model,key,by,roberta,key by roberta,0.6533458828926086
Blogs,2,10,results,key entity detection,able to,match,key entity detection able to match,0.5789158940315247
Blogs,2,10,results,each nancial entity,with,text,each nancial entity with text,0.6444172263145447
Blogs,2,10,results,each nancial entity,to detect,key entities,each nancial entity to detect key entities,0.6222521066665649
Blogs,2,10,results,text,to detect,key entities,text to detect key entities,0.6899144053459167
Blogs,2,10,results,key entities,of,negative information,key entities of negative information,0.5733810663223267
Blogs,2,10,results,match,has,each nancial entity,match has each nancial entity,0.588959276676178
Blogs,2,10,results,results,With,key entity detection,results With key entity detection,0.6414138674736023
Blogs,2,28,results,descriptive statistics,of,dataset,descriptive statistics of dataset,0.532635509967804
Blogs,2,28,results,results,showcase,descriptive statistics,results showcase descriptive statistics,0.5457689166069031
Blogs,2,29,results,evaluation metrics,are,accuracy rate,evaluation metrics are accuracy rate,0.48022347688674927
Blogs,2,29,results,evaluation metrics,are,f1 score,evaluation metrics are f1 score,0.4898214638233185
Blogs,2,29,results,accuracy rate,for,sentiment analysis,accuracy rate for sentiment analysis,0.5888576507568359
Blogs,2,29,results,f1 score,for,key entity detection,f1 score for key entity detection,0.5893462896347046
Blogs,2,29,results,results,has,evaluation metrics,results has evaluation metrics,0.5194434523582458
Blogs,3,13,ablation-analysis,four most frequent aspects,from,dataset,four most frequent aspects from dataset,0.5503634214401245
Blogs,3,13,ablation-analysis,ablation analysis,Selected,four most frequent aspects,ablation analysis Selected four most frequent aspects,0.6677423715591431
Blogs,3,35,ablation-analysis,underperforming,of,lstm,underperforming of lstm,0.60490882396698
Blogs,3,35,ablation-analysis,underperforming,due to,lack of training data,underperforming due to lack of training data,0.6585741639137268
Blogs,3,35,ablation-analysis,ablation analysis,has,underperforming,ablation analysis has underperforming,0.5404157042503357
Blogs,3,17,baselines,different variation of logistic regression,with,linguistic features lstm,different variation of logistic regression with linguistic features lstm,0.6352480053901672
Blogs,3,17,baselines,linguistic features lstm,with,nal and location,linguistic features lstm with nal and location,0.5922207236289978
Blogs,3,17,baselines,nal and location,output,state sentihood dataset,nal and location output state sentihood dataset,0.8028001189231873
Blogs,3,17,baselines,baselines,has,different variation of logistic regression,baselines has different variation of logistic regression,0.5650051832199097
Blogs,3,18,baselines,few strong baseline models,using,logistic regression,few strong baseline models using logistic regression,0.6208865642547607
Blogs,3,18,baselines,few strong baseline models,using,lstm,few strong baseline models using lstm,0.5894532799720764
Blogs,3,18,baselines,few strong baseline models,for,future benchmarking,few strong baseline models for future benchmarking,0.6218717694282532
Blogs,3,18,baselines,lstm,for,future benchmarking,lstm for future benchmarking,0.6407102346420288
Blogs,3,18,baselines,baselines,Develop,few strong baseline models,baselines Develop few strong baseline models,0.6098247170448303
Blogs,3,34,baselines,best performing model,is,logistic regression,best performing model is logistic regression,0.5335603356361389
Blogs,3,34,baselines,logistic regression,with,location masking,logistic regression with location masking,0.6159877777099609
Blogs,3,34,baselines,logistic regression,with,pos information,logistic regression with pos information,0.6160570383071899
Blogs,3,34,baselines,baselines,has,best performing model,baselines has best performing model,0.540871262550354
Blogs,3,6,experiments,design of the space,is,good,design of the space is good,0.62135910987854
Blogs,3,6,experiments,service,is,horrid,service is horrid,0.6801182627677917
Blogs,3,10,experiments,polarity class   none  ,where,sentence,polarity class   none   where sentence,0.6528094410896301
Blogs,3,10,experiments,sentence,does not contain,opinion,sentence does not contain opinion,0.6671649217605591
Blogs,3,10,experiments,opinion,for,aspect a of location l,opinion for aspect a of location l,0.6392592787742615
Blogs,3,30,experiments,sentihood dataset,Contains,annotated sentences,sentihood dataset Contains annotated sentences,0.5999324321746826
Blogs,3,30,experiments,annotated sentences,containing,one or two location entity mentions,annotated sentences containing one or two location entity mentions,0.5991542339324951
Blogs,3,31,experiments,sentences,with,single location entity,sentences with single location entity,0.590965986251831
Blogs,3,31,experiments,sentences,with,two location entities,sentences with two location entities,0.6145602464675903
Blogs,3,31,experiments,5215 sentences,has,sentences,5215 sentences has sentences,0.5870250463485718
Blogs,3,5,results,results,has,tabsa vs absa,results has tabsa vs absa,0.543213963508606
Blogs,3,14,results,results,broken down to,single location sentences,results broken down to single location sentences,0.6250650882720947
Blogs,3,14,results,results,broken down to,two locations sentences,results broken down to two locations sentences,0.6926530003547668
Blogs,3,14,results,results,broken down to,overall test set,results broken down to overall test set,0.7281972765922546
Blogs,3,14,results,results,broken down to,single location sentences,results broken down to single location sentences,0.6250650882720947
Blogs,3,14,results,results,broken down to,overall test set,results broken down to overall test set,0.7281972765922546
Blogs,3,14,results,results,has,results,results has results,0.48582205176353455
Blogs,3,15,results,results,on,single location sentences,results on single location sentences,0.47232910990715027
Blogs,3,15,results,results,on,two locations sentences,results on two locations sentences,0.5196282267570496
Blogs,3,15,results,results,on,two locations sentences,results on two locations sentences,0.5196282267570496
Blogs,3,15,results,single location sentences,showcase,model 's ability,single location sentences showcase model 's ability,0.7621603608131409
Blogs,3,15,results,single location sentences,showcase,model 's ability,single location sentences showcase model 's ability,0.7621603608131409
Blogs,3,15,results,model 's ability,to perform,correct sentiment analysis,model 's ability to perform correct sentiment analysis,0.6741324663162231
Blogs,3,15,results,model 's ability,to detect,relevant sentiment,model 's ability to detect relevant sentiment,0.6652263402938843
Blogs,3,15,results,two locations sentences,show,model 's ability,two locations sentences show model 's ability,0.629916787147522
Blogs,3,15,results,model 's ability,to detect,relevant sentiment,model 's ability to detect relevant sentiment,0.6652263402938843
Blogs,3,15,results,model 's ability,recognise,target entity,model 's ability recognise target entity,0.6016115546226501
Blogs,3,15,results,relevant sentiment,of,aspect,relevant sentiment of aspect,0.5512137413024902
Blogs,3,15,results,relevant sentiment,recognise,target entity,relevant sentiment recognise target entity,0.5990073084831238
Blogs,3,15,results,target entity,of,opinion,target entity of opinion,0.5501447319984436
Blogs,3,15,results,results,on,single location sentences,results on single location sentences,0.47232910990715027
Blogs,3,15,results,results,on,two locations sentences,results on two locations sentences,0.5196282267570496
Blogs,3,15,results,results,on,two locations sentences,results on two locations sentences,0.5196282267570496
Blogs,3,26,results,space,is,great,space is great,0.59559565782547
Blogs,3,26,results,great,in,mcdonalds,great in mcdonalds,0.5831722021102905
Blogs,3,26,results,service,is,horrid,service is horrid,0.6801182627677917
Blogs,3,26,results,staff,are,very friendly,staff are very friendly,0.5501139163970947
Blogs,3,26,results,results,design of,space,results design of space,0.6703417897224426
Blogs,3,36,results,consistent outperformance,of,logistic regression,consistent outperformance of logistic regression,0.5866194367408752
Blogs,3,36,results,consistent outperformance,highlights,advantage,consistent outperformance highlights advantage,0.5965948104858398
Blogs,3,36,results,logistic regression,over,lstm,logistic regression over lstm,0.6372422575950623
Blogs,3,36,results,advantage,of,features engineering,advantage of features engineering,0.5832274556159973
Blogs,3,36,results,advantage,when,volume of data,advantage when volume of data,0.6820091009140015
Blogs,3,36,results,features engineering,when,volume of data,features engineering when volume of data,0.6491478085517883
Blogs,3,36,results,volume of data,is,low,volume of data is low,0.5973436236381531
Blogs,3,36,results,results,has,consistent outperformance,results has consistent outperformance,0.5935763120651245
Blogs,4,10,ablation-analysis,temporal information,useful for,emoji prediction,temporal information useful for emoji prediction,0.6537182331085205
Blogs,4,10,ablation-analysis,emoji prediction,even for,emojis,emoji prediction even for emojis,0.6505936980247498
Blogs,4,10,ablation-analysis,emojis,associated with,time,emojis associated with time,0.6741530299186707
Blogs,4,10,ablation-analysis,ablation analysis,demonstrates,temporal information,ablation analysis demonstrates temporal information,0.657405436038971
Blogs,4,16,ablation-analysis,top 10 emojis,associated to,each emoji,top 10 emojis associated to each emoji,0.5898769497871399
Blogs,4,16,ablation-analysis,top 10 emojis,discovered that,emojis,top 10 emojis discovered that emojis,0.6235623359680176
Blogs,4,16,ablation-analysis,each emoji,in,embedding space,each emoji in embedding space,0.5219295024871826
Blogs,4,16,ablation-analysis,emojis,related to,music,emojis related to music,0.6818041801452637
Blogs,4,16,ablation-analysis,emojis,related to,animal,emojis related to animal,0.7237299680709839
Blogs,4,16,ablation-analysis,emojis,related to,sweets,emojis related to sweets,0.6652612090110779
Blogs,4,16,ablation-analysis,emojis,related to,emotions,emojis related to emotions,0.714415431022644
Blogs,4,16,ablation-analysis,emojis,influenced by,seasonality,emojis influenced by seasonality,0.7510583400726318
Blogs,4,16,ablation-analysis,emotions,influenced by,seasonality,emotions influenced by seasonality,0.6424473524093628
Blogs,4,16,ablation-analysis,ablation analysis,comparing,top 10 emojis,ablation analysis comparing top 10 emojis,0.676904022693634
Blogs,4,27,ablation-analysis,emojis,that had,higher gains,emojis that had higher gains,0.69162917137146
Blogs,4,27,ablation-analysis,higher gains,in,f1 score,higher gains in f1 score,0.5478156805038452
Blogs,4,27,ablation-analysis,f1 score,has,without date,f1 score has without date,0.5949445366859436
Blogs,4,27,ablation-analysis,ablation analysis,has,emojis,ablation analysis has emojis,0.5806708931922913
Blogs,4,28,ablation-analysis,many emojis,are,"season-specific ( e.g. , ? , ? )","many emojis are season-specific ( e.g. , ? , ? )",0.5812892913818359
Blogs,4,28,ablation-analysis,many emojis,benefit from,date embeddings,many emojis benefit from date embeddings,0.655297040939331
Blogs,4,28,ablation-analysis,ablation analysis,observe,many emojis,ablation analysis observe many emojis,0.5953571796417236
Blogs,4,29,ablation-analysis,emojis,not associated to,time,emojis not associated to time,0.7406349182128906
Blogs,4,29,ablation-analysis,emojis,benefit from,temporal information,emojis benefit from temporal information,0.6666112542152405
Blogs,4,29,ablation-analysis,time,benefit from,temporal information,time benefit from temporal information,0.6790344715118408
Blogs,4,29,ablation-analysis,ablation analysis,Even,emojis,ablation analysis Even emojis,0.6861859560012817
Blogs,4,29,ablation-analysis,ablation analysis,has,emojis,ablation analysis has emojis,0.5806708931922913
Blogs,4,30,ablation-analysis,more analysis,on,emoji semantics and usage,more analysis on emoji semantics and usage,0.5316172242164612
Blogs,4,30,ablation-analysis,emoji semantics and usage,over,specific time of the day or week,emoji semantics and usage over specific time of the day or week,0.6486280560493469
Blogs,4,30,ablation-analysis,ablation analysis,on,emoji semantics and usage,ablation analysis on emoji semantics and usage,0.541533350944519
Blogs,4,30,ablation-analysis,ablation analysis,has,more analysis,ablation analysis has more analysis,0.5394825339317322
Blogs,4,33,ablation-analysis,sport-related emojis,varied in,meaning,sport-related emojis varied in meaning,0.7013089656829834
Blogs,4,33,ablation-analysis,meaning,across,seasons,meaning across seasons,0.7471168637275696
Blogs,4,33,ablation-analysis,ablation analysis,has,sport-related emojis,ablation analysis has sport-related emojis,0.55302494764328
Blogs,4,34,ablation-analysis,interesting emoji,related to,school,interesting emoji related to school,0.6867300868034363
Blogs,4,34,ablation-analysis,changed meaning,across,seasons,changed meaning across seasons,0.7690912485122681
Blogs,4,34,ablation-analysis,during autumn,associated with,school-related emojis,during autumn associated with school-related emojis,0.699163556098938
Blogs,4,34,ablation-analysis,interesting emoji,has,changed meaning,interesting emoji has changed meaning,0.5723044276237488
Blogs,4,34,ablation-analysis,school,has,changed meaning,school has changed meaning,0.6010780930519104
Blogs,4,34,ablation-analysis,ablation analysis,has,interesting emoji,ablation analysis has interesting emoji,0.5976042747497559
Blogs,4,8,experiments,leaf clover emoji,associated with,good luck wishes,leaf clover emoji associated with good luck wishes,0.642264187335968
Blogs,4,8,experiments,leaf clover emoji,has,),leaf clover emoji has ),0.5308210849761963
Blogs,4,13,experiments,twitter,to collect,100 million us tweets corpus,twitter to collect 100 million us tweets corpus,0.6531755328178406
Blogs,4,13,experiments,four subsets,by,seasons,four subsets by seasons,0.6508344411849976
Blogs,4,13,experiments,four subsets,of,seasonal datasets,four subsets of seasonal datasets,0.6061484217643738
Blogs,4,20,experiments,"900,000 tweets total",used for,emoji prediction,"900,000 tweets total used for emoji prediction",0.6446577906608582
Blogs,4,5,model,emoji prediction model,based on,time information,emoji prediction model based on time information,0.6139091849327087
Blogs,4,5,model,model,develop,emoji prediction model,model develop emoji prediction model,0.5758982300758362
Blogs,4,7,model,temporal correlation,between,emojis and seasonal events,temporal correlation between emojis and seasonal events,0.641293466091156
Blogs,4,7,model,temporal correlation,to disambiguate,emoji meanings,temporal correlation to disambiguate emoji meanings,0.7684928178787231
Blogs,4,7,model,model,has,temporal correlation,model has temporal correlation,0.5508665442466736
Blogs,4,21,model,architecture,of,emoji prediction model,architecture of emoji prediction model,0.5142138600349426
Blogs,4,21,model,data embeddings,combined through,early fusion approach,data embeddings combined through early fusion approach,0.7394163012504578
Blogs,4,21,model,data embeddings,combined through,late fusion approach,data embeddings combined through late fusion approach,0.7415159940719604
Blogs,4,21,model,model,has,architecture,model has architecture,0.5575731992721558
Blogs,4,23,model,trained ( w/o ),completely ignores,date embeddings,trained ( w/o ) completely ignores date embeddings,0.7621553540229797
Blogs,4,23,model,model,has,third model,model has third model,0.5888231992721558
Blogs,4,37,model,multimodal architecture,to conduct,emoji prediction,multimodal architecture to conduct emoji prediction,0.5327939987182617
Blogs,4,37,model,emoji prediction,based on,deep neural networks,emoji prediction based on deep neural networks,0.5619048476219177
Blogs,4,37,model,model,has,multimodal architecture,model has multimodal architecture,0.5422720313072205
Blogs,4,17,results,meaning,across,seasons,meaning across seasons,0.7471168637275696
Blogs,4,25,results,results,has,"precision , recall , and f1 scores","results has precision , recall , and f1 scores",0.5121526122093201
Blogs,4,26,results,time information,using,early fusion,time information using early fusion,0.6894142627716064
Blogs,4,26,results,early model,outperforms,other models,early model outperforms other models,0.693832278251648
Blogs,4,26,results,time information,has,early model,time information has early model,0.5476198196411133
Blogs,4,26,results,early fusion,has,early model,early fusion has early model,0.5648167729377747
Blogs,4,35,results,top 10 associated emojis per season,for,pine emoji,top 10 associated emojis per season for pine emoji,0.552867591381073
Blogs,4,35,results,results,Check out,top 10 associated emojis per season,results Check out top 10 associated emojis per season,0.6344276666641235
Blogs,5,16,ablation-analysis,linear model,with,l1 regularization,linear model with l1 regularization,0.5745596289634705
Blogs,5,16,ablation-analysis,ablation analysis,training,linear model,ablation analysis training linear model,0.7317191958427429
Blogs,5,17,ablation-analysis,single   sentiment neuron  ,highly predictive of,sentiment value,single   sentiment neuron   highly predictive of sentiment value,0.639007031917572
Blogs,5,17,ablation-analysis,ablation analysis,realized there actually existed,single   sentiment neuron  ,ablation analysis realized there actually existed single   sentiment neuron  ,0.6907447576522827
Blogs,5,36,ablation-analysis,negative update,after,lost,negative update after lost,0.685267984867096
Blogs,5,36,ablation-analysis,negative update,after,larger update,negative update after larger update,0.6622970104217529
Blogs,5,36,ablation-analysis,larger update,at,sentence 's end,larger update at sentence 's end,0.5442913174629211
Blogs,5,97,ablation-analysis,ablation analysis,has,lesson learned to avoid,ablation analysis has lesson learned to avoid,0.6038413643836975
Blogs,5,101,ablation-analysis,strongly indicative words,like,  best   or   horrendous  ,strongly indicative words like   best   or   horrendous  ,0.6519423723220825
Blogs,5,101,ablation-analysis,  best   or   horrendous  ,cause,particularly big shifts,  best   or   horrendous   cause particularly big shifts,0.7312791347503662
Blogs,5,101,ablation-analysis,particularly big shifts,in,color,particularly big shifts in color,0.6180635094642639
Blogs,5,101,ablation-analysis,ablation analysis,Note,strongly indicative words,ablation analysis Note strongly indicative words,0.6009762287139893
Blogs,5,11,experimental-setup,multiplicative lstm,with,"4,096 units","multiplicative lstm with 4,096 units",0.6501482725143433
Blogs,5,11,experimental-setup,multiplicative lstm,to predict,next character,multiplicative lstm to predict next character,0.6947453022003174
Blogs,5,11,experimental-setup,"4,096 units",on,corpus,"4,096 units on corpus",0.5422266125679016
Blogs,5,11,experimental-setup,corpus,of,82 million amazon reviews,corpus of 82 million amazon reviews,0.5633799433708191
Blogs,5,11,experimental-setup,next character,in,chunk of text,next character in chunk of text,0.5330601930618286
Blogs,5,11,experimental-setup,experimental setup,trained,multiplicative lstm,experimental setup trained multiplicative lstm,0.6914010047912598
Blogs,5,12,experimental-setup,training,took,one month,training took one month,0.6576560735702515
Blogs,5,12,experimental-setup,one month,across,four nvidia pascal gpus,one month across four nvidia pascal gpus,0.7004112005233765
Blogs,5,12,experimental-setup,our model,processing,"12,500 characters per second","our model processing 12,500 characters per second",0.6850125789642334
Blogs,5,12,experimental-setup,experimental setup,has,training,experimental setup has training,0.5312813520431519
Blogs,5,24,experimental-setup,package,received,blank,package received blank,0.5948840975761414
Blogs,5,24,experimental-setup,experimental setup,has,package,experimental setup has package,0.5115850567817688
Blogs,5,55,experimental-setup,random samples,from,model,random samples from model,0.6268484592437744
Blogs,5,55,experimental-setup,random samples,after fixing,sentiment unit 's value,random samples after fixing sentiment unit 's value,0.7332911491394043
Blogs,5,55,experimental-setup,sentiment unit 's value,to determine,sentiment,sentiment unit 's value to determine sentiment,0.5912432074546814
Blogs,5,55,experimental-setup,sentiment,of,review,sentiment of review,0.6109952926635742
Blogs,5,55,experimental-setup,experimental setup,select,random samples,experimental setup select random samples,0.6809681057929993
Blogs,5,56,experimental-setup,prefix,through,model,prefix through model,0.6991509795188904
Blogs,5,56,experimental-setup,prefix,select,high - likelihood samples,prefix select high - likelihood samples,0.6949618458747864
Blogs,5,56,experimental-setup,i could n't figure out,through,model,i could n't figure out through model,0.6317203640937805
Blogs,5,56,experimental-setup,experimental setup,pass,prefix,experimental setup pass prefix,0.601568877696991
Blogs,5,74,experimental-setup,scrap off,has,everytime,scrap off has everytime,0.6015722751617432
Blogs,5,74,experimental-setup,experimental setup,has,scrap off,experimental setup has scrap off,0.5543174147605896
Blogs,5,78,experimental-setup,warning,on,box,warning on box,0.5599104762077332
Blogs,5,6,experiments,number of labeled examples,takes,two variants,number of labeled examples takes two variants,0.630702018737793
Blogs,5,6,experiments,two variants,of,our model,two variants of our model,0.6033319234848022
Blogs,5,6,experiments,fully supervised approaches,trained with,"6,920 examples","fully supervised approaches trained with 6,920 examples",0.7115092873573303
Blogs,5,39,experiments,labels,for,important problems,labels for important problems,0.6537045836448669
Blogs,5,39,experiments,important problems,where,reward,important problems where reward,0.681067943572998
Blogs,5,39,experiments,reward,is worth the effort,self-driving,reward is worth the effort self-driving,0.6917523741722107
Blogs,5,54,experiments,synthetic text,generated by,trained model,synthetic text generated by trained model,0.678035318851471
Blogs,5,57,experiments,unsupervised sentiment neuron sentiment,FIXED TO,positive sentiment,unsupervised sentiment neuron sentiment FIXED TO positive sentiment,0.6465258002281189
Blogs,5,57,experiments,positive sentiment,FIXED TO,negative,positive sentiment FIXED TO negative,0.7239201068878174
Blogs,5,4,model,distinct   sentiment neuron  ,contains,sentiment signal,distinct   sentiment neuron   contains sentiment signal,0.6207613348960876
Blogs,5,4,model,distinct   sentiment neuron  ,almost all of,sentiment signal,distinct   sentiment neuron   almost all of sentiment signal,0.6730384230613708
Blogs,5,13,model,"4,096 units",regarded as,feature vector,"4,096 units regarded as feature vector",0.5843252539634705
Blogs,5,13,model,feature vector,string read by,model,feature vector string read by model,0.7659980654716492
Blogs,5,13,model,model,has,"4,096 units","model has 4,096 units",0.5666909217834473
Blogs,5,14,model,mlstm,turned,model,mlstm turned model,0.6254481077194214
Blogs,5,14,model,model,into,sentiment classifier,model into sentiment classifier,0.6245507597923279
Blogs,5,14,model,sentiment classifier,by taking,linear combination,sentiment classifier by taking linear combination,0.5966110229492188
Blogs,5,14,model,linear combination,learning,weights,linear combination learning weights,0.7413663864135742
Blogs,5,14,model,weights,of,combination,weights of combination,0.5860763192176819
Blogs,5,14,model,combination,via,available supervised data,combination via available supervised data,0.6896476149559021
Blogs,5,14,model,linear combination,has,of these units,linear combination has of these units,0.6065922379493713
Blogs,5,14,model,model,training,mlstm,model training mlstm,0.6944535374641418
Blogs,5,20,model,direct dial,to control,sentiment,direct dial to control sentiment,0.7528048753738403
Blogs,5,20,model,direct dial,overwrite,value,direct dial overwrite value,0.7841836810112
Blogs,5,20,model,sentiment,of,resulting text,sentiment of resulting text,0.5785771012306213
Blogs,5,20,model,value,of,sentiment neuron,value of sentiment neuron,0.5572876334190369
Blogs,5,32,model,stays,in,place,stays in place,0.6247197985649109
Blogs,5,32,model,stays,holds,shape,stays holds shape,0.7240151762962341
Blogs,5,32,model,model,has,stays,model has stays,0.6316837072372437
Blogs,5,34,model,sentiment neuron,adjusting,value,sentiment neuron adjusting value,0.6842554211616516
Blogs,5,34,model,value,on,character - by- character basis,value on character - by- character basis,0.5725470781326294
Blogs,5,34,model,model,has,sentiment neuron,model has sentiment neuron,0.5646370053291321
Blogs,5,48,model,hierarchical models,adapt,timescales,hierarchical models adapt timescales,0.7198137640953064
Blogs,5,84,model,model,through away,junk,model through away junk,0.8261321187019348
Blogs,5,95,model,sticks,at,end,sticks at end,0.5589165091514587
Blogs,5,95,model,straight high,has,sticks,straight high has sticks,0.6339887976646423
Blogs,5,95,model,model,has,straight high,model has straight high,0.6472050547599792
Blogs,5,100,model,character - by- character value,of,sentiment neuron,character - by- character value of sentiment neuron,0.5774595141410828
Blogs,5,100,model,character - by- character value,displaying,negative values,character - by- character value displaying negative values,0.7721012830734253
Blogs,5,100,model,character - by- character value,displaying,positive values,character - by- character value displaying positive values,0.7646069526672363
Blogs,5,100,model,negative values,as,red,negative values as red,0.6146325469017029
Blogs,5,100,model,positive values,as,green,positive values as green,0.608695924282074
Blogs,5,3,results,linear model,achieves,state - of - the - art sentiment analysis accuracy,linear model achieves state - of - the - art sentiment analysis accuracy,0.6492198705673218
Blogs,5,3,results,state - of - the - art sentiment analysis accuracy,on,small but extensively - studied dataset,state - of - the - art sentiment analysis accuracy on small but extensively - studied dataset,0.4857673943042755
Blogs,5,3,results,performance,of,previous supervised systems,performance of previous supervised systems,0.5742805004119873
Blogs,5,3,results,previous supervised systems,using,30 - 100x fewer labeled examples,previous supervised systems using 30 - 100x fewer labeled examples,0.6010754704475403
Blogs,5,3,results,results,has,linear model,results has linear model,0.531402587890625
Blogs,5,5,results,our system,beats,other approaches,our system beats other approaches,0.7162697911262512
Blogs,5,5,results,other approaches,on,stanford sentiment treebank,other approaches on stanford sentiment treebank,0.47967594861984253
Blogs,5,5,results,results,has,our system,results has our system,0.5954442024230957
Blogs,5,8,results,our model,learned,interpretable feature,our model learned interpretable feature,0.7149804830551147
Blogs,5,8,results,our model,predicting,next character,our model predicting next character,0.734512209892273
Blogs,5,8,results,next character,in,amazon reviews,next character in amazon reviews,0.555408239364624
Blogs,5,8,results,next character,resulted in,discovering,next character resulted in discovering,0.6812043190002441
Blogs,5,8,results,discovering,concept of,sentiment,discovering concept of sentiment,0.7018619179725647
Blogs,5,9,results,general property,of,certain large neural networks,general property of certain large neural networks,0.5693206787109375
Blogs,5,9,results,certain large neural networks,trained to predict,next step or dimension,certain large neural networks trained to predict next step or dimension,0.7475992441177368
Blogs,5,9,results,next step or dimension,in,inputs,next step or dimension in inputs,0.5144926905632019
Blogs,5,9,results,results,believe,phenomenon,results believe phenomenon,0.46493226289749146
Blogs,5,18,results,sentiment neuron,within,our model,sentiment neuron within our model,0.6837192177772522
Blogs,5,18,results,sentiment neuron,classify,reviews,sentiment neuron classify reviews,0.7238481640815735
Blogs,5,18,results,our model,classify,reviews,our model classify reviews,0.6520535349845886
Blogs,5,18,results,reviews,as,negative or positive,reviews as negative or positive,0.5510774254798889
Blogs,5,18,results,results,has,sentiment neuron,results has sentiment neuron,0.5737000703811646
Blogs,5,21,results,sentiment,FIXED TO,positive sentiment,sentiment FIXED TO positive sentiment,0.6460177898406982
Blogs,5,21,results,sentiment,FIXED TO,negative,sentiment FIXED TO negative,0.7164113521575928
Blogs,5,21,results,positive sentiment,FIXED TO,negative,positive sentiment FIXED TO negative,0.7239201068878174
Blogs,5,21,results,results,has,sentiment,results has sentiment,0.5444703698158264
Blogs,5,22,results,exactly matched seam,to,color contrast,exactly matched seam to color contrast,0.6040425300598145
Blogs,5,22,results,color contrast,with,other pants,color contrast with other pants,0.6452634334564209
Blogs,5,22,results,nice fitted pants,has,exactly matched seam,nice fitted pants has exactly matched seam,0.609233558177948
Blogs,5,22,results,results,has,nice fitted pants,results has nice fitted pants,0.5885676145553589
Blogs,5,23,results,results,has,highly recommended,results has highly recommended,0.5718291997909546
Blogs,5,25,results,results,has,waste of time and money,results has waste of time and money,0.5660944581031799
Blogs,5,29,results,crib,without,some kind of embellishment,crib without some kind of embellishment,0.7835775017738342
Blogs,5,29,results,results,Hard to put on,crib,results Hard to put on crib,0.6049160361289978
Blogs,5,30,results,results,has,guess,results has guess,0.46770673990249634
Blogs,5,33,results,comfy,has,looks so cute,comfy has looks so cute,0.6774199604988098
Blogs,5,33,results,results,has,comfy,results has comfy,0.5776211619377136
Blogs,5,35,results,system,makes,large updates,system makes large updates,0.7180008888244629
Blogs,5,35,results,large updates,after,completion,large updates after completion,0.682542085647583
Blogs,5,35,results,completion,of,sentences and phrases,completion of sentences and phrases,0.5767639875411987
Blogs,5,35,results,results,interesting to note,system,results interesting to note system,0.6217502355575562
Blogs,5,38,results,collecting data,is,easy,collecting data is easy,0.507688581943512
Blogs,5,38,results,results,has,collecting data,results has collecting data,0.47237733006477356
Blogs,5,41,results,large unsupervised next-step-prediction models,on,large amounts of data,large unsupervised next-step-prediction models on large amounts of data,0.5358451008796692
Blogs,5,41,results,large unsupervised next-step-prediction models,may,good approach,large unsupervised next-step-prediction models may good approach,0.6352728009223938
Blogs,5,41,results,results,training,large unsupervised next-step-prediction models,results training large unsupervised next-step-prediction models,0.7062587141990662
Blogs,5,43,results,promising step,towards,general unsupervised representation learning,promising step towards general unsupervised representation learning,0.6976048350334167
Blogs,5,43,results,results,has,our results,results has our results,0.5639954209327698
Blogs,5,44,results,good quality representations,scaled up,existing model,good quality representations scaled up existing model,0.7599956393241882
Blogs,5,44,results,existing model,on,carefullychosen dataset,existing model on carefullychosen dataset,0.5360912084579468
Blogs,5,44,results,results,learn,good quality representations,results learn good quality representations,0.6271591782569885
Blogs,5,44,results,results,scaled up,existing model,results scaled up existing model,0.72645503282547
Blogs,5,46,results,not as strong,for,datasets,not as strong for datasets,0.6678902506828308
Blogs,5,46,results,datasets,of,long documents,datasets of long documents,0.5009869933128357
Blogs,5,46,results,results,has,results,results has results,0.48582205176353455
Blogs,5,47,results,struggles,to remember,information,struggles to remember information,0.7626438140869141
Blogs,5,47,results,information,over,hundreds to thousands of timesteps,information over hundreds to thousands of timesteps,0.7389100790023804
Blogs,5,47,results,our character - level model,has,struggles,our character - level model has struggles,0.6004130840301514
Blogs,5,47,results,results,suspect,our character - level model,results suspect our character - level model,0.639049768447876
Blogs,5,49,results,representation fidelity and performance,on,sentiment analysis and similar tasks,representation fidelity and performance on sentiment analysis and similar tasks,0.555317759513855
Blogs,5,50,results,diverges,from,review data,diverges from review data,0.5987643003463745
Blogs,5,50,results,input text,has,diverges,input text has diverges,0.6087771058082581
Blogs,5,50,results,results,has,model,results has model,0.5339115858078003
Blogs,5,51,results,broadening,results in,equally informative representation,broadening results in equally informative representation,0.6251543164253235
Blogs,5,51,results,corpus,of,text samples,corpus of text samples,0.5851014852523804
Blogs,5,51,results,equally informative representation,applies to,broader domains,equally informative representation applies to broader domains,0.6752411127090454
Blogs,5,51,results,broadening,has,corpus,broadening has corpus,0.6037963032722473
Blogs,5,51,results,results,worth verifying,broadening,results worth verifying broadening,0.5976311564445496
Blogs,5,52,results,very large next-step-prediction models,learn,excellent unsupervised representations,very large next-step-prediction models learn excellent unsupervised representations,0.6498114466667175
Blogs,5,52,results,results,has,our results,results has our results,0.5639954209327698
Blogs,5,53,results,neural network,to predict,next frame,neural network to predict next frame,0.721210241317749
Blogs,5,53,results,neural network,result in,unsupervised representations,neural network result in unsupervised representations,0.6361704468727112
Blogs,5,53,results,results,Training,neural network,results Training neural network,0.7458211183547974
Blogs,5,58,results,her doolittle newsletter,see,great product,her doolittle newsletter see great product,0.6454198956489563
Blogs,5,59,results,results,could n't ascertain,another new one coming out next year,results could n't ascertain another new one coming out next year,0.702850341796875
Blogs,5,62,results,results,am,prolific stuff,results am prolific stuff,0.6801079511642456
Blogs,5,63,results,contents - information consumer,of,company,contents - information consumer of company,0.579600989818573
Blogs,5,63,results,company,has,all the time,company has all the time,0.6195582747459412
Blogs,5,65,results,weapons,has,look,weapons has look,0.6318812966346741
Blogs,5,66,results,beautiful,Fits,good,beautiful Fits good,0.6285585165023804
Blogs,5,70,results,results,suggest,annoying rear piece,results suggest annoying rear piece,0.5775936245918274
Blogs,5,72,results,any man,with,huge pull,any man with huge pull,0.6502872109413147
Blogs,5,72,results,huge pull,down,my back,huge pull down my back,0.7662245035171509
Blogs,5,72,results,huge pull,down,black,huge pull down black,0.8044441342353821
Blogs,5,72,results,results,must watch for,any man,results must watch for any man,0.6866745948791504
Blogs,5,76,results,sentiment,FIXED TO,positive sentiment,sentiment FIXED TO positive sentiment,0.6460177898406982
Blogs,5,76,results,sentiment,FIXED TO,negative,sentiment FIXED TO negative,0.7164113521575928
Blogs,5,76,results,positive sentiment,FIXED TO,negative,positive sentiment FIXED TO negative,0.7239201068878174
Blogs,5,76,results,results,has,sentiment,results has sentiment,0.5444703698158264
Blogs,5,79,results,so glad,to have,found it again,so glad to have found it again,0.7016350626945496
Blogs,5,79,results,results,n't,so glad,results n't so glad,0.7728369832038879
Blogs,5,82,results,results,has,book,results has book,0.5504816770553589
Blogs,5,83,results,results,Might,fantastic book,results Might fantastic book,0.6335116028785706
Blogs,5,85,results,stop,has,drivel,stop has drivel,0.6337360739707947
Blogs,5,87,results,results,use it,all the time,results use it all the time,0.6418465375900269
Blogs,5,88,results,results,has,good worst,results has good worst,0.601102352142334
Blogs,5,90,results,results,skim-read,entire book,results skim-read entire book,0.7921480536460876
Blogs,5,91,results,results,Do n't waste,your time,results Do n't waste your time,0.7510935664176941
Blogs,5,96,results,results,On par with,other buds,results On par with other buds,0.6695570349693298
Blogs,5,103,results,shape,at,first,shape at first,0.5861479640007019
Blogs,5,103,results,results,could n't figure out,shape,results could n't figure out shape,0.5779808163642883
Blogs,5,107,results,results,given it,zero stars,results given it zero stars,0.696082592010498
Blogs,6,17,ablation-analysis,nearby utterances,engages,audience,nearby utterances engages audience,0.743699312210083
Blogs,6,17,ablation-analysis,ablation analysis,included,nearby utterances,ablation analysis included nearby utterances,0.6048658490180969
Blogs,6,22,baselines,two frameworks,for,fusing modalities,two frameworks for fusing modalities,0.5871395468711853
Blogs,6,22,baselines,unimodal features,concatenated and fed into,various contextual lstm networks,unimodal features concatenated and fed into various contextual lstm networks,0.6670312881469727
Blogs,6,22,baselines,non-hierarchical framework,has,unimodal features,non-hierarchical framework has unimodal features,0.5740715265274048
Blogs,6,39,baselines,f1,has,context-independent features,f1 has context-independent features,0.5587360262870789
Blogs,6,50,baselines,different variants,of,lstm model,different variants of lstm model,0.5622962117195129
Blogs,6,50,baselines,unimodal features,used directly with,svm,unimodal features used directly with svm,0.6457194089889526
Blogs,6,50,baselines,svm,for,classification,svm for classification,0.6283344626426697
Blogs,6,50,baselines,sc-lstm,has,unidirectional lstm cells,sc-lstm has unidirectional lstm cells,0.6295854449272156
Blogs,6,50,baselines,uni-svm,has,unimodal features,uni-svm has unimodal features,0.5714178085327148
Blogs,6,50,baselines,baselines,has,different variants,baselines has different variants,0.585557758808136
Blogs,6,41,experimental-setup,audio feature extraction,performed using,opensmile open-source software,audio feature extraction performed using opensmile open-source software,0.58954918384552
Blogs,6,41,experimental-setup,opensmile open-source software,where,low-level features,opensmile open-source software where low-level features,0.6093202829360962
Blogs,6,41,experimental-setup,low-level features,such as,voice intensity and pitch,low-level features such as voice intensity and pitch,0.6327085494995117
Blogs,6,57,experimental-setup,train / test splits,are,disjoint,train / test splits are disjoint,0.6180078983306885
Blogs,6,57,experimental-setup,disjoint,with respect to,speakers,disjoint with respect to speakers,0.7247459292411804
Blogs,6,57,experimental-setup,experimental setup,has,train / test splits,experimental setup has train / test splits,0.5476328134536743
Blogs,6,30,experiments,moud dataset,involved,some translation,moud dataset involved some translation,0.586039125919342
Blogs,6,6,model,long short - term memory ( lstm ) model,enables,utterances ( units of speech bound by breathes or pauses ),long short - term memory ( lstm ) model enables utterances ( units of speech bound by breathes or pauses ),0.651729941368103
Blogs,6,6,model,utterances ( units of speech bound by breathes or pauses ),to capture,contextual information,utterances ( units of speech bound by breathes or pauses ) to capture contextual information,0.7017354965209961
Blogs,6,6,model,model,based on,long short - term memory ( lstm ) model,model based on long short - term memory ( lstm ) model,0.6530764698982239
Blogs,6,9,model,multimodal information,By combining,vocal modulations and facial expressions,multimodal information By combining vocal modulations and facial expressions,0.6794110536575317
Blogs,6,9,model,vocal modulations and facial expressions,with,textual information,vocal modulations and facial expressions with textual information,0.6363006830215454
Blogs,6,9,model,vocal modulations and facial expressions,enrich,feature learning process,vocal modulations and facial expressions enrich feature learning process,0.6199918389320374
Blogs,6,9,model,feature learning process,to better understand,affective states,feature learning process to better understand affective states,0.6055029034614563
Blogs,6,9,model,affective states,of,opinion holders,affective states of opinion holders,0.5509820580482483
Blogs,6,9,model,model,Why,multimodal information,model Why multimodal information,0.723288357257843
Blogs,6,10,model,other behavioral cues,in,vocal and visual modalities,other behavioral cues in vocal and visual modalities,0.44505536556243896
Blogs,6,10,model,model,could be,other behavioral cues,model could be other behavioral cues,0.6378910541534424
Blogs,6,12,model,"order , inter-dependencies , and relations",among,utterances,"order , inter-dependencies , and relations among utterances",0.5535863637924194
Blogs,6,12,model,utterances,in,video,utterances in video,0.5713777542114258
Blogs,6,13,model,surrounding context,help to,better classify,surrounding context help to better classify,0.7273076176643372
Blogs,6,13,model,better classify,sentiment conveyed by,utterances,better classify sentiment conveyed by utterances,0.722825825214386
Blogs,6,13,model,model,has,surrounding context,model has surrounding context,0.5735236406326294
Blogs,6,14,model,"audio , visual , and textual information",to tackle,sentiment and emotion recognition tasks,"audio , visual , and textual information to tackle sentiment and emotion recognition tasks",0.6268095374107361
Blogs,6,14,model,combined,to tackle,sentiment and emotion recognition tasks,combined to tackle sentiment and emotion recognition tasks,0.641200065612793
Blogs,6,14,model,model,has,"audio , visual , and textual information","model has audio , visual , and textual information",0.5435065031051636
Blogs,6,24,model,unimodal features,feed,each unimodal feature,unimodal features feed each unimodal feature,0.7168528437614441
Blogs,6,24,model,each unimodal feature,has,lstm network,each unimodal feature has lstm network,0.5718418955802917
Blogs,6,25,model,framework,as having,some hierarchy,framework as having some hierarchy,0.7049062848091125
Blogs,6,25,model,model,Think of,framework,model Think of framework,0.6810107827186584
Blogs,6,34,model,visual modality,caries,more generalized information,visual modality caries more generalized information,0.7294608950614929
Blogs,6,34,model,model,has,visual modality,model has visual modality,0.5520022511482239
Blogs,6,38,model,few ideas,try to improve,current work,few ideas try to improve current work,0.6804637908935547
Blogs,6,40,model,textual feature extraction,performed using,convolutional neural network ( cnn ),textual feature extraction performed using convolutional neural network ( cnn ),0.5934785008430481
Blogs,6,40,model,convolutional neural network ( cnn ),where,input,convolutional neural network ( cnn ) where input,0.6087926030158997
Blogs,6,40,model,transcription of each utterance,represented by,concatenation of corresponding word2vec word vectors,transcription of each utterance represented by concatenation of corresponding word2vec word vectors,0.7188263535499573
Blogs,6,40,model,model,has,textual feature extraction,model has textual feature extraction,0.5158840417861938
Blogs,6,43,model,visual feature extraction,performed using,3d - cnn,visual feature extraction performed using 3d - cnn,0.5214743614196777
Blogs,6,43,model,3d - cnn,where,frame- level features,3d - cnn where frame- level features,0.5574270486831665
Blogs,6,43,model,model,has,visual feature extraction,model has visual feature extraction,0.5014092326164246
Blogs,6,45,model,lstm - based network,to perform,context-dependent feature extraction,lstm - based network to perform context-dependent feature extraction,0.6300213932991028
Blogs,6,45,model,context-dependent feature extraction,by modeling,relations,context-dependent feature extraction by modeling relations,0.7648298740386963
Blogs,6,45,model,relations,among,utterances,relations among utterances,0.6421348452568054
Blogs,6,45,model,model,has,lstm - based network,model has lstm - based network,0.523078441619873
Blogs,6,46,model,unimodal features,fed as,input,unimodal features fed as input,0.6626485586166382
Blogs,6,46,model,input,to,lstm layer,input to lstm layer,0.4960273206233978
Blogs,6,46,model,lstm layer,produces,contextualized features,lstm layer produces contextualized features,0.5890698432922363
Blogs,6,46,model,model,has,unimodal features,model has unimodal features,0.5587647557258606
Blogs,6,52,model,output,of,first level,output of first level,0.6430091857910156
Blogs,6,52,model,first level,concatenated and fed into,"another lstm network ( i.e. , second level )","first level concatenated and fed into another lstm network ( i.e. , second level )",0.6955243945121765
Blogs,6,52,model,model,has,output,model has output,0.5534584522247314
Blogs,6,66,model,more advanced idea,fusion part of,framework,more advanced idea fusion part of framework,0.7841265201568604
Blogs,6,16,results,results,Without,any context,results Without any context,0.8083945512771606
Blogs,6,19,results,highly subjective,train,machine,highly subjective train machine,0.7294573783874512
Blogs,6,19,results,machine,to detect,correlations,machine to detect correlations,0.7024586200714111
Blogs,6,19,results,correlations,has,automatically,correlations has automatically,0.6107956767082214
Blogs,6,26,results,sc - lstm and bc - lstm models,perform,best,sc - lstm and bc - lstm models perform best,0.581164538860321
Blogs,6,26,results,best,out of,lstm variants,best out of lstm variants,0.5940607190132141
Blogs,6,26,results,best,including,uni-svm model,best including uni-svm model,0.6471990942955017
Blogs,6,26,results,first level,has,unimodal features lstm variants,first level has unimodal features lstm variants,0.5732107162475586
Blogs,6,26,results,results,In,first level,results In first level,0.485065221786499
Blogs,6,27,results,contextual information,when classifying,utterances,contextual information when classifying utterances,0.7289448976516724
Blogs,6,27,results,results,importance of considering,contextual information,results importance of considering contextual information,0.6355658769607544
Blogs,6,29,results,unimodal classifiers,trained on,textual information,unimodal classifiers trained on textual information,0.7220432758331299
Blogs,6,29,results,unimodal classifiers,perform,best,unimodal classifiers perform best,0.6023308038711548
Blogs,6,29,results,best,compared to,other individual modalities,best compared to other individual modalities,0.6408201456069946
Blogs,6,29,results,results,has,unimodal classifiers,results has unimodal classifiers,0.5697553157806396
Blogs,6,31,results,modalities,tend to,boost,modalities tend to boost,0.6728438138961792
Blogs,6,31,results,boost,has,performance,boost has performance,0.5791411995887756
Blogs,6,31,results,results,combining,modalities,results combining modalities,0.5832480192184448
Blogs,6,35,results,fusing,improved,model,fusing improved model,0.7080711722373962
Blogs,6,35,results,modalities,improved,model,modalities improved model,0.7349076271057129
Blogs,6,35,results,fusing,has,modalities,fusing has modalities,0.6067283749580383
Blogs,6,35,results,results,has,fusing,results has fusing,0.5768380761146545
Blogs,6,58,results,mosi,contains,video- based topic reviews,mosi contains video- based topic reviews,0.5490196347236633
Blogs,6,58,results,video- based topic reviews,annotated by,sentiment polarity,video- based topic reviews annotated by sentiment polarity,0.7092923521995544
Blogs,6,58,results,video- based topic reviews,annotated by,sentiment polarity,video- based topic reviews annotated by sentiment polarity,0.7092923521995544
Blogs,6,58,results,product review videos,annotated by,sentiment polarity,product review videos annotated by sentiment polarity,0.7316960096359253
Blogs,6,58,results,scripted affect-related utterances,annotated by,emotion categories,scripted affect-related utterances annotated by emotion categories,0.6893991827964783
Blogs,6,59,results,hierarchical model,has,significantly outperform,hierarchical model has significantly outperform,0.5961243510246277
Blogs,6,59,results,significantly outperform,has,non-hierarchical frameworks,significantly outperform has non-hierarchical frameworks,0.5966604351997375
Blogs,6,59,results,results,observe,hierarchical model,results observe hierarchical model,0.596697986125946
Blogs,6,63,results,own datasets,label them,automatically,own datasets label them automatically,0.7292416095733643
Blogs,6,63,results,own datasets,rendering,large-scale datasets,own datasets rendering large-scale datasets,0.7572951316833496
Blogs,6,64,results,results,keep in mind,domain,results keep in mind domain,0.48322680592536926
Blogs,6,65,results,more cases,where,contextualized information,more cases where contextualized information,0.5906618237495422
Blogs,6,65,results,contextualized information,helps with,sentiment classification,contextualized information helps with sentiment classification,0.6568537950515747
Blogs,6,65,results,results,interesting to see,more cases,results interesting to see more cases,0.7216047048568726
Blogs,7,36,ablation-analysis,rntn,could capture,effect,rntn could capture effect,0.753697395324707
Blogs,7,36,ablation-analysis,effect,of,negative words,effect of negative words,0.5844364762306213
Blogs,7,36,ablation-analysis,negative words,in,positive and negative sentiment sentences,negative words in positive and negative sentiment sentences,0.5132531523704529
Blogs,7,36,ablation-analysis,ablation analysis,suggests,rntn,ablation analysis suggests rntn,0.618495762348175
Blogs,7,6,baselines,"215,154 phrases",with,fine- grained sentiment labels,"215,154 phrases with fine- grained sentiment labels",0.6190627217292786
Blogs,7,6,baselines,fine- grained sentiment labels,has,5 classes ),fine- grained sentiment labels has 5 classes ),0.566866397857666
Blogs,7,20,baselines,baselines,has,rnn : recursive neural network,baselines has rnn : recursive neural network,0.5673654079437256
Blogs,7,23,baselines,mv - rnn,has,matrix-vector rnn,mv - rnn has matrix-vector rnn,0.593315839767456
Blogs,7,23,baselines,baselines,has,mv - rnn,baselines has mv - rnn,0.5757520794868469
Blogs,7,28,baselines,baselines,has,rntn,baselines has rntn,0.5927833914756775
Blogs,7,9,experiments,sentiment sentiment treebank corpus,of,"11,855 sentences","sentiment sentiment treebank corpus of 11,855 sentences",0.5262057185173035
Blogs,7,9,experiments,"11,855 sentences",with,fully labelled parse trees,"11,855 sentences with fully labelled parse trees",0.5989623665809631
Blogs,7,11,experiments,label,using,crowdsourcing,label using crowdsourcing,0.6391184329986572
Blogs,7,11,experiments,crowdsourcing,on,amazon mechanical turk,crowdsourcing on amazon mechanical turk,0.4861743748188019
Blogs,7,11,experiments,movie reviews dataset,has,normalise,movie reviews dataset has normalise,0.5662131309509277
Blogs,7,17,hyperparameters,initialized randomly,from,uniform distribution,initialized randomly from uniform distribution,0.5675132870674133
Blogs,7,17,hyperparameters,hyperparameters,has,word vectors,hyperparameters has word vectors,0.5067952871322632
Blogs,7,18,hyperparameters,classification task,use,compositions word vectors,classification task use compositions word vectors,0.6299174427986145
Blogs,7,18,hyperparameters,compositions word vectors,as input for,softmax,compositions word vectors as input for softmax,0.7012904286384583
Blogs,7,18,hyperparameters,hyperparameters,For,classification task,hyperparameters For classification task,0.5585641860961914
Blogs,7,21,hyperparameters,weight matrix,to be,learnt,weight matrix to be learnt,0.5339279770851135
Blogs,7,25,hyperparameters,matrix,for,each word,matrix for each word,0.6495909690856934
Blogs,7,25,hyperparameters,each word,initialized as,identity matrix,each word initialized as identity matrix,0.6654144525527954
Blogs,7,25,hyperparameters,identity matrix,plus,small gaussian noise,identity matrix plus small gaussian noise,0.6405547857284546
Blogs,7,25,hyperparameters,hyperparameters,has,matrix,hyperparameters has matrix,0.5305720567703247
Blogs,7,26,hyperparameters,hyperparameters,For,parse tree,hyperparameters For parse tree,0.5688552856445312
Blogs,7,27,hyperparameters,number of parameters,depend on,size of vocabulary,number of parameters depend on size of vocabulary,0.7121474146842957
Blogs,7,27,hyperparameters,number of parameters,could be,very large,number of parameters could be very large,0.6483373641967773
Blogs,7,27,hyperparameters,hyperparameters,Con,number of parameters,hyperparameters Con number of parameters,0.5218337178230286
Blogs,7,27,hyperparameters,hyperparameters,has,number of parameters,hyperparameters has number of parameters,0.5162031054496765
Blogs,7,31,hyperparameters,optimal word vector size,between,25 and 35,optimal word vector size between 25 and 35,0.667881965637207
Blogs,7,31,hyperparameters,hyperparameters,has,optimal word vector size,hyperparameters has optimal word vector size,0.49584057927131653
Blogs,7,7,model,recursive neural tensor network - model,to learn,fine- grained sentiment labels,recursive neural tensor network - model to learn fine- grained sentiment labels,0.5945110321044922
Blogs,7,7,model,model,has,recursive neural tensor network - model,model has recursive neural tensor network - model,0.5861279368400574
Blogs,7,15,model,given n-gram,into,binary tree,given n-gram into binary tree,0.5984614491462708
Blogs,7,15,model,each word,using,d-dimensional vector,each word using d-dimensional vector,0.6646323800086975
Blogs,7,15,model,model,Parse,given n-gram,model Parse given n-gram,0.794872522354126
Blogs,7,16,model,recursive neural models,Compute,parent vectors,recursive neural models Compute parent vectors,0.6978943347930908
Blogs,7,16,model,parent vectors,using,bottom - up approach,parent vectors using bottom - up approach,0.7227306962013245
Blogs,7,16,model,parent vectors,using,different composition functions,parent vectors using different composition functions,0.6771174073219299
Blogs,7,16,model,model,has,recursive neural models,model has recursive neural models,0.5771417617797852
Blogs,7,22,model,model,has,con input vectors,model has con input vectors,0.5700828433036804
Blogs,7,24,model,every word and phrase,as,vector and a matrix,every word and phrase as vector and a matrix,0.579060971736908
Blogs,7,24,model,model,Represent,every word and phrase,model Represent every word and phrase,0.5932510495185852
Blogs,7,29,model,v,is,tensor,v is tensor,0.646941065788269
Blogs,7,29,model,tensor,defines,multiple bilinear forms,tensor defines multiple bilinear forms,0.5851344466209412
Blogs,7,29,model,model,has,v,model has v,0.6126318573951721
Blogs,7,33,model,each slice,of,tensor v,each slice of tensor v,0.6024708151817322
Blogs,7,33,model,model,has,each slice,model has each slice,0.5733957290649414
Blogs,7,13,results,shorter phrases,are,neutral,shorter phrases are neutral,0.6045600771903992
Blogs,7,13,results,longer phrases,have,stronger sentiments,longer phrases have stronger sentiments,0.5476723313331604
Blogs,7,14,results,5 - class classification,to capture,variability,5 - class classification to capture variability,0.6402875185012817
Blogs,7,14,results,variability,has,of sentiments,variability has of sentiments,0.5829086303710938
Blogs,7,14,results,results,has,5 - class classification,results has 5 - class classification,0.5746333599090576
Blogs,7,32,results,affected,by,word vectors,affected by word vectors,0.5739791393280029
Blogs,7,32,results,affected,using,word vectors,affected using word vectors,0.7034370303153992
Blogs,7,32,results,word vectors,from,say glove,word vectors from say glove,0.5919163227081299
Blogs,7,32,results,results,has,affected,results has affected,0.47540417313575745
Blogs,7,32,results,results,interesting to see how are,results,results interesting to see how are results,0.5903248190879822
Blogs,7,32,results,results,interesting to see how are,affected,results interesting to see how are affected,0.6119382381439209
Blogs,7,35,results,full sentence binary sentiment rntn,pushes,state of the art,full sentence binary sentiment rntn pushes state of the art,0.6395744681358337
Blogs,7,35,results,state of the art,on,short phrases,state of the art on short phrases,0.5150539875030518
Blogs,7,35,results,short phrases,to,85.4 %,short phrases to 85.4 %,0.519710123538971
Blogs,7,35,results,outperforms,has,other models,outperforms has other models,0.5875559449195862
Blogs,7,35,results,results,has,full sentence binary sentiment rntn,results has full sentence binary sentiment rntn,0.5942448377609253
Blogs,8,16,ablation-analysis,table,showcase,which word,table showcase which word,0.7391948103904724
Blogs,8,16,ablation-analysis,which word,contributes,most,which word contributes most,0.7067161202430725
Blogs,8,16,ablation-analysis,most,to,aspect sentiment polarity,most to aspect sentiment polarity,0.4807238280773163
Blogs,8,16,ablation-analysis,aspect sentiment polarity,by visualising,sentence attention vectors,aspect sentiment polarity by visualising sentence attention vectors,0.7109276652336121
Blogs,8,18,ablation-analysis,model,n't handle,ef ciently,model n't handle ef ciently,0.6826520562171936
Blogs,8,18,ablation-analysis,ablation analysis,In,error analysis,ablation analysis In error analysis,0.520783007144928
Blogs,8,36,baselines,column - wise softmax,to get,target- to-sentence attention,column - wise softmax to get target- to-sentence attention,0.6208257079124451
Blogs,8,37,baselines,row-wise softmax,to get,sentence - to- target attention,row-wise softmax to get sentence - to- target attention,0.6190502643585205
Blogs,8,10,experiments,sentiment class,with,highest probability,sentiment class with highest probability,0.6683533191680908
Blogs,8,10,experiments,highest probability,is,predicted label,highest probability is predicted label,0.5911356210708618
Blogs,8,10,experiments,predicted label,for,sentence,predicted label for sentence,0.6146275997161865
Blogs,8,10,experiments,sentence,given,aspect target,sentence given aspect target,0.6773638725280762
Blogs,8,23,experiments,two domain-speci c datasets,from,semeval 2014 task 4,two domain-speci c datasets from semeval 2014 task 4,0.4866310656070709
Blogs,8,5,model,aoa module,jointly learns,representations,aoa module jointly learns representations,0.7117024064064026
Blogs,8,5,model,aoa module,explicitly captures,interaction,aoa module explicitly captures interaction,0.7821662425994873
Blogs,8,5,model,representations,for,aspects and sentences,representations for aspects and sentences,0.659275472164154
Blogs,8,5,model,interaction,between,aspects and context sentences,interaction between aspects and context sentences,0.635385274887085
Blogs,8,5,model,model,has,aoa module,model has aoa module,0.5723644495010376
Blogs,8,8,model,nal sentence representation,weighted sum of,sentence hidden states,nal sentence representation weighted sum of sentence hidden states,0.6078226566314697
Blogs,8,8,model,sentence hidden states,using,sentence attention,sentence hidden states using sentence attention,0.6539453268051147
Blogs,8,8,model,sentence attention,from,aoa module,sentence attention from aoa module,0.537927508354187
Blogs,8,8,model,model,has,nal sentence representation,model has nal sentence representation,0.5597578287124634
Blogs,8,9,model,nal sentence representation,feed into,linear layer,nal sentence representation feed into linear layer,0.6442766189575195
Blogs,8,9,model,linear layer,with,softmax function,linear layer with softmax function,0.6213467121124268
Blogs,8,9,model,softmax function,to output,probabilities,softmax function to output probabilities,0.7522629499435425
Blogs,8,9,model,probabilities,of,sentiment classes,probabilities of sentiment classes,0.6093798279762268
Blogs,8,9,model,model,has,nal sentence representation,model has nal sentence representation,0.5597578287124634
Blogs,8,21,model,prior language knowledge,to,aoa neural network,prior language knowledge to aoa neural network,0.535131573677063
Blogs,8,21,model,model,incorporate,sentences ' grammar structures,model incorporate sentences ' grammar structures,0.6302587389945984
Blogs,8,27,model,4 main components,in,architecture,4 main components in architecture,0.5297061204910278
Blogs,8,29,model,word embedding,is,standardised step,word embedding is standardised step,0.557836651802063
Blogs,8,29,model,standardised step,convert,text sentence and aspect target,standardised step convert text sentence and aspect target,0.7034043669700623
Blogs,8,29,model,text sentence and aspect target,into,numerical representations,text sentence and aspect target into numerical representations,0.5783267617225647
Blogs,8,29,model,model,has,word embedding,model has word embedding,0.523033618927002
Blogs,8,31,model,word vectors,feed them into,two bi-lstm,word vectors feed them into two bi-lstm,0.6097143292427063
Blogs,8,31,model,two bi-lstm,to learn,hidden semantics,two bi-lstm to learn hidden semantics,0.633418619632721
Blogs,8,31,model,hidden semantics,of,words,hidden semantics of words,0.5765185356140137
Blogs,8,31,model,words,in,sentence and aspect target,words in sentence and aspect target,0.5470983386039734
Blogs,8,31,model,model,get,word vectors,model get word vectors,0.5891270637512207
Blogs,8,33,model,attention weights,for,text,attention weights for text,0.6150904297828674
Blogs,8,33,model,text,using,aoa module,text using aoa module,0.7341644167900085
Blogs,8,33,model,model,calculate,attention weights,model calculate attention weights,0.6672285199165344
Blogs,8,35,model,pair-wise interaction matrix,between,two hidden states,pair-wise interaction matrix between two hidden states,0.6372018456459045
Blogs,8,35,model,correlation,of,word pair,correlation of word pair,0.5986806750297546
Blogs,8,35,model,model,Calculate,pair-wise interaction matrix,model Calculate pair-wise interaction matrix,0.6689798831939697
Blogs,8,38,model,column- wise average,to get,target - level attention,column- wise average to get target - level attention,0.612627387046814
Blogs,8,38,model,target - level attention,tells us,important parts,target - level attention tells us important parts,0.6162458062171936
Blogs,8,38,model,important parts,in,aspect target,important parts in aspect target,0.5228862166404724
Blogs,8,38,model,model,Calculate,column- wise average,model Calculate column- wise average,0.6456193923950195
Blogs,8,39,model,nal sentence - level attention,weighted sum of,each individual target - tosentence attention,nal sentence - level attention weighted sum of each individual target - tosentence attention,0.6727228760719299
Blogs,8,39,model,model,has,nal sentence - level attention,model has nal sentence - level attention,0.540888786315918
Blogs,8,6,results,laptop and restaurant datasets,has,outperforms,laptop and restaurant datasets has outperforms,0.6062634587287903
Blogs,8,6,results,outperforms,has,previous lstm - based architectures,outperforms has previous lstm - based architectures,0.5797304511070251
Blogs,8,6,results,results,on,laptop and restaurant datasets,results on laptop and restaurant datasets,0.47712403535842896
Blogs,8,15,results,aoa - lstm,performed,best,aoa - lstm performed best,0.25188350677490234
Blogs,8,15,results,best,in comparisons to,other baseline methods,best in comparisons to other baseline methods,0.5722219944000244
Blogs,8,15,results,results,has,aoa - lstm,results has aoa - lstm,0.5218364596366882
Blogs,8,24,results,accuracy,is,evaluation metric,accuracy is evaluation metric,0.5101114511489868
Blogs,8,24,results,results,has,accuracy,results has accuracy,0.5888755321502686
Blogs,9,4,baselines,skip-gram,in,word embeddings,skip-gram in word embeddings,0.5005662441253662
Blogs,9,4,baselines,skip-though,in,sentence embeddings,skip-though in sentence embeddings,0.49228906631469727
Blogs,9,7,baselines,textual entailment data,to train,sentence embeddings layer,textual entailment data to train sentence embeddings layer,0.6628111004829407
Blogs,9,7,baselines,sentence embeddings layer,calls,infersent,sentence embeddings layer calls infersent,0.5818805694580078
Blogs,9,21,baselines,best approach,is,bi-directional lstm,best approach is bi-directional lstm,0.5588218569755554
Blogs,9,21,baselines,bi-directional lstm,with,max polling,bi-directional lstm with max polling,0.688014030456543
Blogs,9,23,baselines,embeddings,by,your self,embeddings by your self,0.6311562657356262
Blogs,9,32,baselines,infersent,uses,supervised learning,infersent uses supervised learning,0.6093398928642273
Blogs,9,32,baselines,supervised learning,to compute,word vectors,supervised learning to compute word vectors,0.7148967385292053
Blogs,9,33,baselines,infersent,leverages,word embeddings ( glove / fasttext ),infersent leverages word embeddings ( glove / fasttext ),0.6916394829750061
Blogs,9,33,baselines,word embeddings ( glove / fasttext ),to build,sentence embeddings,word embeddings ( glove / fasttext ) to build sentence embeddings,0.6487343311309814
Blogs,9,33,baselines,baselines,has,infersent,baselines has infersent,0.6182729005813599
Blogs,9,36,baselines,7 different architectures,of,last hidden states,7 different architectures of last hidden states,0.560970664024353
Blogs,9,36,baselines,last hidden states,of,forward and backward gru,last hidden states of forward and backward gru,0.5722880959510803
Blogs,9,37,baselines,baselines,has,bi-directional lstm with mean polling,baselines has bi-directional lstm with mean polling,0.5896539092063904
Blogs,9,38,baselines,bi-directional lstm,with,max polling,bi-directional lstm with max polling,0.688014030456543
Blogs,9,38,baselines,self-attentive network,has,attention with bilstm,self-attentive network has attention with bilstm,0.585591733455658
Blogs,9,38,baselines,baselines,has,bi-directional lstm,baselines has bi-directional lstm,0.531011700630188
Blogs,9,43,baselines,building infersent,by,your self,building infersent by your self,0.6218015551567078
Blogs,9,47,baselines,build vocab,for,"infersent model model.build_vocab(sentences , tokenize =true )","build vocab for infersent model model.build_vocab(sentences , tokenize =true )",0.5079513192176819
Blogs,9,47,baselines,5/6,has,build vocab,5/6 has build vocab,0.5468480587005615
Blogs,9,47,baselines,baselines,has,5/6,baselines has 5/6,0.5599849224090576
Blogs,9,51,baselines,baselines,has,downloading infersent pre-trained model,baselines has downloading infersent pre-trained model,0.5648761987686157
Blogs,9,52,baselines,version 1,trained by,glove,version 1 trained by glove,0.7601662874221802
Blogs,9,52,baselines,version 2,has,leveraged fasttext,version 2 has leveraged fasttext,0.6483357548713684
Blogs,9,52,baselines,baselines,has,version 1,baselines has version 1,0.5884816646575928
Blogs,9,29,experimental-setup,following shell script,in,current folder,following shell script in current folder,0.5485105514526367
Blogs,9,29,experimental-setup,experimental setup,execute,following shell script,experimental setup execute following shell script,0.6841006278991699
Blogs,9,44,experimental-setup,load pre-trained embeddings,provide,2 pre-trained models,load pre-trained embeddings provide 2 pre-trained models,0.597053587436676
Blogs,9,44,experimental-setup,version 1,based on,glove,version 1 based on glove,0.692050039768219
Blogs,9,44,experimental-setup,version 2,based on,fasttext,version 2 based on fasttext,0.6927140951156616
Blogs,9,44,experimental-setup,experimental setup,has,load pre-trained embeddings,experimental setup has load pre-trained embeddings,0.5242186188697815
Blogs,9,48,experimental-setup,pretrained model,supports,glove,pretrained model supports glove,0.6577831506729126
Blogs,9,48,experimental-setup,pretrained model,supports,fasttext,pretrained model supports fasttext,0.6320004463195801
Blogs,9,48,experimental-setup,experimental setup,has,pretrained model,experimental setup has pretrained model,0.5390155911445618
Blogs,9,59,experimental-setup,command,to train,embeddings layers.python train_nli.py,command to train embeddings layers.python train_nli.py,0.6748379468917847
Blogs,9,59,experimental-setup,experimental setup,execute,command,experimental setup execute command,0.6202268004417419
Blogs,9,9,experiments,two apples and walnuts,on,white towel,two apples and walnuts on white towel,0.5653701424598694
Blogs,9,12,experiments,relationship,is,entailment,relationship is entailment,0.6027723550796509
Blogs,9,19,experiments,bilstm,with,mean polling,bilstm with mean polling,0.701129674911499
Blogs,9,19,experiments,mean polling,perform,not very good,mean polling perform not very good,0.5669212937355042
Blogs,9,25,experiments,supervised learning approach,to generate,sentence embeddings,supervised learning approach to generate sentence embeddings,0.6038912534713745
Blogs,9,25,experiments,sentence embeddings,to have,annotated ( labeled ) data,sentence embeddings to have annotated ( labeled ) data,0.5814457535743713
Blogs,9,28,experiments,get_data.bash,in,console,get_data.bash in console,0.5226163268089294
Blogs,9,28,experiments,console,such that,snli ( stanford natural language inference ),console such that snli ( stanford natural language inference ),0.6306416392326355
Blogs,9,28,experiments,multinli ) multigenre nli ) corpus,downloaded and,processed,multinli ) multigenre nli ) corpus downloaded and processed,0.6986910104751587
Blogs,9,6,model,some features,transferred to,downstream,some features transferred to downstream,0.7114619612693787
Blogs,9,6,model,model,has,some features,model has some features,0.5803580284118652
Blogs,9,15,model,two sentences ( premise input and hypothesis input ),transformed,sentence encoder,two sentences ( premise input and hypothesis input ) transformed sentence encoder,0.6816070675849915
Blogs,9,15,model,sentence encoder,has,same weights ),sentence encoder has same weights ),0.5963489413261414
Blogs,9,16,model,3 matching methods,to recognize,relations,3 matching methods to recognize relations,0.7278085947036743
Blogs,9,16,model,relations,between,premise input and hypothesis input,relations between premise input and hypothesis input,0.6766831278800964
Blogs,9,16,model,model,leveraging,3 matching methods,model leveraging 3 matching methods,0.7099534273147583
Blogs,9,27,model,clone infersent original repo,to,local,clone infersent original repo to local,0.5917556285858154
Blogs,9,27,model,model,has,clone infersent original repo,model has clone infersent original repo,0.6236363649368286
Blogs,9,42,model,pre-trained embeddings layer,in,your nlp problems,pre-trained embeddings layer in your nlp problems,0.4953790605068207
Blogs,9,17,results,best approach,believe that,attention,best approach believe that attention,0.670114278793335
Blogs,9,17,results,attention,with,bilstm,attention with bilstm,0.6779640316963196
Blogs,9,17,results,attention,should be,best approach,attention should be best approach,0.703476071357727
Blogs,9,18,results,may harm,when using it in,transfer learning,may harm when using it in transfer learning,0.7362092137336731
Blogs,9,45,results,infersent pre-trained model and glove ( or fasttext ) model,encode,sentence,infersent pre-trained model and glove ( or fasttext ) model encode sentence,0.7726854085922241
Blogs,9,45,results,sentence,to,vectors,sentence to vectors,0.5582771301269531
Blogs,9,45,results,results,Loading,infersent pre-trained model and glove ( or fasttext ) model,results Loading infersent pre-trained model and glove ( or fasttext ) model,0.6565671563148499
Blogs,10,14,ablation-analysis,writing tldr,based on,reviewer comments,writing tldr based on reviewer comments,0.5997195243835449
Blogs,10,16,ablation-analysis,3/10 knowledge,to follow,general research areas,3/10 knowledge to follow general research areas,0.6312741637229919
Blogs,10,16,ablation-analysis,ablation analysis,has,3/10 knowledge,ablation analysis has 3/10 knowledge,0.5595982074737549
Blogs,10,21,ablation-analysis,scitldr,is,much smaller dataset,scitldr is much smaller dataset,0.5863962173461914
Blogs,10,21,ablation-analysis,k papers,due to,manual data collection and annotations,k papers due to manual data collection and annotations,0.6174259781837463
Blogs,10,21,ablation-analysis,ablation analysis,has,dataset analysis,ablation analysis has dataset analysis,0.5267954468727112
Blogs,10,32,ablation-analysis,bart model,to generate,tldr,bart model to generate tldr,0.6892570853233337
Blogs,10,32,ablation-analysis,ablation analysis,netuned,bart model,ablation analysis netuned bart model,0.6730260848999023
Blogs,10,41,ablation-analysis,limitation,on,input length,limitation on input length,0.510023832321167
Blogs,10,41,ablation-analysis,bart,has,limitation,bart has limitation,0.57138991355896
Blogs,10,23,experiments,average document length,is,5009,average document length is 5009,0.5949676036834717
Blogs,10,23,experiments,average document length,compressed into,average summary length,average document length compressed into average summary length,0.6390429139137268
Blogs,10,23,experiments,5009,compressed into,average summary length,5009 compressed into average summary length,0.7180157899856567
Blogs,10,23,experiments,average summary length,of,19,average summary length of 19,0.6493241190910339
Blogs,10,26,experiments,scitldr,investigate,rouge score difference,scitldr investigate rouge score difference,0.636840283870697
Blogs,10,26,experiments,at least two ground - truth tldrs,for,each paper,at least two ground - truth tldrs for each paper,0.6383072137832642
Blogs,10,26,experiments,at least two ground - truth tldrs,in,test set,at least two ground - truth tldrs in test set,0.5172473788261414
Blogs,10,26,experiments,each paper,in,test set,each paper in test set,0.5505006313323975
Blogs,10,26,experiments,rouge score difference,between,different ground - truth tldrs,rouge score difference between different ground - truth tldrs,0.6179909706115723
Blogs,10,26,experiments,scitldr,has,at least two ground - truth tldrs,scitldr has at least two ground - truth tldrs,0.6007870435714722
Blogs,10,29,experiments,rouge -1,of,24.7,rouge -1 of 24.7,0.6046393513679504
Blogs,10,35,experiments,small dataset,for training,neural networks,small dataset for training neural networks,0.7058746814727783
Blogs,10,36,experiments,additional 20 k paper-title pairs,from,arxiv,additional 20 k paper-title pairs from arxiv,0.5856518149375916
Blogs,10,36,experiments,additional 20 k paper-title pairs,up sampling,our scitldr,additional 20 k paper-title pairs up sampling our scitldr,0.7639366388320923
Blogs,10,39,experiments,bart - large model,on,xsum dataset,bart - large model on xsum dataset,0.5659454464912415
Blogs,10,39,experiments,extreme summarisation dataset,on,general news domain,extreme summarisation dataset on general news domain,0.5347104668617249
Blogs,10,34,hyperparameters,size,of,training data,size of training data,0.5888104438781738
Blogs,10,45,hyperparameters,rouge score,for,each ground - truth tldrs,rouge score for each ground - truth tldrs,0.6233369708061218
Blogs,10,45,hyperparameters,rouge score,select,maximum,rouge score select maximum,0.6644337177276611
Blogs,10,45,hyperparameters,hyperparameters,compute,rouge score,hyperparameters compute rouge score,0.6468459963798523
Blogs,10,8,model,model,to have,background knowledge,model to have background knowledge,0.5984506011009216
Blogs,10,38,model,new information,ready to train,our model,new information ready to train our model,0.7283055782318115
Blogs,10,38,model,model,With,new information,model With new information,0.6466166973114014
Blogs,10,2,results,tldr,has,extreme summarization of scientific documents,tldr has extreme summarization of scientific documents,0.5163978338241577
Blogs,10,5,results,shown to outperform,has,extractive and abstractive baselines,shown to outperform has extractive and abstractive baselines,0.5862202048301697
Blogs,10,12,results,extractive oracle,provides,upper bound performance,extractive oracle provides upper bound performance,0.6412376165390015
Blogs,10,12,results,results,has,extractive oracle,results has extractive oracle,0.6007286310195923
Blogs,10,17,results,reviewer comments,are,high quality summaries,reviewer comments are high quality summaries,0.45079779624938965
Blogs,10,17,results,results,has,reviewer comments,results has reviewer comments,0.5015197992324829
Blogs,10,19,results,uniqueness,of,scitldr,uniqueness of scitldr,0.6722220778465271
Blogs,10,19,results,scitldr,is,each paper,scitldr is each paper,0.6881117820739746
Blogs,10,19,results,each paper,in,test set,each paper in test set,0.5505006313323975
Blogs,10,19,results,test set,map to,multiple groundtruth tldrs,test set map to multiple groundtruth tldrs,0.6556040644645691
Blogs,10,20,results,multiple ground - truth summaries,to compute,rouge scores,multiple ground - truth summaries to compute rouge scores,0.6602732539176941
Blogs,10,20,results,author and reader 's tldr,capture,variation,author and reader 's tldr capture variation,0.7118431925773621
Blogs,10,20,results,variation,in,summaries,variation in summaries,0.5548132061958313
Blogs,10,20,results,summaries,based on,reader 's perspective,summaries based on reader 's perspective,0.6624326705932617
Blogs,10,22,results,extremely high compression ratio,compared to,other datasets,extremely high compression ratio compared to other datasets,0.6578391194343567
Blogs,10,22,results,scitldr,has,extremely high compression ratio,scitldr has extremely high compression ratio,0.5901498198509216
Blogs,10,22,results,results,has,scitldr,results has scitldr,0.5614461898803711
Blogs,10,27,results,low rougee - 1 overlap ( 27.40 ),between,author-generated tldrs,low rougee - 1 overlap ( 27.40 ) between author-generated tldrs,0.6108113527297974
Blogs,10,27,results,low rougee - 1 overlap ( 27.40 ),between,pr - generated tldrs,low rougee - 1 overlap ( 27.40 ) between pr - generated tldrs,0.6483252048492432
Blogs,10,28,results,author-generated tldrs,ROUGE - 1 of,34.1,author-generated tldrs ROUGE - 1 of 34.1,0.7576460838317871
Blogs,10,28,results,results,has,author-generated tldrs,results has author-generated tldrs,0.45196545124053955
Blogs,10,40,results,our bart model,on,scitldr and title dataset,our bart model on scitldr and title dataset,0.5742838978767395
Blogs,10,40,results,results,netune,our bart model,results netune our bart model,0.7558400630950928
