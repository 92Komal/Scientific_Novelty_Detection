topic,paper_ID,sentence_ID,info-unit,sub,pred,obj,triplets,pred_weights
Blogs,0,31,ablation-analysis,word vectors,helps with,performance,word vectors helps with performance,0.6572704315185547
Blogs,0,31,ablation-analysis,ablation analysis,Fine tuning,word vectors,ablation analysis Fine tuning word vectors,0.7669583559036255
Blogs,0,15,baselines,baseline,Includes,models,baseline Includes models,0.6590501666069031
Blogs,0,15,baselines,baseline,Includes,image or question features,baseline Includes image or question features,0.6302956342697144
Blogs,0,15,baselines,baseline,Includes,image features,baseline Includes image features,0.655623733997345
Blogs,0,15,baselines,models,where,answer,models where answer,0.6823186874389648
Blogs,0,15,baselines,answer,is,guessed,answer is guessed,0.6220376491546631
Blogs,0,15,baselines,image features,along with,prior knowledge,image features along with prior knowledge,0.6023657917976379
Blogs,0,15,baselines,prior knowledge,of,object,prior knowledge of object,0.5511146783828735
Blogs,0,15,baselines,baselines,has,baseline,baselines has baseline,0.6124745607376099
Blogs,0,16,baselines,knn model,where,system,knn model where system,0.6624546051025391
Blogs,0,16,baselines,system,nds,"nearest ( image , question ) pair","system nds nearest ( image , question ) pair",0.6583433151245117
Blogs,0,27,baselines,baselines,has,vis +lstm,baselines has vis +lstm,0.5347738265991211
Blogs,0,28,baselines,bidirectional lstm img + bow,without dimensionality reduction,bag of words ( averaging word vectors,bidirectional lstm img + bow without dimensionality reduction bag of words ( averaging word vectors,0.7611251473426819
Blogs,0,28,baselines,multinomial logistic regression,on,image features,multinomial logistic regression on image features,0.5359888672828674
Blogs,0,28,baselines,image features,has,twice,image features has twice,0.5876720547676086
Blogs,0,28,baselines,image features,has,in beginning and in the end,image features has in beginning and in the end,0.5900895595550537
Blogs,0,28,baselines,bidirectional lstm img + bow,has,multinomial logistic regression,bidirectional lstm img + bow has multinomial logistic regression,0.5655922889709473
Blogs,0,29,baselines,baselines,has,full - simple average of above 2 models,baselines has full - simple average of above 2 models,0.5589770674705505
Blogs,0,12,experiments,object questions,has,number questions,object questions has number questions,0.5923924446105957
Blogs,0,13,experiments,~ 120 k questions,across,4 semantic types,~ 120 k questions across 4 semantic types,0.6776542663574219
Blogs,0,25,experiments,question ansering,on,real-world images,question ansering on real-world images,0.6039011478424072
Blogs,0,25,experiments,question ansering,has,images,question ansering has images,0.6235146522521973
Blogs,0,25,experiments,real-world images,has,images,real-world images has images,0.5533527731895447
Blogs,0,7,hyperparameters,answer,assumed to be,single word,answer assumed to be single word,0.540966808795929
Blogs,0,7,hyperparameters,single word,bypassing,evaluation issues,single word bypassing evaluation issues,0.7076125741004944
Blogs,0,7,hyperparameters,evaluation issues,of,multi-word,evaluation issues of multi-word,0.5858732461929321
Blogs,0,7,hyperparameters,hyperparameters,has,answer,hyperparameters has answer,0.5684177875518799
Blogs,0,22,hyperparameters,vgg net embeddings,of,image,vgg net embeddings of image,0.5466228127479553
Blogs,0,22,hyperparameters,linear transformation,to match,dimensions,linear transformation to match dimensions,0.7629368305206299
Blogs,0,22,hyperparameters,dimensionality reduction weight matrix ),to match,dimensions,dimensionality reduction weight matrix ) to match dimensions,0.6908577084541321
Blogs,0,22,hyperparameters,dimensions,of,word embeddings,dimensions of word embeddings,0.49344462156295776
Blogs,0,22,hyperparameters,linear transformation,has,dimensionality reduction weight matrix ),linear transformation has dimensionality reduction weight matrix ),0.5149626731872559
Blogs,0,22,hyperparameters,hyperparameters,Obtain,vgg net embeddings,hyperparameters Obtain vgg net embeddings,0.4672742187976837
Blogs,0,23,hyperparameters,image embedding,frozen during,training,image embedding frozen during training,0.663400411605835
Blogs,0,23,hyperparameters,lstm,to combine,word vectors,lstm to combine word vectors,0.6700844168663025
Blogs,0,23,hyperparameters,hyperparameters,Keep,image embedding,hyperparameters Keep image embedding,0.5847697854042053
Blogs,0,10,model,algorithm,for,generating questions,algorithm for generating questions,0.6486601233482361
Blogs,0,10,model,generating questions,using,ms - coco dataset,generating questions using ms - coco dataset,0.6777762174606323
Blogs,0,11,model,preprocessing steps,breaking,large sentences,preprocessing steps breaking large sentences,0.7397244572639465
Blogs,0,11,model,model,Perform,preprocessing steps,model Perform preprocessing steps,0.6521064043045044
Blogs,0,20,model,input image,as,rst word,input image as rst word,0.5218281745910645
Blogs,0,20,model,rst word,in,question,rst word in question,0.5575449466705322
Blogs,0,20,model,model,Treat,input image,model Treat input image,0.5812841653823853
Blogs,0,21,model,vector representation ( skip-gram ),for,words,vector representation ( skip-gram ) for words,0.6057685613632202
Blogs,0,21,model,words,in,question,words in question,0.5680095553398132
Blogs,0,21,model,model,Obtain,vector representation ( skip-gram ),model Obtain vector representation ( skip-gram ),0.585108757019043
Blogs,0,24,model,lstm outputs,fed into,softmax layer,lstm outputs fed into softmax layer,0.5914134979248047
Blogs,0,24,model,softmax layer,generates,answer,softmax layer generates answer,0.6824012398719788
Blogs,0,24,model,model,has,lstm outputs,model has lstm outputs,0.5413433313369751
Blogs,0,8,results,downside,is,even guess work,downside is even guess work,0.6222573518753052
Blogs,0,8,results,even guess work,yield,good results,even guess work yield good results,0.7331272959709167
Blogs,0,8,results,results,has,downside,results has downside,0.5839234590530396
Blogs,0,17,results,metrics accuracy,has,wu -palmer similarity measure,metrics accuracy has wu -palmer similarity measure,0.5116413831710815
Blogs,0,17,results,results,has,metrics accuracy,results has metrics accuracy,0.5356631278991699
Blogs,0,19,results,bene ts,from,averaging,bene ts from averaging,0.596365213394165
Blogs,0,19,results,averaging,across,all the models,averaging across all the models,0.7040627598762512
Blogs,0,19,results,vis -lstm model,has,outperforms,vis -lstm model has outperforms,0.6202430725097656
Blogs,0,19,results,outperforms,has,baselines,outperforms has baselines,0.6144351959228516
Blogs,0,19,results,full model,has,bene ts,full model has bene ts,0.5353885889053345
Blogs,0,19,results,results,has,vis -lstm model,results has vis -lstm model,0.5601519346237183
Blogs,0,32,results,cnn hidden image features,into,zero mean and unit variance,cnn hidden image features into zero mean and unit variance,0.5526717305183411
Blogs,0,32,results,cnn hidden image features,leads to,faster training,cnn hidden image features leads to faster training,0.6556745171546936
Blogs,0,32,results,zero mean and unit variance,leads to,faster training,zero mean and unit variance leads to faster training,0.7035365700721741
Blogs,0,32,results,results,Normalising,cnn hidden image features,results Normalising cnn hidden image features,0.6581441760063171
Blogs,0,33,results,model,does not perform,well,model does not perform well,0.73469477891922
Blogs,0,33,results,counting objects,when,multiple objects are present,counting objects when multiple objects are present,0.6360155940055847
Blogs,0,33,results,results,has,model,results has model,0.5339115858078003
Blogs,1,7,ablation-analysis,aggregated features,helps in,most category of questions,aggregated features helps in most category of questions,0.6795678734779358
Blogs,1,7,ablation-analysis,aggregated features,seems to,hurt,aggregated features seems to hurt,0.7207775115966797
Blogs,1,7,ablation-analysis,hurt,for,counting based questions,hurt for counting based questions,0.6581090688705444
Blogs,1,7,ablation-analysis,ablation analysis,has,aggregated features,ablation analysis has aggregated features,0.5833402872085571
Blogs,1,9,ablation-analysis,ablation analysis,limits,scope of supervision,ablation analysis limits scope of supervision,0.6677761077880859
Blogs,1,6,baselines,soft attention mechanism,weighted sum over,spatial features,soft attention mechanism weighted sum over spatial features,0.7275723814964294
Blogs,1,6,baselines,spatial features,obtain,single feature vector,spatial features obtain single feature vector,0.5648811459541321
Blogs,1,21,hyperparameters,attention weights,are,1,attention weights are 1,0.5854918360710144
Blogs,1,21,hyperparameters,attention weights,are,0,attention weights are 0,0.6005037426948547
Blogs,1,21,hyperparameters,1,when,object,1 when object,0.5951433181762695
Blogs,1,21,hyperparameters,1,when,object,1 when object,0.5951433181762695
Blogs,1,21,hyperparameters,object,present in,proposal,object present in proposal,0.6485181450843811
Blogs,1,21,hyperparameters,object,present in,absent from the proposal,object present in absent from the proposal,0.7013809680938721
Blogs,1,21,hyperparameters,0,when,object,0 when object,0.7170518636703491
Blogs,1,21,hyperparameters,hyperparameters,has,rst assumption,hyperparameters has rst assumption,0.49561044573783875
Blogs,1,28,hyperparameters,attention weight,for,i th proposal,attention weight for i th proposal,0.5872717499732971
Blogs,1,28,hyperparameters,i th proposal,corresponds to,i th node,i th proposal corresponds to i th node,0.7100499868392944
Blogs,1,28,hyperparameters,i th node,in,graph,i th node in graph,0.5456256866455078
Blogs,1,28,hyperparameters,edge,between,nodes i and j,edge between nodes i and j,0.6613932847976685
Blogs,1,28,hyperparameters,nodes i and j,has,weight a i * a j,nodes i and j has weight a i * a j,0.5543829202651978
Blogs,1,28,hyperparameters,hyperparameters,has,attention weight,hyperparameters has attention weight,0.5137538313865662
Blogs,1,39,hyperparameters,number of proposals,correspond of,each instance,number of proposals correspond of each instance,0.6208290457725525
Blogs,1,39,hyperparameters,number of proposals,scale down,edges,number of proposals scale down edges,0.6946276426315308
Blogs,1,39,hyperparameters,each instance,of,object,each instance of object,0.5914262533187866
Blogs,1,39,hyperparameters,edges,corresponding to,different instances,edges corresponding to different instances,0.6037439107894897
Blogs,1,39,hyperparameters,hyperparameters,Count,number of proposals,hyperparameters Count number of proposals,0.6454066634178162
Blogs,1,41,hyperparameters,number of proposals,corresponding to,object,number of proposals corresponding to object,0.594887375831604
Blogs,1,41,hyperparameters,number of proposals,estimated based on,similarity,number of proposals estimated based on similarity,0.7052245736122131
Blogs,1,41,hyperparameters,similarity,between,different proposals,similarity between different proposals,0.681525468826294
Blogs,1,41,hyperparameters,hyperparameters,has,number of proposals,hyperparameters has number of proposals,0.5229668617248535
Blogs,1,48,hyperparameters,k,should be,one,k should be one,0.7664856314659119
Blogs,1,48,hyperparameters,ideal setting,has,k,ideal setting has k,0.6233310699462891
Blogs,1,11,model,model,using,attention maps,model using attention maps,0.640828549861908
Blogs,1,12,model,weighted averaging,based on,different attention maps,weighted averaging based on different attention maps,0.6267881393432617
Blogs,1,12,model,weighted averaging,end up averaging,features,weighted averaging end up averaging features,0.7098037004470825
Blogs,1,12,model,features,corresponding to,difference instances,features corresponding to difference instances,0.5309000611305237
Blogs,1,12,model,difference instances,of,object,difference instances of object,0.5822270512580872
Blogs,1,12,model,model,perform,weighted averaging,model perform weighted averaging,0.6025456786155701
Blogs,1,16,model,count module,is,separate pipeline,count module is separate pipeline,0.5902402997016907
Blogs,1,16,model,separate pipeline,integrated with,most of the existing attention based vqa models,separate pipeline integrated with most of the existing attention based vqa models,0.6879718899726868
Blogs,1,16,model,most of the existing attention based vqa models,without affecting,performance,most of the existing attention based vqa models without affecting performance,0.6644174456596375
Blogs,1,16,model,performance,on,non-count based questions,performance on non-count based questions,0.5456417202949524
Blogs,1,16,model,model,proposed,count module,model proposed count module,0.7663606405258179
Blogs,1,17,model,inputs,to,count module,inputs to count module,0.5928882956504822
Blogs,1,17,model,count module,are,attention maps,count module are attention maps,0.5883016586303711
Blogs,1,17,model,count module,are,object proposals,count module are object proposals,0.5948356986045837
Blogs,1,17,model,countfeature vector,to,answer,countfeature vector to answer,0.5746052861213684
Blogs,1,17,model,answer,has,count based question,answer has count based question,0.6354272961616516
Blogs,1,17,model,model,has,inputs,model has inputs,0.5300602912902832
Blogs,1,18,model,top level idea,given,object proposals,top level idea given object proposals,0.6984712481498718
Blogs,1,18,model,top level idea,given,attention maps,top level idea given attention maps,0.7065422534942627
Blogs,1,18,model,top level idea,create,graph,top level idea create graph,0.6716458201408386
Blogs,1,18,model,attention maps,create,graph,attention maps create graph,0.6664685606956482
Blogs,1,18,model,graph,where,nodes are objects ( object proposals ),graph where nodes are objects ( object proposals ),0.618366003036499
Blogs,1,18,model,graph,where,edges,graph where edges,0.6510108113288879
Blogs,1,18,model,edges,capture,how similar,edges capture how similar,0.6378594040870667
Blogs,1,18,model,how similar,has,object proposals are,how similar has object proposals are,0.546590268611908
Blogs,1,18,model,model,has,top level idea,model has top level idea,0.5563551783561707
Blogs,1,19,model,graph,so that,count of the object,graph so that count of the object,0.6159601807594299
Blogs,1,19,model,transformed,by,removing and scaling edges,transformed by removing and scaling edges,0.6238846182823181
Blogs,1,19,model,transformed,so that,count of the object,transformed so that count of the object,0.6378737092018127
Blogs,1,19,model,count of the object,obtained,easily,count of the object obtained easily,0.653989851474762
Blogs,1,19,model,model,has,graph,model has graph,0.6106921434402466
Blogs,1,22,model,any two object,corresponding to,completely different objects,any two object corresponding to completely different objects,0.5732099413871765
Blogs,1,25,model,attention weights ( a ),to generate,attention matrix ( a ),attention weights ( a ) to generate attention matrix ( a ),0.6892462372779846
Blogs,1,25,model,attention matrix ( a ),by performing,outer product,attention matrix ( a ) by performing outer product,0.7031179666519165
Blogs,1,25,model,outer product,between,a and a t,outer product between a and a t,0.6938678026199341
Blogs,1,25,model,model,has,attention weights ( a ),model has attention weights ( a ),0.5478595495223999
Blogs,1,27,model,a,corresponds to,adjacency matrix,a corresponds to adjacency matrix,0.7366114258766174
Blogs,1,27,model,adjacency matrix,of,graph,adjacency matrix of graph,0.5630601644515991
Blogs,1,27,model,model,has,a,model has a,0.5863970518112183
Blogs,1,29,model,graph,is,weighted directed graph,graph is weighted directed graph,0.5348915457725525
Blogs,1,29,model,graph,is,subgraph of vertices,graph is subgraph of vertices,0.5693567395210266
Blogs,1,29,model,subgraph of vertices,satisfying,condition a i = 1,subgraph of vertices satisfying condition a i = 1,0.6935193538665771
Blogs,1,29,model,condition a i = 1,is,complete directed graph,condition a i = 1 is complete directed graph,0.573486864566803
Blogs,1,29,model,complete directed graph,with,self-loops,complete directed graph with self-loops,0.6041803956031799
Blogs,1,29,model,model,note,graph,model note graph,0.6263100504875183
Blogs,1,29,model,model,note,subgraph of vertices,model note subgraph of vertices,0.5748913288116455
Blogs,1,31,model,proposals,are,distinct,proposals are distinct,0.6870817542076111
Blogs,1,32,model,objective,eliminate,edges,objective eliminate edges,0.6580469012260437
Blogs,1,32,model,edges,such that,underlying objects,edges such that underlying objects,0.5399007201194763
Blogs,1,32,model,model,eliminate,edges,model eliminate edges,0.7325636744499207
Blogs,1,32,model,model,has,objective,model has objective,0.5278581380844116
Blogs,1,33,model,two type of duplicate edges,has,intra-object edges,two type of duplicate edges has intra-object edges,0.5398439764976501
Blogs,1,33,model,model,removing,two type of duplicate edges,model removing two type of duplicate edges,0.7309216260910034
Blogs,1,34,model,removed,by computing,distance matrix,removed by computing distance matrix,0.71586674451828
Blogs,1,34,model,iou matrix,corresponds to,intersection - over - union matrix,iou matrix corresponds to intersection - over - union matrix,0.6893324255943298
Blogs,1,34,model,distance matrix,has,d,distance matrix has d,0.5706809163093567
Blogs,1,34,model,1 -,has,iou,1 - has iou,0.6994302272796631
Blogs,1,34,model,model,has,intra-object edges,model has intra-object edges,0.5373787879943848
Blogs,1,35,model,modi ed adjacency matrix a ',by performing,element -,modi ed adjacency matrix a ' by performing element -,0.6936673521995544
Blogs,1,35,model,wise product,between,f 1 ( a ) and f 2 ( d ),wise product between f 1 ( a ) and f 2 ( d ),0.6393969058990479
Blogs,1,35,model,element -,has,wise product,element - has wise product,0.6028987169265747
Blogs,1,35,model,model,has,modi ed adjacency matrix a ',model has modi ed adjacency matrix a ',0.5838878154754639
Blogs,1,40,model,effect,reducing,weights,effect reducing weights,0.6881207227706909
Blogs,1,40,model,weights,of,multiple proposals,weights of multiple proposals,0.5942184925079346
Blogs,1,40,model,multiple proposals,equivalent to,single proposal,multiple proposals equivalent to single proposal,0.6357001662254333
Blogs,1,40,model,model,creates,effect,model creates effect,0.6156688928604126
Blogs,1,40,model,model,reducing,weights,model reducing weights,0.7195107340812683
Blogs,1,42,model,matrix,corresponding to,"similarity between proposals ( sim i , j )","matrix corresponding to similarity between proposals ( sim i , j )",0.5820456147193909
Blogs,1,42,model,matrix,transformed into,vector,matrix transformed into vector,0.6944220662117004
Blogs,1,42,model,vector,corresponding to,scaling factor,vector corresponding to scaling factor,0.614334225654602
Blogs,1,42,model,scaling factor,of,each node,scaling factor of each node,0.6083597540855408
Blogs,1,42,model,matrix,to scale,incoming and the outgoing edges,matrix to scale incoming and the outgoing edges,0.6865054965019226
Blogs,1,42,model,model,has,matrix,model has matrix,0.5443862080574036
Blogs,1,43,model,self edges,added back,scaling,self edges added back scaling,0.7483891248703003
Blogs,1,43,model,model,has,self edges,model has self edges,0.5661197900772095
Blogs,1,44,model,transformed matrix c,is,complete graph,transformed matrix c is complete graph,0.5632933378219604
Blogs,1,44,model,complete graph,with,selfloops,complete graph with selfloops,0.6403372883796692
Blogs,1,44,model,selfloops,where,nodes,selfloops where nodes,0.6723536849021912
Blogs,1,44,model,nodes,corresponds to,all the relevant object instances,nodes corresponds to all the relevant object instances,0.7023066878318787
Blogs,1,44,model,nodes,not to,object proposals,nodes not to object proposals,0.5973976254463196
Blogs,1,44,model,model,has,transformed matrix c,model has transformed matrix c,0.5746623873710632
Blogs,1,45,model,actual count,obtained from,c,actual count obtained from c,0.6717670559883118
Blogs,1,45,model,c,by performing,sum over all its values,c by performing sum over all its values,0.7064953446388245
Blogs,1,45,model,model,has,actual count,model has actual count,0.5928593873977661
Blogs,1,46,model,original count problem,was,regression problem,original count problem was regression problem,0.5428510904312134
Blogs,1,46,model,original count problem,transformed into,classi cation problem,original count problem transformed into classi cation problem,0.6186316013336182
Blogs,1,46,model,classi cation problem,to avoid,scale issues,classi cation problem to avoid scale issues,0.6588699221611023
Blogs,1,46,model,model,has,original count problem,model has original count problem,0.5649904012680054
Blogs,1,47,model,k-hot n-dimensional vector,called,o,k-hot n-dimensional vector called o,0.6775732636451721
Blogs,1,47,model,number of object proposals,feed into,module,number of object proposals feed into module,0.6546351909637451
Blogs,1,49,model,c,is,exact integer,c is exact integer,0.614538848400116
Blogs,1,49,model,output,is,1 - hot vector,output is 1 - hot vector,0.5447221994400024
Blogs,1,49,model,1 - hot vector,with,value in index corresponding to c,1 - hot vector with value in index corresponding to c,0.6612388491630554
Blogs,1,49,model,value in index corresponding to c,set to,1,value in index corresponding to c set to 1,0.742312490940094
Blogs,1,49,model,c,has,output,c has output,0.6318440437316895
Blogs,1,49,model,exact integer,has,output,exact integer has output,0.5991214513778687
Blogs,1,49,model,model,If,c,model If c,0.6369372606277466
Blogs,1,50,model,c,is,real number,c is real number,0.6023186445236206
Blogs,1,50,model,linear interpolation,between,two one- hot vectors,linear interpolation between two one- hot vectors,0.6654758453369141
Blogs,1,50,model,c,has,output,c has output,0.6318440437316895
Blogs,1,50,model,real number,has,output,real number has output,0.580062210559845
Blogs,1,51,model,count module,computing,con dence,count module computing con dence,0.7510168552398682
Blogs,1,51,model,con dence,of,prediction,con dence of prediction,0.6311585307121277
Blogs,1,51,model,prediction,by de ning,two variables p a and p d,prediction by de ning two variables p a and p d,0.6145282983779907
Blogs,1,51,model,model,has,count module,model has count module,0.6115907430648804
Blogs,1,8,results,counting questions,do not have,ground truth segmentation,counting questions do not have ground truth segmentation,0.6284496784210205
Blogs,1,8,results,ground truth segmentation,of,objects to be counted,ground truth segmentation of objects to be counted,0.5834763050079346
Blogs,1,8,results,ground truth segmentation,where,objects to be counted,ground truth segmentation where objects to be counted,0.6176851391792297
Blogs,1,8,results,objects to be counted,present on,image,objects to be counted present on image,0.7565549612045288
Blogs,1,8,results,results,For,counting questions,results For counting questions,0.5855093002319336
Blogs,1,10,results,modi cation,in,architecture,modi cation in architecture,0.5565038919448853
Blogs,1,10,results,modi cation,to enhance,performance,modi cation to enhance performance,0.7155423164367676
Blogs,1,10,results,modi cation,should not degrade,performance,modi cation should not degrade performance,0.7409775853157043
Blogs,1,10,results,performance,on,counting questions,performance on counting questions,0.5299510359764099
Blogs,1,10,results,performance,on,other classes of questions,performance on other classes of questions,0.523235023021698
Blogs,1,10,results,performance,should not degrade,performance,performance should not degrade performance,0.7414284944534302
Blogs,1,10,results,performance,on,other classes of questions,performance on other classes of questions,0.523235023021698
Blogs,1,10,results,performance,on,other classes of questions,performance on other classes of questions,0.523235023021698
Blogs,1,10,results,results,ensure that,modi cation,results ensure that modi cation,0.19045215845108032
Blogs,1,13,results,indistinguishable,from,scenario,indistinguishable from scenario,0.5659956932067871
Blogs,1,13,results,feature vectors,has,indistinguishable,feature vectors has indistinguishable,0.5892453193664551
Blogs,1,13,results,results,makes,feature vectors,results makes feature vectors,0.6292480230331421
Blogs,1,14,results,results,has,multiple glimpses ( multiple attention steps ),results has multiple glimpses ( multiple attention steps ),0.5419294834136963
Blogs,1,15,results,hard attention,could be,more useful,hard attention could be more useful,0.6470327377319336
Blogs,1,15,results,more useful,than,soft-attention,more useful than soft-attention,0.6097675561904907
Blogs,1,15,results,results,has,hard attention,results has hard attention,0.5850002765655518
Blogs,2,13,ablation-analysis,different learning rates and weight clipping,for,word embedding layer and softmax layer,different learning rates and weight clipping for word embedding layer and softmax layer,0.5667170882225037
Blogs,2,13,ablation-analysis,learning rate,for,embedding layer,learning rate for embedding layer,0.5718069672584534
Blogs,2,13,ablation-analysis,embedding layer,much higher than,softmax layer,embedding layer much higher than softmax layer,0.5345467925071716
Blogs,2,13,ablation-analysis,ablation analysis,has,different learning rates and weight clipping,ablation analysis has different learning rates and weight clipping,0.5335908532142639
Blogs,2,19,ablation-analysis,question words,in uence,answer,question words in uence answer,0.6493829488754272
Blogs,2,19,ablation-analysis,answer,given,bias,answer given bias,0.6247866749763489
Blogs,2,19,ablation-analysis,bias,in,images,bias in images,0.5646641850471497
Blogs,2,19,ablation-analysis,images,occurring in,coco dataset,images occurring in coco dataset,0.6353704333305359
Blogs,2,19,ablation-analysis,ablation analysis,has,question words,ablation analysis has question words,0.5270510315895081
Blogs,2,6,baselines,simple baseline method,of,bag-of-words + image features ( ibowimg ),simple baseline method of bag-of-words + image features ( ibowimg ),0.5082021355628967
Blogs,2,6,baselines,simple baseline method,to make it,competitive,simple baseline method to make it competitive,0.6079185605049133
Blogs,2,6,baselines,competitive,against,more sophisticated lstm models,competitive against more sophisticated lstm models,0.6746299862861633
Blogs,2,6,baselines,baselines,ne tune,simple baseline method,baselines ne tune simple baseline method,0.6845673322677612
Blogs,2,8,model,model vqa,modelled as,classi cation task,model vqa modelled as classi cation task,0.5851072669029236
Blogs,2,8,model,model,has,model vqa,model has model vqa,0.5722792744636536
Blogs,2,9,model,text features,Convert,input question,text features Convert input question,0.6662290096282959
Blogs,2,9,model,text features,transform to,word vectors,text features transform to word vectors,0.6789038181304932
Blogs,2,9,model,input question,to,one-hot vector,input question to one-hot vector,0.5444688200950623
Blogs,2,9,model,word vectors,using,word embedding,word vectors using word embedding,0.6556629538536072
Blogs,2,9,model,model,has,text features,model has text features,0.550437331199646
Blogs,2,10,model,image features,has,last layer activations,image features has last layer activations,0.5198462009429932
Blogs,2,10,model,model,has,image features,model has image features,0.5411174893379211
Blogs,2,12,model,text features,concatenated with,image features,text features concatenated with image features,0.6819291114807129
Blogs,2,12,model,text features,fed into,softmax,text features fed into softmax,0.6248600482940674
Blogs,2,12,model,model,has,text features,model has text features,0.550437331199646
Blogs,2,18,model,correlation,between,answer class,correlation between answer class,0.6721721291542053
Blogs,2,18,model,correlation,between,informative words ( in the question ),correlation between informative words ( in the question ),0.6511746048927307
Blogs,2,18,model,memorise,has,correlation,memorise has correlation,0.6647660136222839
Blogs,2,20,model,importance,of,each single words ( in the question ),importance of each single words ( in the question ),0.6082227230072021
Blogs,2,20,model,each single words ( in the question ),to,answer,each single words ( in the question ) to answer,0.5839237570762634
Blogs,2,20,model,model,quantify,importance,model quantify importance,0.6755158305168152
Blogs,2,21,model,class activation mapping ( cam ) approach,to highlight,informative image regions,class activation mapping ( cam ) approach to highlight informative image regions,0.6165525317192078
Blogs,2,21,model,informative image regions,relevant to,predicted answer,informative image regions relevant to predicted answer,0.6393489837646484
Blogs,2,21,model,model,uses,class activation mapping ( cam ) approach,model uses class activation mapping ( cam ) approach,0.6299638152122498
Blogs,2,14,results,ibowimg model,reports,accuracy,ibowimg model reports accuracy,0.6410222053527832
Blogs,2,14,results,accuracy,of,55.89 %,accuracy of 55.89 %,0.5577804446220398
Blogs,2,14,results,accuracy,of,61.97 %,accuracy of 61.97 %,0.5555040836334229
Blogs,2,14,results,55.89 %,for,open-ended questions,55.89 % for open-ended questions,0.5516124963760376
Blogs,2,14,results,61.97 %,for,multiple - choice questions,61.97 % for multiple - choice questions,0.5705055594444275
Blogs,2,14,results,results,has,ibowimg model,results has ibowimg model,0.5399987697601318
Blogs,2,15,results,strengths and weakness,of,different vqa datasets,strengths and weakness of different vqa datasets,0.5408313274383545
Blogs,2,22,results,comments papers-i-read,has,privacy policy,comments papers-i-read has privacy policy,0.5640309453010559
Blogs,2,22,results,privacy policy,has,login,privacy policy has login,0.5615909695625305
Blogs,2,22,results,login,has,tweet,login has tweet,0.5747577548027039
Blogs,2,22,results,results,has,comments papers-i-read,results has comments papers-i-read,0.5474403500556946
Blogs,2,23,results,start the discussion,has,name,start the discussion has name,0.5557461977005005
Blogs,2,23,results,results,has,start the discussion,results has start the discussion,0.5634199380874634
Blogs,2,24,results,first,to,comment,first to comment,0.5824790000915527
Blogs,2,24,results,results,Be,first,results Be first,0.5573645830154419
Blogs,3,38,ablation-analysis,random assignment,end up,confusing,random assignment end up confusing,0.7054392695426941
Blogs,3,38,ablation-analysis,not remedied,has,random assignment,not remedied has random assignment,0.5848641991615295
Blogs,3,38,ablation-analysis,confusing,has,our model,confusing has our model,0.5809804201126099
Blogs,3,153,ablation-analysis,attention step,is,core technical innovation,attention step is core technical innovation,0.55286705493927
Blogs,3,153,ablation-analysis,attention step,focus of,next article,attention step focus of next article,0.7442099452018738
Blogs,3,153,ablation-analysis,core technical innovation,of,bidaf,core technical innovation of bidaf,0.6092588305473328
Blogs,3,153,ablation-analysis,next article,in,series,next article in series,0.5600900053977966
Blogs,3,153,ablation-analysis,ablation analysis,has,attention step,ablation analysis has attention step,0.5650569796562195
Blogs,3,19,baselines,glove,is,unsupervised learning algorithm,glove is unsupervised learning algorithm,0.6069743037223816
Blogs,3,19,baselines,unsupervised learning algorithm,uses,co-occurrence frequencies,unsupervised learning algorithm uses co-occurrence frequencies,0.5690070390701294
Blogs,3,19,baselines,co-occurrence frequencies,of,words,co-occurrence frequencies of words,0.5671154260635376
Blogs,3,19,baselines,co-occurrence frequencies,to generate,words ' vector representations,co-occurrence frequencies to generate words ' vector representations,0.6381839513778687
Blogs,3,19,baselines,words,in,corpus,words in corpus,0.5251032114028931
Blogs,3,19,baselines,short,has,on time,short has on time,0.6382434964179993
Blogs,3,22,baselines,of glove vectors,to find,word analogies,of glove vectors to find word analogies,0.5950273275375366
Blogs,3,22,baselines,subtraction,has,of glove vectors,subtraction has of glove vectors,0.5425392389297485
Blogs,3,25,baselines,bidaf,uses,pre-trained glove embeddings,bidaf uses pre-trained glove embeddings,0.5810368061065674
Blogs,3,25,baselines,pre-trained glove embeddings,to get,vector representation,pre-trained glove embeddings to get vector representation,0.5953540205955505
Blogs,3,25,baselines,vector representation,of,words,vector representation of words,0.5798678994178772
Blogs,3,25,baselines,words,in,query and the context,words in query and the context,0.5539600849151611
Blogs,3,25,baselines,baselines,has,bidaf,baselines has bidaf,0.6077240705490112
Blogs,3,37,baselines,glove,deals with,oov words,glove deals with oov words,0.7116684317588806
Blogs,3,37,baselines,oov words,assigning them,some random vector values,oov words assigning them some random vector values,0.7036396861076355
Blogs,3,37,baselines,baselines,has,glove,baselines has glove,0.6172672510147095
Blogs,3,56,baselines,1d - cnn,is,algorithm,1d - cnn is algorithm,0.5667182803153992
Blogs,3,56,baselines,1d - cnn,mimics,human capability,1d - cnn mimics human capability,0.7436338067054749
Blogs,3,56,baselines,algorithm,mimics,human capability,algorithm mimics human capability,0.7177520394325256
Blogs,3,56,baselines,human capability,to understand,word parts,human capability to understand word parts,0.6417458057403564
Blogs,3,56,baselines,baselines,has,1d - cnn,baselines has 1d - cnn,0.5173192620277405
Blogs,3,61,baselines,1d - cnn,on,word,1d - cnn on word,0.5640896558761597
Blogs,3,89,baselines,summary scalar,of,f.,summary scalar of f.,0.6048754453659058
Blogs,3,100,baselines,step 4,has,highway network,step 4 has highway network,0.5679140090942383
Blogs,3,100,baselines,baselines,has,step 4,baselines has step 4,0.6137861013412476
Blogs,3,110,baselines,baselines,has,highway network,baselines has highway network,0.5680134296417236
Blogs,3,132,baselines,lstm,is,neural network architecture,lstm is neural network architecture,0.5558469891548157
Blogs,3,132,baselines,lstm,is,neural network architecture,lstm is neural network architecture,0.5558469891548157
Blogs,3,132,baselines,neural network architecture,memorize,long-term dependencies,neural network architecture memorize long-term dependencies,0.6559394598007202
Blogs,3,135,baselines,bidaf,employs,bidirectional - lstm ( bi- lstm ),bidaf employs bidirectional - lstm ( bi- lstm ),0.5618675947189331
Blogs,3,135,baselines,bidirectional - lstm ( bi- lstm ),composed of,forward - as well as backward - lstm sequences,bidirectional - lstm ( bi- lstm ) composed of forward - as well as backward - lstm sequences,0.7266852259635925
Blogs,3,135,baselines,baselines,has,bidaf,baselines has bidaf,0.6077240705490112
Blogs,3,154,baselines,accompanying text,to,query,accompanying text to query,0.5620163679122925
Blogs,3,154,baselines,accompanying text,to,query query,accompanying text to query query,0.5446932315826416
Blogs,3,154,baselines,glossary context,has,accompanying text,glossary context has accompanying text,0.5220580101013184
Blogs,3,154,baselines,baselines,has,glossary context,baselines has glossary context,0.5431081652641296
Blogs,3,5,experimental-setup,glossary,containing,mathematical notations,glossary containing mathematical notations,0.6083747148513794
Blogs,3,9,experimental-setup,symbols t and j,to denote,number of words,symbols t and j to denote number of words,0.6537020802497864
Blogs,3,9,experimental-setup,number of words,in,context and query,number of words in context and query,0.5152850151062012
Blogs,3,9,experimental-setup,bidaf,has,symbols t and j,bidaf has symbols t and j,0.5948551893234253
Blogs,3,17,experimental-setup,word embedding algorithm,used in,original bidaf,word embedding algorithm used in original bidaf,0.6501623392105103
Blogs,3,17,experimental-setup,word embedding algorithm,is,glove,word embedding algorithm is glove,0.5671725869178772
Blogs,3,17,experimental-setup,original bidaf,is,glove,original bidaf is glove,0.593953549861908
Blogs,3,17,experimental-setup,experimental setup,has,word embedding algorithm,experimental setup has word embedding algorithm,0.5125848054885864
Blogs,3,26,experimental-setup,pretrained,means that,glove representations,pretrained means that glove representations,0.5798377990722656
Blogs,3,26,experimental-setup,experimental setup,has,pretrained,experimental setup has pretrained,0.572638988494873
Blogs,3,29,experimental-setup,lengths,of,matrices,lengths of matrices,0.5812389254570007
Blogs,3,29,experimental-setup,lengths,equal,number of words,lengths equal number of words,0.6061241030693054
Blogs,3,29,experimental-setup,matrices,equal,number of words,matrices equal number of words,0.6168567538261414
Blogs,3,29,experimental-setup,number of words,in,context and the query,number of words in context and the query,0.5360663533210754
Blogs,3,29,experimental-setup,j,for,query matrix,j for query matrix,0.6363967061042786
Blogs,3,29,experimental-setup,experimental setup,has,lengths,experimental setup has lengths,0.46581366658210754
Blogs,3,30,experimental-setup,d1,is,preset value,d1 is preset value,0.585056483745575
Blogs,3,30,experimental-setup,preset value,equal to,vector dimension,preset value equal to vector dimension,0.6554079651832581
Blogs,3,30,experimental-setup,vector dimension,from,glove,vector dimension from glove,0.61652010679245
Blogs,3,30,experimental-setup,height,has,d1,height has d1,0.5927039384841919
Blogs,3,30,experimental-setup,experimental setup,has,height,experimental setup has height,0.5061519145965576
Blogs,3,30,experimental-setup,experimental setup,has,d1,experimental setup has d1,0.5502741932868958
Blogs,3,49,experimental-setup,lengths,of,matrices,lengths of matrices,0.5812389254570007
Blogs,3,49,experimental-setup,matrices,equal,number of words,matrices equal number of words,0.6168567538261414
Blogs,3,49,experimental-setup,number of words,in,query - t and j,number of words in query - t and j,0.5723267197608948
Blogs,3,49,experimental-setup,number of words,Context and in,query - t and j,number of words Context and in query - t and j,0.695578932762146
Blogs,3,49,experimental-setup,experimental setup,has,lengths,experimental setup has lengths,0.46581366658210754
Blogs,3,50,experimental-setup,height,denoted as,d2,height denoted as d2,0.7078100442886353
Blogs,3,50,experimental-setup,experimental setup,has,height,experimental setup has height,0.5061519145965576
Blogs,3,63,experimental-setup,vectors,are,randomly initialized,vectors are randomly initialized,0.6242585778236389
Blogs,3,63,experimental-setup,experimental setup,has,vectors,experimental setup has vectors,0.47026243805885315
Blogs,3,65,experimental-setup,d and l,are,4 and 9,d and l are 4 and 9,0.659995973110199
Blogs,3,69,experimental-setup,d,same as,height of c,d same as height of c,0.6934370994567871
Blogs,3,69,experimental-setup,height,has,d,height has d,0.620544970035553
Blogs,3,69,experimental-setup,experimental setup,has,height,experimental setup has height,0.5061519145965576
Blogs,3,69,experimental-setup,experimental setup,has,d,experimental setup has d,0.5380780100822449
Blogs,3,70,experimental-setup,values,within,h,values within h,0.6976172924041748
Blogs,3,70,experimental-setup,h,are,randomly initialized,h are randomly initialized,0.602252721786499
Blogs,3,70,experimental-setup,adjusted,during,model training,adjusted during model training,0.7512238621711731
Blogs,3,70,experimental-setup,experimental setup,has,values,experimental setup has values,0.5088667869567871
Blogs,3,74,experimental-setup,scalar,is,0.1,scalar is 0.1,0.5833733677864075
Blogs,3,75,experimental-setup,scalar,set as,first element,scalar set as first element,0.6618112325668335
Blogs,3,75,experimental-setup,first element,of,new vector,first element of new vector,0.5950988531112671
Blogs,3,75,experimental-setup,new vector,called,f.,new vector called f.,0.6218178272247314
Blogs,3,75,experimental-setup,experimental setup,has,scalar,experimental setup has scalar,0.4798727035522461
Blogs,3,77,experimental-setup,one character,to,right,one character to right,0.6198358535766602
Blogs,3,77,experimental-setup,same operations,to get,another scalar,same operations to get another scalar,0.6232241988182068
Blogs,3,77,experimental-setup,h,has,one character,h has one character,0.6433922648429871
Blogs,3,77,experimental-setup,experimental setup,slide,h,experimental setup slide h,0.7089192271232605
Blogs,3,78,experimental-setup,scalar,set as,second element of f.,scalar set as second element of f.,0.6509717106819153
Blogs,3,78,experimental-setup,experimental setup,has,scalar,experimental setup has scalar,0.4798727035522461
Blogs,3,81,experimental-setup,vector f,is,numeric representation,vector f is numeric representation,0.5890950560569763
Blogs,3,81,experimental-setup,numeric representation,of,word   absurdity  ,numeric representation of word   absurdity  ,0.5286082625389099
Blogs,3,81,experimental-setup,word   absurdity  ,look at,word,word   absurdity   look at word,0.5478807091712952
Blogs,3,81,experimental-setup,word,has,three characters at a time,word has three characters at a time,0.6183351278305054
Blogs,3,81,experimental-setup,experimental setup,has,vector f,experimental setup has vector f,0.5405944585800171
Blogs,3,86,experimental-setup,maximum value,in,f.,maximum value in f.,0.5342445373535156
Blogs,3,86,experimental-setup,experimental setup,record,maximum value,experimental setup record maximum value,0.6441302299499512
Blogs,3,88,experimental-setup,number,is,0.7,number is 0.7,0.5730307102203369
Blogs,3,113,experimental-setup,bias,added to,w*y,bias added to w*y,0.6664227247238159
Blogs,3,113,experimental-setup,b,added to,w*y,b added to w*y,0.6696691513061523
Blogs,3,113,experimental-setup,bias,has,b,bias has b,0.5820522308349609
Blogs,3,113,experimental-setup,experimental setup,has,bias,experimental setup has bias,0.5073955059051514
Blogs,3,113,experimental-setup,experimental setup,has,b,experimental setup has b,0.5136634111404419
Blogs,3,114,experimental-setup,nonlinear function g,such as,relu,nonlinear function g such as relu,0.6641255021095276
Blogs,3,114,experimental-setup,nonlinear function g,such as,tanh,nonlinear function g such as tanh,0.6551912426948547
Blogs,3,117,experimental-setup,value of t,calculated using,sigmoid function,value of t calculated using sigmoid function,0.6880456805229187
Blogs,3,117,experimental-setup,value of t,between,0 and 1,value of t between 0 and 1,0.6266050934791565
Blogs,3,117,experimental-setup,experimental setup,has,value of t,experimental setup has value of t,0.5328866839408875
Blogs,3,141,experimental-setup,feel free to jump ahead,if,short on time,feel free to jump ahead if short on time,0.5870978236198425
Blogs,3,141,experimental-setup,bidaf,has,works,bidaf has works,0.6455093026161194
Blogs,3,147,experimental-setup,context matrix h,is,d-by -t matrix,context matrix h is d-by -t matrix,0.5463970899581909
Blogs,3,147,experimental-setup,query matrix u,is,d-by -j matrix,query matrix u is d-by -j matrix,0.5689521431922913
Blogs,3,147,experimental-setup,experimental setup,has,context matrix h,experimental setup has context matrix h,0.530180811882019
Blogs,3,33,experiments,character level embedding okay,with,glove,character level embedding okay with glove,0.6412068009376526
Blogs,3,33,experiments,character level embedding okay,obtain,vector representations,character level embedding okay obtain vector representations,0.5251196026802063
Blogs,3,33,experiments,glove,obtain,vector representations,glove obtain vector representations,0.5625924468040466
Blogs,3,33,experiments,vector representations,of,most words,vector representations of most words,0.563634991645813
Blogs,3,35,experiments,pretrained glove   dictionary  ,is,huge,pretrained glove   dictionary   is huge,0.5025109052658081
Blogs,3,35,experiments,pretrained glove   dictionary  ,contains,millions of words,pretrained glove   dictionary   contains millions of words,0.6070829629898071
Blogs,3,58,experiments,input sequence,can be,music,input sequence can be music,0.677629292011261
Blogs,3,58,experiments,input sequence,can be,dna,input sequence can be dna,0.6825842261314392
Blogs,3,58,experiments,input sequence,can be,voice recording,input sequence can be voice recording,0.6838715672492981
Blogs,3,58,experiments,input sequence,can be,weblogs,input sequence can be weblogs,0.6592928767204285
Blogs,3,3,model,high- level overview,of,bidaf,high- level overview of bidaf,0.6386479139328003
Blogs,3,4,model,model,receives,incoming query,model receives incoming query,0.6898671388626099
Blogs,3,4,model,model,first portion of,bidaf architecture,model first portion of bidaf architecture,0.629551887512207
Blogs,3,4,model,model,receives,incoming query,model receives incoming query,0.6898671388626099
Blogs,3,8,model,bidaf,first,tokenized,bidaf first tokenized,0.7782459855079651
Blogs,3,8,model,incoming query and its context,first,tokenized,incoming query and its context first tokenized,0.7420491576194763
Blogs,3,8,model,bidaf,has,incoming query and its context,bidaf has incoming query and its context,0.6034418344497681
Blogs,3,8,model,model,In,bidaf,model In bidaf,0.6279520392417908
Blogs,3,10,model,depiction,of,tokenization,depiction of tokenization,0.5825029015541077
Blogs,3,11,model,incoming query,tokenized into,constituent words,incoming query tokenized into constituent words,0.7227237224578857
Blogs,3,11,model,accompanying context,tokenized into,constituent words,accompanying context tokenized into constituent words,0.7105244994163513
Blogs,3,11,model,model,has,incoming query,model has incoming query,0.5977093577384949
Blogs,3,12,model,model,Step 2 .,word level embedding,model Step 2 . word level embedding,0.5407243371009827
Blogs,3,12,model,model,has,word level embedding,model has word level embedding,0.5040550827980042
Blogs,3,13,model,resulting words,subjected to,embedding process,resulting words subjected to embedding process,0.6812504529953003
Blogs,3,13,model,resulting words,converted into,vectors of numbers,resulting words converted into vectors of numbers,0.6074107885360718
Blogs,3,13,model,embedding process,converted into,vectors of numbers,embedding process converted into vectors of numbers,0.6581708192825317
Blogs,3,13,model,model,has,resulting words,model has resulting words,0.594327986240387
Blogs,3,15,model,embedding,done on,three levels of granularity,embedding done on three levels of granularity,0.6826220154762268
Blogs,3,15,model,three levels of granularity,on,"character , word","three levels of granularity on character , word",0.5728157162666321
Blogs,3,15,model,bidaf,has,embedding,bidaf has embedding,0.6449507474899292
Blogs,3,15,model,model,In,bidaf,model In bidaf,0.6279520392417908
Blogs,3,16,model,first embedding layer,has,word embedding,first embedding layer has word embedding,0.5647952556610107
Blogs,3,16,model,model,focus on,first embedding layer,model focus on first embedding layer,0.690554678440094
Blogs,3,18,model,brief overview,of,glove,brief overview of glove,0.6517413854598999
Blogs,3,18,model,model,give,brief overview,model give brief overview,0.613551676273346
Blogs,3,20,model,model,has,vector representations,model has vector representations,0.602286159992218
Blogs,3,21,model,glove vectors,encapsulate,semantic and syntactic information,glove vectors encapsulate semantic and syntactic information,0.7058111429214478
Blogs,3,21,model,some cool stuff,using,vectors,some cool stuff using vectors,0.6977759003639221
Blogs,3,21,model,model,perform,some cool stuff,model perform some cool stuff,0.6600148677825928
Blogs,3,24,model,distance,between,two glove vectors,distance between two glove vectors,0.671802282333374
Blogs,3,24,model,two glove vectors,in,space,two glove vectors in space,0.559890627861023
Blogs,3,24,model,two glove vectors,encapsulates,meaningful concept,two glove vectors encapsulates meaningful concept,0.7379266619682312
Blogs,3,24,model,meaningful concept,such as,gender,meaningful concept such as gender,0.6407710313796997
Blogs,3,24,model,meaningful concept,such as,tense variation,meaningful concept such as tense variation,0.639549970626831
Blogs,3,24,model,meaningful concept,such as,country -capital relationship,meaningful concept such as country -capital relationship,0.6232637166976929
Blogs,3,24,model,model,has,distance,model has distance,0.5828990340232849
Blogs,3,27,model,bidaf 's word embedding step,as,simple dictionary lookup step,bidaf 's word embedding step as simple dictionary lookup step,0.549568235874176
Blogs,3,27,model,simple dictionary lookup step,substitute,words,simple dictionary lookup step substitute words,0.6926443576812744
Blogs,3,27,model,words,with,vectors,words with vectors,0.6469592452049255
Blogs,3,27,model,words,has,  keys   of the glove   dictionary,words has   keys   of the glove   dictionary,0.5752651691436768
Blogs,3,27,model,model,think of,bidaf 's word embedding step,model think of bidaf 's word embedding step,0.6802071928977966
Blogs,3,28,model,output,of,word embedding step,output of word embedding step,0.5466209650039673
Blogs,3,28,model,word embedding step,is,two matrices,word embedding step is two matrices,0.5394513607025146
Blogs,3,28,model,model,has,output,model has output,0.5534584522247314
Blogs,3,31,model,word embedding step,for,context,word embedding step for context,0.563772976398468
Blogs,3,31,model,model,depicts,word embedding step,model depicts word embedding step,0.6065270900726318
Blogs,3,32,model,word embedding step,converts,context tokens,word embedding step converts context tokens,0.6112703084945679
Blogs,3,32,model,word embedding step,converts,query tokens,word embedding step converts query tokens,0.6448042392730713
Blogs,3,32,model,context tokens,into,d1 - by -t matrix,context tokens into d1 - by -t matrix,0.5606232285499573
Blogs,3,32,model,query tokens,into,d1 - by - j matrix,query tokens into d1 - by - j matrix,0.5877514481544495
Blogs,3,32,model,model,has,word embedding step,model has word embedding step,0.5299670100212097
Blogs,3,39,model,another embedding mechanism,can handle,oov words,another embedding mechanism can handle oov words,0.7321826815605164
Blogs,3,39,model,model,need,another embedding mechanism,model need another embedding mechanism,0.7035788297653198
Blogs,3,41,model,character level embedding,uses,one-dimensional convolutional neural network ( 1d - cnn ),character level embedding uses one-dimensional convolutional neural network ( 1d - cnn ),0.549409806728363
Blogs,3,41,model,one-dimensional convolutional neural network ( 1d - cnn ),to find,numeric representation,one-dimensional convolutional neural network ( 1d - cnn ) to find numeric representation,0.6073142886161804
Blogs,3,41,model,numeric representation,of,words,numeric representation of words,0.5637677907943726
Blogs,3,41,model,numeric representation,by looking at,character - level compositions,numeric representation by looking at character - level compositions,0.6453671455383301
Blogs,3,41,model,model,has,character level embedding,model has character level embedding,0.5123854875564575
Blogs,3,43,model,several scanners,sliding through,word,several scanners sliding through word,0.6823767423629761
Blogs,3,43,model,model,think of,1d - cnn,model think of 1d - cnn,0.6200121641159058
Blogs,3,45,model,sweep along,extract,information,sweep along extract information,0.7319626212120056
Blogs,3,45,model,information,from,characters,information from characters,0.5751637816429138
Blogs,3,46,model,information,from,different scanners,information from different scanners,0.5623261332511902
Blogs,3,46,model,scanning process,has,information,scanning process has information,0.5843161940574646
Blogs,3,46,model,model,At,scanning process,model At scanning process,0.6002854108810425
Blogs,3,46,model,model,end of,scanning process,model end of scanning process,0.6744897365570068
Blogs,3,47,model,output,of,character embedding step,output of character embedding step,0.5569549798965454
Blogs,3,47,model,output,of,word embedding step,output of word embedding step,0.5466209650039673
Blogs,3,47,model,model,has,output,model has output,0.5534584522247314
Blogs,3,48,model,two matrices,one for,context,two matrices one for context,0.7547421455383301
Blogs,3,48,model,two matrices,other for,query,two matrices other for query,0.6757853627204895
Blogs,3,48,model,model,obtain,two matrices,model obtain two matrices,0.6443164944648743
Blogs,3,51,model,two matrices,concatenated with,matrices,two matrices concatenated with matrices,0.7322582006454468
Blogs,3,51,model,matrices,obtained from,word embedding step,matrices obtained from word embedding step,0.6043795347213745
Blogs,3,51,model,model,has,two matrices,model has two matrices,0.5807240009307861
Blogs,3,53,model,model,motivates,use of 1d - cnn,model motivates use of 1d - cnn,0.7120264172554016
Blogs,3,57,model,1d - cnn,is,algorithm,1d - cnn is algorithm,0.5667182803153992
Blogs,3,57,model,algorithm,capable of extracting information,shorter segments,algorithm capable of extracting information shorter segments,0.7809370756149292
Blogs,3,57,model,shorter segments,of,long input sequence,shorter segments of long input sequence,0.5954853296279907
Blogs,3,57,model,model,has,1d - cnn,model has 1d - cnn,0.5326250195503235
Blogs,3,59,model,long input sequence,is,words,long input sequence is words,0.5493347644805908
Blogs,3,59,model,  shorter segments,are,letter combinations and morphemes,  shorter segments are letter combinations and morphemes,0.5632342100143433
Blogs,3,59,model,letter combinations and morphemes,make up,words,letter combinations and morphemes make up words,0.6258824467658997
Blogs,3,59,model,bidaf,has,  shorter segments,bidaf has   shorter segments,0.6225587725639343
Blogs,3,59,model,model,In,bidaf,model In bidaf,0.6279520392417908
Blogs,3,62,model,each character,in,word,each character in word,0.5132124423980713
Blogs,3,62,model,each character,as,vector of dimension d,each character as vector of dimension d,0.5921093225479126
Blogs,3,64,model,d,height of,matrix,d height of matrix,0.7452499866485596
Blogs,3,68,model,convolutional filter,is,matrix,convolutional filter is matrix,0.6090012192726135
Blogs,3,68,model,matrix,scan,word,matrix scan word,0.8043317198753357
Blogs,3,68,model,model,has,convolutional filter,model has convolutional filter,0.5597600340843201
Blogs,3,71,model,h,on,leftmost corner of c,h on leftmost corner of c,0.5739612579345703
Blogs,3,71,model,element - wise product,of H,projection on c,element - wise product of H projection on c,0.6596857905387878
Blogs,3,71,model,model,overlay,h,model overlay h,0.8276661038398743
Blogs,3,72,model,same dimension,as,h - a d x l matrix,same dimension as h - a d x l matrix,0.5891241431236267
Blogs,3,73,model,all the numbers,in,output matrix,all the numbers in output matrix,0.5436996817588806
Blogs,3,73,model,all the numbers,to get,scalar,all the numbers to get scalar,0.7429223656654358
Blogs,3,80,model,one more element,to,f,one more element to f,0.6008820533752441
Blogs,3,80,model,vector,reaches,maximum length,vector reaches maximum length,0.7167596817016602
Blogs,3,80,model,maximum length,is,l - w + 1,maximum length is l - w + 1,0.5528243780136108
Blogs,3,83,model,fancier terms,call,h,fancier terms call h,0.6890740990638733
Blogs,3,83,model,fancier terms,call,position invariant,fancier terms call position invariant,0.6432821154594421
Blogs,3,83,model,model,In,fancier terms,model In fancier terms,0.5364512205123901
Blogs,3,84,model,position invariance,of,convolutional filters,position invariance of convolutional filters,0.583705484867096
Blogs,3,84,model,model,has,position invariance,model has position invariance,0.5643609762191772
Blogs,3,92,model,convolutional filter,might have,different width,convolutional filter might have different width,0.6116951704025269
Blogs,3,92,model,model,has,convolutional filter,model has convolutional filter,0.5597600340843201
Blogs,3,94,model,h ',across,word,h ' across word,0.7454484701156616
Blogs,3,94,model,word,to get,vector f,word to get vector f,0.6434532403945923
Blogs,3,94,model,max -pooling,on,f,max -pooling on f,0.5567720532417297
Blogs,3,96,model,scanning process,with,different convolutional filters,scanning process with different convolutional filters,0.6496800780296326
Blogs,3,96,model,several times,with,different convolutional filters,several times with different convolutional filters,0.6159746646881104
Blogs,3,96,model,scanning process,has,several times,scanning process has several times,0.5464784502983093
Blogs,3,96,model,model,repeat,scanning process,model repeat scanning process,0.6919410228729248
Blogs,3,97,model,summary scalars,from,different scanning processes,summary scalars from different scanning processes,0.6010446548461914
Blogs,3,97,model,summary scalars,character embedding of,word,summary scalars character embedding of word,0.6368601322174072
Blogs,3,97,model,model,has,summary scalars,model has summary scalars,0.5150643587112427
Blogs,3,98,model,character - based representation,of,word,character - based representation of word,0.5885182619094849
Blogs,3,98,model,model,obtained,character - based representation,model obtained character - based representation,0.5942956209182739
Blogs,3,101,model,two sets of vector representations,for,our words,two sets of vector representations for our words,0.62939453125
Blogs,3,101,model,one,from,glove ( word ) embedding,one from glove ( word ) embedding,0.612097442150116
Blogs,3,101,model,other,from,1d - cnn ( character ) embedding,other from 1d - cnn ( character ) embedding,0.5690129995346069
Blogs,3,101,model,two sets of vector representations,has,one,two sets of vector representations has one,0.5996428728103638
Blogs,3,101,model,model,obtained,two sets of vector representations,model obtained two sets of vector representations,0.5818239450454712
Blogs,3,104,model,concatenation,produces,two matrices,concatenation produces two matrices,0.6628426909446716
Blogs,3,104,model,two matrices,one for,context,two matrices one for context,0.7547421455383301
Blogs,3,104,model,two matrices,other for,query,two matrices other for query,0.6757853627204895
Blogs,3,104,model,model,has,concatenation,model has concatenation,0.5566678643226624
Blogs,3,105,model,height,is,d,height is d,0.6590512990951538
Blogs,3,105,model,d,sum of,d2,d sum of d2,0.6421137452125549
Blogs,3,105,model,model,has,height,model has height,0.5507778525352478
Blogs,3,108,model,concatenated matrices,from,word embedding and the character embedding steps,concatenated matrices from word embedding and the character embedding steps,0.5849976539611816
Blogs,3,108,model,model,has,concatenated matrices,model has concatenated matrices,0.6014061570167542
Blogs,3,112,model,input vector y,into,single layer,input vector y into single layer,0.528903067111969
Blogs,3,112,model,input vector y,three things will happen before,output z is produced,input vector y three things will happen before output z is produced,0.6680402159690857
Blogs,3,112,model,single layer,of,feed forward neural network,single layer of feed forward neural network,0.5854779481887817
Blogs,3,112,model,model,insert,input vector y,model insert input vector y,0.6754369139671326
Blogs,3,115,model,remaining fraction,permitted to pass through,network untransformed,remaining fraction permitted to pass through network untransformed,0.7282444834709167
Blogs,3,115,model,model,In,highway network,model In highway network,0.5203002095222473
Blogs,3,116,model,fractions,managed by,t,fractions managed by t,0.6952972412109375
Blogs,3,116,model,fractions,managed by,transform gate,fractions managed by transform gate,0.7154518961906433
Blogs,3,116,model,fractions,managed by,( 1 - t ),fractions managed by ( 1 - t ),0.696894645690918
Blogs,3,116,model,fractions,managed by,carry gate,fractions managed by carry gate,0.6815973520278931
Blogs,3,116,model,t,has,transform gate,t has transform gate,0.6230713725090027
Blogs,3,116,model,( 1 - t ),has,carry gate,( 1 - t ) has carry gate,0.5964239239692688
Blogs,3,118,model,open,in,app,open in app,0.6005759239196777
Blogs,3,118,model,open,Upon,exiting,open Upon exiting,0.6840267181396484
Blogs,3,118,model,app,Upon,exiting,app Upon exiting,0.6774815320968628
Blogs,3,118,model,transformed fraction,of,input,transformed fraction of input,0.6075083017349243
Blogs,3,118,model,transformed fraction,summed with,untransformed fraction,transformed fraction summed with untransformed fraction,0.5896160006523132
Blogs,3,118,model,upgrade,has,open,upgrade has open,0.6405450701713562
Blogs,3,118,model,upgrade,has,transformed fraction,upgrade has transformed fraction,0.612041711807251
Blogs,3,118,model,open,has,transformed fraction,open has transformed fraction,0.5901205539703369
Blogs,3,118,model,exiting,has,network,exiting has network,0.599574625492096
Blogs,3,118,model,exiting,has,transformed fraction,exiting has transformed fraction,0.5874109268188477
Blogs,3,118,model,network,has,transformed fraction,network has transformed fraction,0.6142281889915466
Blogs,3,119,model,highway network 's role,adjust,relative contribution,highway network 's role adjust relative contribution,0.6188538670539856
Blogs,3,119,model,relative contribution,from,word embedding and the character embedding steps,relative contribution from word embedding and the character embedding steps,0.5801364779472351
Blogs,3,119,model,model,has,highway network 's role,model has highway network 's role,0.5309397578239441
Blogs,3,122,model,outputs,of,highway network,outputs of highway network,0.5957189202308655
Blogs,3,122,model,highway network,are,two matrices,highway network are two matrices,0.5858877897262573
Blogs,3,122,model,highway network,one for,query,highway network one for query,0.7005670070648193
Blogs,3,122,model,two matrices,one for,context,two matrices one for context,0.7547421455383301
Blogs,3,122,model,query,has,d-by -j matrix,query has d-by -j matrix,0.5526731610298157
Blogs,3,122,model,model,has,outputs,model has outputs,0.5564337968826294
Blogs,3,123,model,adjusted vector representations,of,words,adjusted vector representations of words,0.6148231625556946
Blogs,3,123,model,adjusted vector representations,of,context,adjusted vector representations of context,0.5995935797691345
Blogs,3,123,model,words,in,query,words in query,0.517264723777771
Blogs,3,123,model,context,from,word and character embedding steps,context from word and character embedding steps,0.5756201148033142
Blogs,3,123,model,model,represent,adjusted vector representations,model represent adjusted vector representations,0.6370477676391602
Blogs,3,124,model,model,Step 5 .,contextual embedding,model Step 5 . contextual embedding,0.544873058795929
Blogs,3,126,model,word representations,n't take into account,words ' contextual meaning,word representations n't take into account words ' contextual meaning,0.7275159955024719
Blogs,3,127,model,pair of homonyms,such as,words,pair of homonyms such as words,0.6272294521331787
Blogs,3,127,model,word and character embedding alone,has,pair of homonyms,word and character embedding alone has pair of homonyms,0.5883234739303589
Blogs,3,127,model,words,has,tear,words has tear,0.5791891813278198
Blogs,3,127,model,model,rely on,word and character embedding alone,model rely on word and character embedding alone,0.716202974319458
Blogs,3,129,model,embedding mechanism,can understand,word,embedding mechanism can understand word,0.6829057335853577
Blogs,3,129,model,word,in,its context,word in its context,0.5676901340484619
Blogs,3,131,model,contextual embedding layer,consists of,long- short - term-memory ( lstm ) sequences,contextual embedding layer consists of long- short - term-memory ( lstm ) sequences,0.6256505846977234
Blogs,3,131,model,model,has,contextual embedding layer,model has contextual embedding layer,0.5365297198295593
Blogs,3,133,model,input sequence ( such as a string of text ),into,normal forward lstm layer,input sequence ( such as a string of text ) into normal forward lstm layer,0.523936927318573
Blogs,3,133,model,output sequence,for,each timestep,output sequence for each timestep,0.628809928894043
Blogs,3,133,model,output sequence,encode,information,output sequence encode information,0.772636353969574
Blogs,3,133,model,information,from,timestep,information from timestep,0.5170345306396484
Blogs,3,133,model,information,from,past timesteps,information from past timesteps,0.5296903848648071
Blogs,3,133,model,information,as well as,past timesteps,information as well as past timesteps,0.6082490682601929
Blogs,3,133,model,input sequence ( such as a string of text ),has,output sequence,input sequence ( such as a string of text ) has output sequence,0.5718197822570801
Blogs,3,133,model,model,enter,input sequence ( such as a string of text ),model enter input sequence ( such as a string of text ),0.6449017524719238
Blogs,3,134,model,output embedding,for,each word,output embedding for each word,0.6228036284446716
Blogs,3,134,model,output embedding,for,words,output embedding for words,0.6449636816978455
Blogs,3,134,model,contextual information,from,words,contextual information from words,0.5492056608200073
Blogs,3,139,model,character embedding step,converts,context tokens,character embedding step converts context tokens,0.6212464570999146
Blogs,3,139,model,character embedding step,converts,query tokens,character embedding step converts query tokens,0.649284303188324
Blogs,3,139,model,context tokens,into,d2 - by -t matrix,context tokens into d2 - by -t matrix,0.5608829259872437
Blogs,3,139,model,context tokens,into,d2 - by - j matrix,context tokens into d2 - by - j matrix,0.5715814232826233
Blogs,3,139,model,query tokens,into,d2 - by - j matrix,query tokens into d2 - by - j matrix,0.58951735496521
Blogs,3,139,model,model,has,character embedding step,model has character embedding step,0.5281268954277039
Blogs,3,140,model,model,explain,1d - cnn,model explain 1d - cnn,0.6719731092453003
Blogs,3,143,model,model,has,( backwards ) and future ( forward ) states,model has ( backwards ) and future ( forward ) states,0.5879483222961426
Blogs,3,144,model,contextual information,about,surrounding phrases,contextual information about surrounding phrases,0.6546406149864197
Blogs,3,144,model,surrounding phrases,of,word,surrounding phrases of word,0.5961940288543701
Blogs,3,144,model,model,has,each word representation,model has each word representation,0.5411648154258728
Blogs,3,145,model,output,of,contextual embedding step,output of contextual embedding step,0.5227981805801392
Blogs,3,145,model,contextual embedding step,is,two matrices,contextual embedding step is two matrices,0.5398390889167786
Blogs,3,145,model,two matrices,other from,query,two matrices other from query,0.6261128783226013
Blogs,3,145,model,model,has,output,model has output,0.5534584522247314
Blogs,3,146,model,model,has,bidaf paper,model has bidaf paper,0.6197032928466797
Blogs,3,149,model,contextual embedding step,uses,bi-lstm,contextual embedding step uses bi-lstm,0.5600143074989319
Blogs,3,149,model,bi-lstm,to embed,contextual information,bi-lstm to embed contextual information,0.6883023381233215
Blogs,3,149,model,contextual information,into,output matrices h and u,contextual information into output matrices h and u,0.5641095042228699
Blogs,3,149,model,model,has,contextual embedding step,model has contextual embedding step,0.5588962435722351
Blogs,3,150,model,embedding layers,in,bidaf,embedding layers in bidaf,0.5456404089927673
Blogs,3,151,model,embedding outputs h and u,carry within,"syntactic , semantic as well as contextual information","embedding outputs h and u carry within syntactic , semantic as well as contextual information",0.6898051500320435
Blogs,3,151,model,"syntactic , semantic as well as contextual information",from,all words,"syntactic , semantic as well as contextual information from all words",0.5546777248382568
Blogs,3,151,model,all words,in,query and the context,all words in query and the context,0.5323838591575623
Blogs,3,152,model,h and u,in,next step,h and u in next step,0.5705700516700745
Blogs,3,152,model,h and u,fuse together,information,h and u fuse together information,0.6963339447975159
Blogs,3,152,model,next step,has,attention step,next step has attention step,0.6351919174194336
Blogs,3,152,model,model,use,h and u,model use h and u,0.7107677459716797
Blogs,3,155,model,model upgrade open in,has,app,model upgrade open in has app,0.6340571641921997
Blogs,3,34,results,results,has,glove representations,results has glove representations,0.5334563255310059
Blogs,3,54,results,word,has,underestimate,word has underestimate,0.631636381149292
Blogs,3,82,results,values,within,convolution filter h,values within convolution filter h,0.6917004585266113
Blogs,3,82,results,do n't change,as,h,do n't change as h,0.6111190915107727
Blogs,3,82,results,h,slides through,word,h slides through word,0.7996736764907837
Blogs,3,82,results,values,has,do n't change,values has do n't change,0.6144164800643921
Blogs,3,82,results,convolution filter h,has,do n't change,convolution filter h has do n't change,0.5695825815200806
Blogs,3,99,results,end,of,little digression,end of little digression,0.6614987850189209
Blogs,3,99,results,little digression,on,1d - cnn,little digression on 1d - cnn,0.547106146812439
Blogs,3,106,results,same,as,predecessor matrices,same as predecessor matrices,0.5775545239448547
Blogs,3,106,results,j,for,query matrix,j for query matrix,0.6363967061042786
Blogs,3,106,results,results,has,lengths,results has lengths,0.43406230211257935
Blogs,3,120,results,oov word,such as,misunderestimate,oov word such as misunderestimate,0.6303461790084839
Blogs,3,120,results,relative importance,of,word 's 1d - cnn representation,relative importance of word 's 1d - cnn representation,0.5691156983375549
Blogs,3,120,results,increase,has,relative importance,increase has relative importance,0.5369927287101746
Blogs,3,121,results,common and unambiguous english word,such as,table,common and unambiguous english word such as table,0.6428605914115906
Blogs,3,121,results,common and unambiguous english word,to have,more equal contribution,common and unambiguous english word to have more equal contribution,0.6126974821090698
Blogs,3,121,results,more equal contribution,from,glove and 1d - cnn,more equal contribution from glove and 1d - cnn,0.5980823040008545
Blogs,3,128,results,results,might confuse,our model,results might confuse our model,0.7442048788070679
Blogs,3,138,results,answer,found,verbatim,answer found verbatim,0.6214848756790161
Blogs,3,138,results,verbatim,in,context,verbatim in context,0.5337438583374023
Blogs,3,138,results,results,Notice,answer,results Notice answer,0.5692696571350098
Blogs,3,142,results,ca n't sleep well,without understanding,every moving part,ca n't sleep well without understanding every moving part,0.8199056386947632
Blogs,3,142,results,results,are,type of person,results are type of person,0.485649973154068
Blogs,4,4,baselines,agents,rst train,machine learning methods,agents rst train machine learning methods,0.7049789428710938
Blogs,4,4,baselines,agents,using,machine learning methods,agents using machine learning methods,0.6613703370094299
Blogs,4,4,baselines,machine learning methods,before,continuous learning,machine learning methods before continuous learning,0.6047047972679138
Blogs,4,4,baselines,continuous learning,through,rl,continuous learning through rl,0.6742528080940247
Blogs,4,7,baselines,direct and accurate answers,to,user queries,direct and accurate answers to user queries,0.5629478693008423
Blogs,4,12,baselines,information,has,state tracker,information has state tracker,0.5815158486366272
Blogs,4,17,experiments,task - oriented agents,have access to,external database,task - oriented agents have access to external database,0.6054092049598694
Blogs,4,13,model,essential information,has,dialog policy,essential information has dialog policy,0.5763856172561646
Blogs,4,13,model,model,Tracking,state of the conversation,model Tracking state of the conversation,0.8081952333450317
Blogs,4,13,model,model,Tracking,essential information,model Tracking essential information,0.8109878301620483
Blogs,4,16,model,4 components,in,task - oriented conversational ai,4 components in task - oriented conversational ai,0.5108518600463867
Blogs,4,22,model,top- and low-level processes,captured using,reinforcement learning ( rl ) framework,top- and low-level processes captured using reinforcement learning ( rl ) framework,0.7021026611328125
Blogs,4,22,model,model,formulated using,markov decision processes ( mdps ),model formulated using markov decision processes ( mdps ),0.7225844860076904
Blogs,4,24,model,agent,receives,reward,agent receives reward,0.6795347332954407
Blogs,4,24,model,agent,observes,new state,agent observes new state,0.7013369202613831
Blogs,4,24,model,reward,observes,new state,reward observes new state,0.700516402721405
Blogs,4,24,model,new state,repeating,cycle,new state repeating cycle,0.7857876420021057
Blogs,4,24,model,cycle,until,end,cycle until end,0.7840014100074768
Blogs,4,24,model,model,has,agent,model has agent,0.5836576819419861
Blogs,4,25,model,agent,nd,optimal policies,agent nd optimal policies,0.6142334938049316
Blogs,4,25,model,optimal policies,maximise,expected rewards,optimal policies maximise expected rewards,0.7056490778923035
Blogs,4,25,model,model,has,objective,model has objective,0.5278581380844116
Blogs,4,26,model,rl,where,state-action space,rl where state-action space,0.6243921518325806
Blogs,4,26,model,state-action space,map to,different reward functions,state-action space map to different reward functions,0.6714636087417603
Blogs,4,32,model,user input and knowledge,into,neural semantic representations ( embeddings ),user input and knowledge into neural semantic representations ( embeddings ),0.5643311738967896
Blogs,4,32,model,reasoning,in,neural space,reasoning in neural space,0.5524348616600037
Blogs,4,32,model,reasoning,to generate,answer vector,reasoning to generate answer vector,0.7252705693244934
Blogs,4,32,model,model,Encoding,user input and knowledge,model Encoding user input and knowledge,0.7845951914787292
Blogs,4,9,results,smooth interactions,with,user,smooth interactions with user,0.6733927130699158
Blogs,4,9,results,results,Provide,smooth interactions,results Provide smooth interactions,0.5788649916648865
Blogs,4,28,results,reward functions,seems,contradictory,reward functions seems contradictory,0.6641049981117249
Blogs,4,28,results,contradictory,in terms of,cps,contradictory in terms of cps,0.7498951554298401
Blogs,4,28,results,cps,between,task - oriented and chitchat,cps between task - oriented and chitchat,0.6854963898658752
Blogs,4,28,results,results,has,reward functions,results has reward functions,0.5029773116111755
Blogs,4,29,results,microsoft xiaoice,optimised for,expected cps,microsoft xiaoice optimised for expected cps,0.7390678524971008
Blogs,4,29,results,results,has,microsoft xiaoice,results has microsoft xiaoice,0.5458967685699463
Blogs,4,30,results,results,has,development of neural methods,results has development of neural methods,0.5427517294883728
Blogs,5,4,experiments,our ai system,should be able to,figure out,our ai system should be able to figure out,0.7558225989341736
Blogs,5,4,experiments,our ai system,subject being referenced to,women 's face,our ai system subject being referenced to women 's face,0.6173783540725708
Blogs,5,4,experiments,figure out,subject being referenced to,women 's face,figure out subject being referenced to women 's face,0.6103244423866272
Blogs,5,20,experiments,at least 3 questions ( 5.4 questions,per,image,at least 3 questions ( 5.4 questions per image,0.6234473586082458
Blogs,5,20,experiments,image,10,ground - truth answers,image 10 ground - truth answers,0.575933039188385
Blogs,5,20,experiments,ground - truth answers,from,unique workers,ground - truth answers from unique workers,0.5145652294158936
Blogs,5,3,model,question,should have,common-sense knowledge,question should have common-sense knowledge,0.6657445430755615
Blogs,5,8,model,get started open,build,ai system,get started open build ai system,0.784969687461853
Blogs,5,8,model,ai system,takes as input,image,ai system takes as input image,0.7042003273963928
Blogs,5,8,model,ai system,takes as input,"free-form , openended , or natural language question","ai system takes as input free-form , openended , or natural language question",0.6399048566818237
Blogs,5,8,model,ai system,produces,natural language answer,ai system produces natural language answer,0.5732964277267456
Blogs,5,8,model,"free-form , openended , or natural language question",about,image,"free-form , openended , or natural language question about image",0.6340099573135376
Blogs,5,8,model,natural language answer,as,output,natural language answer as output,0.5155349373817444
Blogs,5,8,model,model,has,get started open,model has get started open,0.606453537940979
Blogs,5,9,model,visual and textual knowledge,from,inputs ( image and question,visual and textual knowledge from inputs ( image and question,0.5244994759559631
Blogs,5,9,model,visual and textual knowledge,combine,two data streams,visual and textual knowledge combine two data streams,0.6443504095077515
Blogs,5,9,model,advanced knowledge,to generate,answer,advanced knowledge to generate answer,0.7054067254066467
Blogs,5,9,model,answer,has,question,answer has question,0.6225500106811523
Blogs,5,9,model,model,learn,visual and textual knowledge,model learn visual and textual knowledge,0.6483874320983887
Blogs,5,16,model,each level,of,question representation,each level of question representation,0.5996202826499939
Blogs,5,16,model,joint question and image co-attention maps,combined,recursively,joint question and image co-attention maps combined recursively,0.604141116142273
Blogs,5,16,model,distribution,over,answers,distribution over answers,0.7464317679405212
Blogs,5,16,model,each level,has,joint question and image co-attention maps,each level has joint question and image co-attention maps,0.5983456373214722
Blogs,5,16,model,question representation,has,joint question and image co-attention maps,question representation has joint question and image co-attention maps,0.5716607570648193
Blogs,5,16,model,model,For,each level,model For each level,0.6538668870925903
Blogs,5,19,model,model,proposes,two co-attention mechanisms,model proposes two co-attention mechanisms,0.6706653237342834
Blogs,5,21,model,model,as,k-class classification problem,model as k-class classification problem,0.5288165807723999
Blogs,5,22,model,hierarchical question - image co-attention,for,visual question answering,hierarchical question - image co-attention for visual question answering,0.5402608513832092
Blogs,5,25,model,model,focus on,question attention,model focus on question attention,0.7843480110168457
Blogs,5,26,model,novel multi-modal attention model,for,vqa,novel multi-modal attention model for vqa,0.5850293636322021
Blogs,5,26,model,model,presents,novel multi-modal attention model,model presents novel multi-modal attention model,0.5911452174186707
Blogs,5,27,model,novel mechanism,jointly reasons for,visual attention and question attention,novel mechanism jointly reasons for visual attention and question attention,0.6626843214035034
Blogs,5,27,model,model,proposes,novel mechanism,model proposes novel mechanism,0.7288005948066711
Blogs,5,28,model,image representation,to guide,question attention,image representation to guide question attention,0.6293826103210449
Blogs,5,28,model,question representation ( s ),to guide,image attention,question representation ( s ) to guide image attention,0.6577883958816528
Blogs,5,28,model,model,has,image representation,model has image representation,0.5320811867713928
Blogs,5,31,model,words,embedded in,vector space,words embedded in vector space,0.6537963151931763
Blogs,5,31,model,vector space,through,embedding matrix,vector space through embedding matrix,0.6402916312217712
Blogs,5,31,model,word level,has,words,word level has words,0.620680034160614
Blogs,5,31,model,model,At,word level,model At word level,0.5542347431182861
Blogs,5,32,model,1 - dimensional convolution neural networks,used on,word representations,1 - dimensional convolution neural networks used on word representations,0.6430030465126038
Blogs,5,32,model,1 - dimensional convolution neural networks,combine,various n-gram responses,1 - dimensional convolution neural networks combine various n-gram responses,0.6716233491897583
Blogs,5,32,model,word representations,with,temporal filters,word representations with temporal filters,0.5980136394500732
Blogs,5,32,model,temporal filters,of,varying support,temporal filters of varying support,0.5835280418395996
Blogs,5,32,model,temporal filters,to capture,information,temporal filters to capture information,0.7058480978012085
Blogs,5,32,model,information,contained in,"unigrams , bigrams , and trigrams","information contained in unigrams , bigrams , and trigrams",0.684658944606781
Blogs,5,32,model,various n-gram responses,by pooling them into,single phrase - level representation,various n-gram responses by pooling them into single phrase - level representation,0.6941105127334595
Blogs,5,32,model,phrase level,has,1 - dimensional convolution neural networks,phrase level has 1 - dimensional convolution neural networks,0.563528299331665
Blogs,5,32,model,model,At,phrase level,model At phrase level,0.5453327894210815
Blogs,5,34,model,recurrent neural network,to encode,entire question,recurrent neural network to encode entire question,0.7473205924034119
Blogs,5,34,model,question level,has,recurrent neural network,question level has recurrent neural network,0.616329550743103
Blogs,5,34,model,model,At,question level,model At question level,0.5807465314865112
Blogs,5,35,model,model,has,image and question attention maps,model has image and question attention maps,0.5567782521247864
Blogs,5,36,model,first mechanism,called,parallel co-attention,first mechanism called parallel co-attention,0.6222692131996155
Blogs,5,36,model,first mechanism,generates,image and question attention simultaneously,first mechanism generates image and question attention simultaneously,0.6366239190101624
Blogs,5,36,model,parallel co-attention,generates,image and question attention simultaneously,parallel co-attention generates image and question attention simultaneously,0.6329327821731567
Blogs,5,36,model,model,has,first mechanism,model has first mechanism,0.562108039855957
Blogs,5,37,model,sequentially alternates,between,generating image and question attentions,sequentially alternates between generating image and question attentions,0.6603378653526306
Blogs,5,38,model,co-attention mechanisms,executed at,all three levels,co-attention mechanisms executed at all three levels,0.6193385124206543
Blogs,5,38,model,all three levels,of,question hierarchy,all three levels of question hierarchy,0.6046931147575378
Blogs,5,38,model,model,has,co-attention mechanisms,model has co-attention mechanisms,0.5356861352920532
Blogs,5,39,model,implementation,of,parallel co-attention model,implementation of parallel co-attention model,0.5759005546569824
Blogs,5,41,model,parallel co-attention,attends to,image and question simultaneously,parallel co-attention attends to image and question simultaneously,0.7395555973052979
Blogs,5,41,model,model,has,parallel co-attention,model has parallel co-attention,0.5636749863624573
Blogs,5,42,model,connected,by calculating,similarity,connected by calculating similarity,0.7057574987411499
Blogs,5,42,model,similarity,between,image and question features,similarity between image and question features,0.661630392074585
Blogs,5,42,model,image and question features,at,all pairs,image and question features at all pairs,0.4956609904766083
Blogs,5,42,model,all pairs,of,image-locations and question -locations,all pairs of image-locations and question -locations,0.612071692943573
Blogs,5,42,model,model,has,image and question,model has image and question,0.5881458520889282
Blogs,5,44,model,affinity matrix c,as,feature,affinity matrix c as feature,0.539795458316803
Blogs,5,44,model,affinity matrix c,has,image and question attention maps,affinity matrix c has image and question attention maps,0.5205664038658142
Blogs,5,44,model,feature,has,image and question attention maps,feature has image and question attention maps,0.599687933921814
Blogs,5,45,model,image and question attention vectors,calculated as,weighted sum,image and question attention vectors calculated as weighted sum,0.5853613018989563
Blogs,5,45,model,weighted sum,of,image features and question features,weighted sum of image features and question features,0.5833389163017273
Blogs,5,6,results,humans,easy for,answer,humans easy for answer,0.7894855737686157
Blogs,5,6,results,humans,see,image,humans see image,0.5910613536834717
Blogs,5,6,results,question,using,our commonsense knowledge,question using our commonsense knowledge,0.661725640296936
Blogs,5,6,results,answer,has,question,answer has question,0.6225500106811523
Blogs,5,6,results,results,As,humans,results As humans,0.5383623242378235
Blogs,5,6,results,results,see,image,results see image,0.6108360290527344
Blogs,5,13,results,ai system,by,number of questions it answers,ai system by number of questions it answers,0.57853764295578
Blogs,5,13,results,number of questions it answers,has,correctly,number of questions it answers has correctly,0.5694257616996765
Blogs,5,13,results,results,evaluate,ai system,results evaluate ai system,0.650922417640686
Blogs,6,23,ablation-analysis,40 % questions,are,  yes / no   questions,40 % questions are   yes / no   questions,0.5456987619400024
Blogs,6,23,ablation-analysis,ablation analysis,Around,40 % questions,ablation analysis Around 40 % questions,0.687505304813385
Blogs,6,20,baselines,two modalities,produce,answer,two modalities produce answer,0.6865079402923584
Blogs,6,20,baselines,answer,multiple,choice,answer multiple choice,0.7557334899902344
Blogs,6,20,baselines,baselines,has,two modalities,baselines has two modalities,0.5920230150222778
Blogs,6,25,baselines,questions,without looking at,images,questions without looking at images,0.6924498677253723
Blogs,6,25,baselines,answer,has,questions,answer has questions,0.5861315131187439
Blogs,6,28,baselines,baseline models,has,random selection prior,baseline models has random selection prior,0.5318406224250793
Blogs,6,28,baselines,baseline models,has,always answer,baseline models has always answer,0.5913687944412231
Blogs,6,28,baselines,random selection prior,has,yes   ),random selection prior has yes   ),0.5809537768363953
Blogs,6,28,baselines,random selection prior,has,always answer,random selection prior has always answer,0.5938412547111511
Blogs,6,28,baselines,yes   ),has,always answer,yes   ) has always answer,0.5947673916816711
Blogs,6,28,baselines,baselines,has,baseline models,baselines has baseline models,0.5690722465515137
Blogs,6,29,baselines,2 - channel model,using,vision and language models,2 - channel model using vision and language models,0.6528878211975098
Blogs,6,29,baselines,2 - channel model,followed by,softmax,2 - channel model followed by softmax,0.6320528984069824
Blogs,6,29,baselines,softmax,over,( k = 1000 ) most frequent answers,softmax over ( k = 1000 ) most frequent answers,0.6363362669944763
Blogs,6,30,baselines,bow q + i method,has,concatenate bow q and i embeddings,bow q + i method has concatenate bow q and i embeddings,0.5517870783805847
Blogs,6,30,baselines,baselines,has,bow q + i method,baselines has bow q + i method,0.5250204801559448
Blogs,6,32,baselines,image embedding,transformed to,1024 - dim,image embedding transformed to 1024 - dim,0.6912571787834167
Blogs,6,32,baselines,1024 - dim,using,fc layer,1024 - dim using fc layer,0.6712774634361267
Blogs,6,32,baselines,tanh nonlinearity,followed by,element - wise multiplication,tanh nonlinearity followed by element - wise multiplication,0.6918802261352539
Blogs,6,32,baselines,element - wise multiplication,of,image and question vectors,element - wise multiplication of image and question vectors,0.6143416166305542
Blogs,6,32,baselines,lstm q + i,has,deeper lstm q + norm i,lstm q + i has deeper lstm q + norm i,0.6331019401550293
Blogs,6,32,baselines,baselines,has,lstm q + i,baselines has lstm q + i,0.5662987232208252
Blogs,6,42,baselines,baselines,has,deeper lstm q,baselines has deeper lstm q,0.5777552127838135
Blogs,6,7,experiments,second version,starting on,27th april 2017 ( today ),second version starting on 27th april 2017 ( today ),0.6780718564987183
Blogs,6,13,experiments,amt,to crowdsource,task of collecting questions and answers,amt to crowdsource task of collecting questions and answers,0.7732805013656616
Blogs,6,13,experiments,task of collecting questions and answers,for,ms coco dataset ( > 200 k images ),task of collecting questions and answers for ms coco dataset ( > 200 k images ),0.5765953660011292
Blogs,6,16,experiments,exhaustive analysis,of,dataset,exhaustive analysis of dataset,0.6198597550392151
Blogs,6,16,experiments,exhaustive analysis,to establish,diversity,exhaustive analysis to establish diversity,0.6956278085708618
Blogs,6,16,experiments,dataset,to establish,diversity,dataset to establish diversity,0.6605679988861084
Blogs,6,16,experiments,question - answers,differ from,standard image captioning datasets,question - answers differ from standard image captioning datasets,0.5162590742111206
Blogs,6,18,experiments,workers,shown,previous questions,workers shown previous questions,0.6702921390533447
Blogs,6,18,experiments,previous questions,writing,new questions,previous questions writing new questions,0.5568267107009888
Blogs,6,18,experiments,new questions,to increase,diversity,new questions to increase diversity,0.7089534401893616
Blogs,6,19,experiments,answers,collected from,multiple users,answers collected from multiple users,0.6945961117744446
Blogs,6,19,experiments,discrepancies,in,answers,discrepancies in answers,0.5638257265090942
Blogs,6,26,experiments,label,if,question,label if question,0.6637109518051147
Blogs,6,26,experiments,question,could be,answered,question could be answered,0.6992555856704712
Blogs,6,26,experiments,answered,using,common sense,answered using common sense,0.7461076378822327
Blogs,6,36,experiments,vision only model,performs,even worse,vision only model performs even worse,0.615168571472168
Blogs,6,36,experiments,even worse,than,model,even worse than model,0.6351568698883057
Blogs,6,36,experiments,  yes  ,as,answer,  yes   as answer,0.5380361080169678
Blogs,6,45,experiments,+ norm i,is,best model,+ norm i is best model,0.5635884404182434
Blogs,6,45,experiments,best model,with,58.16 % accuracy,best model with 58.16 % accuracy,0.5908490419387817
Blogs,6,45,experiments,best model,with,63.09 %,best model with 63.09 %,0.5603604316711426
Blogs,6,45,experiments,best model,far behind,human evaluators,best model far behind human evaluators,0.7117840051651001
Blogs,6,45,experiments,58.16 % accuracy,on,open-ended dataset,58.16 % accuracy on open-ended dataset,0.49950507283210754
Blogs,6,45,experiments,63.09 %,on,multiple - choice,63.09 % on multiple - choice,0.47391241788864136
Blogs,6,45,experiments,human evaluators,has,> 80 % and >90 %,human evaluators has > 80 % and >90 %,0.5407109260559082
Blogs,6,12,hyperparameters,dataset,Created,dataset,dataset Created dataset,0.5747042894363403
Blogs,6,12,hyperparameters,dataset,of,"50000 realistic , abstract images","dataset of 50000 realistic , abstract images",0.5158595442771912
Blogs,6,12,hyperparameters,hyperparameters,Created,dataset,hyperparameters Created dataset,0.5824581980705261
Blogs,6,12,hyperparameters,hyperparameters,has,dataset,hyperparameters has dataset,0.5238766074180603
Blogs,6,14,hyperparameters,three questions,per image,ten answers,three questions per image ten answers,0.7512046694755554
Blogs,6,14,hyperparameters,hyperparameters,has,three questions,hyperparameters has three questions,0.5840114951133728
Blogs,6,33,hyperparameters,embedding,to,mlp - fc neural network,embedding to mlp - fc neural network,0.5662115216255188
Blogs,6,33,hyperparameters,mlp - fc neural network,with,2 hidden layers,mlp - fc neural network with 2 hidden layers,0.6526710987091064
Blogs,6,33,hyperparameters,mlp - fc neural network,with,tanh,mlp - fc neural network with tanh,0.6742526888847351
Blogs,6,33,hyperparameters,1000 neurons and 0.5 dropout ),with,tanh,1000 neurons and 0.5 dropout ) with tanh,0.6509169936180115
Blogs,6,33,hyperparameters,tanh,followed by,softmax,tanh followed by softmax,0.6972625255584717
Blogs,6,33,hyperparameters,2 hidden layers,has,1000 neurons and 0.5 dropout ),2 hidden layers has 1000 neurons and 0.5 dropout ),0.560153603553772
Blogs,6,34,hyperparameters,cross-entropy loss,with,vggnet parameters frozen,cross-entropy loss with vggnet parameters frozen,0.6457487344741821
Blogs,6,34,hyperparameters,hyperparameters,has,cross-entropy loss,hyperparameters has cross-entropy loss,0.5019587278366089
Blogs,6,39,hyperparameters,bag- of- words representation,for,questions,bag- of- words representation for questions,0.6020792126655579
Blogs,6,39,hyperparameters,bag- of- words representation,using,top 1000 words,bag- of- words representation using top 1000 words,0.5703616142272949
Blogs,6,39,hyperparameters,top 1000 words,plus,"top 1 - rst , second and third words","top 1000 words plus top 1 - rst , second and third words",0.6655167937278748
Blogs,6,39,hyperparameters,"top 1 - rst , second and third words",of,questions,"top 1 - rst , second and third words of questions",0.578306257724762
Blogs,6,39,hyperparameters,hyperparameters,has,bag- of- words representation,hyperparameters has bag- of- words representation,0.4860425591468811
Blogs,6,40,hyperparameters,each word,encoded into,300 - dim vectors,each word encoded into 300 - dim vectors,0.7248060703277588
Blogs,6,40,hyperparameters,300 - dim vectors,using,fully connected + tanh nonlinearity,300 - dim vectors using fully connected + tanh nonlinearity,0.668929934501648
Blogs,6,40,hyperparameters,lstm q,has,each word,lstm q has each word,0.5756162405014038
Blogs,6,40,hyperparameters,hyperparameters,has,lstm q,hyperparameters has lstm q,0.5540853142738342
Blogs,6,27,model,suf cient number of questions,in,dataset,suf cient number of questions in dataset,0.5037655830383301
Blogs,6,27,model,suf cient number of questions,required,common sense,suf cient number of questions required common sense,0.7381058931350708
Blogs,6,27,model,common sense,to,answer,common sense to answer,0.6055394411087036
Blogs,6,27,model,model,to establish,suf cient number of questions,model to establish suf cient number of questions,0.6931612491607666
Blogs,6,41,model,embeddings,fed to,lstm,embeddings fed to lstm,0.6258506178855896
Blogs,6,41,model,lstm,to obtain,1024d - dim embedding,lstm to obtain 1024d - dim embedding,0.564490795135498
Blogs,6,41,model,model,has,embeddings,model has embeddings,0.5861875414848328
Blogs,6,43,model,two hidden layers,to obtain,2048 - dim embedding,two hidden layers to obtain 2048 - dim embedding,0.5801377892494202
Blogs,6,44,model,multi-layer perceptron ( mlp ),Combine,image and question embeddings,multi-layer perceptron ( mlp ) Combine image and question embeddings,0.6850100755691528
Blogs,6,44,model,image and question embeddings,to obtain,single embedding,image and question embeddings to obtain single embedding,0.5481895804405212
Blogs,6,44,model,model,has,multi-layer perceptron ( mlp ),model has multi-layer perceptron ( mlp ),0.5748465657234192
Blogs,6,9,results,n-gram statistics based methods,are,not suf cient,n-gram statistics based methods are not suf cient,0.5837054252624512
Blogs,6,9,results,simple,has,n-gram statistics based methods,simple has n-gram statistics based methods,0.5797458291053772
Blogs,6,9,results,results,has,simple,results has simple,0.49837327003479004
Blogs,6,9,results,results,has,n-gram statistics based methods,results has n-gram statistics based methods,0.5028358101844788
Blogs,6,11,results,evaluation,is,easier,evaluation is easier,0.6175525784492493
Blogs,6,17,results,questions,require,image,questions require image,0.7166725397109985
Blogs,6,17,results,image,to be,answered,image to be answered,0.6493809819221497
Blogs,6,17,results,answered,has,correctly,answered has correctly,0.6270310282707214
Blogs,6,22,results,questions,range from,four to ten words,questions range from four to ten words,0.7345609068870544
Blogs,6,22,results,answers,range,one to three words,answers range one to three words,0.6774346232414246
Blogs,6,22,results,answers,from,one to three words,answers from one to three words,0.578562319278717
Blogs,6,22,results,results,has,questions,results has questions,0.5194433331489563
Blogs,6,24,results,inter-human agreement,for,answers,inter-human agreement for answers,0.6425806283950806
Blogs,6,24,results,signi cant ( > 80 % ),has,inter-human agreement,signi cant ( > 80 % ) has inter-human agreement,0.5653268694877625
Blogs,6,24,results,results,has,signi cant ( > 80 % ),results has signi cant ( > 80 % ),0.5153543949127197
Blogs,6,35,results,best model,performs,well,best model performs well,0.6410061120986938
Blogs,6,35,results,best model,performs,poorly,best model performs poorly,0.6263012290000916
Blogs,6,35,results,well,for,answers,well for answers,0.6894671320915222
Blogs,6,35,results,well,for,answers,well for answers,0.6894671320915222
Blogs,6,35,results,well,for,answers,well for answers,0.6894671320915222
Blogs,6,35,results,answers,involving,common visual objects,answers involving common visual objects,0.6583146452903748
Blogs,6,35,results,answers,involving,counts,answers involving counts,0.7362253069877625
Blogs,6,35,results,poorly,for,answers,poorly for answers,0.648111879825592
Blogs,6,35,results,answers,involving,counts,answers involving counts,0.7362253069877625
Blogs,6,35,results,results,has,best model,results has best model,0.5634682774543762
Blogs,7,6,experiments,kb - qa space,go over,symbolic methods,kb - qa space go over symbolic methods,0.6671285629272461
Blogs,7,6,experiments,kb - qa space,go over,neural methods,kb - qa space go over neural methods,0.6796043515205383
Blogs,7,6,experiments,kb - qa space,then,neural methods,kb - qa space then neural methods,0.5671271681785583
Blogs,7,6,experiments,symbolic methods,in,blog post,symbolic methods in blog post,0.5530725717544556
Blogs,7,6,experiments,neural methods,in,tomorrow 's post,neural methods in tomorrow 's post,0.5547437071800232
Blogs,7,8,model,model,review,different neural methods,model review different neural methods,0.6795831918716431
Blogs,7,11,model,s and t,are,entities,s and t are entities,0.6694946885108948
Blogs,7,11,model,model,has,s and t,model has s and t,0.5705221891403198
Blogs,7,12,model,knowledge graph,where,entities,knowledge graph where entities,0.6021568179130554
Blogs,7,12,model,entities,are,nodes,entities are nodes,0.5901741981506348
Blogs,7,12,model,relations,are,directed edges,relations are directed edges,0.5723606944084167
Blogs,7,12,model,model,has,kb,model has kb,0.6005940437316895
Blogs,7,15,model,questions,mapped to,formal meaning representations ( logic form ),questions mapped to formal meaning representations ( logic form ),0.7122165560722351
Blogs,7,15,model,questions,mapped to,equivalent graph representation ( query graph ),questions mapped to equivalent graph representation ( query graph ),0.7112686038017273
Blogs,7,15,model,equivalent graph representation ( query graph ),feed into,kb,equivalent graph representation ( query graph ) feed into kb,0.6637191772460938
Blogs,7,15,model,model,has,questions,model has questions,0.5781121850013733
Blogs,7,16,model,reasoning,nding,sequence of paths,reasoning nding sequence of paths,0.6819201111793518
Blogs,7,16,model,sequence of paths,match,query,sequence of paths match query,0.7880217432975769
Blogs,7,16,model,sequence of paths,retrieve,end nodes,sequence of paths retrieve end nodes,0.6098304986953735
Blogs,7,16,model,model,has,reasoning,model has reasoning,0.6214090585708618
Blogs,8,8,ablation-analysis,two / three supporting facts,Requires,differentiation,two / three supporting facts Requires differentiation,0.7023734450340271
Blogs,8,8,ablation-analysis,differentiation,between,objects and subjects,differentiation between objects and subjects,0.582585334777832
Blogs,8,8,ablation-analysis,ablation analysis,has,two / three supporting facts,ablation analysis has two / three supporting facts,0.5533076524734497
Blogs,8,17,baselines,baselines,has,basic simulations,baselines has basic simulations,0.5643517971038818
Blogs,8,20,baselines,baselines,has,n - gram classifier,baselines has n - gram classifier,0.5392509698867798
Blogs,8,21,baselines,baselines,has,lstms memory networks,baselines has lstms memory networks,0.5382781624794006
Blogs,8,24,baselines,bag of 3 - grams,instead of,bag-of-words,bag of 3 - grams instead of bag-of-words,0.6277811527252197
Blogs,8,41,baselines,basic deduction and induction,Tests,basic deduction,basic deduction and induction Tests basic deduction,0.69484543800354
Blogs,8,41,baselines,basic deduction and induction,Tests,induction,basic deduction and induction Tests induction,0.6529973745346069
Blogs,8,41,baselines,basic deduction and induction,via,inheritance of properties,basic deduction and induction via inheritance of properties,0.6659892797470093
Blogs,8,41,baselines,induction,via,inheritance of properties,induction via inheritance of properties,0.6927147507667542
Blogs,8,41,baselines,baselines,has,basic deduction and induction,baselines has basic deduction and induction,0.5251472592353821
Blogs,8,13,experimental-setup,supervised training,set of,relevant statements,supervised training set of relevant statements,0.6591157913208008
Blogs,8,13,experimental-setup,relevant statements,provided along with,questions and answers,relevant statements provided along with questions and answers,0.4983825981616974
Blogs,8,13,experimental-setup,experimental setup,For,supervised training,experimental setup For supervised training,0.5817268490791321
Blogs,8,18,experimental-setup,synonyms,used for,entities and actions,synonyms used for entities and actions,0.6666924357414246
Blogs,8,18,experimental-setup,variations,has,synonyms,variations has synonyms,0.5326282978057861
Blogs,8,28,experimental-setup,strong supervision,to find,supporting statements,strong supervision to find supporting statements,0.5888262987136841
Blogs,8,28,experimental-setup,strong supervision,use,similar svm,strong supervision use similar svm,0.6394731998443604
Blogs,8,28,experimental-setup,similar svm,to find,response,similar svm to find response,0.6360500454902649
Blogs,8,28,experimental-setup,experimental setup,train with,strong supervision,experimental setup train with strong supervision,0.721017062664032
Blogs,8,14,experiments,tasks,available in,"english , hindi","tasks available in english , hindi",0.5729100704193115
Blogs,8,14,experiments,tasks,available in,shuffled english words,tasks available in shuffled english words,0.609241247177124
Blogs,8,34,experiments,structured svm,performs,very well,structured svm performs very well,0.6045694947242737
Blogs,8,34,experiments,very well,on,path finding task,very well on path finding task,0.5180897116661072
Blogs,8,34,experiments,path finding task,due to,non-greedy search approach,path finding task due to non-greedy search approach,0.7301185727119446
Blogs,8,38,experiments,sentences,describe,possibility and not a certainty,sentences describe possibility and not a certainty,0.6454404592514038
Blogs,8,39,experiments,basic coreference,has,"conjunctions , and compound coreference","basic coreference has conjunctions , and compound coreference",0.5696611404418945
Blogs,8,42,experiments,position and size reasoning,has,path finding,position and size reasoning has path finding,0.6110423803329468
Blogs,8,12,model,different tasks,independent of,each other,different tasks independent of each other,0.7425184845924377
Blogs,8,12,model,model,has,different tasks,model has different tasks,0.5375003218650818
Blogs,8,16,model,certain rules,interact with,other entities,certain rules interact with other entities,0.6360254287719727
Blogs,8,22,model,adaptive memories,learn,number of hops,adaptive memories learn number of hops,0.6338014006614685
Blogs,8,22,model,extensions to memory networks,has,adaptive memories,extensions to memory networks has adaptive memories,0.5776400566101074
Blogs,8,22,model,model,has,extensions to memory networks,model has extensions to memory networks,0.5888959169387817
Blogs,8,25,model,nonlinearity,Apply 2 - layer neural network,tanh nonlinearity,nonlinearity Apply 2 - layer neural network tanh nonlinearity,0.7192794680595398
Blogs,8,25,model,tanh nonlinearity,in,matching function,tanh nonlinearity in matching function,0.5412803292274475
Blogs,8,25,model,model,has,nonlinearity,model has nonlinearity,0.5464851260185242
Blogs,8,7,results,number of supporting facts,has,tougher,number of supporting facts has tougher,0.5674010515213013
Blogs,8,29,results,still fail,on,number of tasks,still fail on number of tasks,0.5691800713539124
Blogs,8,29,results,standard memnn,has,outperform,standard memnn has outperform,0.6282965540885925
Blogs,8,29,results,outperform,has,n-gram and lstm,outperform has n-gram and lstm,0.5921714305877686
Blogs,8,30,results,memnns with adaptive memory,performance,basic induction task,memnns with adaptive memory performance basic induction task,0.7091337442398071
Blogs,8,30,results,results,has,memnns with adaptive memory,results has memnns with adaptive memory,0.5249364972114563
Blogs,8,31,results,memnns with n-gram modeling,improves,results,memnns with n-gram modeling improves results,0.6060291528701782
Blogs,8,31,results,results,when,word order,results when word order,0.5567905902862549
Blogs,8,31,results,word order,has,matters,word order has matters,0.6174654364585876
Blogs,8,31,results,results,has,memnns with n-gram modeling,results has memnns with n-gram modeling,0.513829231262207
Blogs,8,32,results,memnns with nonlinearity,performs,well,memnns with nonlinearity performs well,0.6099994778633118
Blogs,8,32,results,well,on,yes / no tasks,well on yes / no tasks,0.5335680246353149
Blogs,8,32,results,well,on,indefinite knowledge tasks,well on indefinite knowledge tasks,0.5144091248512268
Blogs,8,32,results,results,has,memnns with nonlinearity,results has memnns with nonlinearity,0.5236822962760925
Blogs,8,33,results,not as good,as,memnns,not as good as memnns,0.6115520000457764
Blogs,8,33,results,structured svm,has,outperforms,structured svm has outperforms,0.6227031946182251
Blogs,8,33,results,outperforms,has,vanilla memnns,outperforms has vanilla memnns,0.6045252680778503
Blogs,8,33,results,memnns,has,with modifications,memnns has with modifications,0.5810081362724304
Blogs,8,33,results,results,has,structured svm,results has structured svm,0.5908066630363464
Blogs,8,35,results,questions,has,true / false questions,questions has true / false questions,0.6131941080093384
Blogs,8,35,results,results,has,questions,results has questions,0.5194433331489563
Blogs,9,21,baselines,n,has,total number of words / entities / relation types,n has total number of words / entities / relation types,0.5765024423599243
Blogs,9,21,baselines,baselines,has,n,baselines has n,0.5664021968841553
Blogs,9,23,baselines,a ),gives,answer representation,a ) gives answer representation,0.5640304088592529
Blogs,9,39,baselines,candidate set ),with,highest set,candidate set ) with highest set,0.6820221543312073
Blogs,9,39,baselines,highest set,reported as,correct answer,highest set reported as correct answer,0.6182435154914856
Blogs,9,40,baselines,kb triplets,containing,kb entity,kb triplets containing kb entity,0.6692673563957214
Blogs,9,40,baselines,baselines,has,candidate set generation strategy,baselines has candidate set generation strategy,0.5650946497917175
Blogs,9,42,baselines,only those 2 - hop candidates,where,selected relations,only those 2 - hop candidates where selected relations,0.6521199345588684
Blogs,9,42,baselines,selected relations,appear in,path,selected relations appear in path,0.5940908789634705
Blogs,9,12,experimental-setup,experimental setup,has,task definition,experimental setup has task definition,0.48123839497566223
Blogs,9,14,experimental-setup,answers,are,entities,answers are entities,0.6411423683166504
Blogs,9,14,experimental-setup,entities,in,kb,entities in kb,0.5280968546867371
Blogs,9,14,experimental-setup,questions,are,strings,questions are strings,0.6250434517860413
Blogs,9,14,experimental-setup,experimental setup,has,answers,experimental setup has answers,0.5546883344650269
Blogs,9,15,experimental-setup,freebase,as,kb,freebase as kb,0.5643860697746277
Blogs,9,15,experimental-setup,experimental setup,used,freebase,experimental setup used freebase,0.5805220007896423
Blogs,9,30,experimental-setup,experimental setup,Minimize,margin based ranking loss,experimental setup Minimize margin based ranking loss,0.7038081288337708
Blogs,9,31,experimental-setup,multi-threaded,with,hogwild,multi-threaded with hogwild,0.6237336993217468
Blogs,9,31,experimental-setup,training and loss function stochastic gradient descent,has,multi-threaded,training and loss function stochastic gradient descent has multi-threaded,0.5531135201454163
Blogs,9,31,experimental-setup,experimental setup,has,training and loss function stochastic gradient descent,experimental setup has training and loss function stochastic gradient descent,0.49727532267570496
Blogs,9,34,experimental-setup,experimental setup,has,"scoring function s ( q1 , q2 )","experimental setup has scoring function s ( q1 , q2 )",0.545779287815094
Blogs,9,38,experimental-setup,each question,has,candidate set,each question has candidate set,0.5991953611373901
Blogs,9,38,experimental-setup,experimental setup,For,each question,experimental setup For each question,0.6040974855422974
Blogs,9,6,experiments,information retrieval,Transform,question ( in natural language ),information retrieval Transform question ( in natural language ),0.721314549446106
Blogs,9,6,experiments,question ( in natural language ),into,valid query,question ( in natural language ) into valid query,0.5433158278465271
Blogs,9,33,experiments,training,of,model,training of model,0.6175848245620728
Blogs,9,33,experiments,model,with,paraphrased prediction,model with paraphrased prediction,0.63914555311203
Blogs,9,7,model,fine - grained detection,on,candidate answers,fine - grained detection on candidate answers,0.5433136820793152
Blogs,9,7,model,model,Perform,fine - grained detection,model Perform fine - grained detection,0.6146800518035889
Blogs,9,8,model,semantic parsing,Interpret,correct meaning,semantic parsing Interpret correct meaning,0.6419623494148254
Blogs,9,8,model,semantic parsing,convert it into,exact query,semantic parsing convert it into exact query,0.5809951424598694
Blogs,9,8,model,correct meaning,of,question,correct meaning of question,0.573908269405365
Blogs,9,8,model,correct meaning,convert it into,exact query,correct meaning convert it into exact query,0.5919361114501953
Blogs,9,8,model,model,has,semantic parsing,model has semantic parsing,0.5404258370399475
Blogs,9,13,model,kb,providing,structure,kb providing structure,0.6872419714927673
Blogs,9,13,model,structure,among,answers,structure among answers,0.6653319597244263
Blogs,9,13,model,model,has,kb,model has kb,0.6005940437316895
Blogs,9,16,model,freebase triplets,transformed into,questions,freebase triplets transformed into questions,0.6433910727500916
Blogs,9,16,model,model,has,freebase triplets,model has freebase triplets,0.6145114302635193
Blogs,9,19,model,embedding questions and answers,learns,low-dimensional vector embeddings,embedding questions and answers learns low-dimensional vector embeddings,0.6758798360824585
Blogs,9,19,model,low-dimensional vector embeddings,of,words,low-dimensional vector embeddings of words,0.5370280742645264
Blogs,9,19,model,words,in,question entities and relation types of freebase,words in question entities and relation types of freebase,0.501621425151825
Blogs,9,19,model,question entities and relation types of freebase,such that,questions,question entities and relation types of freebase such that questions,0.5700665712356567
Blogs,9,19,model,represented close to each other,in,joint embedding space,represented close to each other in joint embedding space,0.5067249536514282
Blogs,9,19,model,model,has,embedding questions and answers,model has embedding questions and answers,0.5914461016654968
Blogs,9,20,model,"scoring function s( q , a )",generates,high score,"scoring function s( q , a ) generates high score",0.635106086730957
Blogs,9,20,model,high score,if,answers q.,high score if answers q.,0.632084846496582
Blogs,9,20,model,model,has,"scoring function s( q , a )","model has scoring function s( q , a )",0.5703237056732178
Blogs,9,22,model,vector,encoding,number of times,vector encoding number of times,0.7444419860839844
Blogs,9,22,model,word,appears in,q.,word appears in q.,0.7699386477470398
Blogs,9,22,model,answer,to,embedding space,answer to embedding space,0.6049929261207581
Blogs,9,22,model,number of times,has,word,number of times has word,0.5885540843009949
Blogs,9,24,model,possible representations,of,candidate answers,possible representations of candidate answers,0.5743556618690491
Blogs,9,24,model,possible representations,represented as,single entity,possible representations represented as single entity,0.6164164543151855
Blogs,9,24,model,candidate answers,represented as,single entity,candidate answers represented as single entity,0.5781649351119995
Blogs,9,24,model,single entity,from,freebase,single entity from freebase,0.5572389960289001
Blogs,9,24,model,tbd,is,one - of - n encoded vector,tbd is one - of - n encoded vector,0.5701809525489807
Blogs,9,24,model,model,has,possible representations,model has possible representations,0.5890282988548279
Blogs,9,25,model,answer,represented as,path,answer represented as path,0.664466917514801
Blogs,9,25,model,path,from,question to answer,path from question to answer,0.6259464025497437
Blogs,9,25,model,model,has,answer,model has answer,0.6467141509056091
Blogs,9,26,model,hop paths,resulting in,3 - of - n or 4 - of - n encoded vectors,hop paths resulting in 3 - of - n or 4 - of - n encoded vectors,0.6569580435752869
Blogs,9,26,model,model,considers,hop paths,model considers hop paths,0.6960355043411255
Blogs,9,27,model,subgraph representation,represents,path and the entire subgraph of entities,subgraph representation represents path and the entire subgraph of entities,0.6298861503601074
Blogs,9,27,model,path and the entire subgraph of entities,connected to,answer entity,path and the entire subgraph of entities connected to answer entity,0.7089771628379822
Blogs,9,28,model,two embedding representations,to,differentiate,two embedding representations to differentiate,0.5738502144813538
Blogs,9,28,model,entities,in,path,entities in path,0.5287671685218811
Blogs,9,28,model,entities,in,subgraph,entities in subgraph,0.504764199256897
Blogs,9,28,model,model,has,two embedding representations,model has two embedding representations,0.5823309421539307
Blogs,9,29,model,subgraph approach,based on,hypothesis,subgraph approach based on hypothesis,0.7107620239257812
Blogs,9,29,model,hypothesis,that,more information,hypothesis that more information,0.6842492818832397
Blogs,9,29,model,hypothesis,including,more information,hypothesis including more information,0.7295886874198914
Blogs,9,29,model,hypothesis,improve,results,hypothesis improve results,0.5786982774734497
Blogs,9,29,model,more information,about,answers,more information about answers,0.6454960703849792
Blogs,9,29,model,more information,improve,results,more information improve results,0.6200956702232361
Blogs,9,29,model,model,has,subgraph approach,model has subgraph approach,0.5994265079498291
Blogs,9,41,model,answers,limited to,1 - hop paths,answers limited to 1 - hop paths,0.6381019949913025
Blogs,9,41,model,model,has,answers,model has answers,0.6534027457237244
Blogs,9,9,results,human intervention,to create,"lexicon , grammar , and schema","human intervention to create lexicon , grammar , and schema",0.7125316858291626
Blogs,9,35,results,high score,assigned if,q1 and q2,high score assigned if q1 and q2,0.706977128982544
Blogs,9,35,results,q1 and q2,belong to,same paraphrase cluster,q1 and q2 belong to same paraphrase cluster,0.7326815128326416
Blogs,9,35,results,results,has,high score,results has high score,0.5862372517585754
Blogs,9,44,results,c strategy,has,outperforms,c strategy has outperforms,0.6811509728431702
Blogs,9,44,results,outperforms,has,c approach,outperforms has c approach,0.6264955997467041
Blogs,9,44,results,results,has,c strategy,results has c strategy,0.5786274075508118
Blogs,9,45,results,proposed approach,outperformed by,ensemble of proposed approach,proposed approach outperformed by ensemble of proposed approach,0.7591596245765686
Blogs,9,45,results,proposed approach,with,semantic parsing,proposed approach with semantic parsing,0.6481914520263672
Blogs,9,45,results,ensemble of proposed approach,with,semantic parsing,ensemble of proposed approach with semantic parsing,0.6325240135192871
Blogs,9,45,results,semantic parsing,via,paraphrasing model,semantic parsing via paraphrasing model,0.6186157464981079
Blogs,9,45,results,proposed approach,has,outperforms,proposed approach has outperforms,0.6428829431533813
Blogs,9,45,results,outperforms,has,baseline methods,outperforms has baseline methods,0.5753374099731445
Blogs,9,45,results,results,has,proposed approach,results has proposed approach,0.6086713075637817
Blogs,10,14,baselines,workers,asked to,answer q,workers asked to answer q,0.7350088357925415
Blogs,10,14,baselines,second round,has,workers,second round has workers,0.5945039391517639
Blogs,10,12,hyperparameters,worker,shown,24 nearest - neighbor images,worker shown 24 nearest - neighbor images,0.6343728303909302
Blogs,10,12,hyperparameters,worker,asked to choose,most similar image,worker asked to choose most similar image,0.6104952096939087
Blogs,10,12,hyperparameters,24 nearest - neighbor images,of,i,24 nearest - neighbor images of i,0.6123151779174805
Blogs,10,12,hyperparameters,24 nearest - neighbor images,based on,vggnet features,24 nearest - neighbor images based on vggnet features,0.6098544001579285
Blogs,10,12,hyperparameters,i,based on,vggnet features,i based on vggnet features,0.680162787437439
Blogs,10,12,hyperparameters,most similar image,to I,q,most similar image to I q,0.5826682448387146
Blogs,10,12,hyperparameters,i ',has,worker,i ' has worker,0.699774980545044
Blogs,10,12,hyperparameters,hyperparameters,search for,i ',hyperparameters search for i ',0.6217100620269775
Blogs,10,13,hyperparameters,worker,select,not possible,worker select not possible,0.6754603981971741
Blogs,10,13,hyperparameters,none of the 24 images quali es,has,worker,none of the 24 images quali es has worker,0.5764946341514587
Blogs,10,23,hyperparameters,pairwise hinge ranking loss,so that,score,pairwise hinge ranking loss so that score,0.5313774943351746
Blogs,10,23,hyperparameters,score,of,human picked image,score of human picked image,0.5865725874900818
Blogs,10,23,hyperparameters,score,of,all other images,score of all other images,0.5681867003440857
Blogs,10,23,hyperparameters,higher,score of,all other images,higher score of all other images,0.7279753684997559
Blogs,10,23,hyperparameters,all other images,by,margin,all other images by margin,0.6324285864830017
Blogs,10,23,hyperparameters,margin,of,m ( hyperparameter ),margin of m ( hyperparameter ),0.5870367884635925
Blogs,10,23,hyperparameters,hyperparameters,Trained with,pairwise hinge ranking loss,hyperparameters Trained with pairwise hinge ranking loss,0.6442351937294006
Blogs,10,8,model,balanced version,of,vqa dataset,balanced version of vqa dataset,0.5629589557647705
Blogs,10,8,model,vqa dataset,where,each question,vqa dataset where each question,0.6164669394493103
Blogs,10,8,model,each question,in,dataset,each question in dataset,0.5025960803031921
Blogs,10,8,model,each question,associated with,pair of similar images,each question associated with pair of similar images,0.6297387480735779
Blogs,10,8,model,pair of similar images,such that,same question,pair of similar images such that same question,0.6534122824668884
Blogs,10,8,model,model,present,balanced version,model present balanced version,0.7451751828193665
Blogs,10,9,model,proposed data collection procedure,develop,novel interpretable model,proposed data collection procedure develop novel interpretable model,0.6329447627067566
Blogs,10,9,model,novel interpretable model,given,image,novel interpretable model given image,0.7333475351333618
Blogs,10,9,model,novel interpretable model,given,question,novel interpretable model given question,0.7468050718307495
Blogs,10,9,model,image,similar to,original image,image similar to original image,0.6642270684242249
Blogs,10,9,model,different answer,building,trust,different answer building trust,0.7240244746208191
Blogs,10,9,model,same question,building,trust,same question building trust,0.7305756211280823
Blogs,10,9,model,trust,for,system,trust for system,0.6633899211883545
Blogs,10,9,model,model,develop,novel interpretable model,model develop novel interpretable model,0.658679723739624
Blogs,10,9,model,model,has,proposed data collection procedure,model has proposed data collection procedure,0.545616090297699
Blogs,10,18,model,vqa model,trained on,balanced dataset,vqa model trained on balanced dataset,0.688860297203064
Blogs,10,18,model,model,has,vqa model,model has vqa model,0.57711261510849
Blogs,10,20,model,supervising signal,provided by,data collection procedure,supervising signal provided by data collection procedure,0.6782190799713135
Blogs,10,20,model,supervising signal,humans pick,image i,supervising signal humans pick image i,0.631676197052002
Blogs,10,20,model,image i,from,same set of candidate images,image i from same set of candidate images,0.5494234561920166
Blogs,10,20,model,model,has,supervising signal,model has supervising signal,0.5931691527366638
Blogs,10,21,model,each image,in,candidate set,each image in candidate set,0.5529226660728455
Blogs,10,21,model,each image,compute,inner product,each image compute inner product,0.7445785403251648
Blogs,10,21,model,inner product,of,question - image embedding and answer embedding,inner product of question - image embedding and answer embedding,0.5819154381752014
Blogs,10,21,model,model,For,each image,model For each image,0.6263483762741089
Blogs,10,22,model,k inner product values,passed through,fully connected layer,k inner product values passed through fully connected layer,0.6296078562736511
Blogs,10,22,model,fully connected layer,to generate,k scores,fully connected layer to generate k scores,0.6367650628089905
Blogs,10,22,model,model,has,k inner product values,model has k inner product values,0.5994633436203003
Blogs,10,5,results,standard vqa models,bene t from,inherent bias,standard vqa models bene t from inherent bias,0.7009708881378174
Blogs,10,5,results,inherent bias,in,structure of the world,inherent bias in structure of the world,0.5353439450263977
Blogs,10,5,results,inherent bias,language of,question,inherent bias language of question,0.6884336471557617
Blogs,10,5,results,problem statement,has,standard vqa models,problem statement has standard vqa models,0.5401736497879028
Blogs,10,5,results,results,has,problem statement,results has problem statement,0.4901227653026581
Blogs,10,6,results,question,starts with,do you see a ?,question starts with do you see a ?,0.6588485836982727
Blogs,10,6,results,question,starts with,more likely,question starts with more likely,0.6601635217666626
Blogs,10,6,results,more likely,to be,yes  ,more likely to be yes  ,0.5623122453689575
Blogs,10,6,results,yes  ,than,no,yes   than no,0.6411007642745972
Blogs,10,15,results,2 - stage protocol,results in,signi cantly more balanced dataset,2 - stage protocol results in signi cantly more balanced dataset,0.6516871452331543
Blogs,10,15,results,signi cantly more balanced dataset,than,previous dataset,signi cantly more balanced dataset than previous dataset,0.5689840912818909
Blogs,10,15,results,results,has,2 - stage protocol,results has 2 - stage protocol,0.49707746505737305
Blogs,10,16,results,observation state- of- the- art models,trained on,unbalanced vqa dataset,observation state- of- the- art models trained on unbalanced vqa dataset,0.6800110936164856
Blogs,10,16,results,signi cantly worse,on,"new , balanced dataset","signi cantly worse on new , balanced dataset",0.532752275466919
Blogs,10,16,results,results,has,observation state- of- the- art models,results has observation state- of- the- art models,0.536638617515564
Blogs,10,17,results,balanced dataset,improves,performance,balanced dataset improves performance,0.7190714478492737
Blogs,10,17,results,performance,on,unbalanced dataset,performance on unbalanced dataset,0.5191333889961243
Blogs,10,17,results,results,Training on,balanced dataset,results Training on balanced dataset,0.7529942393302917
Blogs,10,19,results,image,answers,question,image answers question,0.7705757021903992
Blogs,10,19,results,image,from,k nearest neighbours of i,image from k nearest neighbours of i,0.5773012638092041
Blogs,10,19,results,model,answers,question,model answers question,0.7900329232215881
Blogs,10,19,results,model,provides,image,model provides image,0.6833661794662476
Blogs,10,19,results,image,from,k nearest neighbours of i,image from k nearest neighbours of i,0.5773012638092041
Blogs,10,19,results,similar,to,input image,similar to input image,0.5523151755332947
Blogs,10,19,results,image,has,model,image has model,0.5664868950843811
Blogs,11,62,ablation-analysis,relatively high value,indicated by,bright yellow color,relatively high value indicated by bright yellow color,0.6263628005981445
Blogs,11,62,ablation-analysis,ablation analysis,has,cell,ablation analysis has cell,0.5596834421157837
Blogs,11,69,ablation-analysis,contextual contribution,especially important for,small copulas,contextual contribution especially important for small copulas,0.5870342254638672
Blogs,11,69,ablation-analysis,ablation analysis,has,contextual contribution,ablation analysis has contextual contribution,0.5267080664634705
Blogs,11,85,ablation-analysis,semantic similarity,strongly contributes to,relevance,semantic similarity strongly contributes to relevance,0.7218125462532043
Blogs,11,89,ablation-analysis,query word,Where,most relevant query word,query word Where most relevant query word,0.6211913824081421
Blogs,11,89,ablation-analysis,query word,is,most relevant query word,query word is most relevant query word,0.5401289463043213
Blogs,11,89,ablation-analysis,most relevant query word,for,context words,most relevant query word for context words,0.5156503319740295
Blogs,11,89,ablation-analysis,context words,related to,geographical location,context words related to geographical location,0.6601868867874146
Blogs,11,89,ablation-analysis,ablation analysis,see that,query word,ablation analysis see that query word,0.5971767902374268
Blogs,11,99,ablation-analysis,any bright cell,across,row,any bright cell across row,0.7778716683387756
Blogs,11,100,ablation-analysis,no word,in,query,no word in query,0.5293901562690735
Blogs,11,100,ablation-analysis,no word,that is,similar in meaning,no word that is similar in meaning,0.6693967580795288
Blogs,11,100,ablation-analysis,similar in meaning,to,context word,similar in meaning to context word,0.5408096313476562
Blogs,11,100,ablation-analysis,context word,has,small,context word has small,0.5781087279319763
Blogs,11,101,ablation-analysis,maximum value obtained,close to,zero,maximum value obtained close to zero,0.7287065386772156
Blogs,11,101,ablation-analysis,maximum,has,maximum value obtained,maximum has maximum value obtained,0.5865976810455322
Blogs,11,101,ablation-analysis,ablation analysis,take,maximum,ablation analysis take maximum,0.626471221446991
Blogs,11,102,ablation-analysis,word,has,singapore,word has singapore,0.6039731502532959
Blogs,11,102,ablation-analysis,ablation analysis,Contrast,word,ablation analysis Contrast word,0.7589571475982666
Blogs,11,103,ablation-analysis,corresponding value,in,vector z,corresponding value in vector z,0.5302941799163818
Blogs,11,103,ablation-analysis,corresponding value,be,relatively high,corresponding value be relatively high,0.5562209486961365
Blogs,11,103,ablation-analysis,vector z,for,rows,vector z for rows,0.6240343451499939
Blogs,11,103,ablation-analysis,rows,will,relatively high,rows will relatively high,0.6598269939422607
Blogs,11,103,ablation-analysis,maximum,has,corresponding value,maximum has corresponding value,0.5825338959693909
Blogs,11,103,ablation-analysis,ablation analysis,take,maximum,ablation analysis take maximum,0.626471221446991
Blogs,11,105,ablation-analysis,values in z,serve,our attention values,values in z serve our attention values,0.6952338218688965
Blogs,11,105,ablation-analysis,q2c,has,values in z,q2c has values in z,0.5972722172737122
Blogs,11,105,ablation-analysis,ablation analysis,In,q2c,ablation analysis In q2c,0.5285053253173828
Blogs,11,4,baselines,bi-directional attention flow ( bidaf ),are,influential nlp models,bi-directional attention flow ( bidaf ) are influential nlp models,0.5671292543411255
Blogs,11,4,baselines,baselines,has,sequence-to-sequence ( seq2seq ),baselines has sequence-to-sequence ( seq2seq ),0.5597500801086426
Blogs,11,11,baselines,bidaf,by extracting,substring,bidaf by extracting substring,0.756409764289856
Blogs,11,11,baselines,substring,of,context,substring of context,0.5964565277099609
Blogs,11,11,baselines,best answers,has,query,best answers has query,0.617874264717102
Blogs,11,11,baselines,baselines,has,bidaf,baselines has bidaf,0.6077240705490112
Blogs,11,58,baselines,baselines,has,( j = 4,baselines has ( j = 4,0.6025823950767517
Blogs,11,80,baselines,baselines,has,performing c2q,baselines has performing c2q,0.5994840264320374
Blogs,11,112,baselines,seq2seq model,consists of,two recurrent neural networks ( rnns ),seq2seq model consists of two recurrent neural networks ( rnns ),0.6709122061729431
Blogs,11,2,experiments,attention mechanism,in,seq2seq and bidaf,attention mechanism in seq2seq and bidaf,0.5576709508895874
Blogs,11,28,experiments,first paragraph,of,french text,first paragraph of french text,0.5766600370407104
Blogs,11,28,experiments,first paragraph,translate it into,english,first paragraph translate it into english,0.6522771120071411
Blogs,11,28,experiments,english,move on to,second paragraph,english move on to second paragraph,0.7473148703575134
Blogs,11,56,experiments,small country,located in,southeast asia,small country located in southeast asia,0.6250239610671997
Blogs,11,12,hyperparameters,words,has,"query , context and answer","words has query , context and answer",0.5476378798484802
Blogs,11,12,hyperparameters,hyperparameters,capitalize,words,hyperparameters capitalize words,0.705269455909729
Blogs,11,61,hyperparameters,dimension,of,9 - by - 4,dimension of 9 - by - 4,0.6780230402946472
Blogs,11,61,hyperparameters,9,being,length,9 being length,0.6721845269203186
Blogs,11,61,hyperparameters,length,of,context ( t ),length of context ( t ),0.5866542458534241
Blogs,11,61,hyperparameters,4,being,length of the query ( j ),4 being length of the query ( j ),0.5628682374954224
Blogs,11,61,hyperparameters,matrix,has,dimension,matrix has dimension,0.6004137992858887
Blogs,11,61,hyperparameters,hyperparameters,has,matrix,hyperparameters has matrix,0.5305720567703247
Blogs,11,5,model,attention,involves,comparison of two sequences,attention involves comparison of two sequences,0.5490420460700989
Blogs,11,6,model,model,explain,attention mechanism,model explain attention mechanism,0.7173436880111694
Blogs,11,8,model,bidaf,is,"closed - domain , extractive q&a model","bidaf is closed - domain , extractive q&a model",0.5814555287361145
Blogs,11,8,model,model,has,bidaf,model has bidaf,0.6748911142349243
Blogs,11,9,model,answer,contains,query,answer contains query,0.6668795943260193
Blogs,11,9,model,answer,needed to answer,query,answer needed to answer query,0.7408216595649719
Blogs,11,9,model,bidaf,needs to consult,an accompanying text,bidaf needs to consult an accompanying text,0.7103835344314575
Blogs,11,9,model,an accompanying text,contains,information,an accompanying text contains information,0.6634879112243652
Blogs,11,9,model,information,needed to answer,query,information needed to answer query,0.6953760981559753
Blogs,11,9,model,answer,has,query,answer has query,0.6054503321647644
Blogs,11,9,model,answer,has,bidaf,answer has bidaf,0.6692852973937988
Blogs,11,9,model,query,has,bidaf,query has bidaf,0.6386688947677612
Blogs,11,13,model,model,has,conceptual introduction to attention mechanism,model has conceptual introduction to attention mechanism,0.49865731596946716
Blogs,11,14,model,details,of,attention mechanism,details of attention mechanism,0.5512969493865967
Blogs,11,14,model,attention mechanism,used in,bidaf,attention mechanism used in bidaf,0.6545241475105286
Blogs,11,14,model,understanding,has,of what attention,understanding has of what attention,0.600000262260437
Blogs,11,14,model,model,Before delving into,details,model Before delving into details,0.6939241290092468
Blogs,11,14,model,model,first have,understanding,model first have understanding,0.6045655608177185
Blogs,11,15,model,model,has,attention,model has attention,0.587727427482605
Blogs,11,16,model,seq2seq,is,neural network model,seq2seq is neural network model,0.5850027203559875
Blogs,11,16,model,neural network model,convert,one sequence to another sequence,neural network model convert one sequence to another sequence,0.6968796849250793
Blogs,11,16,model,model,has,seq2seq,model has seq2seq,0.5933537483215332
Blogs,11,18,model,first rnn,called,encoder,first rnn called encoder,0.6868559122085571
Blogs,11,18,model,first rnn,responsible for,understanding,first rnn responsible for understanding,0.6445881128311157
Blogs,11,18,model,first rnn,converting,informational content,first rnn converting informational content,0.6729784607887268
Blogs,11,18,model,encoder,responsible for,understanding,encoder responsible for understanding,0.6432234644889832
Blogs,11,18,model,informational content,into,fixed - size intermediary vector,informational content into fixed - size intermediary vector,0.5649016499519348
Blogs,11,18,model,understanding,has,input sequence,understanding has input sequence,0.5746535658836365
Blogs,11,18,model,model,has,first rnn,model has first rnn,0.5932861566543579
Blogs,11,19,model,second rnn,called,decoder,second rnn called decoder,0.6829023957252502
Blogs,11,19,model,second rnn,uses,intermediary vector,second rnn uses intermediary vector,0.6381646394729614
Blogs,11,19,model,intermediary vector,to generate,output sequence,intermediary vector to generate output sequence,0.7181575298309326
Blogs,11,19,model,model,has,second rnn,model has second rnn,0.5847991704940796
Blogs,11,20,model,seq2seq models,deal with,short sequences,seq2seq models deal with short sequences,0.6389931440353394
Blogs,11,20,model,mechanism,has,seq2seq models,mechanism has seq2seq models,0.5991264581680298
Blogs,11,24,model,attention mechanism,to solve,information bottleneck,attention mechanism to solve information bottleneck,0.5671919584274292
Blogs,11,24,model,model,has,attention mechanism,model has attention mechanism,0.5215663909912109
Blogs,11,25,model,core idea,of,attention,core idea of attention,0.5743502378463745
Blogs,11,25,model,attention,is,each step,attention is each step,0.6036422252655029
Blogs,11,25,model,attention,on,each step,attention on each step,0.6004669070243835
Blogs,11,25,model,each step,of,decoding process,each step of decoding process,0.6360529661178589
Blogs,11,25,model,each step,to make,direct connection,each step to make direct connection,0.7051036357879639
Blogs,11,25,model,direct connection,to,specific parts,direct connection to specific parts,0.5818884968757629
Blogs,11,25,model,specific parts,of,encoder,specific parts of encoder,0.6442596912384033
Blogs,11,25,model,model,on,each step,model on each step,0.558532178401947
Blogs,11,25,model,model,has,core idea,model has core idea,0.5185322761535645
Blogs,11,30,model,each time step,during,decoding process,each time step during decoding process,0.72597736120224
Blogs,11,30,model,each time step,compare,decoder hidden state,each time step compare decoder hidden state,0.6555466651916504
Blogs,11,30,model,decoder hidden state,with,all of the encoder hidden states,decoder hidden state with all of the encoder hidden states,0.60941481590271
Blogs,11,30,model,model,At,each time step,model At each time step,0.559150218963623
Blogs,11,31,model,function,takes,two vectors,function takes two vectors,0.7017505764961243
Blogs,11,31,model,scalar,reflects,similarity,scalar reflects similarity,0.7195702791213989
Blogs,11,33,model,scalar output,of,similarity function,scalar output of similarity function,0.591710090637207
Blogs,11,33,model,model,has,scalar output,model has scalar output,0.5217398405075073
Blogs,11,36,model,softmax,of,all these attention scores,softmax of all these attention scores,0.5542823672294617
Blogs,11,36,model,model,take,softmax,model take softmax,0.6321173310279846
Blogs,11,37,model,softmax function,normalizes,attention scores,softmax function normalizes attention scores,0.7398603558540344
Blogs,11,37,model,attention scores,into,probability distribution,attention scores into probability distribution,0.5675384402275085
Blogs,11,37,model,model,has,softmax function,model has softmax function,0.552506685256958
Blogs,11,38,model,probability distribution,called,attention distribution,probability distribution called attention distribution,0.6557735204696655
Blogs,11,38,model,probability distribution,signals,parts of the input sequence,probability distribution signals parts of the input sequence,0.762222409248352
Blogs,11,38,model,attention distribution,signals,parts of the input sequence,attention distribution signals parts of the input sequence,0.6918639540672302
Blogs,11,38,model,parts of the input sequence,most relevant to,decoding process at hand,parts of the input sequence most relevant to decoding process at hand,0.6877159476280212
Blogs,11,38,model,model,has,probability distribution,model has probability distribution,0.5529590249061584
Blogs,11,39,model,blue bars,show,attention distribution,blue bars show attention distribution,0.6763355731964111
Blogs,11,39,model,model,has,blue bars,model has blue bars,0.5699281692504883
Blogs,11,41,model,model,has,multiplying attention distribution,model has multiplying attention distribution,0.5266916751861572
Blogs,11,42,model,each element,of,attention distribution,each element of attention distribution,0.6145445108413696
Blogs,11,42,model,each element,of,corresponding encoder hidden states,each element of corresponding encoder hidden states,0.613408088684082
Blogs,11,42,model,each element,with,corresponding encoder hidden states,each element with corresponding encoder hidden states,0.6407680511474609
Blogs,11,42,model,each element,sum up,products,each element sum up products,0.6480335593223572
Blogs,11,42,model,products,to produce,single vector,products to produce single vector,0.7002166509628296
Blogs,11,42,model,single vector,called,attention output,single vector called attention output,0.6780565977096558
Blogs,11,43,model,attention output,as,selective summary,attention output as selective summary,0.5132310390472412
Blogs,11,43,model,selective summary,of,input sequence,selective summary of input sequence,0.6217025518417358
Blogs,11,43,model,model,think of,attention output,model think of attention output,0.676546573638916
Blogs,11,44,model,attention output,become,input,attention output become input,0.5941187143325806
Blogs,11,44,model,input,to,next decoding step,input to next decoding step,0.6035105586051941
Blogs,11,44,model,model,has,attention output,model has attention output,0.554438054561615
Blogs,11,45,model,seq2seq,generalizable to,other applications,seq2seq generalizable to other applications,0.7152093648910522
Blogs,11,46,model,bidaf,uses,same three steps,bidaf uses same three steps,0.6599469780921936
Blogs,11,46,model,same three steps,implementation of,attention,same three steps implementation of attention,0.7013115286827087
Blogs,11,46,model,model,has,bidaf,model has bidaf,0.6748911142349243
Blogs,11,47,model,quick overview,of,attention mechanism,quick overview of attention mechanism,0.5530216693878174
Blogs,11,47,model,quick overview,implementation in,seq2seq,quick overview implementation in seq2seq,0.7056303024291992
Blogs,11,47,model,attention mechanism,implementation in,seq2seq,attention mechanism implementation in seq2seq,0.7147898077964783
Blogs,11,49,model,step 6,has,formation of similarity matrix,step 6 has formation of similarity matrix,0.5443466901779175
Blogs,11,49,model,model,has,step 6,model has step 6,0.5877460837364197
Blogs,11,50,model,contextual embedding step,produced,two output matrices,contextual embedding step produced two output matrices,0.5913712382316589
Blogs,11,50,model,h,for,context,h for context,0.6565688252449036
Blogs,11,50,model,u,for,query,u for query,0.707356333732605
Blogs,11,51,model,overarching goal,for,attention steps,overarching goal for attention steps,0.5937513113021851
Blogs,11,51,model,attention steps,fuse together,information,attention steps fuse together information,0.7016457319259644
Blogs,11,51,model,information,from,h and u,information from h and u,0.6026166677474976
Blogs,11,51,model,information,from,query,information from query,0.5859482884407043
Blogs,11,51,model,information,to create,several matrix representations,information to create several matrix representations,0.6574999690055847
Blogs,11,51,model,information,information from,query,information information from query,0.7452734708786011
Blogs,11,51,model,several matrix representations,of,context,several matrix representations of context,0.6235771775245667
Blogs,11,51,model,model,has,overarching goal,model has overarching goal,0.5064903497695923
Blogs,11,52,model,similarity matrix s.,is,tall skinny matrix,similarity matrix s. is tall skinny matrix,0.5652737617492676
Blogs,11,52,model,tall skinny matrix,with,dimension,tall skinny matrix with dimension,0.6601481437683105
Blogs,11,52,model,dimension,of,t-by - j,dimension of t-by - j,0.6852285861968994
Blogs,11,53,model,similarity matrix s,corresponds to,first step,similarity matrix s corresponds to first step,0.7040081024169922
Blogs,11,53,model,first step,in,seq2seq attention mechanism,first step in seq2seq attention mechanism,0.5199705958366394
Blogs,11,53,model,model,generation of,similarity matrix s,model generation of similarity matrix s,0.6701465845108032
Blogs,11,54,model,comparison function,to,each column in h,comparison function to each column in h,0.5968057513237
Blogs,11,54,model,comparison function,to,each column,comparison function to each column,0.5784798860549927
Blogs,11,54,model,model,applying,comparison function,model applying comparison function,0.7023990750312805
Blogs,11,55,model,value,in,row t and column j,value in row t and column j,0.5348361134529114
Blogs,11,55,model,row t and column j,of,matrix s,row t and column j of matrix s,0.6177740097045898
Blogs,11,55,model,matrix s,represents,similarity,matrix s represents similarity,0.6793762445449829
Blogs,11,55,model,similarity,of,t-th context word and j-th query word,similarity of t-th context word and j-th query word,0.5697435736656189
Blogs,11,55,model,model,has,value,model has value,0.5481775403022766
Blogs,11,59,model,similarity matrix s,produced from,query / context pair,similarity matrix s produced from query / context pair,0.5865916013717651
Blogs,11,59,model,model,has,similarity matrix s,model has similarity matrix s,0.5621110200881958
Blogs,11,63,model,query word and context word,are,highly similar,query word and context word are highly similar,0.5514013171195984
Blogs,11,63,model,highly similar,to,each other,highly similar to each other,0.577064037322998
Blogs,11,63,model,model,implies that,query word and context word,model implies that query word and context word,0.38295555114746094
Blogs,11,66,model,similarity,of,context word,similarity of context word,0.5513346791267395
Blogs,11,66,model,similarity,of,identical query word,similarity of identical query word,0.5913956761360168
Blogs,11,68,model,information,from,surrounding phrases,information from surrounding phrases,0.5541812181472778
Blogs,11,71,model,our word and character embedding layers,can generate,vector representations,our word and character embedding layers can generate vector representations,0.6629425287246704
Blogs,11,71,model,vector representations,that pretty accurately reflect,word 's meaning,vector representations that pretty accurately reflect word 's meaning,0.6865779161453247
Blogs,11,71,model,model,thanks to,our word and character embedding layers,model thanks to our word and character embedding layers,0.43355488777160645
Blogs,11,72,model,function,comprises,multiplication,function comprises multiplication,0.7155765891075134
Blogs,11,72,model,function,returns,scalar,function returns scalar,0.8053721189498901
Blogs,11,72,model,multiplication,returns,scalar,multiplication returns scalar,0.7777312994003296
Blogs,11,72,model,multiplication,has,of a row vector and a equally - sized column vector,multiplication has of a row vector and a equally - sized column vector,0.5688075423240662
Blogs,11,75,model,similarity function,combine,context matrix h,similarity function combine context matrix h,0.6803651452064514
Blogs,11,75,model,similarity function,combine,query matrix u,similarity function combine query matrix u,0.674221932888031
Blogs,11,75,model,query matrix u,to form,similarity matrix s.,query matrix u to form similarity matrix s.,0.6082440614700317
Blogs,11,75,model,model,Using,similarity function,model Using similarity function,0.7194225192070007
Blogs,11,77,model,similarity matrix s,serves as,input,similarity matrix s serves as input,0.624160885810852
Blogs,11,77,model,model,has,similarity matrix s,model has similarity matrix s,0.5621110200881958
Blogs,11,78,model,model,focus on,c2q,model focus on c2q,0.7731879353523254
Blogs,11,81,model,scalar values,in,s,scalar values in s,0.5912972092628479
Blogs,11,81,model,scalar values,to calculate,attention distribution,scalar values to calculate attention distribution,0.6923529505729675
Blogs,11,81,model,model,use,scalar values,model use scalar values,0.6871449947357178
Blogs,11,83,model,result,is,another matrix,result is another matrix,0.6078258752822876
Blogs,11,83,model,model,has,result,model has result,0.5694593191146851
Blogs,11,84,model,model,call,matrix,model call matrix,0.6379752159118652
Blogs,11,87,model,words,share,strong semantic similarity,words share strong semantic similarity,0.6600531935691833
Blogs,11,90,model,every row,to get,attention distribution,every row to get attention distribution,0.6753912568092346
Blogs,11,90,model,model,take,every row,model take every row,0.7632860541343689
Blogs,11,91,model,at,reflects,relative importance,at reflects relative importance,0.767342746257782
Blogs,11,91,model,dimension,of,1 - by - j.,dimension of 1 - by - j.,0.5892337560653687
Blogs,11,91,model,dimension,reflects,relative importance,dimension reflects relative importance,0.7386382222175598
Blogs,11,91,model,relative importance,of,each query word,relative importance of each query word,0.5781071782112122
Blogs,11,91,model,each query word,for,t-th context word,each query word for t-th context word,0.5769648551940918
Blogs,11,91,model,1 - by - j.,has,at,1 - by - j. has at,0.5969482660293579
Blogs,11,91,model,model,has,at,model has at,0.617371141910553
Blogs,11,92,model,weighted sum,of,query matrix u,weighted sum of query matrix u,0.567980170249939
Blogs,11,92,model,query matrix u,with respect to,each element,query matrix u with respect to each element,0.6661184430122375
Blogs,11,92,model,each element,in,attention distribution,each element in attention distribution,0.52847820520401
Blogs,11,92,model,model,calculate,weighted sum,model calculate weighted sum,0.6687108278274536
Blogs,11,95,model,most similar,has,to either one of the query words,most similar has to either one of the query words,0.5966824889183044
Blogs,11,95,model,answering,has,query,answering has query,0.6225184798240662
Blogs,11,96,model,maximum,across,row,maximum across row,0.7117213010787964
Blogs,11,96,model,row,of,similarity matrix s,row of similarity matrix s,0.5968504548072815
Blogs,11,96,model,similarity matrix s,to get,column vector,similarity matrix s to get column vector,0.6241030693054199
Blogs,11,96,model,model,take,maximum,model take maximum,0.6901970505714417
Blogs,11,97,model,model,has,column vector,model has column vector,0.5407286286354065
Blogs,11,98,model,similarity matrix s,focus,attention,similarity matrix s focus attention,0.690644383430481
Blogs,11,98,model,attention,to,fourth row,attention to fourth row,0.6348856687545776
Blogs,11,98,model,fourth row,corresponds to,context word,fourth row corresponds to context word,0.6920336484909058
Blogs,11,98,model,context word,has,small,context word has small,0.5781087279319763
Blogs,11,98,model,model,has,similarity matrix s,model has similarity matrix s,0.5621110200881958
Blogs,11,106,model,softmax,on,z,softmax on z,0.5491893291473389
Blogs,11,106,model,softmax,to get,attention distribution,softmax to get attention distribution,0.6456547975540161
Blogs,11,106,model,attention distribution,called,b,attention distribution called b,0.6616045236587524
Blogs,11,106,model,model,apply,softmax,model apply softmax,0.6506901979446411
Blogs,11,107,model,b,to take,weighted sum,b to take weighted sum,0.6597366333007812
Blogs,11,107,model,weighted sum,of,context matrix h,weighted sum of context matrix h,0.5699520111083984
Blogs,11,107,model,model,use,b,model use b,0.6471476554870605
Blogs,11,108,model,resulting attention output,is,2d - by - 1 column vector,resulting attention output is 2d - by - 1 column vector,0.550247848033905
Blogs,11,108,model,model,has,resulting attention output,model has resulting attention output,0.561099648475647
Blogs,11,109,model,last step,of,q2c,last step of q2c,0.5977723002433777
Blogs,11,109,model,q2c,combine,copies,q2c combine copies,0.7162317037582397
Blogs,11,109,model,copies,into,2d - by - t matrix,copies into 2d - by - t matrix,0.6135855913162231
Blogs,11,109,model,model,has,last step,model has last step,0.6110069155693054
Blogs,11,115,model,values,in,s,values in s,0.6286330223083496
Blogs,11,115,model,model,calculate,values,model calculate values,0.6452937126159668
Blogs,11,117,model,matrix a,indicates,query words,matrix a indicates query words,0.6854013800621033
Blogs,11,117,model,query words,most relevant to,each context word,query words most relevant to each context word,0.6402482986450195
Blogs,11,117,model,model,has,matrix a,model has matrix a,0.53934246301651
Blogs,11,120,model,matrix representation,of,context,matrix representation of context,0.5980545878410339
Blogs,11,121,model,different information,from,h,different information from h,0.6330611705780029
Blogs,11,121,model,model,contains,different information,model contains different information,0.6757763624191284
Blogs,11,122,model,h,encapsulates,"semantic , syntactic and contextual meaning","h encapsulates semantic , syntactic and contextual meaning",0.730708658695221
Blogs,11,122,model,"semantic , syntactic and contextual meaning",of,each context word,"semantic , syntactic and contextual meaning of each context word",0.5404501557350159
Blogs,11,122,model,relevance,of,each query word,relevance of each query word,0.566659152507782
Blogs,11,122,model,each query word,to,each context word,each query word to each context word,0.5452089309692383
Blogs,11,122,model,model,has,h,model has h,0.6355570554733276
Blogs,11,124,model,similarity matrix s,records,similarity,similarity matrix s records similarity,0.6757265329360962
Blogs,11,124,model,similarity,between,each context word and each query word,similarity between each context word and each query word,0.6084411144256592
Blogs,11,124,model,model,has,similarity matrix s,model has similarity matrix s,0.5621110200881958
Blogs,11,23,results,our poor translator,forget,most of the book,our poor translator forget most of the book,0.6493780016899109
Blogs,11,27,results,seq2seq translation model,with,attention,seq2seq translation model with attention,0.6118887662887573
Blogs,11,29,results,whole content,into,his memory,whole content into his memory,0.5683007836341858
Blogs,11,29,results,whole content,has,of the book,whole content has of the book,0.5469037294387817
Blogs,11,35,results,results,has,conversion of attention scores to attention distribution,results has conversion of attention scores to attention distribution,0.49361202120780945
Blogs,11,40,results,bar,corresponding to,second ? french word,bar corresponding to second ? french word,0.6453702449798584
Blogs,11,40,results,second ? french word,is,tallest,second ? french word is tallest,0.5600385069847107
Blogs,11,40,results,results,see that,bar,results see that bar,0.6879169344902039
Blogs,11,64,results,words,turn out to be,exact same word,words turn out to be exact same word,0.6455269455909729
Blogs,11,64,results,vector representations,are,very similar,vector representations are very similar,0.5903787016868591
Blogs,11,64,results,results,has,words,results has words,0.47040021419525146
Blogs,11,65,results,query word,are,identical,query word are identical,0.5801799297332764
Blogs,11,65,results,vector representations,are,highly similar,vector representations are highly similar,0.5903238654136658
Blogs,11,67,results,value,not as high as,  singapore   par above,value not as high as   singapore   par above,0.7100425958633423
Blogs,11,67,results,results,has,value,results has value,0.5154405236244202
Blogs,11,70,results,similarity value,of,two distinct words,similarity value of two distinct words,0.5642586946487427
Blogs,11,70,results,two distinct words,with,close semantic and grammatical meaning,two distinct words with close semantic and grammatical meaning,0.6464638113975525
Blogs,11,70,results,close semantic and grammatical meaning,such as,situated,close semantic and grammatical meaning such as situated,0.6526457667350769
Blogs,11,70,results,results,see that,similarity value,results see that similarity value,0.6507761478424072
Blogs,11,86,results,most relevant query words,are,singapore,most relevant query words are singapore,0.578931987285614
Blogs,11,88,results,context words,understand,information,context words understand information,0.6735890507698059
Blogs,11,88,results,information,requested by,query words,information requested by query words,0.5966261029243469
Blogs,11,88,results,results,has,context words,results has context words,0.5348743796348572
Blogs,12,37,ablation-analysis,better,better,model,better better model,0.8067734241485596
Blogs,12,37,ablation-analysis,skewness,better,model,skewness better model,0.6870435476303101
Blogs,12,37,ablation-analysis,better,has,skewness,better has skewness,0.5725487470626831
Blogs,12,37,ablation-analysis,ablation analysis,has,better,ablation analysis has better,0.5714473724365234
Blogs,12,9,baselines,baselines,has,roundtrip question filtration,baselines has roundtrip question filtration,0.6101638674736023
Blogs,12,13,baselines,candidate answer,matches,generated answer,candidate answer matches generated answer,0.7634894251823425
Blogs,12,13,baselines,candidate answer,has,question,candidate answer has question,0.592722475528717
Blogs,12,13,baselines,generated answer,has,question,generated answer has question,0.6332932710647583
Blogs,12,38,baselines,question generation,train,question generation model,question generation train question generation model,0.7108127474784851
Blogs,12,38,baselines,question generation model,using,pre-trained gpt - 2 language model,question generation model using pre-trained gpt - 2 language model,0.6245395541191101
Blogs,12,38,baselines,baselines,has,question generation,baselines has question generation,0.580295205116272
Blogs,12,18,experiments,good experiment,to try out,encoder-decoder models,good experiment to try out encoder-decoder models,0.7080165147781372
Blogs,12,18,experiments,encoder-decoder models,for,question generation system,encoder-decoder models for question generation system,0.6029004454612732
Blogs,12,25,experiments,synthetic data,train,q/a model,synthetic data train q/a model,0.7015839219093323
Blogs,12,25,experiments,synthetic data,test,performance,synthetic data test performance,0.7963659167289734
Blogs,12,25,experiments,performance,on,squad 's development set,performance on squad 's development set,0.5781991481781006
Blogs,12,16,hyperparameters,hyperparameters,use,generated answer,hyperparameters use generated answer,0.6599321961402893
Blogs,12,24,hyperparameters,data,use,training,data use training,0.6633530855178833
Blogs,12,24,hyperparameters,data,use,other half,data use other half,0.7133222818374634
Blogs,12,24,hyperparameters,data,for,training,data for training,0.6230091452598572
Blogs,12,24,hyperparameters,data,use,other half,data use other half,0.7133222818374634
Blogs,12,24,hyperparameters,training,all three components in,pipeline,training all three components in pipeline,0.6531973481178284
Blogs,12,24,hyperparameters,other half,to generate,synthetic data,other half to generate synthetic data,0.6547078490257263
Blogs,12,24,hyperparameters,synthetic data,from,trained components,synthetic data from trained components,0.5768689513206482
Blogs,12,24,hyperparameters,hyperparameters,use,other half,hyperparameters use other half,0.6624772548675537
Blogs,12,24,hyperparameters,hyperparameters,has,data,hyperparameters has data,0.5382587313652039
Blogs,12,30,hyperparameters,( context and answer ) pairs,from,squad 's train split,( context and answer ) pairs from squad 's train split,0.5538640022277832
Blogs,12,30,hyperparameters,squad 's train split,for training,model,squad 's train split for training model,0.7625970840454102
Blogs,12,30,hyperparameters,hyperparameters,use,( context and answer ) pairs,hyperparameters use ( context and answer ) pairs,0.6478919386863708
Blogs,12,40,hyperparameters,token,near,question,token near question,0.7544292211532593
Blogs,12,40,hyperparameters,token,as,question markers,token as question markers,0.5824871063232422
Blogs,12,40,hyperparameters,question,has,token,question has token,0.6218118071556091
Blogs,12,47,hyperparameters,answer,matches,generated answer,answer matches generated answer,0.7710853219032288
Blogs,12,47,hyperparameters,answer,consider,generated question,answer consider generated question,0.7259159088134766
Blogs,12,47,hyperparameters,generated answer,consider,generated question,generated answer consider generated question,0.6745471954345703
Blogs,12,47,hyperparameters,generated question,to be,valid,generated question to be valid,0.6112545728683472
Blogs,12,47,hyperparameters,hyperparameters,If,answer,hyperparameters If answer,0.6039227247238159
Blogs,12,8,model,inference,provide,context and answer tokens,inference provide context and answer tokens,0.5782210826873779
Blogs,12,8,model,next occurrence,of,same trigger word,next occurrence of same trigger word,0.5891231894493103
Blogs,12,8,model,model,During,inference,model During inference,0.6954593062400818
Blogs,12,10,model,idea,of,roundtrip filtration,idea of roundtrip filtration,0.6150343418121338
Blogs,12,10,model,roundtrip filtration,built on,motivation,roundtrip filtration built on motivation,0.6871148347854614
Blogs,12,10,model,roundtrip filtration,built on,then filtering things,roundtrip filtration built on then filtering things,0.7190622687339783
Blogs,12,10,model,motivation,of,over-,motivation of over-,0.6183301210403442
Blogs,12,10,model,motivation,of,generating,motivation of generating,0.5727154016494751
Blogs,12,10,model,over-,has,generating,over- has generating,0.5929353833198547
Blogs,12,10,model,model,has,idea,model has idea,0.5339741110801697
Blogs,12,11,model,"question answering model p( a|c , q )",on,labelled data,"question answering model p( a|c , q ) on labelled data",0.5314469337463379
Blogs,12,11,model,labelled data,from,squad,labelled data from squad,0.6148305535316467
Blogs,12,11,model,model,train,"question answering model p( a|c , q )","model train question answering model p( a|c , q )",0.6990790367126465
Blogs,12,12,model,inference,pass in,generated question,inference pass in generated question,0.7219615578651428
Blogs,12,12,model,generated question,along with,context,generated question along with context,0.6321775317192078
Blogs,12,12,model,generated question,to generate,candidate answer,generated question to generate candidate answer,0.7004119753837585
Blogs,12,12,model,context,to generate,candidate answer,context to generate candidate answer,0.6613479256629944
Blogs,12,12,model,model,during,inference,model during inference,0.6954593062400818
Blogs,12,15,model,training phase,proceed with,inference phase,training phase proceed with inference phase,0.7055636644363403
Blogs,12,15,model,answer generation model,that generates,answer,answer generation model that generates answer,0.6814391016960144
Blogs,12,15,model,model,proceed with,inference phase,model proceed with inference phase,0.7246352434158325
Blogs,12,23,model,3 - step pipeline,comprising of,un-conditional answer extraction,3 - step pipeline comprising of un-conditional answer extraction,0.6385449767112732
Blogs,12,23,model,3 - step pipeline,comprising of,question generation,3 - step pipeline comprising of question generation,0.622577428817749
Blogs,12,23,model,3 - step pipeline,comprising of,question filtration,3 - step pipeline comprising of question filtration,0.6681523323059082
Blogs,12,23,model,model,propose,3 - step pipeline,model propose 3 - step pipeline,0.7012050747871399
Blogs,12,27,model,bert model,learns to extract,answer spans,bert model learns to extract answer spans,0.7648472189903259
Blogs,12,27,model,answer spans,over,given context,answer spans over given context,0.7009264826774597
Blogs,12,27,model,model,propose,bert model,model propose bert model,0.6381096243858337
Blogs,12,28,model,model,by,question tokens,model by question tokens,0.5729352831840515
Blogs,12,28,model,model,observing,context,model observing context,0.7416952848434448
Blogs,12,28,model,model,not,question tokens,model not question tokens,0.6787766814231873
Blogs,12,28,model,model,train,model,model train model,0.6881781220436096
Blogs,12,29,model,prior distribution,of,answers,prior distribution of answers,0.6156196594238281
Blogs,12,29,model,answers,in,dataset,answers in dataset,0.5392096042633057
Blogs,12,29,model,model,learn,prior distribution,model learn prior distribution,0.6681389212608337
Blogs,12,32,model,answer extraction head,by learning,start and end tokens jointly,answer extraction head by learning start and end tokens jointly,0.6728655099868774
Blogs,12,32,model,model,model,answer extraction head,model model answer extraction head,0.734264075756073
Blogs,12,34,model,context,through,bert model,context through bert model,0.644972026348114
Blogs,12,34,model,start and end token embeddings,at,output,start and end token embeddings at output,0.515639066696167
Blogs,12,34,model,model,pass,context,model pass context,0.7225450873374939
Blogs,12,35,model,embedding representations,concatenated and passed to,multi-layered perceptron model,embedding representations concatenated and passed to multi-layered perceptron model,0.6661854982376099
Blogs,12,35,model,multi-layered perceptron model,followed by,softmax,multi-layered perceptron model followed by softmax,0.6462743282318115
Blogs,12,35,model,softmax,over,possible start and end spans,softmax over possible start and end spans,0.6737832427024841
Blogs,12,35,model,model,has,embedding representations,model has embedding representations,0.5749883651733398
Blogs,12,36,model,aim,to have,softmax probability tilt,aim to have softmax probability tilt,0.6139495968818665
Blogs,12,36,model,softmax probability tilt,more towards,1,softmax probability tilt more towards 1,0.6992511749267578
Blogs,12,36,model,softmax probability tilt,more towards,diminishing,softmax probability tilt more towards diminishing,0.7341263294219971
Blogs,12,36,model,1,for,actual ground truth spans,1 for actual ground truth spans,0.5552473664283752
Blogs,12,36,model,diminishing,to,0,diminishing to 0,0.6572892665863037
Blogs,12,36,model,0,for,all other spans,0 for all other spans,0.6546046733856201
Blogs,12,36,model,model,has,aim,model has aim,0.5645389556884766
Blogs,12,39,model,"context tokens , answer tokens , and question tokens",into,large single sequence,"context tokens , answer tokens , and question tokens into large single sequence",0.5213294625282288
Blogs,12,39,model,model,concatenate,"context tokens , answer tokens , and question tokens","model concatenate context tokens , answer tokens , and question tokens",0.7020388841629028
Blogs,12,41,model,different input segments,define,three types of segment embeddings,different input segments define three types of segment embeddings,0.5774393081665039
Blogs,12,41,model,model,to make sure,different input segments,model to make sure different input segments,0.6892330050468445
Blogs,12,42,model,answersegment embeddings,to,context embeddings,answersegment embeddings to context embeddings,0.43527331948280334
Blogs,12,42,model,context embeddings,helping,model,context embeddings helping model,0.5852267742156982
Blogs,12,42,model,model,to locate,answer span,model to locate answer span,0.6588637828826904
Blogs,12,42,model,answer span,in,context,answer span in context,0.5100750923156738
Blogs,12,42,model,model,infuse,answersegment embeddings,model infuse answersegment embeddings,0.6816899180412292
Blogs,12,42,model,model,to locate,answer span,model to locate answer span,0.6588637828826904
Blogs,12,45,model,defined context,pass it to,question generation model,defined context pass it to question generation model,0.6259818077087402
Blogs,12,45,model,model,pass it to,question generation model,model pass it to question generation model,0.6409026980400085
Blogs,12,45,model,model,has,defined context,model has defined context,0.5541256666183472
Blogs,12,46,model,candidate question and answer,use,context and generated question,candidate question and answer use context and generated question,0.6501845121383667
Blogs,12,46,model,context and generated question,to get,possible candidate answer,context and generated question to get possible candidate answer,0.6347848176956177
Blogs,12,49,model,5/6,has,inference flow | image,5/6 has inference flow | image,0.5798590183258057
Blogs,12,49,model,model,has,5/6,model has 5/6,0.6266447901725769
Blogs,12,49,model,model,has,inference flow | image,model has inference flow | image,0.5493365526199341
Blogs,12,4,results,free,comment,thoughts,free comment thoughts,0.6837977766990662
Blogs,12,4,results,thoughts,on,same,thoughts on same,0.6302397847175598
Blogs,12,4,results,results,feel,free,results feel free,0.5358194708824158
Blogs,12,4,results,results,comment,thoughts,results comment thoughts,0.7009989023208618
Blogs,12,17,results,q/a model,on,synthetic data,q/a model on synthetic data,0.5475835800170898
Blogs,12,17,results,training,has,q/a model,training has q/a model,0.5958442091941833
Blogs,12,19,results,results,checkout,other research paper summaries,results checkout other research paper summaries,0.7050798535346985
Blogs,12,21,results,video content,over,textual,video content over textual,0.6792857050895691
Blogs,12,21,results,video content,make sure,check out,video content make sure check out,0.6176303625106812
Blogs,12,21,results,check out,Watch,more videos,check out Watch more videos,0.7005239129066467
Blogs,12,44,results,results,has,question generation training,results has question generation training,0.5265248417854309
Blogs,13,31,baselines,cnn and bilstm,to encode,extraction units,cnn and bilstm to encode extraction units,0.7034662961959839
Blogs,13,9,experiments,qa pairs,extracted from,human abstract,qa pairs extracted from human abstract,0.5305728316307068
Blogs,13,9,experiments,questions,using,source document,questions using source document,0.6569480299949646
Blogs,13,16,experiments,better,as,extraction units,better as extraction units,0.5725762844085693
Blogs,13,27,experiments,words or chunks ( phrases ),as,extraction units,words or chunks ( phrases ) as extraction units,0.4965808391571045
Blogs,13,6,hyperparameters,question answer ( qa ) pairs,limit,answer token,question answer ( qa ) pairs limit answer token,0.679462730884552
Blogs,13,6,hyperparameters,answer token,to,salient word,answer token to salient word,0.5223469138145447
Blogs,13,6,hyperparameters,answer token,to,named entity,answer token to named entity,0.5287625789642334
Blogs,13,6,hyperparameters,hyperparameters,To create,question answer ( qa ) pairs,hyperparameters To create question answer ( qa ) pairs,0.6654553413391113
Blogs,13,8,hyperparameters,at least one qa pair,should be extracted from,each sentence,at least one qa pair should be extracted from each sentence,0.6737638115882874
Blogs,13,8,hyperparameters,each sentence,of,abstract,each sentence of abstract,0.5683045387268066
Blogs,13,20,hyperparameters,answer tokens,chosen,randomly,answer tokens chosen randomly,0.7820698618888855
Blogs,13,20,hyperparameters,answer tokens,can be,root word,answer tokens can be root word,0.6079099774360657
Blogs,13,20,hyperparameters,answer tokens,can be,subj / obj word,answer tokens can be subj / obj word,0.6073092222213745
Blogs,13,20,hyperparameters,answer tokens,can be,ner word,answer tokens can be ner word,0.5562695860862732
Blogs,13,20,hyperparameters,hyperparameters,has,answer tokens,hyperparameters has answer tokens,0.5434725880622864
Blogs,13,21,hyperparameters,participants,rate,informativeness,participants rate informativeness,0.73534095287323
Blogs,13,21,hyperparameters,informativeness,of,summary,informativeness of summary,0.6344471573829651
Blogs,13,21,hyperparameters,summary,from,1 - 5,summary from 1 - 5,0.6350524425506592
Blogs,13,21,hyperparameters,summary,being,most informative,summary being most informative,0.5944225788116455
Blogs,13,21,hyperparameters,hyperparameters,asked,participants,hyperparameters asked participants,0.6475948095321655
Blogs,13,21,hyperparameters,hyperparameters,rate,informativeness,hyperparameters rate informativeness,0.7250588536262512
Blogs,13,28,hyperparameters,text chunks,using,sentence constituent parse tree,text chunks using sentence constituent parse tree,0.6148832440376282
Blogs,13,28,hyperparameters,each chunk,has,at most 5 words,each chunk has at most 5 words,0.5950829982757568
Blogs,13,28,hyperparameters,hyperparameters,obtain,text chunks,hyperparameters obtain text chunks,0.5002260208129883
Blogs,13,30,model,model,focused on,ner-grained extraction units,model focused on ner-grained extraction units,0.6885495185852051
Blogs,13,34,model,framework,whereby,importance,framework whereby importance,0.6945050358772278
Blogs,13,34,model,importance,of,t-th source extraction unit,importance of t-th source extraction unit,0.6202343702316284
Blogs,13,34,model,importance,determined by,informativeness,importance determined by informativeness,0.5972493886947632
Blogs,13,34,model,importance,determined by,position,importance determined by position,0.6820070743560791
Blogs,13,34,model,importance,determined by,relationship with the previously selected extraction units,importance determined by relationship with the previously selected extraction units,0.6928896903991699
Blogs,13,34,model,t-th source extraction unit,determined by,informativeness,t-th source extraction unit determined by informativeness,0.6197414398193359
Blogs,13,34,model,position,in,document,position in document,0.5388293862342834
Blogs,13,34,model,model,use,framework,model use framework,0.6615379452705383
Blogs,13,35,model,positional embeddings,to encode,position,positional embeddings to encode position,0.6901742219924927
Blogs,13,35,model,position,has,of the extraction unit,position has of the extraction unit,0.551042377948761
Blogs,13,35,model,model,have,positional embeddings,model have positional embeddings,0.5769782662391663
Blogs,13,36,model,each time step,build,vector representation,each time step build vector representation,0.69443279504776
Blogs,13,36,model,each time step,used it along with,positional embeddings,each time step used it along with positional embeddings,0.6738286018371582
Blogs,13,36,model,vector representation,of,our summary,vector representation of our summary,0.5968841314315796
Blogs,13,36,model,vector representation,used it along with,positional embeddings,vector representation used it along with positional embeddings,0.6547074913978577
Blogs,13,36,model,vector representation,used it along with,our encoded hidden states,vector representation used it along with our encoded hidden states,0.6319332122802734
Blogs,13,36,model,our summary,has,up to time t - 1,our summary has up to time t - 1,0.608049213886261
Blogs,13,37,model,architecture,is,unidirectional lstm,architecture is unidirectional lstm,0.5510374307632446
Blogs,13,37,model,model,is,unidirectional lstm,model is unidirectional lstm,0.5532432198524475
Blogs,13,37,model,model,has,architecture,model has architecture,0.5575731992721558
Blogs,13,5,results,our generated summaries,yielded,competitive results,our generated summaries yielded competitive results,0.7001293301582336
Blogs,13,5,results,competitive results,measured by,automatic metrics,competitive results measured by automatic metrics,0.7263333201408386
Blogs,13,5,results,competitive results,measured by,human assessors,competitive results measured by human assessors,0.6992145776748657
Blogs,13,5,results,results,has,our generated summaries,results has our generated summaries,0.570889413356781
Blogs,13,7,results,salient word or named entity,in,all the sentences,salient word or named entity in all the sentences,0.4974503219127655
Blogs,13,7,results,all the sentences,in,human abstract,all the sentences in human abstract,0.502306342124939
Blogs,13,7,results,answer token,with,blank,answer token with blank,0.6516651511192322
Blogs,13,7,results,blank,to create,cloze-style qa pair,blank to create cloze-style qa pair,0.722269594669342
Blogs,13,7,results,results,identify,salient word or named entity,results identify salient word or named entity,0.5728350281715393
Blogs,13,7,results,results,replace,answer token,results replace answer token,0.6317077279090881
Blogs,13,11,results,root - type qa pairs,have,least number of unique answers,root - type qa pairs have least number of unique answers,0.576668381690979
Blogs,13,11,results,results,observed,root - type qa pairs,results observed root - type qa pairs,0.6474096179008484
Blogs,13,12,results,qasumm + root,performed,best,qasumm + root performed best,0.2699686288833618
Blogs,13,12,results,qasumm + root,performed,best,qasumm + root performed best,0.2699686288833618
Blogs,13,12,results,best,amongst,variant,best amongst variant,0.6040174961090088
Blogs,13,12,results,variant,in,daily mail dataset,variant in daily mail dataset,0.5068886876106262
Blogs,13,12,results,qasumm + ner,performed,best,qasumm + ner performed best,0.2439437359571457
Blogs,13,12,results,best,in,cnn dataset,best in cnn dataset,0.45015332102775574
Blogs,13,12,results,results,has,qasumm + root,results has qasumm + root,0.5383110642433167
Blogs,13,13,results,maximise,has,performance,maximise has performance,0.6080300211906433
Blogs,13,13,results,results,maintaining,good number of unique answers,results maintaining good number of unique answers,0.6671441793441772
Blogs,13,17,results,performance,of,lstm and cnn encoder,performance of lstm and cnn encoder,0.5345045328140259
Blogs,13,17,results,performance,found that,chunks,performance found that chunks,0.6994162201881409
Blogs,13,17,results,performance,found that,chunks,performance found that chunks,0.6994162201881409
Blogs,13,17,results,lstm and cnn encoder,found that,chunks,lstm and cnn encoder found that chunks,0.6514872312545776
Blogs,13,17,results,lstm and cnn encoder,found that,chunks,lstm and cnn encoder found that chunks,0.6514872312545776
Blogs,13,17,results,chunks,with,lstm,chunks with lstm,0.6585763692855835
Blogs,13,17,results,chunks,with,cnn,chunks with cnn,0.6840487122535706
Blogs,13,17,results,chunks,with,lstm,chunks with lstm,0.6585763692855835
Blogs,13,17,results,chunks,performed,best,chunks performed best,0.2754538059234619
Blogs,13,17,results,lstm,performed,best,lstm performed best,0.2753291726112366
Blogs,13,17,results,cnn,with,words,cnn with words,0.6516931056976318
Blogs,13,17,results,cnn,has,outperformed,cnn has outperformed,0.6208545565605164
Blogs,13,17,results,outperformed,has,lstm,outperformed has lstm,0.6128553748130798
Blogs,13,17,results,outperformed,has,cnn,outperformed has cnn,0.6106405258178711
Blogs,13,17,results,results,compared,performance,results compared performance,0.7382499575614929
Blogs,13,22,results,results,evaluated,summaries,results evaluated summaries,0.646599292755127
Blogs,13,23,results,average time it takes,to complete,single question,average time it takes to complete single question,0.6919096112251282
Blogs,13,23,results,average time it takes,to complete,overall accuracy,average time it takes to complete overall accuracy,0.6544033885002136
Blogs,13,23,results,average time it takes,to complete,informativeness score,average time it takes to complete informativeness score,0.6685036420822144
Blogs,13,23,results,results,showcase,average time it takes,results showcase average time it takes,0.7465823292732239
Blogs,13,24,results,our qasumm,with,ner - type qa pairs,our qasumm with ner - type qa pairs,0.692785918712616
Blogs,13,24,results,ner - type qa pairs,able to achieved,highest accuracy and informativeness,ner - type qa pairs able to achieved highest accuracy and informativeness,0.6734198331832886
Blogs,13,24,results,human performance,has,our qasumm,human performance has our qasumm,0.5938490629196167
Blogs,13,24,results,results,Excluding,human performance,results Excluding human performance,0.6741708517074585
Blogs,13,25,results,wide margin,in,qa accuracy,wide margin in qa accuracy,0.5527673959732056
Blogs,13,25,results,wide margin,despite,similar level,wide margin despite similar level,0.6278728246688843
Blogs,13,25,results,best performing model,has,wide margin,best performing model has wide margin,0.5691346526145935
Blogs,13,25,results,results,found that,best performing model,results found that best performing model,0.6768954992294312
Blogs,14,25,baselines,document urls,for,top documents,document urls for top documents,0.5271159410476685
Blogs,14,25,baselines,urls,for,top documents,urls for top documents,0.5277276039123535
Blogs,14,25,baselines,document urls,has,urls,document urls has urls,0.5057235956192017
Blogs,14,25,baselines,baselines,has,document urls,baselines has document urls,0.5616642236709595
Blogs,14,8,experiments,marco questions,sampled from,"real , anonymized user queries","marco questions sampled from real , anonymized user queries",0.7195534706115723
Blogs,14,10,experiments,context documents,extracted using,bing,context documents extracted using bing,0.6449282169342041
Blogs,14,10,experiments,bing,from,real-world documents,bing from real-world documents,0.6357386708259583
Blogs,14,10,experiments,marco,has,context documents,marco has context documents,0.6211315989494324
Blogs,14,13,experiments,human judges,encouraged to generate,complete sentences,human judges encouraged to generate complete sentences,0.6592780351638794
Blogs,14,13,experiments,complete sentences,as,answers,complete sentences as answers,0.5228947997093201
Blogs,14,13,experiments,marco,has,human judges,marco has human judges,0.5745580792427063
Blogs,14,15,experiments,first release,consists of,100k questions,first release consists of 100k questions,0.6436936259269714
Blogs,14,15,experiments,100k questions,releasing,1 m questions,100k questions releasing 1 m questions,0.7657419443130493
Blogs,14,15,experiments,1 m questions,in,future releases,1 m questions in future releases,0.5300348401069641
Blogs,14,23,experiments,subset of questions,has,multiple answers,subset of questions has multiple answers,0.6111162304878235
Blogs,14,23,experiments,another subset,has,no answers,another subset has no answers,0.6592090725898743
Blogs,14,24,experiments,top 10 contextual passages,extracted from,web search engine,top 10 contextual passages extracted from web search engine,0.5255169868469238
Blogs,14,24,experiments,query,has,actual question passage,query has actual question passage,0.5689302086830139
Blogs,14,24,experiments,query,has,top 10 contextual passages,query has top 10 contextual passages,0.563639223575592
Blogs,14,27,experiments,segment - query type,has,description,segment - query type has description,0.5774534940719604
Blogs,14,12,hyperparameters,questions,restricted to,entity,questions restricted to entity,0.717902421951294
Blogs,14,12,hyperparameters,hyperparameters,answer to,questions,hyperparameters answer to questions,0.6972692608833313
Blogs,14,16,hyperparameters,questions,tagged with,segment information,questions tagged with segment information,0.6630841493606567
Blogs,14,16,hyperparameters,hyperparameters,has,questions,hyperparameters has questions,0.5738486051559448
Blogs,14,28,model,memory and attention,derive,power,memory and attention derive power,0.5579748153686523
Blogs,14,28,model,power,from,supervised data,power from supervised data,0.6114153861999512
Blogs,14,28,model,model,has,memory and attention,model has memory and attention,0.5430132150650024
Blogs,14,9,results,most datasets,provide,comparatively small and clean context,most datasets provide comparatively small and clean context,0.5930560231208801
Blogs,14,9,results,comparatively small and clean context,to,answer,comparatively small and clean context to answer,0.5724185109138489
Blogs,14,9,results,answer,has,question,answer has question,0.6225500106811523
Blogs,14,9,results,results,has,most datasets,results has most datasets,0.5133519172668457
Blogs,14,11,results,questions and the context documents,are,noisy,questions and the context documents are noisy,0.595970630645752
Blogs,14,19,results,memory networks,performed better,seq-to-seq,memory networks performed better seq-to-seq,0.7181862592697144
Blogs,14,19,results,generative models,has,memory networks,generative models has memory networks,0.49880197644233704
Blogs,14,19,results,results,Among,generative models,results Among generative models,0.5649886727333069
Blogs,14,20,results,reasonet,achieved,accuracy,reasonet achieved accuracy,0.7489048838615417
Blogs,14,20,results,accuracy,of,approx,accuracy of approx,0.6602455973625183
Blogs,14,20,results,cloze-style test,has,reasonet,cloze-style test has reasonet,0.5857547521591187
Blogs,14,20,results,results,In,cloze-style test,results In cloze-style test,0.48310360312461853
Blogs,14,21,results,attention sum reader,achieved,accuracy,attention sum reader achieved accuracy,0.7031217813491821
Blogs,14,21,results,accuracy,of,approx 55 %,accuracy of approx 55 %,0.5835281014442444
Blogs,14,21,results,results,has,59 %,results has 59 %,0.53274005651474
Blogs,14,21,results,results,has,attention sum reader,results has attention sum reader,0.6004891395568848
Blogs,15,21,baselines,simpler structured databases,like,sets of rdf triples,simpler structured databases like sets of rdf triples,0.6082248687744141
Blogs,15,25,baselines,multiple information sources,from,ibm,multiple information sources from ibm,0.5768676996231079
Blogs,15,25,baselines,multiple information sources,that won,jeopardy,multiple information sources that won jeopardy,0.6495325565338135
Blogs,15,25,baselines,"ibm's watson [ 5 , 6 ] system",from,ibm,"ibm's watson [ 5 , 6 ] system from ibm",0.5596533417701721
Blogs,15,25,baselines,"ibm's watson [ 5 , 6 ] system",that won,jeopardy,"ibm's watson [ 5 , 6 ] system that won jeopardy",0.638442873954773
Blogs,15,25,baselines,ibm,that won,jeopardy,ibm that won jeopardy,0.7810036540031433
Blogs,15,25,baselines,multiple information sources,has,"ibm's watson [ 5 , 6 ] system","multiple information sources has ibm's watson [ 5 , 6 ] system",0.5525082349777222
Blogs,15,26,baselines,baselines,has,challenge in 2011,baselines has challenge in 2011,0.6103453040122986
Blogs,15,29,baselines,deepqa system,extracts,focus,deepqa system extracts focus,0.6356020569801331
Blogs,15,29,baselines,deepqa system,performs,question classification,deepqa system performs question classification,0.5801575183868408
Blogs,15,29,baselines,deepqa system,performs,question sectioning,deepqa system performs question sectioning,0.5903068780899048
Blogs,15,29,baselines,answer type,performs,question sectioning,answer type performs question sectioning,0.6396000385284424
Blogs,15,16,experimental-setup,answer type,specifies,kind of entity,answer type specifies kind of entity,0.669575035572052
Blogs,15,16,experimental-setup,answer,consists of,"person , location , time , etc. )","answer consists of person , location , time , etc. )",0.621651291847229
Blogs,15,16,experimental-setup,kind of entity,has,answer,kind of entity has answer,0.61436527967453
Blogs,15,16,experimental-setup,experimental setup,has,answer type,experimental setup has answer type,0.5520389080047607
Blogs,15,31,experimental-setup,question,classified by,type,question classified by type,0.7398642301559448
Blogs,15,31,experimental-setup,type,as,definition question,type as definition question,0.5167590975761414
Blogs,15,31,experimental-setup,type,as,multiple - choice,type as multiple - choice,0.5631293654441833
Blogs,15,31,experimental-setup,type,as,puzzle,type as puzzle,0.5759110450744629
Blogs,15,31,experimental-setup,type,as,fill - in- the - blank,type as fill - in- the - blank,0.5941670536994934
Blogs,15,31,experimental-setup,experimental setup,has,question,experimental setup has question,0.5308533310890198
Blogs,15,28,experiments,deepqa system,runs,parsing,deepqa system runs parsing,0.6602221727371216
Blogs,15,28,experiments,deepqa system,runs,named entity tagging,deepqa system runs named entity tagging,0.6132447123527527
Blogs,15,28,experiments,deepqa system,runs,relation extraction,deepqa system runs relation extraction,0.6310375332832336
Blogs,15,28,experiments,relation extraction,on,question,relation extraction on question,0.5421403646469116
Blogs,15,44,experiments,same string,refers to,different concepts,same string refers to different concepts,0.6748373508453369
Blogs,15,44,experiments,same string,has,accidentally,same string has accidentally,0.6520731449127197
Blogs,15,51,experiments,crowd-sourced machine reading comprehension dataset,of,120k q&a pairs,crowd-sourced machine reading comprehension dataset of 120k q&a pairs,0.5110488533973694
Blogs,15,17,model,query,specifies,keywords,query specifies keywords,0.6334925889968872
Blogs,15,17,model,keywords,should be used for,ir system,keywords should be used for ir system,0.5917505621910095
Blogs,15,17,model,model,has,query,model has query,0.6049684882164001
Blogs,15,20,model,logical form,of,question,logical form of question,0.5952060222625732
Blogs,15,20,model,logical form,of,query,logical form of query,0.606031596660614
Blogs,15,20,model,logical form,is,query,logical form is query,0.6034055352210999
Blogs,15,20,model,logical form,in,query,logical form in query,0.5408805012702942
Blogs,15,20,model,logical form,converted,one,logical form converted one,0.7425405979156494
Blogs,15,20,model,model,has,logical form,model has logical form,0.560494065284729
Blogs,15,27,model,model,has,first stage,model has first stage,0.5593366026878357
Blogs,15,30,model,deepqa,extracts,question focus,deepqa extracts question focus,0.6282364726066589
Blogs,15,30,model,model,has,deepqa,model has deepqa,0.5597695112228394
Blogs,15,32,model,candidate answer generation stage,according to,question type,candidate answer generation stage according to question type,0.6697545647621155
Blogs,15,32,model,question type,where,processed question,question type where processed question,0.6525329351425171
Blogs,15,32,model,processed question,combined with,external documents and other knowledge sources,processed question combined with external documents and other knowledge sources,0.6869983673095703
Blogs,15,32,model,external documents and other knowledge sources,to suggest,many candidate answers,external documents and other knowledge sources to suggest many candidate answers,0.6222331523895264
Blogs,15,34,model,candidate answer scoring stage,uses,many sources of evidence,candidate answer scoring stage uses many sources of evidence,0.600395679473877
Blogs,15,34,model,many sources of evidence,to score,candidates,many sources of evidence to score candidates,0.693239152431488
Blogs,15,36,model,final answer merging and scoring step,first merges,candidate answers,final answer merging and scoring step first merges candidate answers,0.8429989814758301
Blogs,15,36,model,candidate answers,that are,equivalent,candidate answers that are equivalent,0.6318286657333374
Blogs,15,36,model,model,In,final answer merging and scoring step,model In final answer merging and scoring step,0.5268007516860962
Blogs,15,37,model,merging and ranking,run,iteratively,merging and ranking run iteratively,0.6869619488716125
Blogs,15,37,model,candidates,ranked by,classifier,candidates ranked by classifier,0.7390584945678711
Blogs,15,37,model,rough first value,for,each candidate answer,rough first value for each candidate answer,0.6323452591896057
Blogs,15,37,model,variants,of,name,variants of name,0.5244410634040833
Blogs,15,37,model,model,has,merging and ranking,model has merging and ranking,0.5556759238243103
Blogs,15,55,model,number of pieces,of,information,number of pieces of information,0.6069034934043884
Blogs,15,55,model,information,from,question,information from question,0.5347384214401245
Blogs,15,55,model,question - processing phase,has,number of pieces,question - processing phase has number of pieces,0.5892649292945862
Blogs,15,55,model,model,In,question - processing phase,model In question - processing phase,0.5342640280723572
Blogs,15,7,results,valid answers,mean,answers,valid answers mean answers,0.7614508271217346
Blogs,15,7,results,answers,relevant to,questions,answers relevant to questions,0.6888746619224548
Blogs,15,7,results,results,has,valid answers,results has valid answers,0.5369425415992737
Blogs,15,14,results,more than an order of magnitude larger,than,previous dataset,more than an order of magnitude larger than previous dataset,0.5723142623901367
Blogs,16,12,ablation-analysis,barrier,has,to understanding the model,barrier has to understanding the model,0.5415442585945129
Blogs,16,20,ablation-analysis,words,has,context,words has context,0.5097408890724182
Blogs,16,20,ablation-analysis,words,has,query,words has query,0.5659016370773315
Blogs,16,20,ablation-analysis,ablation analysis,capitalizing,words,ablation analysis capitalizing words,0.7379788756370544
Blogs,16,56,ablation-analysis,bidaf,requires,context,bidaf requires context,0.7313079833984375
Blogs,16,56,ablation-analysis,context,to answer,query,context to answer query,0.633961021900177
Blogs,16,55,baselines,bidaf,is,"closed- domain , extractive q&a model","bidaf is closed- domain , extractive q&a model",0.5814555287361145
Blogs,16,55,baselines,"closed- domain , extractive q&a model",only answer,factoid questions,"closed- domain , extractive q&a model only answer factoid questions",0.7322134971618652
Blogs,16,39,experimental-setup,experimental setup,embedding layers T Upgrade Open in,app,experimental setup embedding layers T Upgrade Open in app,0.7413081526756287
Blogs,16,50,experimental-setup,context,is,accompanying text,context is accompanying text,0.5704730153083801
Blogs,16,50,experimental-setup,accompanying text,contains,information,accompanying text contains information,0.496815949678421
Blogs,16,50,experimental-setup,information,needed to answer,query,information needed to answer query,0.6953760981559753
Blogs,16,15,experiments,ability,to answer,non-factoid queries,ability to answer non-factoid queries,0.6810933947563171
Blogs,16,19,experiments,non-factoid camp,is,very broad,non-factoid camp is very broad,0.5657239556312561
Blogs,16,19,experiments,non-factoid camp,includes,questions,non-factoid camp includes questions,0.6399997472763062
Blogs,16,19,experiments,questions,require,logics and reasoning,questions require logics and reasoning,0.6348478198051453
Blogs,16,8,model,bidaf,inspired,subsequent development,bidaf inspired subsequent development,0.7412014007568359
Blogs,16,8,model,competing models,such as,elmo and bert,competing models such as elmo and bert,0.611656129360199
Blogs,16,10,model,bidaf,exhibits,modular architecture,bidaf exhibits modular architecture,0.6920006275177002
Blogs,16,10,model,composite structure,made out of,lego blocks,composite structure made out of lego blocks,0.709494948387146
Blogs,16,10,model,lego blocks,with,blocks,lego blocks with blocks,0.7215335965156555
Blogs,16,10,model,elements,such as,glove,elements such as glove,0.6680962443351746
Blogs,16,10,model,elements,such as,cnn,elements such as cnn,0.6830870509147644
Blogs,16,10,model,elements,such as,lstm,elements such as lstm,0.6182669401168823
Blogs,16,10,model,model,has,bidaf,model has bidaf,0.6748911142349243
Blogs,16,13,model,bidaf,describe,each component,bidaf describe each component,0.7012911438941956
Blogs,16,13,model,each component,of,bidaf,each component of bidaf,0.6749786138534546
Blogs,16,13,model,model,deconstruct,bidaf,model deconstruct bidaf,0.6932047009468079
Blogs,16,13,model,model,describe,each component,model describe each component,0.7247605323791504
Blogs,16,14,model,model,Copious amount of,pictures and diagrams,model Copious amount of pictures and diagrams,0.5958493947982788
Blogs,16,23,model,model,explore,bidaf is structured,model explore bidaf is structured,0.7198346853256226
Blogs,16,25,model,answer,within,context,answer within context,0.7078625559806824
Blogs,16,25,model,model,has,overview of bidaf structure,model has overview of bidaf structure,0.5701303482055664
Blogs,16,26,model,transformation engine,transforms,vector representation of words,transformation engine transforms vector representation of words,0.7308361530303955
Blogs,16,27,model,model,has,bidaf paper,model has bidaf paper,0.6197032928466797
Blogs,16,29,model,function,to change,representation of words,function to change representation of words,0.6793543696403503
Blogs,16,29,model,representation of words,in,query,representation of words in query,0.5715006589889526
Blogs,16,29,model,representation of words,in,context,representation of words in context,0.5583263635635376
Blogs,16,29,model,context,from,strings,context from strings,0.5813161730766296
Blogs,16,29,model,strings,into,vectors of numbers,strings into vectors of numbers,0.5925336480140686
Blogs,16,29,model,model,has,embedding layers,model has embedding layers,0.5486966967582703
Blogs,16,31,model,query and context representations,enter,attention and modeling layers,query and context representations enter attention and modeling layers,0.6221314668655396
Blogs,16,31,model,model,has,query and context representations,model has query and context representations,0.5671262145042419
Blogs,16,32,model,several matrix operations,to fuse,information,several matrix operations to fuse information,0.7228197455406189
Blogs,16,32,model,information,contained in,query,information contained in query,0.6827990412712097
Blogs,16,32,model,information,contained in,the context,information contained in the context,0.6940221786499023
Blogs,16,33,model,another representation,of,context,another representation of context,0.5612695813179016
Blogs,16,33,model,information,from,query,information from query,0.5859482884407043
Blogs,16,34,model,model,as,query - aware context representation,model as query - aware context representation,0.4996408522129059
Blogs,16,36,model,query- aware context representation,passed into,output layer,query- aware context representation passed into output layer,0.6396726965904236
Blogs,16,36,model,output layer,bunch of,probability values,output layer bunch of probability values,0.7090878486633301
Blogs,16,36,model,model,has,query- aware context representation,model has query- aware context representation,0.5028743743896484
Blogs,16,37,model,probability values,to determine,answer,probability values to determine answer,0.7050021290779114
Blogs,16,37,model,answer,has,starts and ends,answer has starts and ends,0.5682954788208008
Blogs,16,37,model,model,has,probability values,model has probability values,0.5967561602592468
Blogs,16,38,model,simplified diagram,depicts,bidaf architecture,simplified diagram depicts bidaf architecture,0.6884333491325378
Blogs,16,38,model,model,has,simplified diagram,model has simplified diagram,0.5550651550292969
Blogs,16,41,model,attention layers,talk about,modeling and output layers,attention layers talk about modeling and output layers,0.5952817797660828
Blogs,16,41,model,model,talk about,attention layers,model talk about attention layers,0.6233404874801636
Blogs,16,42,model,recap,of,whole bidaf architecture,recap of whole bidaf architecture,0.5620688199996948
Blogs,16,42,model,whole bidaf architecture,presented in,very easy language,whole bidaf architecture presented in very easy language,0.6049659252166748
Blogs,16,42,model,model,include,recap,model include recap,0.6235657334327698
Blogs,16,44,model,broader landscape,of,q&a models,broader landscape of q&a models,0.6033051609992981
Blogs,16,44,model,model,Before delving deeper into,bidaf,model Before delving deeper into bidaf,0.7021430730819702
Blogs,16,47,model,open-domain model,access to,knowledge repository,open-domain model access to knowledge repository,0.6586297154426575
Blogs,16,47,model,answering,has,incoming query,answering has incoming query,0.6219684481620789
Blogs,16,47,model,model,has,open-domain model,model has open-domain model,0.5444206595420837
Blogs,16,52,model,extractive model,answers,query,extractive model answers query,0.6830516457557678
Blogs,16,52,model,query,by returning,substring,query by returning substring,0.7187115550041199
Blogs,16,52,model,substring,of,context,substring of context,0.5964565277099609
Blogs,16,52,model,substring,most relevant to,query,substring most relevant to query,0.6628466248512268
Blogs,16,52,model,model,has,extractive model,model has extractive model,0.5769835114479065
Blogs,16,54,model,abstractive model,goes a step further,paraphrases,abstractive model goes a step further paraphrases,0.6654471755027771
Blogs,16,54,model,substring,to,more human-readable form,substring to more human-readable form,0.5590096116065979
Blogs,16,54,model,substring,before returning,answer,substring before returning answer,0.7892486453056335
Blogs,16,54,model,paraphrases,has,substring,paraphrases has substring,0.6169484257698059
Blogs,16,54,model,model,has,abstractive model,model has abstractive model,0.5751802921295166
Blogs,16,6,results,several weeks,topped,leaderboard,several weeks topped leaderboard,0.699595034122467
Blogs,16,6,results,leaderboard,of,stanford question and answering dataset ( squad ),leaderboard of stanford question and answering dataset ( squad ),0.5444930195808411
Blogs,16,9,results,original bidaf paper,rather overwhelmed by,seemingly complex,original bidaf paper rather overwhelmed by seemingly complex,0.7779507637023926
Blogs,16,17,results,most queries,begin with,"who   ,   where   and   when  ","most queries begin with who   ,   where   and   when  ",0.6581289172172546
Blogs,16,17,results,most queries,begin with,factoid,most queries begin with factoid,0.6629661917686462
Blogs,16,17,results,"who   ,   where   and   when  ",are,factoid,"who   ,   where   and   when   are factoid",0.631004810333252
Blogs,16,17,results,results,has,most queries,results has most queries,0.5392731428146362
Blogs,16,43,results,n't technically inclined,jump to,part 4,n't technically inclined jump to part 4,0.7853991389274597
Blogs,16,43,results,part 4,vis-?- vis,other q&a models,part 4 vis-?- vis other q&a models,0.6466370224952698
Blogs,16,43,results,bidaf,vis-?- vis,other q&a models,bidaf vis-?- vis other q&a models,0.7415356040000916
Blogs,16,57,results,bidaf,returns,substring,bidaf returns substring,0.7343350648880005
Blogs,16,57,results,bidaf,is,substring,bidaf is substring,0.6452643871307373
Blogs,16,57,results,substring,of,provided context,substring of provided context,0.5608441233634949
Blogs,16,57,results,results,has,answer,results has answer,0.45916688442230225
Blogs,16,60,results,answer,found,verbatim,answer found verbatim,0.6214848756790161
Blogs,16,60,results,verbatim,in,context,verbatim in context,0.5337438583374023
Blogs,16,60,results,results,Notice,answer,results Notice answer,0.5692696571350098
Blogs,16,61,results,answer,found,verbatim,answer found verbatim,0.6214848756790161
Blogs,16,61,results,verbatim,in,context,verbatim in context,0.5337438583374023
Blogs,16,61,results,results,Notice,answer,results Notice answer,0.5692696571350098
Blogs,17,44,ablation-analysis,memory,becomes,too full,memory becomes too full,0.6368752121925354
Blogs,17,44,ablation-analysis,' forgetting ' function,could,implemented,' forgetting ' function could implemented,0.6368292570114136
Blogs,17,44,ablation-analysis,' forgetting ' function,be,implemented,' forgetting ' function be implemented,0.5348019599914551
Blogs,17,44,ablation-analysis,memory,has,' forgetting ' function,memory has ' forgetting ' function,0.6016936898231506
Blogs,17,44,ablation-analysis,too full,has,' forgetting ' function,too full has ' forgetting ' function,0.6319478750228882
Blogs,17,44,ablation-analysis,ablation analysis,If,memory,ablation analysis If memory,0.6427159905433655
Blogs,17,28,baselines,boromir,appears in,lord of the rings,boromir appears in lord of the rings,0.7047855257987976
Blogs,17,46,baselines,r,produce,actual wording,r produce actual wording,0.6820028424263
Blogs,17,46,baselines,actual wording,of,question answer,actual wording of question answer,0.5443763732910156
Blogs,17,46,baselines,actual wording,based on,memories,actual wording based on memories,0.6744694113731384
Blogs,17,46,baselines,question answer,based on,memories,question answer based on memories,0.7176202535629272
Blogs,17,46,baselines,memories,found by,o,memories found by o,0.7412011027336121
Blogs,17,46,baselines,baselines,has,r,baselines has r,0.6065232157707214
Blogs,17,47,baselines,rnn,conditioned on,output,rnn conditioned on output,0.7611859440803528
Blogs,17,49,baselines,memnn,for,qa ( question answering ) problems,memnn for qa ( question answering ) problems,0.5981977581977844
Blogs,17,49,baselines,memnn,compare it to,rnns ( recurrent neural network ),memnn compare it to rnns ( recurrent neural network ),0.6322620511054993
Blogs,17,49,baselines,memnn,compare it to,lstms ( long short term memory rnns ),memnn compare it to lstms ( long short term memory rnns ),0.6252886056900024
Blogs,17,50,baselines,most basic version,of,memnn,most basic version of memnn,0.6252272725105286
Blogs,17,50,baselines,baselines,has,most basic version,baselines has most basic version,0.5263280272483826
Blogs,17,55,baselines,n_ memory ( 1 < n ? k ),comparing,all of the n-1 supporting memories,n_ memory ( 1 < n ? k ) comparing all of the n-1 supporting memories,0.6859573125839233
Blogs,17,55,baselines,all of the n-1 supporting memories,against,sentences,all of the n-1 supporting memories against sentences,0.658223032951355
Blogs,17,55,baselines,k > 1,has,n_ memory ( 1 < n ? k ),k > 1 has n_ memory ( 1 < n ? k ),0.6374968886375427
Blogs,17,58,baselines,rnn,to perform,sentence generation,rnn to perform sentence generation,0.6085250377655029
Blogs,17,8,hyperparameters,memory size,limited to,128 locations,memory size limited to 128 locations,0.6311196684837341
Blogs,17,8,hyperparameters,much larger storage,has,up to 14 m sentences,much larger storage has up to 14 m sentences,0.5889980792999268
Blogs,17,8,hyperparameters,hyperparameters,consider,much larger storage,hyperparameters consider much larger storage,0.635693371295929
Blogs,17,31,hyperparameters,feature representation d,from,3 | w| to 5 | w |,feature representation d from 3 | w| to 5 | w |,0.571937084197998
Blogs,17,31,hyperparameters,feature representation d,to model,contexts,feature representation d to model contexts,0.6954339146614075
Blogs,17,31,hyperparameters,3 | w| to 5 | w |,to model,contexts,3 | w| to 5 | w | to model contexts,0.7261044979095459
Blogs,17,31,hyperparameters,hyperparameters,increase,feature representation d,hyperparameters increase feature representation d,0.6483845114707947
Blogs,17,52,hyperparameters,hard work,done in,o and r components,hard work done in o and r components,0.6422573924064636
Blogs,17,3,model,memory network,combines,learning strategies,memory network combines learning strategies,0.7068737149238586
Blogs,17,3,model,learning strategies,from,machine learning literature,learning strategies from machine learning literature,0.5324894189834595
Blogs,17,3,model,learning strategies,with,memory component,learning strategies with memory component,0.5923644304275513
Blogs,17,3,model,model,has,memory network,model has memory network,0.5397774577140808
Blogs,17,5,model,high- level view,of,memory network,high- level view of memory network,0.5544398427009583
Blogs,17,5,model,model,has,high- level view,model has high- level view,0.546071469783783
Blogs,17,7,model,( sequence ) prediction,using,"  large , addressable memory","( sequence ) prediction using   large , addressable memory",0.7074615955352783
Blogs,17,7,model,model,perform,( sequence ) prediction,model perform ( sequence ) prediction,0.6142869591712952
Blogs,17,10,model,considerably more complex models,than,memory network,considerably more complex models than memory network,0.571200430393219
Blogs,17,10,model,model,require,considerably more complex models,model require considerably more complex models,0.6833131313323975
Blogs,17,12,model,memory,has,indexed array of objects ( e.g. vectors or arrays of strings ),memory has indexed array of objects ( e.g. vectors or arrays of strings ),0.5387696027755737
Blogs,17,13,model,input feature map i,converts,incoming input,input feature map i converts incoming input,0.6282916069030762
Blogs,17,13,model,incoming input,to,internal feature representation,incoming input to internal feature representation,0.5199546217918396
Blogs,17,13,model,generalization component g,updates,old memories,generalization component g updates old memories,0.6897960305213928
Blogs,17,13,model,old memories,given,new input,old memories given new input,0.7094807028770447
Blogs,17,13,model,model,has,input feature map i,model has input feature map i,0.5696784257888794
Blogs,17,14,model,memories,at,stage,memories at stage,0.6068941354751587
Blogs,17,14,model,model,call,generalization,model call generalization,0.6406572461128235
Blogs,17,15,model,output feature map o,produces,new output,output feature map o produces new output,0.6676939725875854
Blogs,17,15,model,new output,in,feature representation space,new output in feature representation space,0.5131556987762451
Blogs,17,15,model,new output,given,new input and the current memory state,new output given new input and the current memory state,0.665080726146698
Blogs,17,15,model,model,has,output feature map o,model has output feature map o,0.553360104560852
Blogs,17,16,model,response component r,converts,output,response component r converts output,0.6579691767692566
Blogs,17,16,model,output,into,response format desired,output into response format desired,0.6342357397079468
Blogs,17,16,model,model,has,response component r,model has response component r,0.5175427794456482
Blogs,17,17,model,i,learned,components,i learned components,0.7345089912414551
Blogs,17,17,model,i,make use of,any ideas,i make use of any ideas,0.6485846042633057
Blogs,17,17,model,any ideas,from,existing machine learning literature,any ideas from existing machine learning literature,0.5702090859413147
Blogs,17,17,model,model,has,i,model has i,0.5904558300971985
Blogs,17,19,model,question answering,make use of,standard pre-processing,question answering make use of standard pre-processing,0.6334876418113708
Blogs,17,19,model,standard pre-processing,such as,parsing,standard pre-processing such as parsing,0.6591095924377441
Blogs,17,19,model,standard pre-processing,such as,coreference,standard pre-processing such as coreference,0.6501777172088623
Blogs,17,19,model,standard pre-processing,such as,entity limit textual responses,standard pre-processing such as entity limit textual responses,0.6185686588287354
Blogs,17,19,model,entity limit textual responses,to be,single word,entity limit textual responses to be single word,0.5422959923744202
Blogs,17,19,model,single word,using,scoring function,single word using scoring function,0.6925869584083557
Blogs,17,19,model,scoring function,over,all of the words,scoring function over all of the words,0.6612238883972168
Blogs,17,19,model,all of the words,in,dictionary,all of the words in dictionary,0.5323784351348877
Blogs,17,20,model,i,is,stream of words,i is stream of words,0.6170247793197632
Blogs,17,20,model,model,input to,i,model input to i,0.7739315629005432
Blogs,17,21,model,sequence,written to,memory,sequence written to memory,0.703982949256897
Blogs,17,23,model,two schemes,to reduce,number of sentences,two schemes to reduce number of sentences,0.6195586323738098
Blogs,17,23,model,number of sentences,to be,compared,number of sentences to be compared,0.5739082098007202
Blogs,17,23,model,compared,by putting,sentences,compared by putting sentences,0.6274420022964478
Blogs,17,23,model,sentences,into,buckets,sentences into buckets,0.6297856569290161
Blogs,17,23,model,sentences,into,all buckets,sentences into all buckets,0.6286687254905701
Blogs,17,23,model,all buckets,corresponding to,words,all buckets corresponding to words,0.6338602304458618
Blogs,17,23,model,clustered word embeddings,using,k-means,clustered word embeddings using k-means,0.6403632164001465
Blogs,17,23,model,k-means,to cluster,word vectors,k-means to cluster word vectors,0.7461694478988647
Blogs,17,23,model,model,consider,two schemes,model consider two schemes,0.7483306527137756
Blogs,17,24,model,model,with,output scoring function,model with output scoring function,0.5910375714302063
Blogs,17,24,model,output scoring function,based on,"triples ( x , y , y ' )","output scoring function based on triples ( x , y , y ' )",0.6459411382675171
Blogs,17,24,model,three new feature variables,values,0 and 1,three new feature variables values 0 and 1,0.699888288974762
Blogs,17,26,model,our model,to take into account,memory slot,our model to take into account memory slot,0.6540094017982483
Blogs,17,26,model,model,extend,our model,model extend our model,0.6930211782455444
Blogs,17,29,model,bag of words,co-occurred with,one bag,bag of words co-occurred with one bag,0.6462966799736023
Blogs,17,29,model,bag of words,co-occurred with,one,bag of words co-occurred with one,0.7001079320907593
Blogs,17,29,model,one bag,for,left context,one bag for left context,0.6252926588058472
Blogs,17,29,model,one,for,right,one for right,0.7031509280204773
Blogs,17,30,model,model,has,unknown word,model has unknown word,0.5781466960906982
Blogs,17,32,model,new words,during,training,new words during training,0.7115932703018188
Blogs,17,32,model,new words,using,  dropout   technique,new words using   dropout   technique,0.7019606828689575
Blogs,17,32,model,model,learns to deal with,new words,model learns to deal with new words,0.7969880104064941
Blogs,17,38,model,input,into,internal feature representation,input into internal feature representation,0.5905276536941528
Blogs,17,38,model,text,to,sparse or dense feature vector,text to sparse or dense feature vector,0.5402523279190063
Blogs,17,38,model,model,encode,input,model encode input,0.7563918232917786
Blogs,17,39,model,function h,updates,memory,function h updates memory,0.7618118524551392
Blogs,17,39,model,i,to,individual memory slot,i to individual memory slot,0.5762383937835693
Blogs,17,40,model,more sophisticated variants of g,go back and update,"earlier stored memories ( potentially , all memories )","more sophisticated variants of g go back and update earlier stored memories ( potentially , all memories )",0.6932080984115601
Blogs,17,40,model,"earlier stored memories ( potentially , all memories )",based on,new evidence,"earlier stored memories ( potentially , all memories ) based on new evidence",0.6525059342384338
Blogs,17,40,model,new evidence,from,current input x,new evidence from current input x,0.5858809351921082
Blogs,17,40,model,model,has,more sophisticated variants of g,model has more sophisticated variants of g,0.5965394377708435
Blogs,17,43,model,function h,designed or trained to store,memories,function h designed or trained to store memories,0.7895398736000061
Blogs,17,43,model,memories,by,entity or topic,memories by entity or topic,0.5048983693122864
Blogs,17,43,model,' huge ' memory ( e.g. all of wikipedia ),has,function h,' huge ' memory ( e.g. all of wikipedia ) has function h,0.5981708765029907
Blogs,17,43,model,model,For,' huge ' memory ( e.g. all of wikipedia ),model For ' huge ' memory ( e.g. all of wikipedia ),0.5631667375564575
Blogs,17,45,model,inference,to deduce,set of relevant memories,inference to deduce set of relevant memories,0.7384328842163086
Blogs,17,45,model,set of relevant memories,needed to perform,good response,set of relevant memories needed to perform good response,0.7318103313446045
Blogs,17,48,model,"components i , g , o , & r",are,neural networks,"components i , g , o , & r are neural networks",0.611620306968689
Blogs,17,48,model,resulting system,as,memory neural network ( memnn ),resulting system as memory neural network ( memnn ),0.5696481466293335
Blogs,17,48,model,model,describe,resulting system,model describe resulting system,0.6823329329490662
Blogs,17,51,model,i,given,sentence,i given sentence,0.7939655780792236
Blogs,17,51,model,i,given,sentence,i given sentence,0.7939655780792236
Blogs,17,51,model,sentence,in,next available memory slot,sentence in next available memory slot,0.5254753828048706
Blogs,17,51,model,g,stores,sentence,g stores sentence,0.7712986469268799
Blogs,17,51,model,sentence,in,next available memory slot,sentence in next available memory slot,0.5254753828048706
Blogs,17,51,model,model,has,i,model has i,0.5904558300971985
Blogs,17,53,model,o,to,nd,o to nd,0.16731344163417816
Blogs,17,53,model,o,to,up to k,o to up to k,0.6604930758476257
Blogs,17,53,model,nd,has,up to k,nd has up to k,0.593235194683075
Blogs,17,53,model,up to k,has,supporting memories,up to k has supporting memories,0.6251978278160095
Blogs,17,53,model,model,has,o,model has o,0.6093984246253967
Blogs,17,54,model,rst memory,found by,scoring,rst memory found by scoring,0.6585869193077087
Blogs,17,54,model,match,between,input sentence,match between input sentence,0.66863614320755
Blogs,17,54,model,match,between,each sentence,match between each sentence,0.663009762763977
Blogs,17,54,model,each sentence,in,memory,each sentence in memory,0.531947910785675
Blogs,17,54,model,scoring,has,match,scoring has match,0.5847070813179016
Blogs,17,54,model,model,has,rst memory,model has rst memory,0.577090322971344
Blogs,17,56,model,sentence,with,highest matching score,sentence with highest matching score,0.6157987713813782
Blogs,17,56,model,model,has,sentence,model has sentence,0.6082519292831421
Blogs,17,57,model,list of sentences,containing,original input sentence,list of sentences containing original input sentence,0.6313390731811523
Blogs,17,59,model,compromise,to,inputs,compromise to inputs,0.6200454831123352
Blogs,17,59,model,compromise,store,each chunk,compromise store each chunk,0.812803328037262
Blogs,17,59,model,inputs,store,each chunk,inputs store each chunk,0.7815386056900024
Blogs,17,59,model,model,has,compromise,model has compromise,0.5734212398529053
Blogs,18,33,ablation-analysis,relation vector   citizenship,closely mapped to,relation vector   born - in,relation vector   citizenship closely mapped to relation vector   born - in,0.6954334378242493
Blogs,18,12,baselines,baselines,has,kb,baselines has kb,0.6323225498199463
Blogs,18,25,baselines,pra,uses,random walks,pra uses random walks,0.5139541029930115
Blogs,18,25,baselines,random walks,to perform,multiple depth-rst search,random walks to perform multiple depth-rst search,0.6133244037628174
Blogs,18,25,baselines,multiple depth-rst search,to nd,relational paths,multiple depth-rst search to nd relational paths,0.5701233744621277
Blogs,18,25,baselines,baselines,has,pra,baselines has pra,0.6060128808021545
Blogs,18,47,baselines,crowd - sourced workers,compose,sequence of related questions,crowd - sourced workers compose sequence of related questions,0.7108761072158813
Blogs,18,47,baselines,baselines,has,crowd - sourced workers,baselines has crowd - sourced workers,0.5244385600090027
Blogs,18,18,experiments,score,for,particular path query,score for particular path query,0.6249641180038452
Blogs,18,18,experiments,score,compute,multi-step reasoning,score compute multi-step reasoning,0.7790350317955017
Blogs,18,18,experiments,multi-step reasoning,on,kb,multi-step reasoning on kb,0.5572964549064636
Blogs,18,22,experiments,"triplet ( obama , born - in , hawaii ) and ( hawaii , part-of , usa )",connect,obama 's citizenship,"triplet ( obama , born - in , hawaii ) and ( hawaii , part-of , usa ) connect obama 's citizenship",0.6801403164863586
Blogs,18,22,experiments,obama 's citizenship,to be,usa,obama 's citizenship to be usa,0.5782760381698608
Blogs,18,22,experiments,obama 's citizenship,using,born - in and part - of relations,obama 's citizenship using born - in and part - of relations,0.6615568399429321
Blogs,18,40,experiments,conversational kb - qa agent,equipped with,dialogue manager ( dm ),conversational kb - qa agent equipped with dialogue manager ( dm ),0.6968687176704407
Blogs,18,40,experiments,dialogue manager ( dm ),tracks,dialogue state,dialogue manager ( dm ) tracks dialogue state,0.7347601652145386
Blogs,18,40,experiments,dialogue manager ( dm ),to determine,question,dialogue manager ( dm ) to determine question,0.6897692084312439
Blogs,18,40,experiments,question,to ask,user next,question to ask user next,0.69940584897995
Blogs,18,40,experiments,question,navigate,kb,question navigate kb,0.7520697116851807
Blogs,18,40,experiments,semantic parser and kbr engine,has,conversational kb - qa agent,semantic parser and kbr engine has conversational kb - qa agent,0.5858713388442993
Blogs,18,40,experiments,kb,has,effectively,kb has effectively,0.7106676697731018
Blogs,18,5,model,model,has,embedding - based methods,model has embedding - based methods,0.5706575512886047
Blogs,18,7,model,architecture,consists of,3 components,architecture consists of 3 components,0.6950305104255676
Blogs,18,7,model,3 components,has,encoder and decoder,3 components has encoder and decoder,0.5432208180427551
Blogs,18,7,model,model,has,architecture,model has architecture,0.5575731992721558
Blogs,18,10,model,embeddings,to encode,all the entities and relations,embeddings to encode all the entities and relations,0.7468969225883484
Blogs,18,10,model,all the entities and relations,in,kb,all the entities and relations in kb,0.5293400287628174
Blogs,18,11,model,different paraphrased questions,with,similar semantics,different paraphrased questions with similar semantics,0.585357666015625
Blogs,18,11,model,similar semantics,closely in,neural space,similar semantics closely in neural space,0.6534149646759033
Blogs,18,11,model,model,maps,different paraphrased questions,model maps different paraphrased questions,0.6839611530303955
Blogs,18,13,model,bilinear model,is one of,basic kb embedding models,bilinear model is one of basic kb embedding models,0.6269682049751282
Blogs,18,13,model,embedding vector,for,each entity,embedding vector for each entity,0.5773903727531433
Blogs,18,13,model,matrix,each relation in,kb,matrix each relation in kb,0.752811849117279
Blogs,18,13,model,model,has,bilinear model,model has bilinear model,0.5503109097480774
Blogs,18,14,model,how likely,has,triplet holds,how likely has triplet holds,0.5854814052581787
Blogs,18,15,model,answer queries,involves,multiple steps,answer queries involves multiple steps,0.6484706401824951
Blogs,18,15,model,model,extended to,answer queries,model extended to answer queries,0.6779270768165588
Blogs,18,16,model,where did tad lincoln 's parents live ?,to have,initial anchor entity s ( tad lincoln ),where did tad lincoln 's parents live ? to have initial anchor entity s ( tad lincoln ),0.66357421875
Blogs,18,16,model,model,to have,initial anchor entity s ( tad lincoln ),model to have initial anchor entity s ( tad lincoln ),0.6403827667236328
Blogs,18,17,model,sequence of relations,represented by,combining individual matrix relation,sequence of relations represented by combining individual matrix relation,0.7258417010307312
Blogs,18,17,model,sequence of relations,form,relation embeddings pathway,sequence of relations form relation embeddings pathway,0.6945146322250366
Blogs,18,17,model,model,has,sequence of relations,model has sequence of relations,0.6152443289756775
Blogs,18,20,model,multi-step reasoning,for,each relation,multi-step reasoning for each relation,0.6343400478363037
Blogs,18,20,model,each relation,interested in,subsequent relational paths,each relation interested in subsequent relational paths,0.6435110569000244
Blogs,18,20,model,subsequent relational paths,that are,connected and relevant,subsequent relational paths that are connected and relevant,0.6482192277908325
Blogs,18,20,model,model,To do,multi-step reasoning,model To do multi-step reasoning,0.4436807334423065
Blogs,18,26,model,set of relational paths,for,r relation,set of relational paths for r relation,0.6159955263137817
Blogs,18,26,model,r relation,to traverse,kb,r relation to traverse kb,0.728503406047821
Blogs,18,26,model,candidate answer t,using,linear model,candidate answer t using linear model,0.655287504196167
Blogs,18,26,model,model,given,query,model given query,0.7787366509437561
Blogs,18,29,model,source entity and relation,into,respective embedding vectors,source entity and relation into respective embedding vectors,0.5717645883560181
Blogs,18,29,model,initial hidden vector,for,controller,initial hidden vector for controller,0.6535524725914001
Blogs,18,30,model,decoder,takes in,controller hidden state,decoder takes in controller hidden state,0.6440938711166382
Blogs,18,30,model,controller hidden state,to generate,output vector,controller hidden state to generate output vector,0.6723071336746216
Blogs,18,30,model,output vector,map onto,symbolic space,output vector map onto symbolic space,0.7379209995269775
Blogs,18,30,model,symbolic space,to generate,nal output answer,symbolic space to generate nal output answer,0.66439288854599
Blogs,18,30,model,model,has,decoder,model has decoder,0.6226420402526855
Blogs,18,31,model,shared memory m,consists of,list of vectors,shared memory m consists of list of vectors,0.6531854271888733
Blogs,18,31,model,randomly initialised and updated,through,training,randomly initialised and updated through training,0.6545815467834473
Blogs,18,31,model,model,has,shared memory m,model has shared memory m,0.5700002908706665
Blogs,18,32,model,distance between these vectors,capture,semantic relatedness,distance between these vectors capture semantic relatedness,0.7047160267829895
Blogs,18,32,model,semantic relatedness,has,of these vectors,semantic relatedness has of these vectors,0.5751203894615173
Blogs,18,32,model,model,has,vector,model has vector,0.564267635345459
Blogs,18,34,model,initial hidden state,from,encoder,initial hidden state from encoder,0.5476300120353699
Blogs,18,34,model,attention mechanism,to iteratively update,hidden state,attention mechanism to iteratively update hidden state,0.6961380839347839
Blogs,18,34,model,hidden state,decides to terminate,reasoning process,hidden state decides to terminate reasoning process,0.7532604336738586
Blogs,18,35,model,reasoning process,formulated as,markov decision processes ( mdp ),reasoning process formulated as markov decision processes ( mdp ),0.6157540082931519
Blogs,18,35,model,markov decision processes ( mdp ),as,number of iteration steps,markov decision processes ( mdp ) as number of iteration steps,0.5206510424613953
Blogs,18,35,model,number of iteration steps,during,reasoning process,number of iteration steps during reasoning process,0.663581371307373
Blogs,18,35,model,model,has,reasoning process,model has reasoning process,0.5696302652359009
Blogs,18,42,model,belief tracker,identify,user intents,belief tracker identify user intents,0.5965651273727417
Blogs,18,42,model,belief tracker,tracking,dialogue state,belief tracker tracking dialogue state,0.7701521515846252
Blogs,18,42,model,user intents,extracting,relatable attributes,user intents extracting relatable attributes,0.6769341230392456
Blogs,18,42,model,model,has,belief tracker,model has belief tracker,0.5383175015449524
Blogs,18,44,model,beliefs summary,summarises,vector state,beliefs summary summarises vector state,0.6104095578193665
Blogs,18,44,model,model,has,beliefs summary,model has beliefs summary,0.5610708594322205
Blogs,18,45,model,dialogue policy network,determines,next action,dialogue policy network determines next action,0.6699078679084778
Blogs,18,45,model,next action,based on,dialogue state,next action based on dialogue state,0.6225271224975586
Blogs,18,45,model,model,has,dialogue policy network,model has dialogue policy network,0.58399498462677
Blogs,18,27,results,disadvantage,of,pra,disadvantage of pra,0.7217419743537903
Blogs,18,27,results,pra,does not capture,semantic similarities,pra does not capture semantic similarities,0.7199528813362122
Blogs,18,27,results,pra,produce,millions of distinct paths,pra produce millions of distinct paths,0.671582043170929
Blogs,18,27,results,semantic similarities,between,relations,semantic similarities between relations,0.655241847038269
Blogs,18,27,results,results,has,disadvantage,results has disadvantage,0.5165038108825684
Blogs,18,43,results,soft - kb lookup,behaves like,other kb - qa models,soft - kb lookup behaves like other kb - qa models,0.7143481373786926
Blogs,18,43,results,other kb - qa models,except,input data,other kb - qa models except input data,0.6526398062705994
Blogs,18,43,results,input data,based on,dialogue history,input data based on dialogue history,0.6501815915107727
Blogs,18,43,results,results,has,soft - kb lookup,results has soft - kb lookup,0.5837645530700684
Blogs,19,20,ablation-analysis,fine-tuned swedish bert,for,swedish qa,fine-tuned swedish bert for swedish qa,0.6607683897018433
Blogs,19,20,ablation-analysis,ablation analysis,use,fine-tuned swedish bert,ablation analysis use fine-tuned swedish bert,0.641220211982727
Blogs,19,21,ablation-analysis,ablation analysis,Mistranslation of,dataset,ablation analysis Mistranslation of dataset,0.6809389591217041
Blogs,19,38,ablation-analysis,ablation analysis,translate,answer 2nd century bce,ablation analysis translate answer 2nd century bce,0.6960552930831909
Blogs,19,47,ablation-analysis,ablation analysis,has,vervakning,ablation analysis has vervakning,0.582814633846283
Blogs,19,53,ablation-analysis,some answers,not found in,context,some answers not found in context,0.7350203990936279
Blogs,19,53,ablation-analysis,ablation analysis,has,some answers,ablation analysis has some answers,0.5935443639755249
Blogs,19,84,ablation-analysis,atmospheric oxygen levels,show,global downward trend,atmospheric oxygen levels show global downward trend,0.606833279132843
Blogs,19,84,ablation-analysis,ablation analysis,monitoring of,atmospheric oxygen levels,ablation analysis monitoring of atmospheric oxygen levels,0.6773096919059753
Blogs,19,86,ablation-analysis,special marker,around,answer diatomic oxygen,special marker around answer diatomic oxygen,0.7159592509269714
Blogs,19,86,ablation-analysis,[ 0 ],around,answer diatomic oxygen,[ 0 ] around answer diatomic oxygen,0.6958973407745361
Blogs,19,86,ablation-analysis,20.8 %,of,earth 's atmosphere,20.8 % of earth 's atmosphere,0.5285254716873169
Blogs,19,86,ablation-analysis,special marker,has,[ 0 ],special marker has [ 0 ],0.5614457130432129
Blogs,19,86,ablation-analysis,special marker,has,oxygen,special marker has oxygen,0.5901353359222412
Blogs,19,87,ablation-analysis,atmospheric oxygen levels,show,global downward trend,atmospheric oxygen levels show global downward trend,0.606833279132843
Blogs,19,87,ablation-analysis,ablation analysis,monitoring of,atmospheric oxygen levels,ablation analysis monitoring of atmospheric oxygen levels,0.6773096919059753
Blogs,19,5,baselines,baselines,has,bert,baselines has bert,0.5950736403465271
Blogs,19,11,baselines,squad2.0,combines,"100,000 questions","squad2.0 combines 100,000 questions",0.7403575778007507
Blogs,19,11,baselines,"100,000 questions",with,"over 50,000 unanswerable questions","100,000 questions with over 50,000 unanswerable questions",0.6271159052848816
Blogs,19,11,baselines,baselines,has,squad2.0,baselines has squad2.0,0.5757483839988708
Blogs,19,13,baselines,bert - family,to do,question answering task,bert - family to do question answering task,0.40836143493652344
Blogs,19,13,baselines,question answering task,in,swedish,question answering task in swedish,0.5129975080490112
Blogs,19,14,baselines,swedish questions,into,english,swedish questions into english,0.5846360325813293
Blogs,19,14,baselines,swedish questions,process it,english bert,swedish questions process it english bert,0.6985574960708618
Blogs,19,14,baselines,swedish questions,with,english bert,swedish questions with english bert,0.6682232022285461
Blogs,19,14,baselines,english answers,back into,swedish,english answers back into swedish,0.6540238857269287
Blogs,19,22,baselines,swedish squad,to build,swedish qa bert,swedish squad to build swedish qa bert,0.6572222709655762
Blogs,19,46,baselines,diatomiskt syre,has,gas utg? r,diatomiskt syre has gas utg? r,0.662467896938324
Blogs,19,46,baselines,gas utg? r,has,"20,8 %","gas utg? r has 20,8 %",0.5825634598731995
Blogs,19,46,baselines,baselines,has,diatomiskt syre,baselines has diatomiskt syre,0.6184858679771423
Blogs,19,59,baselines,kb lab model,trained on,squad,kb lab model trained on squad,0.7279958128929138
Blogs,19,61,baselines,fine-tuned,on,our swedish translation of squad 2.0 train dataset,fine-tuned on our swedish translation of squad 2.0 train dataset,0.4767841696739197
Blogs,19,80,baselines,baselines,has,5/8simple strategy,baselines has 5/8simple strategy,0.5603317618370056
Blogs,19,85,baselines,20.8 %,of,earth 's atmosphere,20.8 % of earth 's atmosphere,0.5285254716873169
Blogs,19,9,experiments,question answering task,using,squad 2.0,question answering task using squad 2.0,0.6356252431869507
Blogs,19,24,experiments,squad 2.0,using,google translate api,squad 2.0 using google translate api,0.6554321050643921
Blogs,19,24,experiments,automatically,using,google translate api,automatically using google translate api,0.6812610626220703
Blogs,19,24,experiments,squad 2.0,has,automatically,squad 2.0 has automatically,0.6283789277076721
Blogs,19,29,experiments,oxygen text,in,squad 2.0 dev,oxygen text in squad 2.0 dev,0.5517693758010864
Blogs,19,32,experiments,atomic number,of,periodic table,atomic number of periodic table,0.44633975625038147
Blogs,19,32,experiments,periodic table,for,oxygen,periodic table for oxygen,0.6375434398651123
Blogs,19,33,experiments,span,of,answer,span of answer,0.6228930950164795
Blogs,19,33,experiments,span,of,answer,span of answer,0.6228930950164795
Blogs,19,33,experiments,answer,from,60 to 61,answer from 60 to 61,0.6350961923599243
Blogs,19,33,experiments,60 to 61,indicates,position,60 to 61 indicates position,0.6992579698562622
Blogs,19,33,experiments,position,of,start and end,position of start and end,0.6052096486091614
Blogs,19,33,experiments,start and end,of,answer,start and end of answer,0.6078169345855713
Blogs,19,33,experiments,answer,in,excerpted context,answer in excerpted context,0.5046789050102234
Blogs,19,37,experiments,f?rsta k?nda,experimenten om,f?rh?llandet,f?rsta k?nda experimenten om f?rh?llandet,0.7069463729858398
Blogs,19,54,experiments,translated dataset,is,90 %,translated dataset is 90 %,0.589817225933075
Blogs,19,54,experiments,translated dataset,about,90 %,translated dataset about 90 %,0.6107128262519836
Blogs,19,54,experiments,90 %,of,original dataset,90 % of original dataset,0.5728864073753357
Blogs,19,56,experiments,swedish bert,pre-trained by,national library of sweden ( kb lab ),swedish bert pre-trained by national library of sweden ( kb lab ),0.7243746519088745
Blogs,19,57,experiments,first model,is,multilingual xlm -roberta,first model is multilingual xlm -roberta,0.6132391095161438
Blogs,19,57,experiments,multilingual xlm -roberta,trained on,squad,multilingual xlm -roberta trained on squad,0.740013599395752
Blogs,19,57,experiments,squad,by,deepset gmbh,squad by deepset gmbh,0.6393651366233826
Blogs,19,78,experiments,first known experiments,on,combustion and air conducted,first known experiments on combustion and air conducted,0.5474072098731995
Blogs,19,82,experiments,oxygen text,in,squad 2.0 dev,oxygen text in squad 2.0 dev,0.5517693758010864
Blogs,19,93,experiments,recent nobel prize in physics,as,contexts,recent nobel prize in physics as contexts,0.5593053102493286
Blogs,19,2,hyperparameters,sign up,for,variable,sign up for variable,0.6069257259368896
Blogs,19,2,hyperparameters,hyperparameters,has,sign up,hyperparameters has sign up,0.5629818439483643
Blogs,19,30,hyperparameters,oxygen,is,chemical element,oxygen is chemical element,0.5478788018226624
Blogs,19,30,hyperparameters,chemical element,with,symbol o,chemical element with symbol o,0.5438132286071777
Blogs,19,30,hyperparameters,chemical element,with,atomic number,chemical element with atomic number,0.46180328726768494
Blogs,19,30,hyperparameters,hyperparameters,Context,oxygen,hyperparameters Context oxygen,0.6694425940513611
Blogs,19,34,hyperparameters,context,translated to,swedish,context translated to swedish,0.6854855418205261
Blogs,19,34,hyperparameters,hyperparameters,has,context,hyperparameters has context,0.5262600183486938
Blogs,19,50,hyperparameters,start and end,of,marked sentence,start and end of marked sentence,0.5946485996246338
Blogs,19,50,hyperparameters,marked sentence,will be,span,marked sentence will be span,0.6517040133476257
Blogs,19,50,hyperparameters,span,of,answer,span of answer,0.6228930950164795
Blogs,19,50,hyperparameters,hyperparameters,has,start and end,hyperparameters has start and end,0.5606300830841064
Blogs,19,63,hyperparameters,hyperparameters,has,manually created question - answer pairs,hyperparameters has manually created question - answer pairs,0.548372209072113
Blogs,19,81,hyperparameters,translation,insert,special marker,translation insert special marker,0.7106976509094238
Blogs,19,81,hyperparameters,special marker,around,answer,special marker around answer,0.7470664978027344
Blogs,19,81,hyperparameters,answer,in,context,answer in context,0.5304944515228271
Blogs,19,81,hyperparameters,hyperparameters,Before,translation,hyperparameters Before translation,0.6687173843383789
Blogs,19,90,hyperparameters,model,available in,huggingface model hub,model available in huggingface model hub,0.646155595779419
Blogs,19,90,hyperparameters,fine-tuned model,has,model,fine-tuned model has model,0.5590360760688782
Blogs,19,90,hyperparameters,hyperparameters,to use,fine-tuned model,hyperparameters to use fine-tuned model,0.6977155804634094
Blogs,19,8,model,purpose,of,post,purpose of post,0.5088728070259094
Blogs,19,8,model,model,has,purpose,model has purpose,0.5476922392845154
Blogs,19,16,model,translation,performed for,every inference,translation performed for every inference,0.6736912727355957
Blogs,19,16,model,model,has,translation,model has translation,0.5934292674064636
Blogs,19,41,model,model,translate,context and the answer,model translate context and the answer,0.7200163006782532
Blogs,19,43,model,special marker,not limited to,[ 0 ],special marker not limited to [ 0 ],0.7581345438957214
Blogs,19,44,model,model,Translate,marked context,model Translate marked context,0.7401257753372192
Blogs,19,48,model,marked sentence,from,translated context,marked sentence from translated context,0.5637116432189941
Blogs,19,48,model,model,Extract,marked sentence,model Extract marked sentence,0.696060299873352
Blogs,19,73,model,position,in,context,position in context,0.5247306227684021
Blogs,19,73,model,translate,has,context,translate has context,0.6460341215133667
Blogs,19,19,results,multilingual models,have,larger model size,multilingual models have larger model size,0.5239167213439941
Blogs,19,19,results,larger model size,than,monolingual models,larger model size than monolingual models,0.5676687955856323
Blogs,19,19,results,inefficient,process,swedish,inefficient process swedish,0.8051132559776306
Blogs,19,19,results,results,has,multilingual models,results has multilingual models,0.5098084211349487
Blogs,19,25,results,results,sounds like,straightforward task,results sounds like straightforward task,0.6088253259658813
Blogs,19,27,results,translated answer,may not be included in,translated context,translated answer may not be included in translated context,0.6730388402938843
Blogs,19,27,results,translated independently,has,translated answer,translated independently has translated answer,0.6352474689483643
Blogs,19,36,results,context,by,google,context by google,0.5760319232940674
Blogs,19,36,results,results,Translating,context,results Translating context,0.6922639608383179
Blogs,19,40,results,ground truth answer,may not be found in,context,ground truth answer may not be found in context,0.6289581656455994
Blogs,19,40,results,context,has,ground truth answer,context has ground truth answer,0.5405179858207703
Blogs,19,40,results,independently,has,ground truth answer,independently has ground truth answer,0.605489194393158
Blogs,19,40,results,results,translate,context,results translate context,0.6269397139549255
Blogs,19,45,results,results,has,result,results has result,0.5303357243537903
Blogs,19,49,results,results,will be,translated answer,results will be translated answer,0.6371698379516602
Blogs,19,52,results,strategy,is,not perfect,strategy is not perfect,0.6280103921890259
Blogs,19,52,results,results,admit that,strategy,results admit that strategy,0.5755069851875305
Blogs,19,67,results,performance,of,our fine-tuned model,performance of our fine-tuned model,0.5547544360160828
Blogs,19,67,results,other finetuned models,on,translated dataset,other finetuned models on translated dataset,0.5288687944412231
Blogs,19,67,results,our model,performs,relatively well,our model performs relatively well,0.6360014081001282
Blogs,19,67,results,results,compared,performance,results compared performance,0.7382499575614929
Blogs,19,68,results,savantic,has,ai company,savantic has ai company,0.5922619700431824
Blogs,19,72,results,correct span,of,answer,correct span of answer,0.5457030534744263
Blogs,19,72,results,answer,from,53 to 54,answer from 53 to 54,0.6562361121177673
Blogs,19,72,results,results,has,correct span,results has correct span,0.5838323831558228
Blogs,19,89,results,110m parameters,achieves,better scores,110m parameters achieves better scores,0.6815587878227234
Blogs,19,89,results,110m parameters,establishes,close f1 score,110m parameters establishes close f1 score,0.5695975422859192
Blogs,19,89,results,better scores,than,kb lab model,better scores than kb lab model,0.5748192071914673
Blogs,19,89,results,close f1 score,compared to,xlm - roberta,close f1 score compared to xlm - roberta,0.6869667768478394
Blogs,19,95,results,realistic,use,fine-tuned model,realistic use fine-tuned model,0.6271265745162964
Blogs,19,95,results,fine-tuned model,without,further training,fine-tuned model without further training,0.7169151306152344
Blogs,19,95,results,results,use,fine-tuned model,results use fine-tuned model,0.6223657131195068
Blogs,19,97,results,our model,achieved,better results,our model achieved better results,0.7049545645713806
Blogs,19,97,results,better results,in,exact match,better results in exact match,0.5511835217475891
Blogs,19,97,results,better results,in,f1 score,better results in f1 score,0.49865561723709106
Blogs,19,97,results,results,has,our model,results has our model,0.5871725678443909
