topic,paper_ID,sentence_ID,info-unit,sub,pred,obj,triplets,pred_weights
Blogs,0,23,ablation-analysis,rapidly,as,average score,rapidly as average score,0.602495014667511
Blogs,0,23,ablation-analysis,average score,of,summaries,average score of summaries,0.591006338596344
Blogs,0,23,ablation-analysis,proportion of consistent improvement ( f/ n ratio ),has,decrease,proportion of consistent improvement ( f/ n ratio ) has decrease,0.5770311951637268
Blogs,0,23,ablation-analysis,decrease,has,rapidly,decrease has rapidly,0.6083329319953918
Blogs,0,23,ablation-analysis,ablation analysis,show that,proportion of consistent improvement ( f/ n ratio ),ablation analysis show that proportion of consistent improvement ( f/ n ratio ),0.49560993909835815
Blogs,0,40,ablation-analysis,correlations,between,metrics,correlations between metrics,0.6639003157615662
Blogs,0,40,ablation-analysis,correlations,some are,even negative,correlations some are even negative,0.7056106328964233
Blogs,0,40,ablation-analysis,metrics,are,low,metrics are low,0.5828683972358704
Blogs,0,40,ablation-analysis,high-scoring summaries ( t ),has,correlations,high-scoring summaries ( t ) has correlations,0.5568841695785522
Blogs,0,40,ablation-analysis,ablation analysis,in,high-scoring summaries ( t ),ablation analysis in high-scoring summaries ( t ),0.5089846253395081
Blogs,0,19,baselines,consistent improvements,across,metrics,consistent improvements across metrics,0.6977621912956238
Blogs,0,28,baselines,size of longest common subsequence,between,generated summaries and ground- truth,size of longest common subsequence between generated summaries and ground- truth,0.599822461605072
Blogs,0,28,baselines,baselines,has,size of longest common subsequence,baselines has size of longest common subsequence,0.533462643623352
Blogs,0,29,baselines,soft matching,based on,cosine similarity and word embeddings,soft matching based on cosine similarity and word embeddings,0.6063714027404785
Blogs,0,29,baselines,baselines,has,soft matching,baselines has soft matching,0.5517553687095642
Blogs,0,30,baselines,jensen-shannon divergence,to measure,difference,jensen-shannon divergence to measure difference,0.7010664939880371
Blogs,0,30,baselines,difference,between,bigram distributions,difference between bigram distributions,0.6861289143562317
Blogs,0,8,experiments,methodology,to study,evaluation metrics,methodology to study evaluation metrics,0.673504114151001
Blogs,0,8,experiments,evaluation metrics,in,high-scoring range,evaluation metrics in high-scoring range,0.47202563285827637
Blogs,0,33,experiments,generated dataset,consists of,"160,523 summaries","generated dataset consists of 160,523 summaries",0.6790004968643188
Blogs,0,34,experiments,high-scoring summaries,use,lexrank,high-scoring summaries use lexrank,0.6567791104316711
Blogs,0,34,experiments,lexrank,to lter out,summaries,lexrank to lter out summaries,0.7783673405647278
Blogs,0,34,experiments,underperform,has,benchmark,underperform has benchmark,0.6104233860969543
Blogs,0,35,experiments,nal dataset ( t ),of,102 summaries per topic,nal dataset ( t ) of 102 summaries per topic,0.5795137286186218
Blogs,0,35,experiments,nal dataset ( t ),around,102 summaries per topic,nal dataset ( t ) around 102 summaries per topic,0.6260681748390198
Blogs,0,35,experiments,102 summaries per topic,after removing,duplicates and ltering,102 summaries per topic after removing duplicates and ltering,0.7225343585014343
Blogs,0,36,experiments,correlation analysis,has,paradox,correlation analysis has paradox,0.5658090114593506
Blogs,0,14,model,correlation,between,pairs of metrics,correlation between pairs of metrics,0.6778770089149475
Blogs,0,14,model,correlation,in,different scoring ranges,correlation in different scoring ranges,0.5608263611793518
Blogs,0,14,model,pairs of metrics,in,different scoring ranges,pairs of metrics in different scoring ranges,0.50902259349823
Blogs,0,14,model,model,computes,correlation,model computes correlation,0.7043029069900513
Blogs,0,32,model,genetic algorithm,for,summarisation,genetic algorithm for summarisation,0.6045575141906738
Blogs,0,32,model,summarisation,to generate,summaries,summarisation to generate summaries,0.6467769145965576
Blogs,0,32,model,summaries,optimise,each metrics,summaries optimise each metrics,0.735546886920929
Blogs,0,32,model,model,use,genetic algorithm,model use genetic algorithm,0.6161379218101501
Blogs,0,6,results,strong disagreement,between,evaluation metrics,strong disagreement between evaluation metrics,0.6239694356918335
Blogs,0,6,results,evaluation metrics,behave,similarly,evaluation metrics behave similarly,0.7177147269248962
Blogs,0,9,results,more human annotations,in,appropriate scoring range,more human annotations in appropriate scoring range,0.4714323580265045
Blogs,0,12,results,score distribution,of,ground - truth summaries,score distribution of ground - truth summaries,0.5346671342849731
Blogs,0,12,results,score distribution,of,generated summaries,score distribution of generated summaries,0.5793629884719849
Blogs,0,12,results,generated summaries,by,modern summarisation systems,generated summaries by modern summarisation systems,0.5400832891464233
Blogs,0,13,results,evaluation metrics,behave similar to,human evaluation,evaluation metrics behave similar to human evaluation,0.5520261526107788
Blogs,0,13,results,human evaluation,in,red distribution ( high -scoring range ),human evaluation in red distribution ( high -scoring range ),0.49280840158462524
Blogs,0,17,results,results,has,bigram overlap between generated summaries and ground- truth,results has bigram overlap between generated summaries and ground- truth,0.5302668809890747
Blogs,0,18,results,results,has,measuring consistent improvements across metrics,results has measuring consistent improvements across metrics,0.5654332637786865
Blogs,0,21,results,summaries,better than,s,summaries better than s,0.6983789801597595
Blogs,0,21,results,s,for,one metric,s for one metric,0.6222639083862305
Blogs,0,21,results,results,Among,summaries,results Among summaries,0.5931007266044617
Blogs,0,22,results,summaries,better than,s,summaries better than s,0.6983789801597595
Blogs,0,22,results,s,for,all metrics,s for all metrics,0.6518640518188477
Blogs,0,22,results,results,Among,summaries,results Among summaries,0.5931007266044617
Blogs,0,25,results,f,divide by,n,f divide by n,0.5974829196929932
Blogs,0,25,results,n,to obtain,ratio,n to obtain ratio,0.6054570078849792
Blogs,0,25,results,results,has,f,results has f,0.5239986181259155
Blogs,0,37,results,high correlation,between,evaluation metrics,high correlation between evaluation metrics,0.6148824691772461
Blogs,0,37,results,r - 2 and js - 2,having,strongest correlation,r - 2 and js - 2 having strongest correlation,0.6492125391960144
Blogs,0,37,results,results,for,dataset a and w,results for dataset a and w,0.5997369885444641
Blogs,0,41,results,no global agreement,between,metrics,no global agreement between metrics,0.6336264610290527
Blogs,0,41,results,metrics,to measure,improvements,metrics to measure improvements,0.6991312503814697
Blogs,0,41,results,improvements,examine,summaries,improvements examine summaries,0.7297618985176086
Blogs,0,41,results,summaries,better than,lexrank,summaries better than lexrank,0.7153552174568176
Blogs,0,42,results,increases,with,higher - scoring summaries,increases with higher - scoring summaries,0.6372816562652588
Blogs,0,42,results,disagreement,has,increases,disagreement has increases,0.6166732907295227
Blogs,0,44,results,our current evaluation metrics,good at distinguishing,very bad summaries,our current evaluation metrics good at distinguishing very bad summaries,0.7361053228378296
Blogs,0,44,results,very bad summaries,from,very good summaries,very bad summaries from very good summaries,0.4965316951274872
Blogs,0,44,results,results,tell us that,our current evaluation metrics,results tell us that our current evaluation metrics,0.5665798783302307
Blogs,1,11,ablation-analysis,position bias,is,very strong,position bias is very strong,0.5652182102203369
Blogs,1,11,ablation-analysis,position bias,remains,most effective approach,position bias remains most effective approach,0.6388054490089417
Blogs,1,11,ablation-analysis,very strong,in,news,very strong in news,0.491252064704895
Blogs,1,11,ablation-analysis,most effective approach,in selecting,positive information,most effective approach in selecting positive information,0.6454001069068909
Blogs,1,11,ablation-analysis,ablation analysis,shows us that,position bias,ablation analysis shows us that position bias,0.5854781866073608
Blogs,1,14,baselines,position - agnostic graphs,extended,lexrank,position - agnostic graphs extended lexrank,0.6172033548355103
Blogs,1,14,baselines,lexrank,using,sbert ( slr ),lexrank using sbert ( slr ),0.6986710429191589
Blogs,1,14,baselines,sbert ( slr ),to measure,cosine similarity,sbert ( slr ) to measure cosine similarity,0.656398594379425
Blogs,1,15,baselines,af nity propagation clustering algorithm ( sc ),which,center,af nity propagation clustering algorithm ( sc ) which center,0.6328568458557129
Blogs,1,15,baselines,af nity propagation clustering algorithm ( sc ),clusters,sentences,af nity propagation clustering algorithm ( sc ) clusters sentences,0.7402023077011108
Blogs,1,15,baselines,cluster,selected to build,pseudo reference,cluster selected to build pseudo reference,0.7383319735527039
Blogs,1,17,baselines,slr and sc,have,two variations,slr and sc have two variations,0.571328341960907
Blogs,1,23,baselines,tc,Label,top n sentences,tc Label top n sentences,0.7215197086334229
Blogs,1,23,baselines,top n sentences,from,each document,top n sentences from each document,0.5300644040107727
Blogs,1,23,baselines,top n sentences,as,salient,top n sentences as salient,0.5214198231697083
Blogs,1,25,baselines,new unsupervised evaluation metric,to guide,training,new unsupervised evaluation metric to guide training,0.6619755029678345
Blogs,1,25,baselines,training,of,rl - based multidocument summariser,training of rl - based multidocument summariser,0.5173420310020447
Blogs,1,27,baselines,supert,selects,top 10 - 15 sentences,supert selects top 10 - 15 sentences,0.6883164644241333
Blogs,1,27,baselines,supert,uses,sbert,supert uses sbert,0.590796172618866
Blogs,1,27,baselines,top 10 - 15 sentences,from,each source document,top 10 - 15 sentences from each source document,0.5370620489120483
Blogs,1,27,baselines,each source document,as,pseudo references,each source document as pseudo references,0.5100564956665039
Blogs,1,27,baselines,sbert,to measure,semantic similarity,sbert to measure semantic similarity,0.6780535578727722
Blogs,1,27,baselines,semantic similarity,between,summaries and pseudo references,semantic similarity between summaries and pseudo references,0.6116287708282471
Blogs,1,27,baselines,baselines,has,supert,baselines has supert,0.6091812252998352
Blogs,1,21,experiments,pacsum,selects,sentences,pacsum selects sentences,0.7508254647254944
Blogs,1,21,experiments,sentences,that are,semantically central,sentences that are semantically central,0.6171478629112244
Blogs,1,21,experiments,high average similarity,with,succeeding sentences,high average similarity with succeeding sentences,0.6401255130767822
Blogs,1,21,experiments,low average similarity,with,preceding sentences,low average similarity with preceding sentences,0.6225818395614624
Blogs,1,21,experiments,semantically central,has,meaning,semantically central has meaning,0.6204291582107544
Blogs,1,21,experiments,meaning,has,high average similarity,meaning has high average similarity,0.6081122159957886
Blogs,1,5,model,pseudo reference summary,generated by selecting,salient sentences,pseudo reference summary generated by selecting salient sentences,0.7227113246917725
Blogs,1,5,model,salient sentences,from,source documents,salient sentences from source documents,0.4908202290534973
Blogs,1,5,model,salient sentences,using,contextualised embeddings,salient sentences using contextualised embeddings,0.619194507598877
Blogs,1,5,model,salient sentences,using,soft token alignment,salient sentences using soft token alignment,0.6475614309310913
Blogs,1,5,model,model,has,pseudo reference summary,model has pseudo reference summary,0.554490327835083
Blogs,1,13,model,two graph- based approach,to building,pseudo references,two graph- based approach to building pseudo references,0.6238071918487549
Blogs,1,13,model,model,explored,two graph- based approach,model explored two graph- based approach,0.7275846600532532
Blogs,1,16,model,clustering algorithm,preset,number of clusters,clustering algorithm preset number of clusters,0.6390683054924011
Blogs,1,16,model,model,has,clustering algorithm,model has clustering algorithm,0.5945653319358826
Blogs,1,18,model,individual graph,builds,graph,individual graph builds graph,0.6937177181243896
Blogs,1,18,model,individual graph,selects,top k sentences,individual graph selects top k sentences,0.665132462978363
Blogs,1,18,model,graph,for,each source document,graph for each source document,0.6206992268562317
Blogs,1,18,model,model,has,individual graph,model has individual graph,0.5477928519248962
Blogs,1,19,model,global graph,builds,graph,global graph builds graph,0.6869493722915649
Blogs,1,19,model,global graph,selects,top m sentences,global graph selects top m sentences,0.7009866833686829
Blogs,1,19,model,graph,using,all the sentences,graph using all the sentences,0.6932075023651123
Blogs,1,19,model,all the sentences,from,all the source documents,all the sentences from all the source documents,0.5338843464851379
Blogs,1,19,model,all the source documents,of,same topic,all the source documents of same topic,0.5480690002441406
Blogs,1,19,model,model,has,global graph,model has global graph,0.5641012191772461
Blogs,1,20,model,position - aware graphs,extended,pacsum,position - aware graphs extended pacsum,0.6843569278717041
Blogs,1,20,model,pacsum,using,sbert ( sps ),pacsum using sbert ( sps ),0.6908427476882935
Blogs,1,20,model,pacsum,consider,individual and global - graph versions,pacsum consider individual and global - graph versions,0.7109442949295044
Blogs,1,20,model,model,For,position - aware graphs,model For position - aware graphs,0.5616887807846069
Blogs,1,22,model,top + clique ( tc ),selects,top n sentences,top + clique ( tc ) selects top n sentences,0.6833429336547852
Blogs,1,22,model,top + clique ( tc ),selects,semantically central sentences,top + clique ( tc ) selects semantically central sentences,0.69554603099823
Blogs,1,22,model,semantically central sentences,to build,pseudo references,semantically central sentences to build pseudo references,0.6315820217132568
Blogs,1,22,model,model,proposed,top + clique ( tc ),model proposed top + clique ( tc ),0.7056344747543335
Blogs,1,6,results,supert,achieve,better correlation,supert achieve better correlation,0.6894695162773132
Blogs,1,6,results,better correlation,with,human evaluation,better correlation with human evaluation,0.6082729697227478
Blogs,1,6,results,human evaluation,of,18 - 39 %,human evaluation of 18 - 39 %,0.5626615285873413
Blogs,1,6,results,results,has,supert,results has supert,0.6143671870231628
Blogs,1,7,results,supert,with,reinforcement learning summariser,supert with reinforcement learning summariser,0.6393105983734131
Blogs,1,7,results,supert,yielded,strong performance,supert yielded strong performance,0.7193783521652222
Blogs,1,8,results,outperformed,has,baseline models,outperformed has baseline models,0.6163802146911621
Blogs,1,9,results,positionagnostic graphs,has,underperformed,positionagnostic graphs has underperformed,0.6069387197494507
Blogs,1,9,results,underperformed,has,position - aware graphs,underperformed has position - aware graphs,0.5726909637451172
Blogs,1,9,results,results,has,positionagnostic graphs,results has positionagnostic graphs,0.5437160730361938
Blogs,1,10,results,position - aware graphs,has,underperformed,position - aware graphs has underperformed,0.5999802350997925
Blogs,1,10,results,underperformed,has,simple sentence extraction method,underperformed has simple sentence extraction method,0.5450406670570374
Blogs,1,10,results,results,has,position - aware graphs,results has position - aware graphs,0.5301089286804199
Blogs,1,28,results,ntd with supert,yielded,strongest results,ntd with supert yielded strongest results,0.7104395031929016
Blogs,2,29,baselines,opinion merging,used,word embeddings,opinion merging used word embeddings,0.58753502368927
Blogs,2,29,baselines,word embeddings,to merge,similar opinions,word embeddings to merge similar opinions,0.6753780841827393
Blogs,2,29,baselines,similar opinions,into,different clusters,similar opinions into different clusters,0.5749016404151917
Blogs,2,29,baselines,baselines,has,opinion merging,baselines has opinion merging,0.5702974200248718
Blogs,2,31,baselines,opinion ltering,control,selection process,opinion ltering control selection process,0.6685181260108948
Blogs,2,31,baselines,selection process,by ltering,opinions,selection process by ltering opinions,0.7503706812858582
Blogs,2,31,baselines,opinions,based on,aspect category or sentiment,opinions based on aspect category or sentiment,0.5901045203208923
Blogs,2,31,baselines,baselines,has,last operation,baselines has last operation,0.5568630695343018
Blogs,2,34,baselines,evaluation metrics,are,"rouge - 1 , - 2 , and - l","evaluation metrics are rouge - 1 , - 2 , and - l",0.5505168437957764
Blogs,2,34,baselines,best / worst review,has,highest / lowest average word overlap,best / worst review has highest / lowest average word overlap,0.5317088961601257
Blogs,2,34,baselines,highest / lowest average word overlap,has,with input reviews,highest / lowest average word overlap has with input reviews,0.5676864385604858
Blogs,2,34,baselines,baselines,has,evaluation metrics,baselines has evaluation metrics,0.5402852296829224
Blogs,2,6,experiments,opiniondigest,generate,summaries,opiniondigest generate summaries,0.6608269214630127
Blogs,2,6,experiments,summaries,based on,different user needs,summaries based on different user needs,0.6867775917053223
Blogs,2,6,experiments,summaries,by ltering,selected opinion,summaries by ltering selected opinion,0.7118710875511169
Blogs,2,6,experiments,selected opinion,based on,user 's aspect and / or sentiment,selected opinion based on user 's aspect and / or sentiment,0.6454606652259827
Blogs,2,7,experiments,model,produces,informative customisable summaries,model produces informative customisable summaries,0.6362810730934143
Blogs,2,7,experiments,able to outperformed,has,other baseline models,able to outperformed has other baseline models,0.5967519283294678
Blogs,2,26,experiments,content support study,where,judges,content support study where judges,0.6612802147865295
Blogs,2,26,experiments,judges,given,8 input reviews,judges given 8 input reviews,0.7394205927848816
Blogs,2,26,experiments,8 input reviews,from,yelp,8 input reviews from yelp,0.6426012516021729
Blogs,2,33,experiments,yelp dataset,has,624 k training reviews,yelp dataset has 624 k training reviews,0.5505831241607666
Blogs,2,33,experiments,hotel,has,688k reviews,hotel has 688k reviews,0.6255432367324829
Blogs,2,42,experiments,summaries,includes,speci ed aspects,summaries includes speci ed aspects,0.6804324388504028
Blogs,2,42,experiments,speci ed aspects,has,"exclusively , partially","speci ed aspects has exclusively , partially",0.5727163553237915
Blogs,2,49,experiments,generated summaries,using,aspects and sentiments,generated summaries using aspects and sentiments,0.6590775847434998
Blogs,2,50,experiments,generated summaries,using,sentiments,generated summaries using sentiments,0.6824992895126343
Blogs,2,14,hyperparameters,pre-trained tagging model,to obtain,our opinion set,pre-trained tagging model to obtain our opinion set,0.5294024348258972
Blogs,2,14,hyperparameters,our opinion set,contains,extracted opinion phrases,our opinion set contains extracted opinion phrases,0.5937918424606323
Blogs,2,14,hyperparameters,our opinion set,contains,respective polarity and aspect categories,our opinion set contains respective polarity and aspect categories,0.6238976716995239
Blogs,2,14,hyperparameters,hyperparameters,used,pre-trained tagging model,hyperparameters used pre-trained tagging model,0.5753713846206665
Blogs,2,5,model,opinion phrases,from,multiple reviews,opinion phrases from multiple reviews,0.5432333946228027
Blogs,2,5,model,most popular ones,at,summarisation time,most popular ones at summarisation time,0.4619719684123993
Blogs,2,5,model,model,merge,opinion phrases,model merge opinion phrases,0.7217145562171936
Blogs,2,9,model,each entity,to generate,abstractive summaries,each entity to generate abstractive summaries,0.6925522089004517
Blogs,2,9,model,abstractive summaries,of,most salient opinions,abstractive summaries of most salient opinions,0.5152386426925659
Blogs,2,9,model,most salient opinions,in,relevant reviews,most salient opinions in relevant reviews,0.4696561098098755
Blogs,2,9,model,model,For,each entity,model For each entity,0.586022138595581
Blogs,2,10,model,opiniondigest,has,three main components,opiniondigest has three main components,0.5744983553886414
Blogs,2,10,model,model,has,opiniondigest,model has opiniondigest,0.5942567586898804
Blogs,2,16,model,each review,extract,entity 's opinion set,each review extract entity 's opinion set,0.6654172539710999
Blogs,2,16,model,model,For,each review,model For each review,0.6411417722702026
Blogs,2,19,model,reviews,from,extracted opinion phrases,reviews from extracted opinion phrases,0.5096780061721802
Blogs,2,19,model,reviews,generate,opinion summaries,reviews generate opinion summaries,0.6099182963371277
Blogs,2,19,model,opinion summaries,from,selected opinions,opinion summaries from selected opinions,0.5613796710968018
Blogs,2,19,model,model,reconstruct,reviews,model reconstruct reviews,0.7131854295730591
Blogs,2,20,model,transformer model,by encoding,extracted opinion phrases,transformer model by encoding extracted opinion phrases,0.7680782079696655
Blogs,2,20,model,transformer model,by encoding,learning,transformer model by encoding learning,0.8121761083602905
Blogs,2,20,model,extracted opinion phrases,of,single review,extracted opinion phrases of single review,0.5039520859718323
Blogs,2,20,model,learning,to reconstruct,review 's full text,learning to reconstruct review 's full text,0.5815160870552063
Blogs,2,20,model,model,train,transformer model,model train transformer model,0.6976329684257507
Blogs,2,21,model,trained transformer,to generate,summaries,trained transformer to generate summaries,0.6912499666213989
Blogs,2,21,model,model,used,trained transformer,model used trained transformer,0.6314522624015808
Blogs,2,22,model,summarisation,use,selected opinions,summarisation use selected opinions,0.6219534277915955
Blogs,2,22,model,selected opinions,as,input,selected opinions as input,0.5448430180549622
Blogs,2,22,model,input,to,our trained transformer model,input to our trained transformer model,0.5621010661125183
Blogs,2,22,model,our trained transformer model,to generate,respective summary,our trained transformer model to generate respective summary,0.6635300517082214
Blogs,2,22,model,selected opinions,has,concatenated together ),selected opinions has concatenated together ),0.6169745922088623
Blogs,2,22,model,model,During,summarisation,model During summarisation,0.64948570728302
Blogs,2,27,model,model,has,selecting the most salient opinions,model has selecting the most salient opinions,0.5511966347694397
Blogs,2,36,model,framework,is,unsupervised model,framework is unsupervised model,0.5615794658660889
Blogs,2,36,model,framework,not an,unsupervised model,framework not an unsupervised model,0.6382984519004822
Blogs,2,36,model,framework,required,labelled data,framework required labelled data,0.663378119468689
Blogs,2,36,model,labelled data,for,our opinion extractor model,labelled data for our opinion extractor model,0.5512559413909912
Blogs,2,36,model,model,has,framework,model has framework,0.5441871285438538
Blogs,2,25,results,opiniondigest 's summaries,scored,highest,opiniondigest 's summaries scored highest,0.6961169838905334
Blogs,2,25,results,highest,in,informativeness and coherence,highest in informativeness and coherence,0.49849992990493774
Blogs,2,35,results,yelp dataset,shows,our framework,yelp dataset shows our framework,0.6350077986717224
Blogs,2,35,results,our framework,has,outperformed,our framework has outperformed,0.5918945670127869
Blogs,2,35,results,outperformed,has,all the baseline models,outperformed has all the baseline models,0.5952280759811401
Blogs,2,35,results,results,on,yelp dataset,results on yelp dataset,0.5335524082183838
Blogs,2,39,results,proportion of sentences,in,summary,proportion of sentences in summary,0.5221617817878723
Blogs,2,39,results,proportion of sentences,"fully , partially and not supported by",input reviews,"proportion of sentences fully , partially and not supported by input reviews",0.5442811250686646
Blogs,2,39,results,summary,"fully , partially and not supported by",input reviews,"summary fully , partially and not supported by input reviews",0.48644885420799255
Blogs,2,39,results,results,showcase,proportion of sentences,results showcase proportion of sentences,0.6903634071350098
Blogs,2,40,results,opiniondigest,able to generate,summaries,opiniondigest able to generate summaries,0.6851098537445068
Blogs,2,40,results,summaries,higher proportion of,fully and partially supported sentences,summaries higher proportion of fully and partially supported sentences,0.6288427114486694
Blogs,2,40,results,results,show,opiniondigest,results show opiniondigest,0.6479992270469666
Blogs,2,41,results,how well,generate,summaries,how well generate summaries,0.5790067315101624
Blogs,2,41,results,our framework,generate,summaries,our framework generate summaries,0.6456397771835327
Blogs,2,41,results,summaries,based on,different aspects,summaries based on different aspects,0.7332322597503662
Blogs,2,41,results,how well,has,our framework,how well has our framework,0.5724499225616455
Blogs,2,41,results,results,measure,how well,results measure how well,0.6596766114234924
Blogs,2,41,results,results,measure,our framework,results measure our framework,0.6943311095237732
Blogs,2,44,results,opiniondigest,can generate,summaries,opiniondigest can generate summaries,0.7205362319946289
Blogs,2,44,results,summaries,exclusively or partially related to,speci ed aspects,summaries exclusively or partially related to speci ed aspects,0.5962995290756226
Blogs,2,44,results,results,show,opiniondigest,results show opiniondigest,0.6479992270469666
Blogs,2,46,results,example summaries,showcase,opiniondigest 's ability,example summaries showcase opiniondigest 's ability,0.8002922534942627
Blogs,2,46,results,summaries,using,opinion ltering,summaries using opinion ltering,0.6418460607528687
Blogs,2,46,results,opinion ltering,of,aspects and sentiments,opinion ltering of aspects and sentiments,0.5778369307518005
Blogs,2,46,results,opiniondigest 's ability,has,to summaries more 100 + reviews,opiniondigest 's ability has to summaries more 100 + reviews,0.5997918844223022
Blogs,2,47,results,model,to generate,summaries,model to generate summaries,0.7258272171020508
Blogs,2,47,results,summaries,based on,8 and 128 reviews,summaries based on 8 and 128 reviews,0.7224223613739014
Blogs,2,48,results,our framework,n't aggregate,review representations,our framework n't aggregate review representations,0.7604994177818298
Blogs,2,48,results,results,has,our framework,results has our framework,0.6097875237464905
Blogs,3,6,baselines,research papers,in,free-text query,research papers in free-text query,0.478974848985672
Blogs,3,6,baselines,research papers,by choosing,categorised values,research papers by choosing categorised values,0.6440368890762329
Blogs,3,6,baselines,categorised values,such as,scienti c tasks,categorised values such as scienti c tasks,0.6713381409645081
Blogs,3,6,baselines,categorised values,such as,datasets,categorised values such as datasets,0.6613027453422546
Blogs,3,4,experiments,summarising,has,computer science research papers,summarising has computer science research papers,0.541348397731781
Blogs,3,7,experiments,proposed system,ingested,"270,000 papers","proposed system ingested 270,000 papers",0.7651990652084351
Blogs,3,8,experiments,ibm science summariser,produces,summaries,ibm science summariser produces summaries,0.6643392443656921
Blogs,3,8,experiments,ibm science summariser,produces,queryfocused summarisation,ibm science summariser produces queryfocused summarisation,0.5796533226966858
Blogs,3,8,experiments,summaries,focuses on,user 's queries,summaries focuses on user 's queries,0.7489243149757385
Blogs,3,8,experiments,user 's queries,has,queryfocused summarisation,user 's queries has queryfocused summarisation,0.5801302790641785
Blogs,3,12,experiments,12 authors,evaluate,summaries,12 authors evaluate summaries,0.516613245010376
Blogs,3,12,experiments,summaries,of,two papers,summaries of two papers,0.6071139574050903
Blogs,3,16,experiments,48 summaries,to be,evaluated,48 summaries to be evaluated,0.60749751329422
Blogs,3,17,experiments,each sections of the paper,covered in,summary,each sections of the paper covered in summary,0.780404269695282
Blogs,3,17,experiments,how well,has,each sections of the paper,how well has each sections of the paper,0.5441209077835083
Blogs,3,24,experiments,support,for,more entities,support for more entities,0.6075384020805359
Blogs,3,24,experiments,support,ingest,more papers,support ingest more papers,0.5543773174285889
Blogs,3,27,experiments,queries,use,lters,queries use lters,0.6603813767433167
Blogs,3,27,experiments,lters,on,metadata elds,lters on metadata elds,0.5267105102539062
Blogs,3,9,model,various sections,of the paper,independently,various sections of the paper independently,0.6018244028091431
Blogs,3,9,model,model,summarises,various sections,model summarises various sections,0.6462175846099854
Blogs,3,10,model,interaction,between,user 's queries,interaction between user 's queries,0.6360671520233154
Blogs,3,10,model,interaction,between,various entities,interaction between various entities,0.6747717261314392
Blogs,3,10,model,model,allows for,interaction,model allows for interaction,0.7391364574432373
Blogs,3,5,results,different scenarios,such as,discovery,different scenarios such as discovery,0.6519291996955872
Blogs,3,5,results,different scenarios,such as,exploration,different scenarios such as exploration,0.6375517249107361
Blogs,3,5,results,different scenarios,such as,understanding of scienti c documents,different scenarios such as understanding of scienti c documents,0.6324125528335571
Blogs,3,21,results,section - based summary,scored,higher,section - based summary scored higher,0.7104199528694153
Blogs,3,21,results,higher,in,68 %,higher in 68 %,0.586362898349762
Blogs,3,21,results,task 2,has,section - based summary,task 2 has section - based summary,0.5789352059364319
Blogs,3,21,results,68 %,has,of the papers,68 % has of the papers,0.5486425161361694
Blogs,3,21,results,results,For,task 2,results For task 2,0.47405534982681274
Blogs,3,22,results,average score,for,section - based summaries,average score for section - based summaries,0.6204443573951721
Blogs,3,22,results,section - based summaries,is,3.32,section - based summaries is 3.32,0.5542446374893188
Blogs,3,22,results,3.32,highlights,quality of section - based summaries,3.32 highlights quality of section - based summaries,0.5654485821723938
Blogs,3,22,results,results,has,average score,results has average score,0.5574581027030945
Blogs,3,28,results,relevant papers,returned with,summarisation results,relevant papers returned with summarisation results,0.6492859721183777
Blogs,3,28,results,results,has,relevant papers,results has relevant papers,0.5194989442825317
Blogs,3,29,results,entities,has,accurately highlighted,entities has accurately highlighted,0.5708123445510864
Blogs,4,25,ablation-analysis,subjectiveness,of,important,subjectiveness of important,0.5922495722770691
Blogs,4,25,ablation-analysis,subjectiveness,deem,important,subjectiveness deem important,0.5606175065040588
Blogs,4,25,ablation-analysis,subjectiveness,to be,important,subjectiveness to be important,0.5843629240989685
Blogs,4,25,ablation-analysis,important,in,ndings,important in ndings,0.5109639763832092
Blogs,4,25,ablation-analysis,ablation analysis,due to,subjectiveness,ablation analysis due to subjectiveness,0.6542036533355713
Blogs,4,28,ablation-analysis,findings,consists of,detailed observations and interpretation,findings consists of detailed observations and interpretation,0.6250948309898376
Blogs,4,28,ablation-analysis,detailed observations and interpretation,of,imaging study,detailed observations and interpretation of imaging study,0.5862383246421814
Blogs,4,28,ablation-analysis,impression,summarises,most critical ndings,impression summarises most critical ndings,0.6828027367591858
Blogs,4,28,ablation-analysis,ablation analysis,has,findings,ablation analysis has findings,0.5422948002815247
Blogs,4,30,ablation-analysis,improvement,of generation of IMPRESSION,signi cantly improve,improvement of generation of IMPRESSION signi cantly improve,0.6765158176422119
Blogs,4,30,ablation-analysis,signi cantly improve,to select,most important ontological concepts,signi cantly improve to select most important ontological concepts,0.6840571761131287
Blogs,4,30,ablation-analysis,most important ontological concepts,within,report,most important ontological concepts within report,0.6579805612564087
Blogs,4,30,ablation-analysis,ablation analysis,has,automation,ablation analysis has automation,0.5389354228973389
Blogs,4,8,experiments,our approach,generated,good quality summaries,our approach generated good quality summaries,0.653499960899353
Blogs,4,8,experiments,good quality summaries,comparison to,ground -truth,good quality summaries comparison to ground -truth,0.6421183943748474
Blogs,4,12,experiments,mimic - cxr,has,107372,mimic - cxr has 107372,0.6636979579925537
Blogs,4,12,experiments,mimic - cxr,has,radiology reports,mimic - cxr has radiology reports,0.5967816710472107
Blogs,4,12,experiments,107372,has,radiology reports,107372 has radiology reports,0.4914814531803131
Blogs,4,12,experiments,openi,has,3366 reports,openi has 3366 reports,0.6565142869949341
Blogs,4,13,experiments,radiology lexicon,used,radlex,radiology lexicon used radlex,0.6535748243331909
Blogs,4,13,experiments,radlex,consists of,68534 radiological terms,radlex consists of 68534 radiological terms,0.6950284242630005
Blogs,4,20,hyperparameters,100 generated impressions,with,gold summaries,100 generated impressions with gold summaries,0.6339569687843323
Blogs,4,20,hyperparameters,100 generated impressions,associated,gold summaries,100 generated impressions associated gold summaries,0.5561391711235046
Blogs,4,20,hyperparameters,hyperparameters,randomly sampled,100 generated impressions,hyperparameters randomly sampled 100 generated impressions,0.6976218223571777
Blogs,4,32,hyperparameters,each word,tag with,1,each word tag with 1,0.724025309085846
Blogs,4,32,hyperparameters,word,is,ontology term,word is ontology term,0.5035696625709534
Blogs,4,32,hyperparameters,two criteria,has,word,two criteria has word,0.5858373641967773
Blogs,4,32,hyperparameters,hyperparameters,has,each word,hyperparameters has each word,0.5258165597915649
Blogs,4,33,hyperparameters,word,directly copied into,impression,word directly copied into impression,0.7615789771080017
Blogs,4,33,hyperparameters,hyperparameters,has,word,hyperparameters has word,0.5605258941650391
Blogs,4,6,model,content selection,treated as,word-level sequence - tagging problem,content selection treated as word-level sequence - tagging problem,0.6357356309890747
Blogs,4,6,model,model,has,content selection,model has content selection,0.542818546295166
Blogs,4,16,model,bottomsum,most relevant to,architecture,bottomsum most relevant to architecture,0.6866497993469238
Blogs,4,16,model,bottomsum,utilises,separate content selector,bottomsum utilises separate content selector,0.6249536275863647
Blogs,4,16,model,separate content selector,for,abstractive text summarisation,separate content selector for abstractive text summarisation,0.5810075402259827
Blogs,4,16,model,model,has,bottomsum,model has bottomsum,0.568874716758728
Blogs,4,34,model,copy likelihood,of,each word,copy likelihood of each word,0.5966416001319885
Blogs,4,34,model,copy likelihood,to measure,importance of the word,copy likelihood to measure importance of the word,0.7212019562721252
Blogs,4,34,model,model,capture,copy likelihood,model capture copy likelihood,0.7612533569335938
Blogs,4,35,model,overall architecture,is,bilstm,overall architecture is bilstm,0.5597724318504333
Blogs,4,35,model,bilstm,on top of,bert embeddings layer,bilstm on top of bert embeddings layer,0.6459963917732239
Blogs,4,35,model,bilstm,during,inference time,bilstm during inference time,0.6350482106208801
Blogs,4,35,model,our content selector,output,selection probability,our content selector output selection probability,0.7372216582298279
Blogs,4,35,model,selection probability,of,each token,selection probability of each token,0.609033465385437
Blogs,4,35,model,each token,in,our source sequence,each token in our source sequence,0.5176284313201904
Blogs,4,35,model,inference time,has,our content selector,inference time has our content selector,0.5700181722640991
Blogs,4,35,model,model,has,overall architecture,model has overall architecture,0.5773155689239502
Blogs,4,38,model,bilstm,takes in,word embeddings,bilstm takes in word embeddings,0.6332533359527588
Blogs,4,38,model,bilstm,generates,encoded hidden representation,bilstm generates encoded hidden representation,0.6323828101158142
Blogs,4,38,model,model,is,bilstm,model is bilstm,0.5741544365882874
Blogs,4,39,model,lstm,takes in,identi ed ontology terms,lstm takes in identi ed ontology terms,0.6547281742095947
Blogs,4,39,model,lstm,generates,x context vector,lstm generates x context vector,0.6290605068206787
Blogs,4,39,model,model,is,lstm,model is lstm,0.5091975331306458
Blogs,4,40,model,lstm,generates,impression,lstm generates impression,0.6845037341117859
Blogs,4,40,model,ltering gate,re ne,findings word representations,ltering gate re ne findings word representations,0.5478289127349854
Blogs,4,40,model,findings word representations,using,ontology vector,findings word representations using ontology vector,0.6563621163368225
Blogs,4,40,model,ontology vector,to produce,ontology - aware word representations,ontology vector to produce ontology - aware word representations,0.6761202216148376
Blogs,4,40,model,model,is,lstm,model is lstm,0.5091975331306458
Blogs,4,41,model,ltering gate,concatenates,current hidden state,ltering gate concatenates current hidden state,0.73746657371521
Blogs,4,41,model,current hidden state,has,of word x and the x ontology vector,current hidden state has of word x and the x ontology vector,0.577965259552002
Blogs,4,41,model,model,has,ltering gate,model has ltering gate,0.5778331756591797
Blogs,4,42,model,ontology - aware word representations,take,output,ontology - aware word representations take output,0.6306923031806946
Blogs,4,42,model,ontology - aware word representations,perform,element - wise multiplication,ontology - aware word representations perform element - wise multiplication,0.5988288521766663
Blogs,4,42,model,output,of,ltering gate,output of ltering gate,0.6161862015724182
Blogs,4,42,model,element - wise multiplication,with,current hidden state of word x,element - wise multiplication with current hidden state of word x,0.6221639513969421
Blogs,4,42,model,model,To compute,ontology - aware word representations,model To compute ontology - aware word representations,0.6979206800460815
Blogs,4,43,model,decoder,is,lstm,decoder is lstm,0.5407543778419495
Blogs,4,43,model,lstm,generates,impression,lstm generates impression,0.6845037341117859
Blogs,4,43,model,model,has,decoder,model has decoder,0.6226420402526855
Blogs,4,44,model,decoder,compute,current decoding state,decoder compute current decoding state,0.6976152062416077
Blogs,4,44,model,current decoding state,using,previous hidden state and previous generated tokens,current decoding state using previous hidden state and previous generated tokens,0.6427724957466125
Blogs,4,44,model,model,has,decoder,model has decoder,0.6226420402526855
Blogs,4,46,model,attention distribution,to compute,context vector,attention distribution to compute context vector,0.6647120714187622
Blogs,4,46,model,model,has,attention distribution,model has attention distribution,0.503185510635376
Blogs,4,47,model,context vector and the current decoding state,feed into,feed-forward neural network,context vector and the current decoding state feed into feed-forward neural network,0.6805287599563599
Blogs,4,47,model,feed-forward neural network,to either generate,next token,feed-forward neural network to either generate next token,0.692913293838501
Blogs,4,47,model,feed-forward neural network,to either generate,copy,feed-forward neural network to either generate copy,0.6949992775917053
Blogs,4,47,model,model,has,context vector and the current decoding state,model has context vector and the current decoding state,0.5300372838973999
Blogs,4,7,results,improve,on,sota results,improve on sota results,0.5245075225830078
Blogs,4,7,results,sota results,based on,mimic - cxr and openi datasets,sota results based on mimic - cxr and openi datasets,0.6750679016113281
Blogs,4,7,results,results,proven to,improve,results proven to improve,0.7271221876144409
Blogs,4,18,results,our model,has,signi cantly,our model has signi cantly,0.5938307046890259
Blogs,4,21,results,three experts,score,impressions,three experts score impressions,0.7118558287620544
Blogs,4,21,results,impressions,on,scale,impressions on scale,0.5448046922683716
Blogs,4,21,results,impressions,on,"readability , accuracy , and completeness","impressions on readability , accuracy , and completeness",0.46420717239379883
Blogs,4,21,results,scale,of,1 - 3 ( 3,scale of 1 - 3 ( 3,0.6485329270362854
Blogs,4,21,results,results,asked,three experts,results asked three experts,0.6602038145065308
Blogs,4,23,results,scored as good,as,associated human-written impressions,scored as good as associated human-written impressions,0.5731636881828308
Blogs,4,24,results,73 % and 71 %,of,our impressions,73 % and 71 % of our impressions,0.6133735179901123
Blogs,4,24,results,73 % and 71 %,of,impressions,73 % and 71 % of impressions,0.6129037141799927
Blogs,4,24,results,73 % and 71 %,scored,3,73 % and 71 % scored 3,0.6843787431716919
Blogs,4,24,results,73 % and 71 %,scored,ties,73 % and 71 % scored ties,0.6536114811897278
Blogs,4,24,results,our impressions,scored,ties,our impressions scored ties,0.6951053142547607
Blogs,4,24,results,3,on,readability and accuracy,3 on readability and accuracy,0.4449835419654846
Blogs,4,24,results,ties,with,human-written impressions,ties with human-written impressions,0.6928473711013794
Blogs,4,24,results,results,has,73 % and 71 %,results has 73 % and 71 %,0.5223709344863892
Blogs,4,26,results,our generated impressions,are,high quality,our generated impressions are high quality,0.6068643927574158
Blogs,4,26,results,our generated impressions,of,high quality,our generated impressions of high quality,0.5942284464836121
Blogs,4,27,results,results,has,radiology reports,results has radiology reports,0.5455659031867981
Blogs,4,48,results,outperformed,has,all,outperformed has all,0.6429647207260132
Blogs,4,48,results,outperformed,has,extractive and abstractive baseline models,outperformed has extractive and abstractive baseline models,0.6073580980300903
Blogs,4,48,results,all,has,extractive and abstractive baseline models,all has extractive and abstractive baseline models,0.5310840010643005
Blogs,4,48,results,results,has,outperformed,results has outperformed,0.636634886264801
Blogs,4,49,results,abstractive models,has,signi cantly outperformed,abstractive models has signi cantly outperformed,0.5977357029914856
Blogs,4,49,results,signi cantly outperformed,has,extractive one,signi cantly outperformed has extractive one,0.6219298243522644
Blogs,4,49,results,results,has,abstractive models,results has abstractive models,0.5407604575157166
Blogs,4,50,results,rouge performance,between,pg,rouge performance between pg,0.5902235507965088
Blogs,4,50,results,rouge performance,between,ontologyaware pg,rouge performance between ontologyaware pg,0.6326857209205627
Blogs,4,50,results,salient ontological terms,in,summarisation,salient ontological terms in summarisation,0.4899180829524994
Blogs,4,50,results,results,difference in,rouge performance,results difference in rouge performance,0.6329925060272217
Blogs,4,51,results,bottomsum,achieve,best results,bottomsum achieve best results,0.6386805772781372
Blogs,4,51,results,best results,among,baseline models,best results among baseline models,0.608468234539032
Blogs,4,51,results,results,has,bottomsum,results has bottomsum,0.5764352083206177
Blogs,4,53,results,bene t,of incorporating,content selection,bene t of incorporating content selection,0.6894352436065674
Blogs,4,53,results,content selection,to,summarisation model,content selection to summarisation model,0.5218498110771179
Blogs,4,53,results,results,showcase,bene t,results showcase bene t,0.8347051739692688
Blogs,4,54,results,openi,against,bottomsum,openi against bottomsum,0.691430926322937
Blogs,4,55,results,our model,able to outperformed,bottomsum,our model able to outperformed bottomsum,0.7175885438919067
Blogs,4,55,results,bottomsum,in,ope ni,bottomsum in ope ni,0.7402649521827698
Blogs,4,55,results,results,has,our model,results has our model,0.5871725678443909
Blogs,5,5,ablation-analysis,absolute encoding,of,source code tokens ' position,absolute encoding of source code tokens ' position,0.576167643070221
Blogs,5,5,ablation-analysis,relative encoding,has,signi cantly improves,relative encoding has signi cantly improves,0.6044108271598816
Blogs,5,5,ablation-analysis,signi cantly improves,has,performance,signi cantly improves has performance,0.5908153653144836
Blogs,5,18,ablation-analysis,mutual interactions,between,tokens,mutual interactions between tokens,0.6878323554992676
Blogs,5,18,ablation-analysis,mutual interactions,in uence,meaning of the source code,mutual interactions in uence meaning of the source code,0.7584201097488403
Blogs,5,27,ablation-analysis,decrease,in,performance,decrease in performance,0.5227082371711731
Blogs,5,27,ablation-analysis,performance,when include,absolute position encoding,performance when include absolute position encoding,0.6575050354003906
Blogs,5,27,ablation-analysis,ablation analysis,showcase,decrease,ablation analysis showcase decrease,0.7960772514343262
Blogs,5,24,baselines,our baseline models,n't incorporate,copy attention mechanism,our baseline models n't incorporate copy attention mechanism,0.6454787254333496
Blogs,5,24,baselines,our baseline models,n't incorporate,copy attention mechanism,our baseline models n't incorporate copy attention mechanism,0.6454787254333496
Blogs,5,24,baselines,our baseline models,shown that,copy attention mechanism,our baseline models shown that copy attention mechanism,0.5882277488708496
Blogs,5,24,baselines,copy attention mechanism,does improve,performance,copy attention mechanism does improve performance,0.6974905729293823
Blogs,5,24,baselines,performance,of,our full model,performance of our full model,0.594908595085144
Blogs,5,24,baselines,baselines,has,our baseline models,baselines has our baseline models,0.5645362734794617
Blogs,5,8,experiments,java and python dataset,from,github,java and python dataset from github,0.5349121689796448
Blogs,5,4,model,simple transformer - based model,with,relative position representations,simple transformer - based model with relative position representations,0.620958685874939
Blogs,5,4,model,simple transformer - based model,with,copy attention mechanism,simple transformer - based model with copy attention mechanism,0.6095353364944458
Blogs,5,4,model,copy attention mechanism,to generate,sota results,copy attention mechanism to generate sota results,0.6971005797386169
Blogs,5,4,model,sota results,for,source code summarisation,sota results for source code summarisation,0.5897781848907471
Blogs,5,6,model,objective,encode,source code,objective encode source code,0.6318272352218628
Blogs,5,6,model,objective,generate,readable summary,objective generate readable summary,0.5671309232711792
Blogs,5,6,model,readable summary,describes,functionality of the program,readable summary describes functionality of the program,0.6956547498703003
Blogs,5,6,model,model,encode,source code,model encode source code,0.737008810043335
Blogs,5,6,model,model,has,objective,model has objective,0.5278581380844116
Blogs,5,12,model,code and summary,as,sequence of embeddings,code and summary as sequence of embeddings,0.5766156911849976
Blogs,5,12,model,model,encoded,code and summary,model encoded code and summary,0.7272514700889587
Blogs,5,13,model,vanilla transformer,stacked of,multi-head attention and linear transformation layers,vanilla transformer stacked of multi-head attention and linear transformation layers,0.6967617869377136
Blogs,5,13,model,multi-head attention and linear transformation layers,in,encoder and decoder,multi-head attention and linear transformation layers in encoder and decoder,0.5096414089202881
Blogs,5,13,model,model,has,vanilla transformer,model has vanilla transformer,0.5405058860778809
Blogs,5,14,model,copy attention,in,transformer,copy attention in transformer,0.569449245929718
Blogs,5,14,model,copy attention,to allow,model,copy attention to allow model,0.7296291589736938
Blogs,5,14,model,rare tokens,from,source code,rare tokens from source code,0.5462426543235779
Blogs,5,14,model,model,included,copy attention,model included copy attention,0.6407577395439148
Blogs,5,16,model,absolute position encoding,on,sequential order,absolute position encoding on sequential order,0.5512861013412476
Blogs,5,16,model,absolute position encoding,on,pairwise relationship encoding,absolute position encoding on pairwise relationship encoding,0.5232241153717041
Blogs,5,16,model,sequential order,of,source code tokens,sequential order of source code tokens,0.5779032111167908
Blogs,5,16,model,pairwise relationship encoding,in,transformer,pairwise relationship encoding in transformer,0.5298389792442322
Blogs,5,16,model,model,explored,absolute position encoding,model explored absolute position encoding,0.7319132089614868
Blogs,5,17,model,absolute position encoding,aims to capture,order information,absolute position encoding aims to capture order information,0.652043879032135
Blogs,5,17,model,absolute position encoding,aims to capture,order information,absolute position encoding aims to capture order information,0.652043879032135
Blogs,5,17,model,absolute position encoding,show,order information,absolute position encoding show order information,0.6647220849990845
Blogs,5,17,model,order information,of,source tokens,order information of source tokens,0.5425234436988831
Blogs,5,17,model,order information,leads to,bad summarisation,order information leads to bad summarisation,0.6688098907470703
Blogs,5,17,model,not helpful,in learning,source code representations,not helpful in learning source code representations,0.649170994758606
Blogs,5,17,model,not helpful,leads to,bad summarisation,not helpful leads to bad summarisation,0.5856605768203735
Blogs,5,17,model,model,has,absolute position encoding,model has absolute position encoding,0.5517977476119995
Blogs,5,19,model,pairwise relationships,between,input tokens,pairwise relationships between input tokens,0.6183387041091919
Blogs,5,19,model,pairwise relationships,capture,relative positional representations,pairwise relationships capture relative positional representations,0.7548449635505676
Blogs,5,19,model,relative positional representations,of,two position i and j,relative positional representations of two position i and j,0.5928165912628174
Blogs,5,19,model,two position i and j,for,each token,two position i and j for each token,0.6500446200370789
Blogs,5,9,results,evaluation metrics,are,bleu,evaluation metrics are bleu,0.48648929595947266
Blogs,5,9,results,evaluation metrics,are,meteor,evaluation metrics are meteor,0.5623734593391418
Blogs,5,9,results,evaluation metrics,are,rouge -l.,evaluation metrics are rouge -l.,0.5550309419631958
Blogs,5,9,results,results,has,evaluation metrics,results has evaluation metrics,0.5194434523582458
Blogs,5,22,results,our full model,has,outperformed,our full model has outperformed,0.5858570337295532
Blogs,5,22,results,outperformed,has,all the baseline models,outperformed has all the baseline models,0.5952280759811401
Blogs,5,22,results,results,has,our full model,results has our full model,0.5411279201507568
Blogs,5,23,results,base model,trained on,dataset,base model trained on dataset,0.7648485898971558
Blogs,5,23,results,all baseline models,except on,rouge -l metric,all baseline models except on rouge -l metric,0.5662243962287903
Blogs,5,23,results,base model,has,outperformed,base model has outperformed,0.6390305161476135
Blogs,5,23,results,outperformed,has,all baseline models,outperformed has all baseline models,0.6212381720542908
Blogs,5,23,results,results,has,base model,results has base model,0.5908223986625671
Blogs,5,26,results,performance,of performing,absolute position encoding,performance of performing absolute position encoding,0.5221571326255798
Blogs,5,26,results,absolute position encoding,on,source and targets,absolute position encoding on source and targets,0.5208662152290344
Blogs,5,28,results,bene t,of learning,pairwise relationship,bene t of learning pairwise relationship,0.6747753620147705
Blogs,5,28,results,pairwise relationship,between,source code tokens,pairwise relationship between source code tokens,0.6420106887817383
Blogs,5,28,results,results,showcase,bene t,results showcase bene t,0.8347051739692688
Blogs,5,31,results,deeper model ( more layers ),performs,better,deeper model ( more layers ) performs better,0.6021891832351685
Blogs,5,31,results,better,than,wider model,better than wider model,0.6164184212684631
Blogs,5,31,results,wider model,has,more neurons per layer,wider model has more neurons per layer,0.5723409652709961
Blogs,5,31,results,results,showcase,deeper model ( more layers ),results showcase deeper model ( more layers ),0.7677776217460632
Blogs,5,32,results,deeper model,is,more bene cial,deeper model is more bene cial,0.5573222041130066
Blogs,5,32,results,more bene cial,in,source code summarisation,more bene cial in source code summarisation,0.4829588830471039
Blogs,5,32,results,more bene cial,depends more on,semantic information,more bene cial depends more on semantic information,0.6994568705558777
Blogs,5,32,results,semantic information,than,syntactic,semantic information than syntactic,0.5585970282554626
Blogs,5,32,results,results,suspect,deeper model,results suspect deeper model,0.734769880771637
Blogs,6,6,ablation-analysis,scienti c papers,suitable for,data-driven summarisation,scienti c papers suitable for data-driven summarisation,0.6175701022148132
Blogs,6,6,ablation-analysis,ablation analysis,show,scienti c papers,ablation analysis show scienti c papers,0.620717465877533
Blogs,6,44,ablation-analysis,large variation,of,sentence locations,large variation of sentence locations,0.5903634428977966
Blogs,6,44,ablation-analysis,sentence locations,selected by,extractive models,sentence locations selected by extractive models,0.624169111251831
Blogs,6,44,ablation-analysis,extractive models,on,title-gen,extractive models on title-gen,0.595609188079834
Blogs,6,4,baselines,gen,applied,wide range of extractive and abstractive models,gen applied wide range of extractive and abstractive models,0.6870008707046509
Blogs,6,4,baselines,baselines,has,gen,baselines has gen,0.6292609572410583
Blogs,6,21,baselines,tfidf - emb,creates,sentence representation,tfidf - emb creates sentence representation,0.6095468997955322
Blogs,6,21,baselines,baselines,has,tfidf - emb,baselines has tfidf - emb,0.5714586973190308
Blogs,6,22,baselines,rwmd-rank,ranks,sentences,rwmd-rank ranks sentences,0.7692778706550598
Blogs,6,22,baselines,sentences,by how similar,sentence,sentences by how similar sentence,0.6954041719436646
Blogs,6,22,baselines,sentence,compared to,all the other sentences,sentence compared to all the other sentences,0.6591172218322754
Blogs,6,22,baselines,all the other sentences,in,document,all the other sentences in document,0.5482886433601379
Blogs,6,22,baselines,baselines,has,rwmd-rank,baselines has rwmd-rank,0.5487363934516907
Blogs,6,23,baselines,rwmd,stands for,relaxed word mover 's distance,rwmd stands for relaxed word mover 's distance,0.6904425024986267
Blogs,6,23,baselines,lexrank,to rank,sentences,lexrank to rank sentences,0.7237579822540283
Blogs,6,23,baselines,baselines,has,rwmd,baselines has rwmd,0.5342739224433899
Blogs,6,25,baselines,baselines,has,three baselines,baselines has three baselines,0.6189775466918945
Blogs,6,26,baselines,lstm,is,common lstm encoder-decoder model,lstm is common lstm encoder-decoder model,0.5557541251182556
Blogs,6,26,baselines,lstm,with,attention mechanism,lstm with attention mechanism,0.6298797726631165
Blogs,6,26,baselines,attention mechanism,at,word-level,attention mechanism at word-level,0.5302723050117493
Blogs,6,26,baselines,baselines,has,lstm,baselines has lstm,0.5395978093147278
Blogs,6,27,baselines,fconv,is,cnn encoder-decoder,fconv is cnn encoder-decoder,0.56256103515625
Blogs,6,27,baselines,cnn encoder-decoder,on,subword - level,cnn encoder-decoder on subword - level,0.514611542224884
Blogs,6,27,baselines,cnn encoder-decoder,separating,words,cnn encoder-decoder separating words,0.7130021452903748
Blogs,6,27,baselines,words,into,smaller units,words into smaller units,0.6249912977218628
Blogs,6,27,baselines,smaller units,using,byte-pair encoding ( bpe ),smaller units using byte-pair encoding ( bpe ),0.7046510577201843
Blogs,6,27,baselines,baselines,has,fconv,baselines has fconv,0.5681837797164917
Blogs,6,11,experimental-setup,title-gen,constructed using,medline,title-gen constructed using medline,0.7199851870536804
Blogs,6,11,experimental-setup,abstract-gen,conducted using,pubmed,abstract-gen conducted using pubmed,0.6162289381027222
Blogs,6,11,experimental-setup,experimental setup,has,title-gen,experimental setup has title-gen,0.5811014771461487
Blogs,6,5,experiments,title- gen dataset,consists of,5 million biomedical papers,title- gen dataset consists of 5 million biomedical papers,0.596240222454071
Blogs,6,5,experiments,abstract - gen dataset,consists of,900k papers,abstract - gen dataset consists of 900k papers,0.6655173301696777
Blogs,6,12,experiments,title- gen,pairs,abstract,title- gen pairs abstract,0.6710777878761292
Blogs,6,12,experiments,abstract,to,title of the paper,abstract to title of the paper,0.48536255955696106
Blogs,6,12,experiments,full body,to,abstract summary,full body to abstract summary,0.46565747261047363
Blogs,6,15,experiments,repeat score,measures,average overlap,repeat score measures average overlap,0.5096071362495422
Blogs,6,15,experiments,average overlap,of,each sentence,average overlap of each sentence,0.5826500058174133
Blogs,6,15,experiments,each sentence,in,text,each sentence in text,0.5332339406013489
Blogs,6,15,experiments,text,with,remainder of the text,text with remainder of the text,0.600926399230957
Blogs,6,16,experiments,repetitive content,body text of,paper,repetitive content body text of paper,0.7237885594367981
Blogs,6,34,experiments,meteor score,used for,machine translation,meteor score used for machine translation,0.5903477072715759
Blogs,6,13,model,repeat score,for,each data pairs,repeat score for each data pairs,0.6708940863609314
Blogs,6,13,model,model,has,text processing pipeline,model has text processing pipeline,0.5623595118522644
Blogs,6,14,model,overlap score,measures,overlapping tokens,overlap score measures overlapping tokens,0.5295286774635315
Blogs,6,14,model,overlapping tokens,between,summary ( title or abstract ) and the input text ( abstract or full body ),overlapping tokens between summary ( title or abstract ) and the input text ( abstract or full body ),0.6356430053710938
Blogs,6,14,model,model,has,overlap score,model has overlap score,0.5766340494155884
Blogs,6,29,model,c2 c,is,character - level encoder-decoder model,c2 c is character - level encoder-decoder model,0.5822293758392334
Blogs,6,29,model,model,has,c2 c,model has c2 c,0.6062495708465576
Blogs,6,30,model,character representations,from,input,character representations from input,0.5713807940483093
Blogs,6,30,model,character representations,feed it into,lstm encoderdecoder model,character representations feed it into lstm encoderdecoder model,0.5633248090744019
Blogs,6,30,model,input,using,cnn,input using cnn,0.6577777862548828
Blogs,6,30,model,model,builds,character representations,model builds character representations,0.6814757585525513
Blogs,6,17,results,summary statistics,of,both datasets,summary statistics of both datasets,0.5089781880378723
Blogs,6,28,results,results,has,character,results has character,0.4583595097064972
Blogs,6,32,results,evaluation metrics,are,rouge scores,evaluation metrics are rouge scores,0.4949949383735657
Blogs,6,32,results,evaluation metrics,are,meteor score,evaluation metrics are meteor score,0.48422858119010925
Blogs,6,32,results,evaluation metrics,are,overlap score,evaluation metrics are overlap score,0.5204201340675354
Blogs,6,32,results,evaluation metrics,are,repeat score,evaluation metrics are repeat score,0.522280752658844
Blogs,6,32,results,results,has,evaluation metrics,results has evaluation metrics,0.5194434523582458
Blogs,6,37,results,rwmd-rank,is,best extractive model,rwmd-rank is best extractive model,0.5628480315208435
Blogs,6,37,results,all extractive models,by,large margin,all extractive models by large margin,0.5344643592834473
Blogs,6,37,results,large margin,including,oracle,large margin including oracle,0.6684619784355164
Blogs,6,37,results,title- gen results,has,rwmd-rank,title- gen results has rwmd-rank,0.5628853440284729
Blogs,6,37,results,c2,has,model ),c2 has model ),0.6511105895042419
Blogs,6,37,results,c2,has,outperformed,c2 has outperformed,0.6608618497848511
Blogs,6,37,results,model ),has,outperformed,model ) has outperformed,0.636633038520813
Blogs,6,37,results,outperformed,has,all extractive models,outperformed has all extractive models,0.6140191555023193
Blogs,6,37,results,results,For,title- gen results,results For title- gen results,0.6059083342552185
Blogs,6,38,results,both c2 c and fconv,achieved,similar results,both c2 c and fconv achieved similar results,0.7140377163887024
Blogs,6,38,results,similar results,with,similar high overlap scores,similar results with similar high overlap scores,0.6523811221122742
Blogs,6,38,results,results,has,both c2 c and fconv,results has both c2 c and fconv,0.5223059058189392
Blogs,6,39,results,lead - 10,was,strong baseline,lead - 10 was strong baseline,0.6651270985603333
Blogs,6,39,results,abstract - gen results,has,lead - 10,abstract - gen results has lead - 10,0.6069270372390747
Blogs,6,39,results,results,For,abstract - gen results,results For abstract - gen results,0.6088465452194214
Blogs,6,40,results,all extractive models,achieved,similar rouge scores,all extractive models achieved similar rouge scores,0.666898250579834
Blogs,6,40,results,similar rouge scores,with,similar repeat score,similar rouge scores with similar repeat score,0.6335461139678955
Blogs,6,40,results,results,has,all extractive models,results has all extractive models,0.5192540287971497
Blogs,6,41,results,abstractive models,performed,poorly,abstractive models performed poorly,0.2949185371398926
Blogs,6,41,results,poorly,based on,rouge scores,poorly based on rouge scores,0.6398877501487732
Blogs,6,41,results,all models,in terms of,meteor score,all models in terms of meteor score,0.636907160282135
Blogs,6,41,results,outperformed,has,all models,outperformed has all models,0.6317006945610046
Blogs,6,41,results,results,has,abstractive models,results has abstractive models,0.5407604575157166
Blogs,6,42,results,results,has,qualitative evaluation,results has qualitative evaluation,0.5084247589111328
Blogs,6,45,results,abstractive generated titles,tend to be,high quality,abstractive generated titles tend to be high quality,0.6257219910621643
Blogs,6,45,results,abstractive generated titles,of,high quality,abstractive generated titles of high quality,0.538952112197876
Blogs,6,45,results,lstm,generate,more novel words,lstm generate more novel words,0.672314465045929
Blogs,6,45,results,results,has,abstractive generated titles,results has abstractive generated titles,0.5454053282737732
Blogs,6,46,results,generated titles,occasionally make mistakes,incorrect words,generated titles occasionally make mistakes incorrect words,0.7012060284614563
Blogs,6,46,results,results,has,generated titles,results has generated titles,0.5899250507354736
Blogs,6,48,results,important content,spread across,sections,important content spread across sections,0.6441863775253296
Blogs,6,48,results,results,has,important content,results has important content,0.5095093250274658
Blogs,6,49,results,output,of,fconv abstractive model,output of fconv abstractive model,0.6016596555709839
Blogs,6,49,results,fconv abstractive model,is,bad quality,fconv abstractive model is bad quality,0.5541505217552185
Blogs,6,49,results,fconv abstractive model,of,bad quality,fconv abstractive model of bad quality,0.5882718563079834
Blogs,6,49,results,bad quality,lacks,coherent and content ow,bad quality lacks coherent and content ow,0.6878625750541687
Blogs,6,49,results,results,has,output,results has output,0.5624434947967529
Blogs,7,31,baselines,cnn and bilstm,to encode,extraction units,cnn and bilstm to encode extraction units,0.7034662961959839
Blogs,7,9,experiments,qa pairs,extracted from,human abstract,qa pairs extracted from human abstract,0.5305728316307068
Blogs,7,9,experiments,questions,using,source document,questions using source document,0.6569480299949646
Blogs,7,16,experiments,better,as,extraction units,better as extraction units,0.5725762844085693
Blogs,7,27,experiments,words or chunks ( phrases ),as,extraction units,words or chunks ( phrases ) as extraction units,0.4965808391571045
Blogs,7,6,hyperparameters,question answer ( qa ) pairs,limit,answer token,question answer ( qa ) pairs limit answer token,0.679462730884552
Blogs,7,6,hyperparameters,answer token,to,salient word,answer token to salient word,0.5223469138145447
Blogs,7,6,hyperparameters,answer token,to,named entity,answer token to named entity,0.5287625789642334
Blogs,7,6,hyperparameters,hyperparameters,To create,question answer ( qa ) pairs,hyperparameters To create question answer ( qa ) pairs,0.6654553413391113
Blogs,7,8,hyperparameters,at least one qa pair,should be extracted from,each sentence,at least one qa pair should be extracted from each sentence,0.6737638115882874
Blogs,7,8,hyperparameters,each sentence,of,abstract,each sentence of abstract,0.5683045387268066
Blogs,7,20,hyperparameters,answer tokens,chosen,randomly,answer tokens chosen randomly,0.7820698618888855
Blogs,7,20,hyperparameters,answer tokens,can be,root word,answer tokens can be root word,0.6079099774360657
Blogs,7,20,hyperparameters,answer tokens,can be,subj / obj word,answer tokens can be subj / obj word,0.6073092222213745
Blogs,7,20,hyperparameters,answer tokens,can be,ner word,answer tokens can be ner word,0.5562695860862732
Blogs,7,20,hyperparameters,hyperparameters,has,answer tokens,hyperparameters has answer tokens,0.5434725880622864
Blogs,7,21,hyperparameters,participants,rate,informativeness,participants rate informativeness,0.73534095287323
Blogs,7,21,hyperparameters,informativeness,of,summary,informativeness of summary,0.6344471573829651
Blogs,7,21,hyperparameters,summary,from,1 - 5,summary from 1 - 5,0.6350524425506592
Blogs,7,21,hyperparameters,summary,being,most informative,summary being most informative,0.5944225788116455
Blogs,7,21,hyperparameters,hyperparameters,asked,participants,hyperparameters asked participants,0.6475948095321655
Blogs,7,21,hyperparameters,hyperparameters,rate,informativeness,hyperparameters rate informativeness,0.7250588536262512
Blogs,7,28,hyperparameters,text chunks,using,sentence constituent parse tree,text chunks using sentence constituent parse tree,0.6148832440376282
Blogs,7,28,hyperparameters,each chunk,has,at most 5 words,each chunk has at most 5 words,0.5950829982757568
Blogs,7,28,hyperparameters,hyperparameters,obtain,text chunks,hyperparameters obtain text chunks,0.5002260208129883
Blogs,7,30,model,model,focused on,ner-grained extraction units,model focused on ner-grained extraction units,0.6885495185852051
Blogs,7,34,model,framework,whereby,importance,framework whereby importance,0.6945050358772278
Blogs,7,34,model,importance,of,t-th source extraction unit,importance of t-th source extraction unit,0.6202343702316284
Blogs,7,34,model,importance,determined by,informativeness,importance determined by informativeness,0.5972493886947632
Blogs,7,34,model,importance,determined by,position,importance determined by position,0.6820070743560791
Blogs,7,34,model,importance,determined by,relationship with the previously selected extraction units,importance determined by relationship with the previously selected extraction units,0.6928896903991699
Blogs,7,34,model,t-th source extraction unit,determined by,informativeness,t-th source extraction unit determined by informativeness,0.6197414398193359
Blogs,7,34,model,position,in,document,position in document,0.5388293862342834
Blogs,7,34,model,model,use,framework,model use framework,0.6615379452705383
Blogs,7,35,model,positional embeddings,to encode,position,positional embeddings to encode position,0.6901742219924927
Blogs,7,35,model,position,has,of the extraction unit,position has of the extraction unit,0.551042377948761
Blogs,7,35,model,model,have,positional embeddings,model have positional embeddings,0.5769782662391663
Blogs,7,36,model,each time step,build,vector representation,each time step build vector representation,0.69443279504776
Blogs,7,36,model,each time step,used it along with,positional embeddings,each time step used it along with positional embeddings,0.6738286018371582
Blogs,7,36,model,vector representation,of,our summary,vector representation of our summary,0.5968841314315796
Blogs,7,36,model,vector representation,used it along with,positional embeddings,vector representation used it along with positional embeddings,0.6547074913978577
Blogs,7,36,model,vector representation,used it along with,our encoded hidden states,vector representation used it along with our encoded hidden states,0.6319332122802734
Blogs,7,36,model,our summary,has,up to time t - 1,our summary has up to time t - 1,0.608049213886261
Blogs,7,37,model,architecture,is,unidirectional lstm,architecture is unidirectional lstm,0.5510374307632446
Blogs,7,37,model,model,is,unidirectional lstm,model is unidirectional lstm,0.5532432198524475
Blogs,7,37,model,model,has,architecture,model has architecture,0.5575731992721558
Blogs,7,5,results,our generated summaries,yielded,competitive results,our generated summaries yielded competitive results,0.7001293301582336
Blogs,7,5,results,competitive results,measured by,automatic metrics,competitive results measured by automatic metrics,0.7263333201408386
Blogs,7,5,results,competitive results,measured by,human assessors,competitive results measured by human assessors,0.6992145776748657
Blogs,7,5,results,results,has,our generated summaries,results has our generated summaries,0.570889413356781
Blogs,7,7,results,salient word or named entity,in,all the sentences,salient word or named entity in all the sentences,0.4974503219127655
Blogs,7,7,results,all the sentences,in,human abstract,all the sentences in human abstract,0.502306342124939
Blogs,7,7,results,answer token,with,blank,answer token with blank,0.6516651511192322
Blogs,7,7,results,blank,to create,cloze-style qa pair,blank to create cloze-style qa pair,0.722269594669342
Blogs,7,7,results,results,identify,salient word or named entity,results identify salient word or named entity,0.5728350281715393
Blogs,7,7,results,results,replace,answer token,results replace answer token,0.6317077279090881
Blogs,7,11,results,root - type qa pairs,have,least number of unique answers,root - type qa pairs have least number of unique answers,0.576668381690979
Blogs,7,11,results,results,observed,root - type qa pairs,results observed root - type qa pairs,0.6474096179008484
Blogs,7,12,results,qasumm + root,performed,best,qasumm + root performed best,0.2699686288833618
Blogs,7,12,results,qasumm + root,performed,best,qasumm + root performed best,0.2699686288833618
Blogs,7,12,results,best,amongst,variant,best amongst variant,0.6040174961090088
Blogs,7,12,results,variant,in,daily mail dataset,variant in daily mail dataset,0.5068886876106262
Blogs,7,12,results,qasumm + ner,performed,best,qasumm + ner performed best,0.2439437359571457
Blogs,7,12,results,best,in,cnn dataset,best in cnn dataset,0.45015332102775574
Blogs,7,12,results,results,has,qasumm + root,results has qasumm + root,0.5383110642433167
Blogs,7,13,results,maximise,has,performance,maximise has performance,0.6080300211906433
Blogs,7,13,results,results,maintaining,good number of unique answers,results maintaining good number of unique answers,0.6671441793441772
Blogs,7,17,results,performance,of,lstm and cnn encoder,performance of lstm and cnn encoder,0.5345045328140259
Blogs,7,17,results,performance,found that,chunks,performance found that chunks,0.6994162201881409
Blogs,7,17,results,performance,found that,chunks,performance found that chunks,0.6994162201881409
Blogs,7,17,results,lstm and cnn encoder,found that,chunks,lstm and cnn encoder found that chunks,0.6514872312545776
Blogs,7,17,results,lstm and cnn encoder,found that,chunks,lstm and cnn encoder found that chunks,0.6514872312545776
Blogs,7,17,results,chunks,with,lstm,chunks with lstm,0.6585763692855835
Blogs,7,17,results,chunks,with,cnn,chunks with cnn,0.6840487122535706
Blogs,7,17,results,chunks,with,lstm,chunks with lstm,0.6585763692855835
Blogs,7,17,results,chunks,performed,best,chunks performed best,0.2754538059234619
Blogs,7,17,results,lstm,performed,best,lstm performed best,0.2753291726112366
Blogs,7,17,results,cnn,with,words,cnn with words,0.6516931056976318
Blogs,7,17,results,cnn,has,outperformed,cnn has outperformed,0.6208545565605164
Blogs,7,17,results,outperformed,has,lstm,outperformed has lstm,0.6128553748130798
Blogs,7,17,results,outperformed,has,cnn,outperformed has cnn,0.6106405258178711
Blogs,7,17,results,results,compared,performance,results compared performance,0.7382499575614929
Blogs,7,22,results,results,evaluated,summaries,results evaluated summaries,0.646599292755127
Blogs,7,23,results,average time it takes,to complete,single question,average time it takes to complete single question,0.6919096112251282
Blogs,7,23,results,average time it takes,to complete,overall accuracy,average time it takes to complete overall accuracy,0.6544033885002136
Blogs,7,23,results,average time it takes,to complete,informativeness score,average time it takes to complete informativeness score,0.6685036420822144
Blogs,7,23,results,results,showcase,average time it takes,results showcase average time it takes,0.7465823292732239
Blogs,7,24,results,our qasumm,with,ner - type qa pairs,our qasumm with ner - type qa pairs,0.692785918712616
Blogs,7,24,results,ner - type qa pairs,able to achieved,highest accuracy and informativeness,ner - type qa pairs able to achieved highest accuracy and informativeness,0.6734198331832886
Blogs,7,24,results,human performance,has,our qasumm,human performance has our qasumm,0.5938490629196167
Blogs,7,24,results,results,Excluding,human performance,results Excluding human performance,0.6741708517074585
Blogs,7,25,results,wide margin,in,qa accuracy,wide margin in qa accuracy,0.5527673959732056
Blogs,7,25,results,wide margin,despite,similar level,wide margin despite similar level,0.6278728246688843
Blogs,7,25,results,best performing model,has,wide margin,best performing model has wide margin,0.5691346526145935
Blogs,7,25,results,results,found that,best performing model,results found that best performing model,0.6768954992294312
