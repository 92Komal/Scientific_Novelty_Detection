title
TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph

abstract
Multi-hop Question Answering (QA) is a challenging task because it requires precise reasoning with entity relations at every step towards the answer. The relations can be represented in terms of labels in knowledge graph (e.g., spouse) or text in text corpus (e.g., they have been married for 26 years). Existing models usually infer the answer by predicting the sequential relation path or aggregating the hidden graph features. The former is hard to optimize, and the latter lacks interpretability. In this paper, we propose Trans-ferNet, an effective and transparent model for multi-hop QA, which supports both label and text relations in a unified framework. Trans-ferNet jumps across entities at multiple steps. At each step, it attends to different parts of the question, computes activated scores for relations, and then transfer the previous entity scores along activated relations in a differentiable way. We carry out extensive experiments on three datasets and demonstrate that TransferNet surpasses the state-of-the-art models by a large margin. In particular, on MetaQA, it achieves 100% accuracy in 2-hop and 3-hop questions. By qualitative analysis, we show that TransferNet has transparent and interpretable intermediate results.

Introduction Question answering (QA) plays a central role in artificial intelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus  (Rajpurkar et al., 2016; Joshi et al., 2017; Chen et al., 2017)  or structured knowledge base  (Bordes et al., 2015; Yih et al., 2015; Jiang et al., 2019) . Along with the fast development of deep learning, especially the pretraining technology  (Devlin et al., 2018; Lan et al., 2019) , state-of-the-art models have been shown comparative with human per-Figure  1 : Answering a multi-hop question over the relation graph. The relations are constrained predicates in the label form (i.e., knowledge graph) while free texts in the text form. The reasoning process has been marked in the graph, where the correspondence between relations and question words has been highlighted in the same color. formance on simple questions that only need a single hop  (Petrochuk and Zettlemoyer, 2018; , e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far from resolved  (Yang et al., 2018; Dua et al., 2019; Zhang et al., 2017; Talmor and Berant, 2018) . In this paper, we focus on multi-hop QA based on relation graphs, which consists of entities and their relations. As shown in Figure  1 , the relations can be represented by two forms: ? Label form, also known as knowledge graph (e.g., Freebase  (Bollacker et al., 2008) , Wikidata  (Vrande?i? and Kr?tzsch, 2014) ), whose relations are manually-defined constrained predicates (e.g., Spouse, CEO). ? Text form, whose relations are free texts retrieved from textual corpus. We can easily build the graph by extracting the co-occuring sentences of two entities. Since the label form is expensive and usually incomplete, the text form is more economical and practical. In this paper, we aim to tackle multi-hop questions over these two different forms in a unified framework. Existing methods for multi-hop QA have two main strands. The first is to predict the sequential relation path in a weakly supervised setting  (Zhang et al., 2017; Qiu et al., 2020) , that is, to learn the intermediate path only based on the final answer. These works suffer from the convergence issues due to the huge search space, which heavily hinders their performance. Besides, they are mostly proposed for the label form. So, it is not clear how to adapt them to the text form, whose search space is even much huger. The second strand is to collect evidences by using graph neural networks  (Sun et al., 2018 . They can handle both the two relation forms and achieve state-of-the-art performance. Although they prevail over the path-based models in performance, they are weak in interpretability since their intermediate reasoning process is black-box neural network layers. In this paper, we propose a novel model for multi-hop QA, dubbed TransferNet, which has the following advantages: 1) Generality. It can deal with the label form, the text form, and their combinations in a unified framework. 2) Effectiveness. TransferNet outperforms previous models significantly, achieving 100% accuracy of 2-hop and 3-hop questions in MetaQA dataset. 3) Transparency. TransferNet is fully attention-based, so its intermediate steps can be easily visualized and understood by humans. Specifically, TransferNet infers the answer by transfering entity scores along relation scores of multiple steps. It starts from the topic entity of the question and maintains an entity score vector, whose elements indicate the probability of an entity being activated. At each step, it attends to some question words (e.g., the wife of ) and compute scores for the relations in the graph. Relations relevant to the question words will have high scores (e.g., Spouse). We formulate these relation scores into an adjacent matrix, where each entry indicates the transfer probability of an entity pair. By multiplying the entity score vector with the relation score matrix, we can "hop" along relations in a differentiable manner. After repeating for multiple steps, we can finally arrive at the target entity. We conduct experiments for the two forms respectively. For the label form, we use MetaQA  (Zhang et al., 2017 ), WebQSP (Yih et al., 2016  and CompWebQ  (Talmor and Berant, 2018) . TransferNet achieves 100% accuracy in the 2-hop and 3-hop questions of MetaQA. On WebQSP and CompWebQ, we also achieve a significant improvement over state-of-the-art models. For the text form, following , we construct the relation graph of MetaQA from the WikiMovies corpus  (Miller et al., 2016) . We demonstrate that TransferNet surpasses previous models by a large margin, especially for the 2-hop and 3-hop questions. When we mix the label form and the text form, TransferNet still keeps its superiority. Moreover, by visualizing the intermediate results, we show its strong interpretability. 1 

 Related Work In this paper we focus on multi-hop question answering over the graph structure that is either knowledge graph or built from text corpus. In previous works, GraftNet  (Sun et al., 2018)  and PullNet  have a similar setting to ours but they mostly aim at the mixed form, which includes both label relations and text relations. They first retrieve a question-specific subgraph and then use graph convolutional networks  (Kipf and Welling, 2016)  to implicitly infer the answer entity. These GCN-based methods are usually weak in interpretability because they cannot produce the intermediate reasoning path, which is necessary in our opinion for the task of multi-hop question answering. Besides, there are many works specifically for only one graph form: For the label form, which is also known as "KBQA" or "KGQA", existing methods fall into two categories: information retrieval  (Miller et al., 2016; Xu et al., 2019; Zhao et al., 2019b; Saxena et al., 2020)  and semantic parsing  (Berant et al., 2013; Yih et al., 2015; Liang et al., 2017; Guo et al., 2018; Saha et al., 2019) . The former retrieves answer from KG by learning representations of question and graph, while the latter queries answer by parsing the question into logical form. Among these methods, VRN  (Zhang et al., 2017)  and SRN  (Qiu et al., 2020)  have a good interpretability as they learn an explicit reasoning path with reinforcement learning. However, they suffer from the convergency issue due to the huge search space. IRN  and  ReifKB (Cohen et al., 2020)  learn a soft distribution for intermediate relations and can be optimized using only the final answer. However, it is not clear how to extend them to the text form. Question answering over text corpus is also known as "reading comprehension". For simple questions, whose answer can be retrieved directly from the text, pretrained models  (Devlin et al., 2018; Lan et al., 2019)  have performed better than humans . For multi-hop questions that are much more challenging, existing works  (Ding et al., 2019; Fang et al., 2019; Tu et al., 2020; Zhao et al., 2019a)  usually convert the text into a rule-based or learning-based entity graph, and then use graph neural networks  (Kipf and Welling, 2016)  to perform implicit reasoning. Similar to PullNet, they are weak in interpretability. Besides, most of them build the graph by just connecting relevant entities, missing the important edge textual information. 

 Methodology 

 Preliminary We conduct multi-hop reasoning on a relation graph, which takes entities as nodes and relations between them as edges. The relations can be of different forms, specifically, constrained labels or free texts. The former is also known as structured Knowledge Graph (e.g., Wikidata  (Vrande?i? and Kr?tzsch, 2014) ), which predefines a set of predicates to represent the entity relations. The latter can be easily extracted from large-scale document corpora according to the co-occurence of entity pairs. Figure  1  shows examples of these two forms. In this paper we call them label form and text form respectively, and use mixed form to denote a relation graph consisting of both labels and texts. We denote a relation graph as G, its entities as E and its edges as R. Let n denote the number of entities, then R is an n ? n matrix whose element r i,j represents the relations between the head entity e i and the tail entity e j . r i,j can be a set of labels (for label form) or texts (for text form) or both (for mixed form). A multi-hop question q usually starts from a topic entity e x and needs to traverse across relations to reach the answer entities Y = {e y 1 , ? ? ? , e y |Y | }. 

 TransferNet To infer the answer of a multi-hop question, Trans-ferNet starts from the topic entity and jumps for T steps. At each step, it attends to different parts of the question to determine the most proper relation. TransferNet maintains a score for each entity to denote their activated probabilities, which are initialized to 1 for the topic entity and 0 for the others. At each step, TransferNet computes a score for each relation to denote their activated probabilities in terms of the current query, and then transfer the entity scores across those activated relations. Figure  2  shows the framework. Formally, we denote the entity scores of step t as a row vector a t ? [0, 1] n , where [0, 1] means a real number between 0 and 1. a 0 is the initial scores, i.e., only the topic entity e x gets 1. At step t, we attend to part of the question to get the query vector q t ? R d , where d is the hidden dimension. q, (h 1 , ? ? ? , h |q| ) = Encoder(q; ? e ), qk t = f t (q; ? f t ), b t = Softmax(qk t ? [h 1 ; ? ? ? ; h |q| ] ), q t = |q| i=1 b t i h i . (1) q denotes the question embedding. f t is a projecting function of step t, which maps q to a specific query key qk t . qk t is the attention key to compute scores for each word based on their hidden vector h i . q t is the weighted sum of h i . In terms of q t TransferNet computes the relation scores W t ? [0, 1] n?n : W t = g(q t ; ? g ). (2) ? g denotes the learnable parameters. We will have different implementations of g for the label form and the text form, which will be introduced in Sec.3.5. Then we can simulate the "jumping across edges" as the following formulation: a t = a t?1 W t . (3) Specifically, we have a t j = n i=1 a t?1 i ? W t i,j . (4) It means that the production of entity e i 's previous score and the edge r i,j 's current score will be collected into e j 's current score. Bill & Melinda Gates Foundation < l a t e x i t s h a 1 _ b a s e 6 4 = " z q f u J / y T r J U h x 4  I / l u h m k B 4 + O Y I = " > A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q m R E U X c F N y 4 r 2 A e 0 Y 8 m k m T Y 0 k x m S j F K G + Q 8 3 L h R x 6 7 + 4 8 2 / M t L P Q 1 g O B w z n 3 c k + O H w u u D c b f T m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 d Z Q o y l o 0 E p H q + k Q z w S V r G W 4 E 6 8 a K k d A X r O N P b n K / 8 8 i U 5 p G 8 N 9 O Y e S E Z S R 5 w S o y V H v o h M W M / S E k 2 S H E 2 q N Z w H c + A l o l b k B o U a A 6 q X / 1 h R J O Q S U M F 0 b r n 4 t h 4 K V G G U 8 G y S j / R L C Z 0 Q k a s Z 6 k k I d N e O k u d o R O r D F E Q K f u k Q T P 1 9 0 Z K Q q 2 n o W 8 n 8 5 R 6 0 c v F / 7 x e Y o I r L + U y T g y T d H 4 o S A Q y E c o r Q E O u G D V i a g m h i t u s i I 6 J I t T Y o i q 2 B H f x y 8 u k f V Z 3 L + r 4 7 r z W u C 7 q K M M R H M M p u H A J D b i F J r S A p V K + m I x E c x 1 R m P Z O b B x 8 = " > A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s y I o u 4 K b l x W s A 9 o x 5 J J M 2 1 o k h m S j F K G + Q 8 3 L h R x 6 7 + 4 8 2 / M t L P Q 1 g O B w z n 3 c k 9 O E H O m j e t + O 6 W V 1 b X 1 j f J m Z W t 7 Z 3 e v u n / Q 1 l G i C G 2 R i E e q G 2 B N O Z O 0 Z Z j h t B s r i k X A a S e Y 3 O R + 5 5 E q z S J 5 b 6 Y x 9 Q U e S R Y y g o 2 V H v o C m 3 E Q p p 1 s k H r Z o F p z 6 + 4 M a J l 4 B a l B g e a g + t U f R i Q R V B r C s d Y 9 z 4 2 N n 2 J l G O E 0 q / Q T T W N M J n h E e 5 Z K L K j 2 0 1 n q D J 1 Y Z Y j C S N k n D Z q p v z d S L L S e i s B O 5 i n 1 o p e L / 3 m 9 x I R X f s p k n B g q y f x Q m H B k I p R X g I Z M U W L 4 1 B J M F L N Z E R l j h Y m x R V V s C d 7 i l 5 d J + 6 z u X d T d u / N a 4 7 q o o w x H c A y n 4 M E l N O A W m t A C A g q e 4 R X e n C f n x X l 3 P u a j J a f Y O Y Q / c D 5 / A M K a k q Y = < / l a t e x i t > 

 W1 < l a t e x i t s h a 1 _ b a s e 6 4 = " g E j e l H 8 4 / + 3 S g q r 4 C + 4 s e A w P y J 8 = " > A A A C E X i c b V D L S s N A F L 2 p r 1 p f U Z d u B o v Q V U l E U R d C w Y 3 L C v Y B b Q i T 6 a Q d O n k w M x F K y C + 4 8 V f c u F D E r T t 3 / o 2 T N k J t P T B w 7 j n 3 M v c e L + Z M K s v 6 N k o r q 2 v r G + X N y t b 2 z u 6 e u X / Q l l E i C G 2 R i E e i 6 2 F J O Q t p S z H F a T c W F A c e p x 1 v f J P 7 n Q c q J I v C e z W J q R P g Y c h 8 R r D S k m v W + g F W I 8 9 P c e a m d n Y 9 V 1 r o t + h k r u 2 a V a t u T Y G W i V 2 Q K h R o u u Z X f x C R J K C h I h x L 2 b O t W D k p F o o R T r N K P 5 E 0 x m S M h 7 S n a Y g D K p 1 0 e l G G T r Q y Q H 4 k 9 A s V m q r z E y k O p J w E n u 7 M d 5 S L X i 7 + 5 / U S 5 V 8 6 K Q v j R N G Q z D 7 y E 4 5 U h P J 4 0 I A J S h S f a I K J Y H p X R E Z Y Y K J 0 i B U d g r 1 4 8 j J p n 9 b t 8 7 p 1 d 1 Z t X B V x l O E I j q E G N l x A A 2 6 h C S 0 g 8 A j P 8 A p v x p P x Y r w b H 7 P W k l H M H M I f G J 8 / 5 x + d p Q = = < / l a t e x i t > a1 = a0W1 < l a t e x i t s h a 1 _ b a s e 6 4 = " I l i t o T 0 e o r T t D G H S 2 F K J x I E r 6 x U = " > A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l Z m i q L u C G 5 c V 7 A P a s W T S T B u a S Y Y k o 5 R h / s O N C 0 X c + i / u / B s z 7 S y 0 9 U D g c M 6 9 3 J M T x J x p 4 7 r f z s r q 2 v r G Z m m r v L 2 z u 7 d f O T h s a 5 k o Q l t E c q m 6 A d a U M 0 F b h h l O u 7 G i O A o 4 7 Q S T m 9 z v P F K l m R T 3 Z h p T P 8 I j w U J G s L H S Q z / C Z h y E a S c b p P V s U K m 6 N X c G t E y 8 g l S h Q H N Q + e o P J U k i K g z h W O u e 5 8 b G T 7 E y j H C a l f u J p j E m E z y i P U s F j q j 2 0 1 n q D J 1 a Z Y h C q e w T B s 3 U 3 x s p j r S e R o G d z F P q R S 8 X / / N 6 i Q m v / J S J O D F U k P m h M O H I S J R X g I Z M U W L 4 1 B J M F L N Z E R l j h Y m x R Z V t C d 7 i l 5 d J u 1 7 z L m r u 3 X m 1 c V 3 U U Y J j O I E z 8 O A S G n A L T W g B A Q X P 8 A p v z p P z 4 r w 7 H / P R F a f Y O Y I / c D 5 / A M Q f k q c = < / l a t e x i t > W2 < l a t e x i t s h a 1 _ b a s e 6 4 = " D B R 2 9 s F 2 R Y Y G H h u Q p z w W 7 N T J p 3 8 = " > A A A C E X i c b V D L S s N A F L 3 x W e s r 6 t L N Y B G 6 K k l R 1 I V Q c O O y g n 1 A G 8 J k O m m H T h 7 M T I Q S 8 g t u / B U 3 L h R x 6 8 6 d f + O k j V B b D w y c e 8 6 9 z L 3 H i z m T y r K + j Z X V t f W N z d J W e X t n d 2 / f P D h s y y g R h L Z I x C P R 9 b C k n I W 0 p Z j i t B s L i g O P 0 4 4 3 v s n 9 z g M V k k X h v Z r E 1 A n w M G Q + I 1 h p y T W r / Q C r k e e n O H P T e n Y 9 V 9 r o t + h k b t 0 1 K 1 b N m g I t E 7 s g F S j Q d M 2 v / i A i S U B D R T i W s m d b s X J S L B Q j n G b l f i J p j M k Y D 2 l P 0 x A H V D r p 9 K I M n W p l g P x I 6 B c q N F X n J 1 I c S D k J P N 2 Z 7 y g X v V z 8 z + s l y r 9 0 U h b G i a I h m X 3 k J x y p C O X x o A E T l C g + 0 Q Q T w f S u i I y w w E T p E M s 6 B H v x 5 G X S r t f s 8 5 p 1 d 1 Z p X B V x l O A Y T q A K N l x A A 2 6 h C S 0 g 8 A j P 8 A p v x p P x Y r w b H 7 P W F a O Y O Y I / M D 5 / A O v T n a g = < / l a t e x i t > a2 = a1W2 Label Form 

 Text Form Relation Graphs 

 Example Question: What organization did the wife of Bill Gates found? < l a t e x i t s h a 1 _ b a s e 6 4 = " C r o 1 K F t H 7 9 6 d p k / W w q v F 0 s I z 2 D 4 = " > A A A B + X i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w Y 0 l E 0 Z U U 3 L i s Y B / Q h j C Z T t q h k 0 m Y u S m U k D 9 x 4 0 I R t / 6 J O / / G S Z u F t h 4 Y O J x z L / f M C R L B N T j O t 1 V Z W 9 / Y 3 K p u 1 3 Z 2 9 / Y P 7 M O j j o 5 T R V m b x i J W v Y B o J r h k b e A g W C 9 R j E S B Y N 1 g c l / 4 3 S l T m s f y C W Y J 8 y I y k j z k l I C R f N s e R A T G Q Z i R 3 M / g w s 1 9 u + 4 0 n D n w K n F L U k c l W r 7 9 N R j G N I 2 Y B C q I 1 n 3 X S c D L i A J O B c t r g 1 S z h N A J G b G + o Z J E T H v Z P H m O z 4 w y x G G s z J O A 5 + r v j Y x E W s + i w E w W O f W y V 4 j / e f 0 U w l s v 4 z J J g U m 6 O B S m A k O M i x r w k C t G Q c w M I V R x k x X T M V G E g i m r Z k p w l 7 + 8 S j q X D f e 6 4 T x e 1 Z t 3 Z R 1 V d I J O 0 T l y 0 Q 1 q o g f U Q m 1 E 0 R Q 9 o 1 f 0 Z m X W i / V u f S x G K 1 a 5 c 4 z + w P r 8 A Z U h k 5 s = < / l a t e x i t > a t 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " p / b 1 L I n r n v a 7 9 W q s / g W g A N 4 d 3 B c = " > A A A B 9 X i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S i K K r q T g x m U F + 4 A 2 l s l 0 0 g 6 d T O L M j V J C / s O N C 0 X c + i / u / B s n b R b a e m D g c M 6 9 3 D P H j w X X 6 D j f 1 t L y y u r a e m m j v L m 1 v b N b 2 d t v 6 S h R l D V p J C L V 8 Y l m g k v W R I 6 C d W L F S O g L 1 v b H 1 7 n f f m R K 8 0 j e 4 S R m X k i G k g e c E j T S f S 8 k O P K D 9 C H r p 5 j 1 K 1 W n 5 k x h L x K 3 I F U o 0 O h X v n q D i C Y h k 0 g F 0 b r r O j F 6 K V H I q W B Z u Z d o F h M 6 J k P W N V S S k G k v n a b O 7 G O j D O w g U u Z J t K f q 7 4 2 U h F p P Q t 9 M 5 i n 1 v J e L / 3 n d B I N L L + U y T p B J O j s U J M L G y M 4 r s A d c M Y p i Y g i h i p u s N h 0 R R S i a o s q m B H f + y 4 u k d V p z z 2 v O 7 V m 1 f l X U U Y J D O I I T c O E C 6 n A D D W g C B Q X P 8 A p v 1 p P 1 Y r 1 b H 7 P R J a v Y O Y A / s D 5 / A F H j k w g = < / l a t e x i t > q t < l a t e x i t s h a 1 _ b a s e 6 4 = " P P O r i J K v 8 e 1 V K p N Z H E z k R H x O f + k = " > A A A B 9 X i c b V D L S s N A F L 2 p r 1 p f V Z d u g k V w V R J R d C U F N y 4 r 2 A e 0 s U y m k 3 b o Z B J m b p Q S 8 h 9 u X C j i 1 n 9 x 5 9 8 4 a b P Q 1 g M D h 3 P u 5 Z 4 5 f i y 4 R s f 5 t k o r q 2 v r G + X N y t b 2 z u 5 e d f + g r a N E U d a i k Y h U 1 y e a C S 5 Z C z k K 1 o 0 V I 6 E v W M e f 3 O R + 5 5 E p z S N 5 j 9 O Y e S E Z S R 5 w S t B I D / 2 Q 4 N g P 0 k 4 2 S D E b V G t O 3 Z n B X i Z u Q W p Q o D m o f v W H E U 1 C J p E K o n X P d W L 0 U q K Q U 8 G y S j / R L C Z 0 Q k a s Z 6 g k I d N e O k u d 2 S d G G d p B p M y T a M / U 3 x s p C b W e h r 6 Z z F P q R S 8 X / / N 6 C Q Z X X s p l n C C T d H 4 o S I S N k Z 1 X Y A + 5 Y h T F 1 B B C F T d Z b T o m i l A 0 R V V M C e 7 i l 5 d J + 6 z u X t S d u / N a 4 7 q o o w x H c A y n 4 M I l N O A W m t A C C g q e 4 R X e r C f r x X q 3 P u a j J a v Y O Y Q / s D 5 / A C n 5 k u 4 = < / l a t e x i t > W t < l a t e x i t s h a 1 _ b a s e 6 4 = " p W 8 h F 7 U p y 1 7 6 I p M S l p q g C R N w 5 In 2000, Melinda Gates cofounded the <obj> with her husband <sub>. + E = " > A A A C F 3 i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w Y 0 l E 0 Y 1 S c O O y g n 1 A G 8 J k O m m H T h 7 M 3 A g l 5 C / c + C t u X C j i V n f + j Z M 2 S G 0 9 M H D m n H u 5 9 x 4 v F l y B Z X 0 b p a X l l d W 1 8 n p l Y 3 N r e 8 f c 3 W u p K J G U N W k k I t n x i G K C h 6 w J H A T r x J K R w B O s 7 Y 1 u c r / 9 w K T i U X g P 4 5 g 5 A R m E 3 O e U g J Z c s 9 Y L C A w 9 P y W Z C / g K z 3 x T O L G z X 6 G d C 5 l r V q 2 a N Q F e J H Z B q q h A w z W / e v 2 I J g E L g Q q i V N e 2 Y n B S I o F T w b J K L 1 E s J n R E B q y r a U g C p p x 0 c l e G j 7 T S x 3 4 k 9 Q s B T 9 T Z j p Q E S o 0 D T 1 f m W 6 p 5 L x f / 8 7 o J + J d O y s M 4 A R b S 6 S A / E R g i n I e E + 1 w y C m K s C a G S 6 1 0 x H R J J K O g o K z o E e / 7 k R d I 6 r d n n N e v u r F q / L u I o o w N 0 i I 6 R j S 5 Q H d 2 i B m o i i h 7 R M 3 p F b 8 a T 8 W K 8 G x / T 0 p J R 9 O y j P z A + f w C 5 V K B G < / l a t e x i t > a t = a t 1 W t < l a t e x i t s h a 1 _ b a s e 6 4 = " 5 F 7 E N i u S g f z B 1 v b 5 3 T 1 v v i w R y 9 0 = " > A A A C b H i c b V H J T s M w E H X C V s J W l g M I I V l U I E 6 R g 1 j K D Y k L R 5 A o I D V V 5 T j T Y t V x I t t B V F F P / C E 3 P o E L 3 4 B T I p b C S J b f v J n n s Z + j T H B t C H l 1 3 K n p m d m 5 2 r y 3 s L i 0 v F J f X b v V a a 4 Y t F g q U n U f U Q 2 C S 2 g Z b g T c Z w p o E g m 4 i w Y X Z f 3 u E Z T m q b w x w w w 6 C e 1 L 3 u O M G k t 1 6 8 9 h B H 0 u i y y h R v G n k U f w P i b + 2 Y n d w j g 1 u k x x G H r E b 4 7 h B B 0 + V t k 3 i H 8 z p X Z S 6 Y U g 4 6 + Z 3 X q D + G Q c + C 8 I K t B A V V x 1 6 y / 2 J J Y n I A 0 T V O t 2 Q D L T K a g y n A k Y e W G u I a N s Q P v Q t l D S B H S n G J s 1 w n u W i X E v V X Z J g 8 f s T 0 V B E 6 2 H S W Q 7 7 f 0 e 9 G S t J P + r t X P T a 3 Y K L r P c g G S f g 3 q 5 w C b F p f M 4 5 g q Y E U M L K F P c 3 h W z B 6 o o M / Z / P G t C M P n k v + D 2 0 A + O f X J 9 1 D g / q + y o o W 2 0 i w 5 Q g E 7 R O b p E V 6 i F G H p z V p x N Z 8 t 5 d z f c b X f n s 9 V 1 K s 0 6 + h X u / g In 2000, <sub> co-founded the <obj> with her husband Bill Gates. During his career at <sub>, <obj> held the positions of chairman, chief executive officer (CEO), president and chief software architect. < l a t e x i t s h a 1 _ b a s e 6 4 = " z p 3 T u 8 R y N j 5 H U p x n v q T S Q k d Q Y 5 o = " > A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y B E 8 l U Q U P U n B i 8 c K 9 g P a U D a b T b t 2 s x t 2 J 0 I J / Q 9 e P C j i 1 f / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e m A p u 0 P O + n Z X V t f W N z d J W e X t n d 2 + / c n D Y M i r T l D W p E k p 3 Q m K Y 4 J I 1 k a N g n V Q z k o S C t c P R 7 d R v P z F t u J I P O E 5 Z k J C B 5 D G n B K 3 U 6 t F I o e l X q l 7 N m 8 F d J n 5 B q l C g 0 a 9 8 9 S J F s 4 R J p I I Y 0 / W 9 F I O c a O R U s E m 5 l x m W E j o i A 9 a 1 V J K E m S C f X T t x T 6 0 S u b H S t i S 6 M / X 3 R E 4 S Y 8 Z J a D s T g k O z 6 E 3 F / 7 x u h v F 1 k H O Z Z s g k n S + K M + G i c q e v u x H X j K I Y W 0 K o 5 v Z W l w 6 J J h R t Q G U b g r / 4 8 j J p n d f 8 y 5 p 3 f 1 G t 3 x R x l O A Y T u A M f L i C O t x B A 5 p A 4 R G e 4 R X e H O W 8 O O / O x 7 x 1 x S l m j u A P n M 8 f r n W P L w = = < / l a t e x i t > ? ? ? Relations < l a t e x i t s h a 1 _ b a s e 6 4 = " G M o h Y m r C K b U g w d m P I 2 Y T E v 2 V D E k = " > A A A C G 3 i c b V D L S s N A F J 3 U V 4 2 v q E s 3 g 0 V x V Z K i q L u C G 5 c V 7 A O a U C b T 2 3 b o Z B J m J m I J / Q 8 3 / o o b F 4 q 4 E l z 4 N 0 7 T I t p 6 4 M L h n H t n 7 j 1 h w p n S r v t l F Z a W V 1 b X i u v 2 x u b W 9 o 6 z u 9 d Q c S o p 1 G n M Y 9 k K i Q L O B N Q 1 0 x x a i Q Q S h R y a 4 f B q 4 j f v Q C o W i 1 s 9 S i C I S F + w H q N E G 6 n j V P w Q + k x k S U S 0 Z P d j 2 8 P H 2 D X l d 2 O t c u 7 7 t g + i + 9 P S c U p u 2 c 2 B F 4 k 3 I y U 0 Q 6 3 j f J j H a B q B 0 J Q T p d q e m + g g I 1 I z y m F s + 6 m C h N A h 6 U P b U E E i U E G W 3 z b G R 0 b p 4 l 4 s T Q m N c / X 3 R E Y i p U Z R a D r N f g M 1 7 0 3 E / 7 x 2 q n s X Q c Z E k m o Q d P p R L + V Y x 3 g S F O 4 y C V T z k S G E S m Z 2 x X R A J K H a x G m b E L z 5 k x d J o 1 L 2 z s r u z W m p e j m L o 4 g O 0 C E 6 Q R 4 6 R 1 V 0 j W q o j i h 6 Q E / o B b 1 a j 9 a z 9 W a 9 T 1 s L 1 m x m H / 2 B 9 f k N q q 2 f T Q = = < / l a t e x i t > 1 0 . . . 0 < l a t e x i t s h a 1 _ b a s e 6 4 = " y 1 V D d z 5 G R A X u 8 A a b u E a m w 5 H 7 r T Q = " > A A A C H n i c b V B N S w M x E M 3 W r 7 p + V T 1 6 C R b F U 9 k V q / Z W 8 O K x g v 2 A 7 l K y 6 b Q N z W a X J C u W p b / E i 3 / F i w d F B E / 6 b 0 z b R b R 1 I O T l z Z v J z A t i z p R 2 n C 8 r t 7 S 8 s r q W X 7 c 3 N r e 2 d w q 7 e w 0 V J Z J C n U Y 8 k q 2 A K O B M Q F 0 z z a E V S y B h w K E Z D K 8 m + e Y d S M U i c a t H M f g h 6 Q v W Y 5 R o Q 3 U K Z S + A P h N p H B I t 2 f 3 Y d v A x d k q V c 3 N 5 3 U i r y R N 7 n u 2 B 6 P 6 o O o W i U 3 K m g R e B m 4 E i y q L W K X y Y Z j Q J Q W j K i V J t 1 4 m 1 n x K p G e U w t r 1 E Q U z o k P S h b a A g I S g / n a 4 3 x k e G 6 e J e J M 0 R G k / Z 3 x U p C Z U a h Y F R m v k G a j 4 3 I f / L t R P d u / R T J u J E g 6 C z j 3 o J x z r C E 6 9 w l 0 m g m o 8 M I F Q y M y u m A y I J 1 c Z R 2 5 j g z q + 8 C B q n J b d c c m 7 O i t V K Z k c e H a B D d I J c d I G q 6 B r V U B 1 R 9 I C e 0 A t 6 t R 6 t Z + v N e p 9 J c 1 Z W s 4 / + h P X 5 D S 8 3 o A c = < / l a t e x i t > 0 0.96 . . . 0 

 Encoder t 

 Attention Over Words 

 STEP t < l a t e x i t s h a 1 _ b a s e 6 4 = " W 4 N J c p 4 7 y A b Z Y D Z g L D g V y l 4 e e L M = " > A A A B + X i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w Y 0 l E U X c F N y 4 r 2 A e 0 I U y m k 3 b o Z B J m b g o l 5 E / c u F D E r X / i z r 9 x 0 m a h r Q c G D u f c y z 1 z g k R w D Y 7 z b V X W 1 j c 2 t 6 r b t Z 3 d v f 0 D + / C o o + N U U d a m s Y h V L y C a C S 5 Z G z g I 1 k s U I 1 E g W D e Y 3 B d + d 8 q U 5 r F 8 g l n C v I i M J A 8 5 J W A k 3 7 Y H E Y F x E G Y k 9 z O 4 c H P f r j s N Z w 6 8 S t y S 1 F G J l m 9 / D Y Y x T S M m g Q q i d d 9 1 E v A y o o B T w f L a I N U s I X R C R q x v q C Q R 0 1 4 2 T 5 7 j M 6 M M c R g r 8 y T g u f p 7 I y O R 1 r M o M J N F T r 3 s F e J / X j + F 8 N b L u E x S Y J I u D o W p w B D j o g Y 8 5 I p R E D N D C F X c Z M V 0 T B S h Y M q q m R L c 5 S + v k s 5 l w 7 1 u O I 9 X 9 e Z d W U c V n a B T d I 5 c d I O a 6 A G 1 U B t R N E X P 6 B W 9 W Z n 1 Y r 1 b H 4 v R i l X u H K M / s D 5 / A J O g k 5 Y = < / l a t e x i t > at 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " n k e s Y R l z W G i E F e C + B 0 O X 9 S S 6 r 7 k = " > A A A B 9 X i c b V D L S s N A F L 2 p r 1 p f V Z d u g k V w V R J R 1 F 3 B j c s K 9 g F t L J P p p B 0 6 m Y S Z G 6 W E / I c b F 4 q 4 9 V / c + T d O 2 i y 0 9 c D A 4 Z x 7 u W e O H w u u 0 X G + r d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 y h R l L V o J C L V 9 Y l m g k v W Q o 6 C d W P F S O g L 1 v E n N 7 n f e W R K 8 0 j e 4 z R m X k h G k g e c E j T S Q z 8 k O P a D l G S D F L N B t e b U n R n s Z e I W p A Y F m o P q V 3 8 Y 0 S R k E q k g W v d c J 0 Y v J Q o 5 F S y r 9 B P N Y k I n Z M R 6 h k o S M u 2 l s 9 S Z f W K U o R 1 E y j y J 9 k z 9 v Z G S U O t p 6 J v J P K V e 9 H L x P 6 + X Y H D l p V z G C T J J 5 4 e C R N g Y 2 X k F 9 p A r R l F M D S F U c Z P V p m O i C E V T V M W U 4 C 5 + e Z m 0 z + r u R d 2 5 O 6 8 1 r o s 6 y n A E x 3 A K L l x C A 2 6 h C S 2 g o O A Z X u H N e r J e r H f r Y z 5 a s o q d Q / g D 6 / M H N 9 K S 8 w = = < / l a t e x i t > at Answer < l a t e x i t s h a 1 _ b a s e 6 4 = " z p 3 T u 8 R y N j 5 H U p x n v q T S Q k d Q Y 5 o = " > A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y B E 8 l U Q U P U n B i 8 c K 9 g P a U D a b T b t 2 s x t 2 J 0 I J / Q 9 e P C j i 1 f / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e m A p u 0 P O + n Z X V t f W N z d J W e X t n d 2 + / c n D Y M i r T l D W p E k p 3 Q m K Y 4 J I 1 k a N g n V Q z k o S C t c P R 7 d R v P z F t u J I P O E 5 Z k J C B 5 D G n B K 3 U 6 t F I o e l X q l 7 N m 8 F d J n 5 B q l C g 0 a 9 8 9 S J F s 4 R J p I I Y 0 / W 9 F I O c a O R U s E m 5 l x m W E j o i A 9 a 1 V J K E m S C f X T t x T 6 0 S u b H S t i S 6 M / X 3 R E 4 S Y 8 Z J a D s T g k O z 6 E 3 F / 7 x u h v F 1 k H O Z Z s g k n S + K M + G i c q e v u x H X j K I Y W 0 K o 5 v Z W l w 6 J J h R t Q G U b g r / 4 8 j J p n d f 8 y 5 p 3 f 1 G t 3 x R x l O A Y T u A M f L i C O t x B A 5 p A 4 R G e 4 R X e H O W 8 O O / O x 7 x 1 x S l m j u A P n M 8 f r n W P L w = = < / l a t e x i t > ? ? ? < l a t e x i t s h a 1 _ b a s e 6 4 = " 0 A x L Y x j X q L B w O X V 9 V 7 a C I p d 0 0 d Q = " > A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i S i q L u C G 5 c V + o K m l M n 0 p h 0 6 m Y S Z i V B C f 8 O N C 0 X c + j P u / B s n b R Z a P T B w O O d e 7 p k T J I J r 4 7 p f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 5 1 d J w q h m 0 W i 1 j 1 A q p R c I l t w 4 3 A X q K Q R o H A b j C 9 y / 3 u I y r N Y 9 k y s w Q H E R 1 L H n J G j Z V 8 P 6 J m E o Q Z n Q 9 b w 2 r N r b s L k L / E K 0 g N C j S H 1 U 9 / F L M 0 Q m m Y o F r 3 P T c x g 4 w q w 5 n A e c V P N S a U T e k Y + 5 Z K G q E e Z I v M c 3 J m l R E J Y 2 W f N G S h / t z I a K T 1 L A r s Z J 5 R r 3 q 5 + J / X T 0 1 4 M 8 i 4 T F K D k i 0 P h a k g J i Z 5 A W T E F T I j Z p Z Q p r j N S t i E K s q M r a l i S / B W v / y X d C 7 q 3 l X d f b i s N W 6 L O s p w A q d w D h 5 c Q w P u o Q l t Y J D A E 7 z A q 5 M 6 z 8 6 b 8 7 4 c L T n F z j H 8 g v P x D T r o k c c = < / l a t e x i t > aT Target Entity 

 STEP t-1 STEP T < l a t e x i t s h a 1 _ b a s e 6 4 = " z p 3 T u 8 R y N j 5 H U p After repeating for T times, we get the entity scores of each step a 1 , a 2 , ? ? ? , a T . Then we compute their weighted sum as the final output: x n v q T S Q k d Q Y 5 o = " > A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y B E 8 l U Q U P U n B i 8 c K 9 g P a U D a b T b t 2 s x t 2 J 0 I J / Q 9 e P C j i 1 f / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e m A p u 0 P O + n Z X V t f W N z d J W e X t n d 2 + / c n D Y M i r T l D W p E k p 3 Q m K Y 4 J I 1 k a N g n V Q z k o S C t c P R 7 d R v P z F t u J I P O E 5 Z k J C B 5 D G n B K 3 U 6 t F I o e l X q l 7 N m 8 F d J n 5 B q l C g 0 a 9 8 9 S J F s 4 R J p I I Y 0 / W 9 F I O c a O R U s E m 5 l x m W E j o i A 9 a 1 V J K E m S C f X T t x T 6 0 S u b H S t i S 6 M / X 3 R E 4 S Y 8 Z J a D s T g k O z 6 E 3 F / 7 x u h v F 1 k H O Z Z s g k n S + K M + G i c q e v u x H X j K I Y W 0 K o 5 v Z W l w 6 J J h R t Q G U b g r / 4 8 j J p n d f 8 y 5 p 3 f 1 G t 3 x R x l O A Y T u A M f L i C O t x B A 5 p A 4 R G e 4 R X c = Softmax(MLP(q)), a * = T t=1 c t a t , (5) where c ? [0, 1] T denotes the probability distribution of the question's hop, and c t is the probability value of hop t. We can answer all questions from 1-hop to T -hop by automatically determine its hop number. The entity with maximum score in a * is outputed as the answer. TransferNet is a highly-transparent model. As shown in the example of Figure  2 , we can easily track the model behaviour by visualizing the activated words, relations, and entities at each step (see Sec.5.4 for more examples). 

 Training Given the golden answer set Y = {e y 1 , ? ? ? , e y |Y | }, we construct the target score vector y ? {0, 1} n by y i = 1, if e i ? Y, 0, else. ( 6 ) Then we take the L2 Euclidean distance between a * and y as our training objective: L = a * ? y . ( 7 ) Note that TransferNet is totally differentiable, therefore we can learn all of the intermediate scores (i.e., question attention, relation scores, and entity scores of each step) via this simple objective.. 

 Additional Modules We propose two modules to facilitate the learning of TransferNet. Score Truncation. According to Equation 4, a t j may exceed 1 after a transfer step. A too large score will have a bad influence to the gradient computation. Especially when the hop increases, it may lead to gradient explosion. Besides, our loss function, Equation  7 , will fail if the final score has an unlimited value. So we need to rectify the entity scores after each transfer step, to ensure the value range is in [0, 1]. At the same time, we need to maintain the differentiability of the operation. We propose such a truncation function: Trunc(a) = a/z(a), z(a) = a.detach(), if a > 1, 1, if a ? 1. (8) After each transfer step, we truncate a t by applying this function to each of its elements. Language Mask. TranferNet does not consider the language bias of the question, which may include some hints for its answer. For example, in the textformed relation graph we may have (Harry Potter, <sub> was published in <obj>, United Kingdom) and (Harry Potter, <sub> was published in <obj>, 1997). These two triples depict different aspects (i.e., the publication place and the publication time of Harry Potter) but with the same relation text. As a result, given the question Where was Harry Potter published, TransferNet will produce the same scores for United Kingdom and 1997, and thus use 1997 to wrongly answer the Where-question. To solve this issue, we propose a language mask to incorporate the question hints. We predict a mask score for each entity using the question embedding: m = Sigmoid(MLP(q)), (9) where m ? [0, 1] n , m i denotes the mask score of entity e i , MLP (short for multi-layer perceptron) projects d-dimensional feature to n-dimension. We multiply the mask to the final entity scores, ? * = m a * , (10) where means element-wise multiplication. The a * in the objective function Equation  7 should be replaced with ? * . Note that we need the language mask only in the text form, because the predicates of label form have no ambiguity. 

 Relation Score Computation Consider Equation 2, W t = g(q t ; ? g ), we design different implementations of g for different relation forms. 

 Label Form In the label form, relations are represented with a fixed predicate set P. We first compute probabilities for these predicates in terms of q t , and then collect corresponding probabilities of r i,j as W t i,j . Formally, the predicate distribution is computed by p t = Softmax(MLP(q t )). The Softmax function can be replaced with Sigmoid if predicates are not mutually exclusive, i.e., multiple predicates will be activated meanwhile. Let b denote the maximum number of relations between a pair of entity, then we can denote the relation as r i,j = {r i,j,1 , ? ? ? , r i,j,b }, where r i,j,k ? {1, 2, ? ? ? , |P|}. The predicate probabilities are collected in terms of the relation labels: W t i,j = b k=1 p t r i,j,k . (12) We gather the probabilities by summing them up. max is another feasible option, but we find is more efficient and more stable. 

 Text Form In the text form, relations are represented with natural language descriptions. The graph is built by extracting the co-occuring sentence of a pair of entity and replacing the entities with special placeholders. For example, the sentence Bill Gates and Melinda Gates have been married for 26 years contributes an edge from Bill Gates to Melinda Gates, whose relation text is <sub> and <obj> have been married for 26 years, as shown in Figure  2 . We can get the reverse relations by exchanging the placeholders of subject and object, but for simplicity, we do not show them in the figure. Let r i,j = {r i,j,1 , ? ? ? , r i,j,b } and r i,j,k denotes the k-th relation sentence. We use a relation encoder to obtain the relation embeddings, and then compute the relation score by r i,j,k = Encoder(r i,j,k ; ? r ), p t r i,j,k = Sigmoid(MLP(r i,j,k q t )), W t i,j = b k=1 p t r i,j,k , (13) where means element-wise product, MLP maps the feature from d-dimensional to 1-dimensional. Since there are a huge amount of (usually millions of) relation texts in a relation graph, it is impossible to compute the embeddings and scores for all of them. So in practice, we select a subset of relations at each step. Specifically, at step t, we select entities whose previous score a t?1 i is larger than a predefined threshold ? and only consider relations that start from these entities. Besides, if there are too many relations meeting this condition, we will only preserve top ? of them, sorting based on their subject entity score. By doing so, we just need to consider at most ? relations at each step. We use the same method to process the mixed form, by simply regarding the label predicates as one-word sentences. 

 Experiments 

 Datasets MetaQA  (Zhang et al., 2017 ) is a largescale dataset of multi-hop question answering over knowledge graph, which extends Wiki-Movies  (Miller et al., 2016)  from single-hop to multi-hop. It contains more than 400k questions, which are generated using dozens of templates and have up to 3 hops. Its knowledge graph is from the movie domain, including 43k entities, 9 predicates, and 135k triples. Besides the label from, we also constructed the text form of MetaQA by extracting the text corpus of WikiMovies  (Miller et al., 2016) , which introduces the information of movies with free text. Following , we used exact match of surface forms for entity recognition and linking. Given an article of a movie, we took the movie as subject and the other relavant entities (e.g., mentioned actor, year, and etc) as objects. The sentence was processed with placeholders, that is, replacing the movie with <sub> (if it occurs) and the object entity with <obj>, and then regarded as the relation texts. An entity pair can have multiple textual relations.  WebQSP (Yih et al., 2016)  has a smaller scale of questions but larger scale of knowledge graph. It contains thousands of natural language questions based on Freebase  (Bollacker et al., 2008) , which has millions of entities and triples. Its questions are either 1-hop or 2-hop. Following  (Saxena et al., 2020) , we pruned the knowledge base to contain only mentioned predicates and within 2-hop triples of mentioned entities. As a result, the processed knowledge graph includes 1.8 million entities, 572 predicates, and 5.7 million triples. We only consider the label form of WebQSP due to its huge scale. CompWebQ  (Talmor and Berant, 2018)  is an extended version of WebQSP with more hops and constraints. Following , we retrieved a subgraph for each question using PageRank algorithm. On average, there are 1948 entities in each subgraph and the recall is 64%.  

 Baselines KVMemNN  (Miller et al., 2016)  uses the keyvalue memory to store knowledge and conducts multi-hop reasoning by iteratively reading the memory. VRN  (Zhang et al., 2017)  learns the reasoning path via reinforcement learning. Its intermediate results have a good interpretability. SRN  (Qiu et al., 2020)  improves VRN by beam search and reward shaping strategy, boosting its speed and performance. GraftNet  (Sun et al., 2018)  extracts a questionspecific subgraph from the entire relation graph with heuristics, and then uses graph neural networks to infer the answer. PullNet  improves GraftNet by learning to retrieve the subgraph with a graph CNN instead of heuristics. ReifKB  (Cohen et al., 2020)  proposes a scalable implementation of probability transfer over largescale knowledge graph of label form. It can be regarded as a degenerated case of TransferNet. EmbedKGQA  (Saxena et al., 2020)  takes KGQA as a link prediction task and incorporates knowledge graph embeddings  (Bordes et al., 2013; Trouillon et al., 2016)  to help predict the answer. 

 Implementations We added reversed relations into the relation graph, leading to double size of predicates and triples. For the text form, we exchanged the placeholder <sub> and <obj> as the reversed relation, e.g., <sub> co-founded the <obj> is converted to <obj> cofounded the <sub>. For the experiments of MetaQA, we set the step number T = 3. We used bi-directional GRU  (Chung et al., 2014)  as the question encoder, and set the hidden dimension as 1024. The projecting function f t was a stack of linear layer and Tanh layer. The involved MLPs were implemented as simple linear layers. For the text form, we used another bi-directional GRU as the relation encoder. The threshold ? was set to 0.7 and ? was set to 400. Since the question hop is provided in MetaQA, we used the golden hop number as an auxiliary objective to help learn the hop distribution c. We computed the cross entropy loss and added it into Equation 7 after multiplying a factor of 0.01. The model was optimized using RAdam  (Liu et al., 2020)  with a learning rate 0.001 for 20 epochs, which took several hours for the label form and about one day for the text form on a single GPU of NVIDIA 1080Ti. For the experiments of WebQSP and Comp-WebQ, we set the step number T = 2. We used a pretrained BERT  (Devlin et al., 2018)  as the question encoder and finetuned its parameters on our task. There is no hop annotations so we did not use the auxiliary loss. Other settings are the same as MetaQA. 

 Model MetaQA WebQSP CompWebQ 1-hop 2-hop 3-hop KVMemNN  (Miller et al., 2016)  95.8 25.1 10.1 46.7 21.1 VRN  (Zhang et al., 2017)  97.5 89.9 62.5 --GraftNet  (Sun et al., 2018)  97.0 94.8 77.7 66.4 32.8 PullNet  97.0 99.9 91.4 68.1 47.2 SRN  (Qiu et al., 2020)  97 Table  3 : Hits@1 results on MetaQA of the text form and mixed form.  

 Results 

 Results on Label-Formed Graph 

 Results on Text-Formed Graph In Table  2   Besides the pure text form, we also compare the mixed form following  (Sun et al., 2018 . That is, randomly selecting 50% of the label-formed triples and add them into the text-formed relation graph. In this setting, we simply consider the predicates as sentences containing just one word, and use the relation encoder (see Sec.3.5.2) to process them. These 50% labels slightly improve the performance of TransferNet over the pure text form (about 0.4%), because some relations are missing in the text corpus. Compared with PullNet, Trans-ferNet is still in the lead by a large gap (85.2% v.s. 94.7%). Step 0 topic entity Step 1 Step 2 Step 3 answer entity who acted in the movies directed by the director of Some Mother's Son Table  4 : Ablation study on MetaQA. We show the average hits@1 of different hops. 

 Ablation Study Table  4  shows results of ablation study. We can see that the score truncation and language mask are both important, especially for the text form. As stated in Sec. 3.4, the language mask is not needed in the label form. The auxiliary loss (see Sec. 4.3) slightly improves the performance because it helps the learning of hop attention. 

 Interpretability We visualize the intermediate results of Transfer-Net for two 3-hop questions in Figure  3 . The entities and relations whose score is larger than 0.8 are highlighted in red. The top question is aimed at the label-formed relation graph. The activated predicates for three hops are directed_by, directed_by_rev, and starred_actors respectively, where the suffix _rev means reverse relation. The bottom question is aimed at the text form. At step 1, TransferNet tries to find the screenwriter of the topic movie, and activates the relation whose tex-tual description is "based on the novel of the same name by <obj>". At step 2, the movie written by Harold Bell Wright is found. At step 3, we aim to find the movie's release year. But since the text descriptions of Western (which is the movie's genre) and 1926 are very similar, both of these two entities are activated. Here the proposed language mask successfully filters the wrong answers out. Figure  4  shows the average hits@1 on the label form of MetaQA when the models are trained with partial training examples (left) and at different epochs (right). We can see that TransferNet is very data-efficient and converges very fast. With only 10% training data, it still achieves the same performance as the entire training set. And it only needs two epochs to reach the optimal results. 

 Model Efficiency 

 Conclusions We proposed TransferNet, an effective and transparent framework for multi-hop QA over knowledge graph or text-formed relation graph. It achieved 100% accuracy on 2-hop and 3-hop questions of label-formed MetaQA, nearly solving the dataset. On the more challenging WebQSP, CompWebQ and text-formed MetaQA, it also outperforms other state-of-the-art models significantly. Qualitative analysis shows the good interpretability of Trans-ferNet. g o J n e I U 3 5 8 l 5 c d 6 d j / l o y S l 2 D u E P n M 8 f 0 G + S r w = = < / l a t e x i t > a0 < l a t e x i t s h a 1 _ b a s e 6 4 = " L e e B p V Z 

 Figure 2 : 2 Figure 2: The framework of TransferNet (top) and example of reasoning process (bottom). 

 Figure 4 : 4 Figure 4: Comparison of data efficiency (left) and convergency speed (right) on label-formed MetaQA. 

 Table 1 : 1 Table 1 lists the statistics of these datasets. Dataset statistics. Dataset Train Dev Test MetaQA 1-hop 96,106 9,992 9,947 MetaQA 2-hop 118,948 14,872 14,872 MetaQA 3-hop 114,196 14,274 14,274 WebQSP 2,998 100 1,639 CompWebQ 27,623 3,518 3,531 

 Table 2 : 2 Hits@1 results of the label-formed datasets. TransferNet achieves 100% accuracy in the 2-hop and 3-hop questions of MetaQA. On WebQSP and CompWebQ it also outperforms baseline models by a large margin. .0 95.1 75.2 - - ReifKB (Cohen et al., 2020) 96.2 81.1 72.3 52.7 - EmbedKGQA (Saxena et al., 2020) 97.5 98.8 94.8 66.6 - TransferNet (Ours) 97.5 100 100 71.4 48.6 Model MetaQA Text 1-hop 2-hop 3-hop 1-hop 2-hop MetaQA Text + 50% Label 3-hop KVMemNN (Miller et al., 2016) 75.4 7.0 19.5 75.7 48.4 35.2 GraftNet (Sun et al., 2018) 82.5 36.2 40.2 91.5 69.5 66.4 PullNet (Sun et al., 2019) 84.4 81.0 78.2 92.4 90.4 85.2 TransferNet (Ours) 95.5 98.1 94.3 96.0 98.5 94.7 

 Table 2 2 results with Sun et al. (2019) on the dev set. Trans- ferNet achieves 48.6% accuracy, still better than PullNet (47.2%). compares different models on label-formed datasets. TransferNet performs perfectly in the 2-hop and 3-hop questions of MetaQA, that is, achieving 100% accuracy. As for the 1-hop ques- tions of MetaQA, TransferNet achieves 97.5%, on a par with previous models like VRN and Embed- KGQA. We analyze the wrong cases of 1-hop and find that the errors are caused by the ambiguity of entities. For example, the question who acted in The Last of the Mohicans asks the actors of the movie The Last of the Mohicans. In the knowledge graph there are two movies with this name, one re- leased in 1936 and the other released in 1920. Our model outputs the actors of both movies, whereas the MetaQA dataset only considers the actors of the 1920 one as golden answer, causing an inevitable mismatch. Previous work's performance should also suffer from this dataset fault. In the ques- tions of 2-hop and 3-hop, the ambiguity is mostly eliminated by the relation restrictions. Therefore, TransferNet can achieve 100% accuracy. We can say that the label-formed MetaQA dataset has been nearly solved by our TransferNet. WebQSP is more challenging than MetaQA, be- cause it has a much more predicates and triples yet much less training examples. TransferNet achieves 71.4% accuracy, beating previous state-of-the-art models (68.1%) by a large margin, implying that it is well qualified for large-scale knowledge base. On the CompWebQ dataset, we compare the 

 ub > is a <o bj> Am er ica n W es ter n sil en t film dir ec ted by He nr y Ki ng 1926 the films that share screenwriters with The Shepherd of the Hills were released in which years Figure 3: Reasoning process of 3-hop questions. The top is in label form, where the suffix "_rev" means reverse relation. The bottom is in text form, where "mask" in blue means the language mask. We show the relation scores in purple and highlight the activated entities and relations (score > 0.8) and words (score > 0.05) in red. Jim Sheridan A Bright Shining Lie Bill Paxton Some Mother's Son directed_by wr itt en _b y 0.01 0.99 Terry George d ir e ct e d _ b y_ re v directed_by_rev 1.00 Reservation Road 1.00 starred_actors rele ase _ye ar starred_actors 1998 Joaquin Phoenix 1.00 0.00 1.00 written_by st ar re d_ ac to rs 0.01 0.00 Helen Mirren di re ct ed _b y_ re v Hotel Rwanda 1.00 starred_actors ha s_ ge nre 1.00 0.00 Don Cheadle Drama Question who acted in the movies directed by the director of Some Mother's Son who acted in the movies directed by the director of Some Mother's Son John Wayne Track of the Cat Western The Shepherd of the Hills based on the novel of the same name by <obj> <s ub > is a 19 41 Am er ica n dr am a film sta rri ng <o bj> <s ub > is a <o bj> Am er ica n dr am a film Harold Bell Wright 1941 <obj> is a <sub> twelve-chapter Republic Pictures film serial 0.01 based on the novel ''<obj>'' by <sub>, the film is about an <obj> was produced by <sub> and Robert Fellows 0.03 0.99 engineer The Winning of Barbara Worth Adventures of 0.02 Captain Marvel <s ub > is a 19 26 Am er ica n <o bj> sil en t 0.01 0.93 film dir ec ted by He nr y Ki ng 0.94 0.94 mask: 0 mask: 1 Question the films that share screenwriters with The Shepherd of the Hills were the films that share screenwriters with The Shepherd of the Hills were released in which years released in which years Label Form Text Form TransferNet 99.4 95.8 w/o score truncation 94.7 75.3 w/o language mask - 62.1 w/o auxiliary loss 98.6 94.7 <s 

			 https://github.com/shijx12/TransferNet
