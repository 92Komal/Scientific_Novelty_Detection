title
Generating Sports News from Live Commentary: A Chinese Dataset for Sports Game Summarization

abstract
Sports game summarization focuses on generating news articles from live commentaries. Unlike traditional summarization tasks, the source documents and the target summaries for sports game summarization tasks are written in quite different writing styles. In addition, live commentaries usually contain many named entities, which makes summarizing sports games precisely very challenging. To deeply study this task, we present SPORTSSUM 1 , a Chinese sports game summarization dataset which contains 5,428 soccer games of live commentaries and the corresponding news articles. Additionally, we propose a two-step summarization model consisting of a selector and a rewriter for SPORTSSUM. To evaluate the correctness of generated sports summaries, we design two novel score metrics: name matching score and event matching score. Experimental results show that our model performs better than other summarization baselines on ROUGE scores as well as the two designed scores.

Introduction There are a large number of sports games playing every day. Apparently, manually writing sports news articles to summarize every game is laborintensive and infeasible. How to automatically generate sports summaries, therefore, becomes a popular and demanding task. Recently, generating news from live commentaries has gradually attracted attention in the academic community  (Zhang et al., 2016; Yao et al., 2017) . At the same time, several trials have been done in the industry such as sports news from Toutiao's Xiaoming Bot 2 , Sohu Ruibao 3 and AI football news 4 . The ball flew into the goal through the lower right corner. The ball went in! Muller gave the assist. Bayern Munich 1-0 Dortmund. 

 71' 1-0 ? ?,?.?. Bayern Munich's player Ribery tried to shoot with his right foot from the penalty area's left side, but the ball was higher than the crossbar. Lahm passed the ball to him. 

 Sports News Ariticle ?3? ?8? ?12?13? ?27?(...) In the 3rd minutes, Kroos's free kick on the left was tipped to the back, and Ribery's shot from the penalty area missed. In the 8th minute, Muller and Mandzukic had teamwork, and Muller's shot from the 12 meters ahead the goal line was touched out by Suboti?. In the 13th minute, Ribery passed the ball from the right, and Kroos's shot near the 27 meters ahead the goal line missed. (...) Table  1 : An example of SPORTSSUM dataset. Unlike traditional text summarization tasks  (Hermann et al., 2015; Rush et al., 2015) , the source documents and the target summaries for sports game summarization tasks are written in quite different styles. Live commentaries are the real-time transcripts of the commentators. Accordingly, commentary sentences are more colloquial and informal. In contrast, news summaries are usually more narrative and well-organized since they are written after the games. In addition, commentaries contain a large number of player names. One player can be referred to multiple times in the whole game, and one commentary sentence may mention multiple player names simultaneously. Those properties make sports games summarization tasks very challenging. In this paper, we present SPORTSSUM, a Chinese dataset for studying sports game summarization tasks. We collect 5,428 pairs of live commentaries and news articles from seven famous soccer leagues. To the best of our knowledge, SPORTSSUM is the largest Chinese sports game summarization dataset. In addition, we propose a two-step summarization model for SPORTSSUM, which learns a selector to extract important commentary sentences and trains a rewriter to convert the selected sentences to a news article. To encourage the model to capture the relations between players and actions better, we replace all the player names in the training sentences with a special token and train the proposed model on the modified template-like sentences. The proposed model performs better than existing extractive and abstractive summarization baseline models in ROUGE scores  (Lin, 2004) . However, we observe that ROUGE scores cannot evaluate the correctness of generated summaries very well. Therefore, we design two new scores, name matching score and event matching score, as the auxiliary metrics for SPORTSSUM. Our experimental results demonstrate that the proposed model is superior to the baseline models in all the metrics. Summarizing documents between two articles written in different styles and involving many named entities is not limited to the sports game summarization tasks. There are many possible applications, such as summarizing events from tweets and summarizing trends from forum comments. We hope that SPORTSSUM provides a potential research platform to develop advanced techniques for this type of summarization tasks. 

 Dataset We present SPORTSSUM, a sports game summarization dataset in Chinese. Data collection. We crawl the records of soccer games from Sina Sports Live 5 . The collected records contain soccer games in seven different leagues (Bundesliga, CSL, Europa, La Liga, Ligue 1, PL, Series A, UCL) from 2012 to 2018. For each game, we have a live commentary document C and a news article R, as illustrated in  sists of a series of tuples (t i , s i , c i ), where t i is the timeline information, s i represents the current scores, and c i denotes the commentary sentence. The news article R consists of several news sentences r i . In addition to commentaries and news reports, we also include some metadata, such as rosters, starting lineups, and player positions, which is potentially helpful for sports game summarization tasks. Data cleaning. The crawled live commentary documents and news articles are quite noisy. Therefore, we apply multiple steps of data cleaning to improve the quality of the dataset. We first remove all the HTML tags from the commentary documents and the news articles. Then, we observe that there are usually some descriptions that cannot be directly inferred from the commentaries at the beginning of news articles, such as matching history. Hence, we design a heuristic rule to remove those descriptions. We identify several starting keywords which can indicate the start of a game, such as "? ?(at the beginning of the game)" and "? ?(after the game started)". The full list of starting keywords can be found in Appendix A. Once we see a starting keyword appearing in a news report, we remove all the sentences before the starting keyword. Finally, we discard those games with the number of news sentences being less than 5 and the number of commentary sentences being less than 20. After data cleaning, we have 5,428 games remaining (detailed numbers of games are shown in Table  2 ). Notice that SPORTSSUM (5,428 games) is much larger than the only public sports game summariza-tion dataset (150 games)  (Zhang et al., 2016) . Statistics and properties. Table  3  shows the statistics of SPORTSSUM. On average, there are 193.77 sentences per commentary document and 23.80 sentences per news article. After applying word segmentation by pyltp tool 6 , the average numbers of words for commentary documents and news reports are 1825.63 and 427.98, respectively. As mentioned in Section 1, commentary sentences and news sentences are in quite different writing styles. Commentary sentences are more colloquial and informal, while news sentences are more narrative and well-organized. Also, commentaries contain a large number of player names, which makes the model easy to generate news reports with incorrect facts, as shown in Section 3. 

 Sports Game Summarization The goal of sports game summarization is to generate a sports news report R = {r 1 , r2 , .., rn } from a given live commentary document C = {(t 1 , s 1 , c 1 ), ..., (t m , s m , c m )}. The generated news report R is expected to cover most of the important events in the games and describe those events correctly. In this paper, we propose a twostep model for SPORTSSUM. The proposed model first learns a selector to extract important commentary sentences and then utilizes a rewriter to convert the selected sentences to a news article. Sentence mapping. To train the selector and rewriter, we need some labels to indicate the importance of commentary sentences and the corresponding news sentences. To obtain the labels, we consider the timeline information and BERTScore  (Zhang et al., 2020) , a metric to measure the sentence similarity, and map each news sentence to a commentary sentence. Although we have no explicit timeline information for news sentences, we observe that many news sentences start with "in the n-th minute" and thus we can extract the timeline information for some news sentences. We map sentences by the following steps: 1) For each news sentence r i , we extract the timeline information h i if possible. Otherwise, we do not map this news sentence. 2) We consider those commentary sentences c j with t j being close to h i . More specifically, we consider C (i) = {c k , c k+1 , ...c k+l }, where c j is the commentary sentence with timeline information t j ? [h i , h i +3] 6 https://github.com/HIT-SCIR/pyltp for k ? j ? k + l. 3) We compute BERTScore of the news sentence r i and all the commentary sentences in C  (i)  . The commentary sentence c j ? C  (i)  with the highest score is considered to be mapped with the news sentences r i . With the above mapping process, we obtain a set of mapped commentary sentences and news sentences D = {(c 1 , r1 ), (c 2 , r2 ), ..., (c s , rs )}, which can be used for training our selector and rewriter. Selector. There are many commentary sentences in a live commentary document, but only few of them contain valuable information and should be reported in the news article. Therefore, we learn a selector to pick up those important sentences. More specifically, Given a commentary document C = {(t 1 , s 1 , c 1 ), ..., (t m , s m , c m )}, the selector outputs a set C select = {c 1 , c2 , ..., cn } which contains only important commentary sentences. We train a binary classifier as the selector to choose important commentary sentences. When training, for each commentary sentence c i in C, we assign a positive label if c i can be mapped with a news sentence by the aforementioned mapping process. Otherwise, we give a negative label. Rewriter. The rewriter converts the selected commentary sentences C select = {c 1 , c2 , ..., cn } to a news report R = {r 1 , r2 , .., rn }. We focus on the sentence-level rewriter. That is, we convert each selected commentary sentence ci to a news sentence ri . An intuitive way to learn the sentencelevel rewriter is training a sequence-to-sequence (seq2seq) model, such as LSTM  (Hochreiter and Schmidhuber, 1997)  and Transformer  (Vaswani et al., 2017) , on the mapped sentences D. However, as illustrated in Table  4 , we observe that the seq2seq model tends to generate high-frequency player names rather than the correct player names even though the high-frequency player names do not appear in the commentary sentences. We call this situation name mismatch problem. To solve the name mismatch problem, we train the rewriter in a template-to-template (tem2tem) way instead of in a seq2seq way. We first build a dictionary of player names from the lineup data (metadata). Next, for each (c i , ri ) in D, we replace all the player names in ci and ri with a special token "[player]" so that the new sentence is like a template. If there are multiple player names in a sentence, we append a number to the special token to distinguish them, as shown in Table  5 . 

 Live Commentary Sentence ? ? ? ? ? ? ?,?.? ? ? ? ?. Ribery tried to shoot with his right foot from the left side of the penalty area, but the ball was higher than the crossbar. Lahm passed the ball to him. 

 Gound Truth News Sentence ? ? ? ? ? ? ? ? ? ? ?12? Lahm passed the ball to the left, and Ribery cut in the left penalty area and shot from 12 meters ahead the goal line. The shot was too high. 

 News Sentence Generated by Seq2seq Model ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Ribery passed the ball and Mandzukic's shot from the left side of the penalty area was out of the goalpost. Lahm made a low pass on the right and Ribery's shot from the front was blocked by Adler.  After converting ci and ri to the template sentences, we train a seq2seq model on the template sentences. By training models in a tem2tem way, the model focuses more on the relations between players and actions and is less influenced by the high-frequency player names. Tem2tem ? ?!!![player1] ? ? ? ? ? ? ? ? ?[player2] ?. ?[player3]. [player3] ? ? ? ? ?[player1]? ? ? ? ?[player2]? Shoot!!! [player1]'s right When predicting, for each commentary sentence ci in C select , we use the aforementioned way to convert ci to a commentary template sentence. Then, we generate a news template sentence by the rewriter and replace all the special tokens in the sentence with the original player names. 

 Experiments SPORTSSUM contains 5,428 games and we split them into three sets: training (4,828 games), validation (300 games), and testing (300 games) sets. Evaluation. We consider ROUGE scores  (Lin, 2004) , which are standard metrics for summarization tasks. More precisely, we focus on ROUGE-1, ROUGE-2, and ROUGE-L. However, we observe that ROUGE scores cannot accurately evaluate the correctness of summaries. Some summaries may get high ROUGE scores but contain many incorrect facts. Therefore, we design two metrics: name matching score (NMS) and event matching score (EMS). The name matching score evaluates the closeness of the player names in the ground truth news article R and the generated summaries R. Let N g and N p denote the set of the player names appearing in R and R, respectively. We define the name matching score as NMS(R, R) = F-score(N g , N p ). Similarly, the event matching score evaluates the closeness of the events in R and R. We define an event as a pair (subject, verb) in the sentence. Two pairs (subject 1 , verb 1 ) and (subject 2 , verb 2 ) are viewed as equivalent if and only if 1) subject 1 is the same as subject 2 and 2) verb 1 and verb 2 are synonym 7 to each other. Let E g and E p represent the set of events in R and R, respectively, the event matching score is defined as EMS(R, R) = F-score(E g , E p ). Implementations and Models. We consider the convolutional neural network  (Kim, 2014)  as the selector. For the rewriter, we consider the following: (1) LSTM: a bidirectional LSTM with attention mechanism  (Bahdanau et al., 2015) . (2) Transformer.  (Vaswani et al., 2017)  (3) PGNet: pointergenerator network, an encoder-decoder model with copy mechanism  (See et al., 2017) . For comparison, we consider two extractive summarization baselines: (1) RawSent: the raw sentences selected by the selector without rewriting. (2) LTR: the learning-to-rank approach for sports game summarization proposed by the previous work  (Zhang et al., 2016) . In addition, we train a bidirectional LSTM with attention mechanism (Abs-LSTM) and a pointergenerator network (Abs-PGNet) on the paired commentaries and news articles as two simple abstractive summarization baselines. More implementation details can be found in Appendix C. Results. Table  6  shows the experimental results. We observe that the extractive models (RawSent and LTR) get low ROUGE scores but high NMS and EMS. That means the extractive models can generate summaries with correct information, but the writing style is different from the ground truth. On the contrary, the abstractive models get higher ROUGE scores but lower NMS and EMS. That implies the summaries generated by the abstractive models usually contain incorrect facts. Our proposed two-step model performs better than the extractive models and the abstractive models on ROUGE scores, NMS, and EMS. This verifies our design of the selector and the rewriter. In addition, we observe that when training the model in a tem2tem way, we can get better NMS and EMS, which implies that training by tem2tem can improve the correctness of summaries. 

 Related Work Text summarization. Existing approaches can be grouped into two families: extractive models and abstractive models. Extractive models select a part of sentences from the source document as the summary. Traditional approaches  (Carbonell and Goldstein, 1998; Erkan and Radev, 2004; Mc-Donald, 2007)  utilize graph or optimization techniques. Recently, neural models achieve good performance  (Cheng and Lapata, 2016; Nallapati et al., 2017; Jadhav and Rajan, 2018) . Abstractive summarization models aim to rephrase the source document. Most work applies neural models for this task.  (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; Zeng et al., 2016; See et al., 2017; Gehrmann et al., 2018) . 

 Factual correctness of summaries. There is a lot of work focusing on evaluation and improvement of the factual correctness of summaries  (Falke et al., 2019; Kryscinski et al., 2019; Wang et al., 2020; Maynez et al., 2020; Zhu et al., 2020) .  

 Conclusion We present SPORTSSUM, a Chinese dataset for sports game summarization, as well as a model that consists of a selector and a rewriter. To improve the quality of generated news, we train the model in a tem2tem way. We design two metrics to evaluate the correctness of generated summaries. The experimental results demonstrate that the proposed model performs well on ROUGE scores and the two designed scores. 
