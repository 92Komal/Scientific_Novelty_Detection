title
Graph-based Neural Multi-Document Summarization

abstract
We propose a neural multi-document summarization (MDS) system that incorporates sentence relation graphs. We employ a Graph Convolutional Network (GCN) on the relation graphs, with sentence embeddings obtained from Recurrent Neural Networks as input node features. Through multiple layer-wise propagation, the GCN generates high-level hidden sentence features for salience estimation. We then use a greedy heuristic to extract salient sentences while avoiding redundancy. In our experiments on DUC 2004, we consider three types of sentence relation graphs and demonstrate the advantage of combining sentence relations in graphs with the representation power of deep neural networks. Our model improves upon traditional graph-based extractive approaches and the vanilla GRU sequence model with no graph, and it achieves competitive results against other state-of-the-art multidocument summarization systems.

Introduction Document summarization aims to produce fluent and coherent summaries covering salient information in the documents. Many previous summarization systems employ an extractive approach by identifying and concatenating the most salient text units (often whole sentences) in the document. Traditional extractive summarizers produce the summary in two steps: sentence ranking and sentence selection. First, they utilize humanengineered features such as sentence position and length  (Radev et al., 2004a) , word frequency and importance  (Nenkova et al., 2006; , among others, to rank sentence salience. Then, they select summary-worthy sentences using a range of algorithms, such as graph centrality  (Erkan and Radev, 2004) , constraint optimization via Integer Linear Programming  (Mc-Donald, 2007; Gillick and Favre, 2009; Li et al., 2013) , or Support Vector Regression  (Li et al., 2007)  algorithms. Optionally, sentence reordering  (Lapata, 2003; Barzilay et al., 2001)  can follow to improve coherence of the summary. Recently, thanks to their strong representation power, neural approaches have become popular in text summarization, especially in sentence compression  (Rush et al., 2015)  and single-document summarization  (Cheng and Lapata, 2016) . Despite their popularity, neural networks still have issues when dealing with multi-document summarization (MDS). In previous neural multi-document summarizers  (Cao et al., 2015 (Cao et al., , 2017 , all the sentences in the same document cluster are processed independently. Hence, the relationships between sentences and thus the relationships between different documents are ignored. However,  Christensen et al. (2013)  demonstrates the importance of considering discourse relations among sentences in multi-document summarization. This work proposes a multi-document summarization system that exploits the representational power of deep neural networks and the sentence relation information encoded in graph representations of document clusters. Specifically, we apply Graph Convolutional Networks (Kipf and Welling, 2017) on sentence relation graphs. First, we discuss three different techniques to produce sentence relation graphs, where nodes represent sentences in a cluster and edges capture the connections between sentences. Given a relation graph, our summarization model apples a Graph Convolutional Network (GCN), which takes in sentence embeddings from Recurrent Neural Networks as input node features. Through multiple layer-wise prop-agation, the GCN generates high-level hidden features for the sentences. We then obtain sentence salience estimations through a regression on top, and extract salient sentences in a greedy manner while avoiding redundancy. We evaluate our model on the DUC 2004 multidocument summarization (MDS) task. Our model shows a clear advantage over traditional graphbased extractive summarizers, as well as a baseline GRU model that does not use any graph, and achieves competitive results with other state-ofthe-art MDS systems. This work provides a new gateway to incorporating graph-based techniques into neural summarization. 

 Related Work 

 Graph-based MDS Graph-based MDS models have traditionally employed surface level  (Erkan and Radev, 2004; Mihalcea and Tarau, 2005; Wan and Yang, 2006)  or deep level  (Pardo et al., 2006; Antiqueira et al., 2009)  approaches based on topological features and the number of nodes  (Albert and Barab?si, 2002) . Efforts have been made to improve decision making of these systems by using discourse relationships between sentences  (Radev, 2000; Radev et al., 2001) .  Erkan and Radev (2004)  introduce LexRank to compute sentence importance based on the eigenvector centrality in the connectivity graph of inter-sentence cosine similarity.  Mei et al. (2010)  propose DivRank to balance the prestige and diversity of the top ranked vertices in information networks and achieve improved results on MDS.  Christensen et al. (2013)  build multi-document graphs to identify pairwise ordering constraints over the sentences by accounting for discourse relationships between sentences  (Mann and Thompson, 1988) . In our work, we build on the Approximate Discourse Graph (ADG) model  (Christensen et al., 2013)  and account for macro level features in sentences to improve sentence salience prediction. 

 Summarization Using Neural Networks Neural networks have recently been popular for text summarization  (K?geb?ck et al., 2014; Rush et al., 2015; Yin and Pei, 2015; Cao et al., 2016; Wang and Ling, 2016; Cheng and Lapata, 2016; Nallapati et al., 2016 Nallapati et al., , 2017 See et al., 2017) . For example,  Rush et al. (2015)  introduce a neural attention feed-forward network-based model for sentence compression.  Wang and Ling (2016)  employ encoder-decoder RNNs to effectively produce short abstractive summaries for opinions.  Cao et al. (2016)  develop a query-focused summarization system called AttSum which deals with saliency ranking and relevance ranking using query-attention-weighted CNNs. Very recently, thanks to the large scale news article datasets  (Hermann et al., 2015) ,  Cheng and Lapata (2016)  train an extractive summarization system with attention-based encoder-decoder RNNs to sequentially label summary-worth sentences in single documents.  See et al. (2017) , adopting an abstractive approach, augment the standard attention-based encoder-decoder RNNs with the ability to copy words from the source text via pointing and to keep track of what has been summarized. These models  (Cheng and Lapata, 2016; See et al., 2017)  achieve state-of-the-art performance on the DUC 2002 single-document summarization task. However, scaling up these RNN sequence-to-sequence approaches to the multidocument summarization task has not been successful, 1) due to the lack of large multi-document summarization datasets needed to train the computationally expensive sequence-to-sequence model, and 2) because of the inadequacy of RNNs to capture the complex discourse relations across multiple documents. Our multi-document summarization model resolves these issues 1) by breaking down the summarization task into salience estimation and sentence selection that do not require an expensive decoder architecture, and 2) by utilizing sentence relation graphs. 

 Method Given a document cluster, our method extracts sentences as a summary in two steps: sentence salience estimation and sentence selection. Figure  1  illustrates our architecture for sentence salience estimation. Given a document cluster, we first build a sentence relation graph, where interacting sentence nodes are connected by edges. For each sentence, we apply an RNN with Gated Recurrent Units (GRU sent )  Chung et al., 2014)  and extract the last hidden state as the sentence embedding. We then apply Graph Convolutional Networks (Kipf and Welling, 2017) on the sentence relation graph with the sentence embeddings as the input node features, to produce final sentence embeddings that reflect the graph representation. Thereafter, a second level GRU (GRU doc ) produces the entire cluster embedding Figure  1 : Illustration of our architecture for sentence salience estimation. In this example, there are two documents in the cluster and each document has two sentences. Sentences are processed by the GRU sent to get input sentence embeddings. The GCN takes the input sentence embeddings and the sentence relation graph, and outputs high-level hidden features for individual sentences. GRU doc produces the cluster embedding from the output sentence embeddings. The salience is estimated from the output sentence embeddings and the cluster embedding. w i : the word embedding for i-th word. h i : the hidden state of GRU at i-th step. by sequentially connecting the final sentence embeddings. We estimate the salience of each sentence from the final sentence embeddings and the cluster embedding. Finally, based on the estimated salience scores, we select sentences in a greedy way until reaching the length limit. 

 Graph Representation of Clusters To best evaluate the architecture, we consider three graph representation methods to model sentence relationships within clusters. First, as prior methods in representing document clusters often adhere to the standard of cosine similarity  (Erkan and Radev, 2004) , our initial baseline approach naturally used this representation. Specifically, we add an edge between two sentences if the tf-idf cosine similarity measure between them, using the bag-of-words model, is above a threshold of 0.2. Secondly, the G-Flow system  (Christensen et al., 2013)  utilizes discourse relationships between sentences to create its graph representations, known as Approximate Discourse Graph (ADG). The ADG constructs edges between sentences by counting discourse relation indicators such as deverbal noun references, event and entity continuations, discourse markers, and co-referent mentions. These features allow characterization of sentence relationships, rather than simply their similarity. While G-Flow's ADG provides many improvements from baseline graph representations, it suffers several disadvantages that diminish its ability to aid salience prediction when given to the neural network. Specifically, the ADG lacks much diversity in its assigned edge weights. Because the weights are discretely incremented, they are multiples of 0.5; many edge weights are 1.0. While the presence of an edge provides a remarkable amount of underlying knowledge on the discourse relationships, edge weights can further include information about the strength -and, similarly, importance -of these relationships. We hope to improve the edge weights by making them more diverse, while infusing more information in the weights themselves. In doing so, we contribute our Personalized Discourse Graph (PDG). To advance the ADG's performance in providing predictors for sentence salience, we apply a multiplicative effect to the ADG's edge weights via sentence personalization. A baseline sentence personalization score s(v), which can be viewed as weighting of sentences, is calculated for every sentence v to account for surface features in each sentence. These features, listed in Table  1 , are used as input for linear regression, as per  Christensen et al. (2013) . The regression is applied to each sentence to obtain the personalization score, s(v). Each edge weight in the original ADG is then transformed by this sentence personalization score and normalized over the total outgoing scores. That is, for directed edge (u, v) ? E, the weight is w P DG (u, v) = w ADG (u, v)s(v) u ?V w ADG (u , v)s(u ) (1) The inclusion of the sentence personalization scores allows the PDG to account for macro-level features in each sentence, augmenting information for salience estimation. To provide more clarity, we include a figure of the PDG in later sections. Although it may be possible to incorporate the sentence personalization features later into the salience estimation network, we chose to encode them in the PDG to improve the edge weight distribution of sentence relation graphs and to make our salience estimation architecture methodically consistent. Additionally, in order to maintain consistency between graph representations, following two modifications are made to the discourse graphs. First, the directed edges of both the ADG and PDG are made undirected by averaging the edges weights in both directions. Second, edge weights are rescaled to a maximum edge weight of 1 prior to being fed to the GCN. 

 Graph Convolutional Networks We apply Graph Convolutional Networks (GCN) from Kipf and Welling (2017) on top of the sentence relation graph. In this subsection, we explain in detail the formulation of GCN, and how GCN produces the final sentence embeddings. The goal of GCN is to learn a function f (X, A) that takes as input: ? A ? R N ?N , the adjacency matrix of graph G, where N is the number of nodes in G. ? X ? R N ?D , the input node feature matrix, where D is the dimension of input node feature vectors. and outputs high-level hidden features for each node, Z ? R N ?F , that encapsulate the graph structure. F is the dimension of output feature vectors. The function f (X, A) takes a form of layer-wise propagation based on neural networks. We compute the activation matrix in the (l + 1) th layer as H (l+1) , starting from H 0 = X. The out- put of L-layer GCN is Z = f (X, A) = H (L) . To introduce the formulation, consider a simple form of layer-wise propagation: H (l+1) = ? AH (l) W (l) (2) where ? is an activation function such as ReLU(?) = max(0, ?). W  (l)  is the parameter to learn in the l th layer. Eq 2 has two limitations. First, multiplying by A means that for each node, we sum up the feature vectors of all neighboring nodes but not the node itself. We fix this by adding self-loops in the graph. Second, since A is not normalized, multiplying by A will change the scale of feature vectors. To overcome this, we apply a symmetric normalization by using D ? 1 2 AD ? 1 2 where D is the node degree matrix. These two renormalization tricks result in the following propagation rule: H (l+1) = ? D? 1 2 ? D? 1 2 H (l) W (l) (3) where ? = A + I N is the adjacency matrix of the graph G with added self-loops (I N is the identity matrix). D is the degree matrix with Dii = j ?ij . Kipf and Welling (2017) also provide a theoretical justification of Eq 3 as a first-order approximation of spectral graph convolution  (Hammond et al., 2011; Defferrard et al., 2016) . As an example, if we have a two-layer GCN, we first calculate ? = D? 1 2 ? D? 1 2 in a preprocessing step, and then produce Z = f (X, A) = ? ? ? ?XW (0) W (1) 

 Sentence Embeddings As the input node features X of GCN, we use sentence embeddings calculated by GRU sent . Given a document cluster C with N sentences (s 1 , s 2 , ..., s N ) in total, for each sentence s i of L words (w 1 , w 2 , ..., w L ), GRU sent recurrently updates hidden states at each time step t: h sent t = GRU sent (h sent t?1 , w t ) (4) where w t is the word embedding for w t , h sent t is the hidden state of GRU sent . h 0 is initialized as a zero vector, and the input sentence embedding x i is the last hidden state: x i = h sent L (5) All sentence embeddings from the given document cluster are grouped as the node feature matrix X: X = ? ? ? ? ? ? ? x T 1 x T 2 . . . x T N ? ? ? ? ? ? ? (6) X is fed into GCN subsequently to obtain the final sentence embeddings s i that incorporate the graph representation of sentence relationships: Z = f (X, A) = ? ? ? ? ? ? ? s T 1 s T 2 . . . s T N ? ? ? ? ? ? ? (7) 

 Cluster Embedding Additionally, in order to have a global view of the entire document cluster, we apply a secondlevel RNN, GRU doc , to encode the entire document cluster. Given a document cluster C with M documents (d 1 , d 2 , ..., d M ), for document d i with |d i | sentences, GRU doc first builds the document embedding d i on top of sentence embeddings: h doc t = GRU doc (h doc t?1 , s t ) (8) d i = h doc |d i | (9) where s t is the sentence embedding in the document d i . In Eq 9, we extract the last hidden state as the document embedding for d i . In Eq 10, we average over document embeddings to produce the cluster embedding C: C = 1 M M i=1 d i (10) All the GRUs we used are forward. We also experimented with backward GRUs and bi-directional GRUs, but neither of them meaningfully improved upon forward GRUs. 

 Salience Estimation For the sentence s i in the cluster C, we calculate the salience of s i as the following, similarly to the attention mechanism in neural machine translation  (Bahdanau et al., 2015) : f (s i ) = v T tanh(W 1 C + W 2 s i ) (11) salience(s i ) = f (s i ) s j ?C f (s j ) (12) where v, W 1 , W 2 are learnable parameters. In Eq 11, we first calculate the score f (s i ) by considering the sentence embedding itself, s i , and the cluster embedding C for the global context of the multi-document. The score is then normalized as salience(s i ) via softmax in Eq 12. 

 Training The model parameters include the parameters in GRU sent and GRU doc , the weights in GCN layers, and the parameters for salience estimation (v, W 1 , W 2 ). Parameters in GRU sent and GRU doc are not shared. The model is trained endto-end to minimize the following cross-entropy loss between the salience prediction and the normalized ROUGE score of each sentence: L = ? C s i ?C R(s i ) log(salience(s i )) (13) R(s i ) is calculated by R(s i ) = softmax(? r(s i )) , where r(s i ) is the average of ROUGE-1 and ROUGE-2 Recall scores of sentence s i by measuring with the ground-truth human-written summaries. ? is a constant rescaling factor to make the distribution sharper. The value of ? is determined from the validation data set. ?r(s i ) is then normalized across the cluster via softmax, similarly to Eq 12. 

 Sentence Selection Given the salience score estimation, we apply a simple greedy procedure to select sentences. Sentences with higher salience scores have higher priorities. First, we sort sentences in descending order of the salience scores. Then, we select one sentence from the top of the list and append to the summary if the sentence is of reasonable length (8-55 words, as in  (Erkan and Radev, 2004) ) and is not redundant. The sentence is redundant if the tfidf cosine similarity between the sentence and the current summary is above 0.5 . We select sentences this way until we reach the length limit. 

 Experiments In we further study the effect of graph and different graph representations on the summarization performance and investigate the correlation of graph structure and sentence salience estimation. 

 Data Set and Evaluation We use the benchmark data sets from the Document Understanding Conferences (DUC) containing clusters of English news articles and human reference summaries. Table  2  shows the statistics of the data sets. We use  DUC 2001 DUC , 2002 DUC , 2003 DUC and 2004 , 30 and 50 clusters of nearly 10 documents each respectively. Our model is trained on  DUC 2001 DUC and 2002 DUC , validated on 2003 DUC , and tested on 2004 . For evaluation, we use the ROUGE-1,2 metric, with stemming and stop words not removed as suggested by  Owczarzak et al. (2012) . 

 Experimental Setup We conduct four experiments on our model: three using each of the three types of graphs discussed earlier, and one without using any graph. In the experiments with graphs, for each document cluster, we tokenize all the documents into sentences and generate a graph representation of their relations by the three methods: Cosine Similarity Graph, Approximate Discourse Graph (ADG) from G-Flow, and our Personalized Discourse Graph (PDG). Note that for the Cosine Similarity Graph, we compute the tf-idf cosine similarity for every pair of sentences using the bag-of-word model and add an edge for similarity above 0.2. The weight of the edge is the value of similarity. We apply GCNs with the graphs in the final step of sentence encoding. For the experiment without any graph, we omit the GCN part and simply use the GRU sentence and cluster encoders. We use 300-dimensional pre-trained word2vec embeddings  (Mikolov et al., 2013)  as input to GRU sent in Eq 4. The word embeddings are finetuned during training. We use three GCN hidden Table  3 : ROUGE Recalls on DUC 2004. We show mean (and standard deviation for R-1) over 10 repeated trials for each of our experiments. layers (L = 3). The hidden states in GRU sent , GCN hidden layers, and GRU doc are all 300dimensional vectors (D = F = 300). The rescaling factor ? in the objective function (Eq 13) is chosen as 40 from {10, 20, 30, 40, 50, 100} based on the validation performance. The objective function is optimized using Adam  (Kingma and Ba, 2015)  stochastic gradient descent with a learning rate of 0.001 and a batch size of 1. We use gradient clipping with a maximum gradient norm of 1.0. The model is validated every 10 iterations, and the training is stopped early if the validation performance does not improve for 10 consecutive steps. We trained using a single Tesla K80 GPU. For all the experiments, the training took approximately 30 minutes until a stop. 

 Results Table  3  summarizes our results. First we take our simple GRU model as the baseline of the RNNbased regression approach. As seen from the table, the addition of Cosine Similarity Graph on top of the GRU clearly boosts the performance. Furthermore, the addition of ADG from G-Flow gives a slighly better performance. Our Personalized Discourse Graph (PDG) enhances the R-1 score by more than 1.50. The improvement indicates that the combination of graphs and GCNs processes sentence relations across documents better than the vanilla RNN sequence models. To gain a global view of our performance, we also compare our result with other baseline multi-document summarizers and the state-of-the- Table  4 : Training statistics for the four experiments. The first row shows the number of iterations the model took to reach the best validation result before an early stop. The train cost and validation cost at that time step are shown in the second row and third row, respectively. All the values are the average over 10 repeated trials. art systems related to our regression method. We compute ROUGE scores from the actual output summary of each system. We run the G-Flow code released by  Christensen et al. (2013)  to get the output summary of the G-Flow system. The output summary of other systems are compiled in . To ensure fair comparison, we use ROUGE-1.5.5 with the same parameters as in  across all methods: -n 2 -m -l 100 -x -c 95 -r 1000 -f A -p 0.5 -t 0. From Table  3 , we observe that our GCN system significantly outperforms the commonly used baselines and traditional graph approaches such as Centroid, LexRank, and G-Flow. This indicates the advantage of the representation power of neural networks used in our model. Our system also exceeds CLASSY04, the best peer system in DUC 2004, and Support Vector Regression (SVR), a widely used regression-based summarizer. We remain at a comparable level to Reg-Sum, the state-of-the-art multi-document summarizer using regression. The major difference is that RegSum performs regression on word level and estimates the salience of each word through a rich set of word features, such as frequency, grammar, context, and hand-crafted dictionaries. Reg-Sum then computes sentence salience based on the word scores. On the other hand, our model simply works on sentence level, spotlighting sentence relations encoded as a graph. Incorporating more word-level features into our discourse graphs may be an interesting future direction to explore. 

 Discussion As shown in Table  3 , our graph-based models outperform the vanilla GRU model, which has no graph. Additionally, for the three graphs we consider, PDG improves R-1 score by 0.82 over ADG, and ADG outperforms the Cosine Similar-  ity Graph by 0.08 on the R-1 score. While the Cosine Similarity Graph encodes general word-level connections between sentences, discourse graphs, especially our personalized version, specialize in representing the narrative and logical relations between sentences. Therefore, we hypothesize that the PDG provides a more informative guide to estimating the importance of each sentence. In an attempt to better understand the results and validate the effect of sentence relation graphs (especially of the PDG), we have conducted the analysis that follows. Training Statistics. We compare the learning curves of the four different settings: GRU without any graph, GRU+GCN with the Cosine Similarity Graph, GRU+GCN with ADG, and GRU+GCN with PDG (see Table  4  & Figure  2 ). Without a graph, the model converges faster and achieves lower training cost than the Cosine Similarity Graph and ADG. This is most likely due to the simplicity of the architecture, but it is also less generalizable, yielding a higher validation cost  than the models with graphs. For the three graph methods, ADG converges faster and has better validation performance than the Cosine Similarity Graph. PDG converges even faster than "No Graph" and achieves the lowest training cost and validation cost amongst all methods. This shows that the PDG has particularly strong representation power and generalizability. Graph Statistics. We also analyze the characteristics of the three graph representation methods on DUC 2004 document clusters. Table  5  summarizes the following basic statistics: the number of nodes (i.e. sentences), the number of edges, average edge weight, and average node degree per graph. We include the correlation between node degree and salience, as well. As seen from the table, PDG and ADG have approximately the same number of edges. This is expected since the PDG is built by transforming the edge weights in ADG. The Cosine Similarity Graph has slightly fewer edges, simply due to the implemented threshold. Moreover, note that the ADG has significantly higher average edge weight and node degree as compared to the PDG. These values reflect the discrete nature of the ADG's edge assignmentfurther evidence of this can be seen in Figure  3 . Because the ADG's raw edge weight assignment is done by increments of 0.5, the average node degree tends to be significantly large. This motivated the construction of our PDG, which corrects for this by coercing the average edge weight and node degree to be more diverse and, consequently, smaller (after rescaling). The process of including sentence personalization scores in edge weight assignments of the PDG leads to a select number of edges gaining markedly large distinction. This aids the GCN in identifying the most important edge connections along with the affili-ated sentences. Node Degree and Salience. In Table  5 , we also calculate the correlation coefficient ?, per graph, between the degree of each sentence node and its salience score. We observe that all the graph representations show positive correlation between the node degree and the salience score. Moreover, the order of correlation strength is PDG > ADG > Cosine Similarity Graph. Though node degree is a simple measure of these graphs, this observation supports our hypothesis on the efficacy of sentence relation graphs, particularly of PDGs, to provide a guide to salience estimation.  1  As a case study to illustrate our observation, we chose one cluster (d30011t) from DUC 2004. Figure  3  shows the scatter plots of the node degree and salience score of each sentence. Visualization of the PDG. Finally, to demonstrate the functionality of the PDG and complement our discussion from Section 3.1, we visualize the PDG on cluster d30011t with the salience score on each node in Figure  4  (also see Figure  5  for the actual sentences). From the visualization, it can be observed that the nodes representing salient sentences (such as (d 6 , s 8 ), (d 6 , s 7 ), and (d 2 , s 4 )) tend to have higher degrees in the PDG. We can also observe that the PDG represents edges which connect nodes of sentences from different documents, in contrast with the traditional sequence model. From Figure  5 , we note that the most salient sentence (d 6 , s 8 ) actually describes much of the reference summary. As an example of discourse relation, (d 6 , s 7 ) and (d 2 , s 4 ), the two nodes connected to (d 6 , s 8 ), provide the background for  (d 6 , s 8 ), even though they do not share many words in common with it. On the other hand, (d 0 , s 22 ), which is only connected with (d 2 , s 4 ), is not salient as it does not provide a central message for the summary. 

 Conclusion In this paper, we presented a novel multi-document summarization system that exploits the representational power of neural networks and graph representations of sentence relationships. On top of a simple GRU model as an RNN-based regression baseline, we build a Graph Convolutional Network (GCN) architecture applied on a Personalized Discourse Graph. Our model, unlike traditional RNN models, can capture sentence relations across documents and demonstrates improved salience prediction and summarization, achieving competitive performance with current state-of-the-art systems. Furthermore, through multiple analyses, we have validated the efficacy of sentence relation graphs, particularly of PDG, to help to learn the salience of sentences. This work shows the promise of the GCN models and of discourse graphs applied to processing multi-document inputs. Figure 1 :Figure 2 : 12 Figure 1: Learning curves of the four experiments based on the validation costs. Note that the vertical axis is only displaying the interval 4.0 -7.0. 
