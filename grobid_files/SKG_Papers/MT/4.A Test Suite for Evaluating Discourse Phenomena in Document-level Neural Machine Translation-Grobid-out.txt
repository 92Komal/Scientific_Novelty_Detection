title
A Test Suite for Evaluating Discourse Phenomena in Document-level Neural Machine Translation

abstract
The need to evaluate the ability of contextaware neural machine translation (NMT) models in dealing with specific discourse phenomena arises in document-level NMT. However, test sets that satisfy this need are rare. In this paper, we propose a test suite to evaluate three common discourse phenomena in English-Chinese translation: pronoun, discourse connective and ellipsis where discourse divergences lie across the two languages. The test suite contains 1,200 instances, 400 for each type of discourse phenomena. We perform both automatic and human evaluation with three state-of-the-art context-aware NMT models on the proposed test suite. Results suggest that our test suite can be used as a challenging benchmark test bed for evaluating document-level NMT. The test suite will be publicly available soon.

Introduction Document-level NMT has attracted extensive interest in recent years. Different from sentence-level NMT models, discourse-level models need to not only cope with intra-sentence dependencies, but also incorporate context beyond current sentence into context-aware translation. Inter-sentence links usually exhibit a wide variety of discourse phenomena: coreference, lexical cohesion, coherence, discourse relations, etc. The quality of a documentlevel NMT model therefore can be evaluated based on its ability in dealing with these discourse phenomena. Widely-used automatic evaluation metrics, e.g., BLEU  (Papineni et al., 2002) , normally consider fragments in a local window for translation quality assessment, while cross-sentence discourse links are usually neglected. Hence, for document-level models, current automatic evaluation metrics may be not a reasonably good fit for evaluation. One possible alternative is using manually-created test suites which are composed of carefully selected examples with discourse phenomena  (Hardmeier, 2015) . Such test suites  (Guillou et al., 2018; Rysov? et al., 2019; Vojt?chov? et al., 2019; Voita et al., 2019; Popovi?, 2019)  have been constructed for several language pairs, such as English-Czech, English-German, English-Russian, French-German, but few in English-Chinese translation. In this paper, we propose a test suite aiming at English-Chinese discourse phenomena evaluation. Three frequent discourse phenomena in English-Chinese translation are selected in our test suite, namely pronoun, discourse connective and ellipsis, each of which forms an individual test set. We choose examples from the OpenSubtitles  (Lison and Tiedemann, 2016)  to construct the three test sets. Unlike corpora from news domain, this corpus is more conversational and colloquial. We use this test suite to evaluate several typical context-aware NMT models. The experiment results show that our test suite can evaluate the ability of NMT models in dealing with discourse phenomena and that it is still very challenging for current context-aware models to capture different discourse phenomena. 

 Related Work Research on the evaluation of document-level machine translation is usually on specific discourse phenomena. A few test suites and methods have been designed for evaluating NMT from the perspective of discourse phenomena. For pronoun translation evaluation, recent test sets on pronoun evaluation have consisted of contrastive pairs.  Bawden et al. (2018)  provide 50 example blocks of English-French contrastive pairs.  M?ller et al. (2018)  have also created contrastive pairs of pronoun "it" in English-German translation. Contrastive test sets allow us to automatically evaluate document-level NMT by only judging whether the evaluated model can choose the correct translation against the wrong from each contrastive pair according to their model score. However, this is an indirect rather than a direct way to evaluate the ability of context-aware NMT in modeling discourse phenomena as we do not evaluate the actual translations generated by these NMT systems. To evaluate discourse connective translation,  Meyer et al. (2012)  propose ACT (accuracy of connective translation) to evaluate connective translation. For French-English discourse relation and discourse connective translation assessment, Smith and Specia (2018) use pretrained bilingual embeddings of discourse connectives.  Popovi? (2019)  investigates conjunction disambiguation in English-German and French-German translation. For the evaluation on ellipsis translation,  Voita et al. (2019)  explore contrastive examples to evaluate the verb phrase ellipsis and morphological inflection in English-Russian translation. In our work, we also investigate verb ellipsis in English-Chinese translation. 

 Test Sets We choose three types of discourse phenomena, i.e., pronoun, discourse connective and ellipsis, as they appear frequently in English-Chinese documentlevel NMT. In the following parts, we will introduce corpus construction and then the three test sets separately. 

 Test Sets Construction Due to the lack of such a test set for English-Chinese translation, we manually construct our test sets. We select instances from the open-source corpus OpenSubtitles  (Lison and Tiedemann, 2016)  as our data sources. First, we filter out characters and tokens written in languages other than English and Chinese. We then extract snippets with two neighboring sentences. Finally, we select test cases from extracted snippets according to different language phenomena. For the construction of the pronoun test set, we discard snippets where the two adjacent sentences both include "you" or "they" in English. We then construct the test set from the remaining examples that contain "?", "?", "?", "?" and "? ?" on the Chinese side. For the construction of the discourse connective As for the ellipsis test set, we first choose cases where the second sentence in English contains auxiliary verbs. If the Chinese translations of the chosen cases whether include ellipsis verbs, such cases are finally selected. As Chinese translations are provided by nonprofessional translators, they are sometimes noisy with errors. We hire professional translators to review the selected instances and correct translation errors. Each test set contains 400 examples. Data statistics are displayed in Table  1 . 

 Pronoun Test Set In the pronoun test set, we focus on the second person pronoun "you" and the third person pronoun "they" as well as their accusative and possessive forms. In Chinese, "you" can be translated as "?" (single form) or "?" (plural form). And "they" is translated into words of different genders: "? ?" (plural form of "he"), "?" (plural form of "she") and "?" (plural form of "it"). Each type of pronouns has 80 examples in this test set. Figure  1  displays an example from this test set. In order to help document-level NMT models choose a correct translation for "you" and "they", we provide the previous sentence as context, which is guaranteed to elliminate such translation ambiguity. For "you", the preceding sentence usually contains nouns or names which indicate the plural or single information of the pronoun. As for "they", nouns with gender information, common names of men and women or non-human nouns in the source side context can be explored for translation disambiguation. 

 Discourse Connective Test Set For this test set, we focus on ambiguous discourse connective in English-Chinese translation. Particu-  larly, we select five ambiguous discourse connectives according to  Webber et al. (2019) , namely while, as, since, though and or. Different senses of these ambiguous connectives are frequently occurring in English texts. The number of cases for each connective is 80. An example of discourse connective in this test set is demonstrated in Figure  2 . Discourse connectives are important to express the discourse relation between sentences. The same connective in different context, may convey different discourse relations in the sense hierarchy  (Webber et al., 2019) . In order to correctly translate these ambiguous connectives, context-aware NMT models have to recognize discourse relations between clauses or sentences by taking sufficient context into account. 

 Ellipsis Test Set We cover verb ellipsis in English in this test set. As illustrated in Figure  3 , Chinese and English exhibit different ellipsis patterns, which pose challenges for machine translation. If we are only given a sentence with ellipsis, we cannot fully understand this sentence as crucial information may be missing, which can only be recovered by resorting to previous context. For context-aware NMT models, this means that they have to find the elided information if this informa-tion should be present in the target language. 

 Experiment We used the proposed test suite as a benchmark test bed to evaluate state-of-the-art context-aware NMT models against the three types of discourse phenomena. 

 Models We used the following three document-level NMT models:  

 Data We used the following corpora to train the three NMT models: 6M sentence pairs randomly selected from AI Challenger corpus in spoken language. IWSLT'17 English-Chinese MT corpus comprises of TED talks. Thumt and CADec were trained on the sentencelevel data, i.e., the 6M-sentence subset of the AI Challenger 2017 corpus, in the first stage. In the second phase of context-aware training, the combination of the IWSLT'17 training data and the subset of the OpenSubtitles corpus was used. Bert-nmt was trained on only IWSLT'17 data following  Zhu et al. (2020) . 

 Results The BLEU scores of the three models on our test suite are shown in Table  2 . In addition to the automatic evaluation, we further performed human evaluation to investigate the translation accuracy on the three types of discourse phenomena. In human evaluation, we focus on whether the relevant phenomena are correctly translated and ignore other errors. Human evaluation is better at evaluating discourse phenomena translation. Human evaluation results are shown in Table  3 . Overall, CADec achieves the best results in most cases but not in all cases. In translating you (sing.), while and ellipsis, thumt achieves the highest accuracy, while bert-nmt is better than the others in translating they (it (pl.)). For pronoun translation, "you" is usually translated into "?" (you (sing.)) while "they" into "? ?" (he (pl.)). This is because these two cases are more frequent than other cases (e.g., "?", "? ?"). This also happens for discourse connective translation. For example, "while" is often translated into "?" rather than "?" (but) as the former is more common that the latter. Compared with pronouns and discourse connectives, ellipsis is more challenging for the three context-aware models, which achieves a translation accuracy of <11%. Verb ellipsis usually occurs in questions or replies in spoken dialogues. We observe that auxiliary verb "do" is often wrongly translated into "do" (notional verb) or "know". This suggests that these context-aware models cannot correctly recognize ellipsis and detect omitted fragments from context. 

 Conclusion We have presented a discourse-level test suite for the evaluation of context-aware neural machine translation. We constructed 1,200 instances for three types of discourse phenomena in English-Chinese translation, 400 instances per discourse phenomenon. Our experiments with three stateof-the-art document-level NMT models suggest that ellipsis is the most challenging discourse issue among the three test sets. Figure 3 : 3 Figure 3: An example from the ellipsis test set. 
