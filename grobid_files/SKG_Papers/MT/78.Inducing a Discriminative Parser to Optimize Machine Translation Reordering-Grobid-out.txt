title
Inducing a Discriminative Parser to Optimize Machine Translation Reordering

abstract
This paper proposes a method for learning a discriminative parser for machine translation reordering using only aligned parallel text. This is done by treating the parser's derivation tree as a latent variable in a model that is trained to maximize reordering accuracy. We demonstrate that efficient large-margin training is possible by showing that two measures of reordering accuracy can be factored over the parse tree. Using this model in the pre-ordering framework results in significant gains in translation accuracy over standard phrasebased SMT and previously proposed unsupervised syntax induction methods.

Introduction Finding the appropriate word ordering in the target language is one of the most difficult problems for statistical machine translation (SMT), particularly for language pairs with widely divergent syntax. As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT , hierarchical phrase-based translation  (Chiang, 2007) , syntax-based translation  (Yamada and Knight, 2001) , or preordering  (Xia and McCord, 2004) . In particular, systems that use sourcelanguage syntax allow for the handling of longdistance reordering without large increases in The first author is now affiliated with the Nara Institute of Science and Technology. decoding time. However, these require a good syntactic parser, which is not available for many languages. In recent work, DeNero and  Uszkoreit (2011)  suggest that unsupervised grammar induction can be used to create source-sentence parse structure for use in translation as a part of a pre-ordering based translation system. In this work, we present a method for inducing a parser for SMT by training a discriminative model to maximize reordering accuracy while treating the parse tree as a latent variable. As a learning framework, we use online large-margin methods to train the model to directly minimize two measures of reordering accuracy. We propose a variety of features, and demonstrate that learning can succeed when no linguistic information (POS tags or parse structure) is available in the source language, but also show that this linguistic information can be simply incorporated when it is available. Experiments find that the proposed model improves both reordering and translation accuracy, leading to average gains of 1.2 BLEU points on English-Japanese and Japanese-English translation without linguistic analysis tools, or up to 1.5 BLEU points when these tools are incorporated. In addition, we show that our model is able to effectively maximize various measures of reordering accuracy, and that the reordering measure that we choose has a direct effect on translation results. 

 Preordering for SMT Machine translation is defined as transformation of source sentence F = f 1 . . . f J to target sentence E = e 1 . . . e I . In this paper, we take Figure  1 : An example with a source sentence F reordered into target order F , and its corresponding target sentence E. D is one of the BTG derivations that can produce this ordering. the pre-ordering approach to machine translation  (Xia and McCord, 2004) , which performs translation as a two step process of reordering and translation (Figure  1 ). Reordering first deterministically transforms F into F , which contains the same words as F but is in the order of E. Translation then transforms F into E using a method such as phrase-based SMT  (Koehn et al., 2003) , which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are defined over this parse either through machine learning techniques  (Xia and McCord, 2004; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima'an, 2011)  or linguistically motivated manual rules  (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b) . However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser  (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011) , and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero and Uszkoreit (2011) learn a reordering model through a three-step process of bilingual grammar induction, training a monolingual parser to reproduce the induced trees, and training a reordering model that selects a reordering based on this parse structure. In contrast, our method trains the model in a single step, treating the parse structure as a latent variable in a discriminative reordering model. In addition  Tromble and Eisner (2009)  and  Visweswariah et al. (2011)  present models that use binary classification to decide whether each pair of words should be placed in forward or reverse order. In contrast, our method uses traditional contextfree-grammar models, which allows for simple parsing and flexible parameterization, including features such as those that utilize the existence of a span in the phrase table. Our work is also unique in that we show that it is possible to directly optimize several measures of reordering accuracy, which proves important for achieving good translations. 1 

 Training a Reordering Model with Latent Derivations In this section, we provide a basic overview of the proposed method for learning a reordering model with latent derivations using online discriminative learning. 

 Space of Reorderings The model we present here is based on the bracketing transduction grammar (BTG,  Wu (1997) ) framework. BTGs represent a binary tree derivation D over the source sentence F as shown in Figure  1 . Each non-terminal node can either be a straight (str) or inverted (inv) production, and terminals (term) span a nonempty substring f . 2 The ordering of the sentence is determined by the tree structure and the non-terminal labels str and inv, and can be built bottom-up. Each subtree represents a source substring f and its reordered counterpart f . For each terminal node, no reordering occurs and f is equal to f . For each non-terminal node spanning f with its left child spanning f 1 and its right child spanning f 2 , if the non-terminal symbol is str, the reordered strings will be concatenated in order as f = f 1 f 2 , and if the non-terminal symbol is inv, the reordered strings will be concatenated in inverted order as f = f 2 f 1 . We define the space of all reorderings that can be produced by the BTG as F , and attempt to find the best reordering F within this space. 3 

 Reorderings with Latent Derivations In order to find the best reordering F given only the information in the source side sentence F , we define a scoring function S(F |F ), and choose the ordering of maximal score: ? = arg max F S(F |F ). As our model is based on reorderings licensed by BTG derivations, we also assume that there is an underlying derivation D that produced F . As we can uniquely determine F given F and D, we can define a scoring function S(D|F ) over derivations, find the derivation of maximal score ? = arg max D S(D|F ) and use ? to transform F into F . Furthermore, we assume that the score S(D|F ) is the weighted sum of a number of feature functions defined over D and F S(D|F, w) = ? i w i ? i (D, F ) where ? i is the ith feature function, and w i is its corresponding weight in weight vector w. Given this model, we must next consider how to learn the weights w. As the final goal of our model is to produce good reorderings F , it is natural to attempt to learn weights that will allow us to produce these high-quality reorderings.  

 Evaluating Reorderings Before we explain the learning algorithm, we must know how to distinguish whether the F produced by the model is good or bad. This section explains how to calculate oracle reorderings, and assign each F a loss and an accuracy according to how well it reproduces the oracle. 

 Calculating Oracle Orderings In order to calculate reordering quality, we first define a ranking function r(f j |F, A), which indicates the relative position of source word f j in the proper target order (Figure  2 (a) ). In order to calculate this ranking function, we define A = a 1 , . . . , a J , where each a j is a set of the indices of the words in E to which f j is aligned. 4 Given these alignments, we define an ordering function a j 1 < a j 2 that indicates that the indices in a j 1 come before the indices in a j 2 . Formally, we define this function as "the first index in a j 1 is at most the first index in a j 2 , similarly for the last index, and either the first or last index in a j 1 is less than that of a j 2 ." Given this ordering, we can sort every alignment a j , and use its relative position in the sentence to assign a rank to its word r(f j ). In the case of ties, where neither a j 1 < a j 2 nor a j 2 < a j 1 , both f j 1 and f j 2 are assigned the same rank. We can now define measures of reordering accuracy for F by how well it arranges the words in order of ascending rank. It should be noted that as we allow ties in rank, there are multiple possible F where all words are in strictly ascending order, which we will call oracle orderings. 

 Kendall's ? The first measure of reordering accuracy that we will consider is Kendall's ?  (Kendall, 1938) , a measure of pairwise rank correlation which has been proposed for evaluating translation reordering accuracy  (Isozaki et al., 2010a; Birch et al., 2010)  and pre-ordering accuracy . The fundamental idea behind the measure lies in comparisons between each pair of elements f j 1 and f j 2 of the reordered sentence, where j 1 < j 2 . Because j 1 < j 2 , f j 1 comes before f j 2 in the reordered sentence, the ranks should be r(f j 1 ) ? r(f j 2 ) in order to produce the correct ordering. Based on this criterion, we first define a loss L t (F ) that will be higher for orderings that are further from the oracle. Specifically, we take the sum of all pairwise orderings that do not follow the expected order L t (F ) = J?1 ? j 1 =1 J ? j 2 =j 1 +1 ?(r(f j 1 ) > r(f j 2 )) where ?(?) is an indicator function that is 1 when its condition is true, and 0 otherwise. An example of this is given in Figure  2 (b) . To calculate an accuracy measure for ordering F , we first calculate the maximum loss for the sentence, which is equal to the total number of non-equal rank comparisons in the sentence 5 max F L t (F ) = J?1 ? j 1 =1 J ? j 2 =j 1 +1 ?(r(f j 1 ) = r(f j 2 )). (1)  5  The traditional formulation of Kendall's ? assumes no ties in rank, and thus the maximum loss can be calculated as J(J ? 1)/2. Finally, we use this maximum loss to normalize the actual loss to get an accuracy A t (F ) = 1 ? L t (F ) max F L t ( F ) , which will take a value between 0 (when F has maximal loss), and 1 (when F matches one of the oracle orderings). In Figure  2  (b), L t (F ) = 2 and max F L t ( F ) = 8, so A t (F ) = 0.75. 

 Chunk Fragmentation Another measure that has been used in evaluation of translation accuracy  (Banerjee and Lavie, 2005)  and pre-ordering accuracy ) is chunk fragmentation. This measure is based on the number of chunks that the sentence needs to be broken into to reproduce the correct ordering, with a motivation that the number of continuous chunks is equal to the number of times the reader will have to jump to a different position in the reordered sentence to read it in the target order. One way to measure the number of continuous chunks is considering whether each word pair f j and f j+1 is discontinuous (the rank of f j+1 is not equal to or one greater than f j ) discont(f j , f j+1 ) = ?(r(f j ) = r(f j+1 ) ? r(f j ) + 1 = r(f j+1 )) and sum over all word pairs in the sentence to create a sentence-based loss L c (F ) = J?1 ? j=1 discont(f j , f j+1 ) (2) While this is the formulation taken by previous work, we found that this under-penalizes bad reorderings of the first and last words of the sentence, which can contribute to the loss only once, as opposed to other words which can contribute to the loss twice. To account for this, when calculating the chunk fragmentation score, we additionally add two sentence boundary words f 0 and f J+1 with ranks r(f 0 ) = 0 and r(f J+1 ) = 1 + max f j ?F r(f j ) and redefine the summation in Equation (  2 ) to consider these words (e.g. Figure  2  (c)). Similarly to Kendall's ? , we can also define an accuracy measure between 0 and 1 using the maximum loss, which will be at most J + 1, which corresponds to the total number of comparisons made in calculating the loss 6 A c (F ) = 1 ? L c (F ) J + 1 . In Figure  2  (c), L c (F ) = 3 and J + 1 = 6, so A c (F ) = 0.5. 

 Learning a BTG Parser for Reordering Now that we have a definition of loss over reorderings produced by the model, we have a clear learning objective: we would like to find reorderings F with low loss. The learning algorithm we use to achieve this goal is motivated by discriminative training for machine translation systems  (Liang et al., 2006) , and extended to use large-margin training in an online framework  (Watanabe et al., 2007) . 

 Learning Algorithm Learning uses the general framework of largemargin online structured prediction  (Crammer et al., 2006) , which makes several passes through the data, finding a derivation with high model score (the model parse) and a derivation with minimal loss (the oracle parse), and updating w if these two parses diverge (Figure  3 ). In order to create both of these parses efficiently, we first create a parse forest encoding a large number of derivations D i according to the model scores. Next, we find the model parse ?i , which is the parse in the forest D i that maximizes the sum of the model score and the loss S(D k |F k , w)+L(D k |F k , A k ). It should be noted that here we are considering not only the model score, but also the derivation's loss. This is necessary for loss-driven large-margin training  (Crammer et al., 2006) , and follows the basic intuition that during training, we would like to make it easier to select negative examples with large loss, causing these examples to be penalized more often and more heavily. We also find an oracle parse Di , which is selected solely to minimize the loss L(D k |F k , A k ). One important difference between the model we describe here and traditional parsing models is that the target derivation Dk is a latent variable. Because many D k achieve a particular reordering F , many reorderings F are able to minimize the loss L(F k |F k , A k ). Thus it is necessary to choose a single oracle derivation to treat as the target out of many equally good reorderings. DeNero and Uszkoreit (2011) resolve this ambiguity with four features with empirically tuned scores before training a monolingual parser and reordering model. In contrast, we follow previous work on discriminative learning with latent variables (Yu and Joachims, 2009), and break ties within the pool of oracle derivations by selecting the derivation with the largest model score. From an implementation point of view, this can be done by finding the derivation that minimizes L(D k |F k , A k ) ? ?S(D k |F k , w), where ? is a constant small enough to ensure that the effect of the loss will always be greater than the effect of the score. Finally, if the model parse ?k has a loss that is greater than that of the oracle parse Dk , we update the weights to increase the score of the oracle parse and decrease the score of the model parse. Any criterion for weight updates may be used, such as the averaged perceptron  (Collins, 2002)  and MIRA  (Crammer et al., 2006 ), but we opted to use Pegasos  (Shalev-Shwartz et al., 2007)  as it allows for the introduction of regularization and relatively stable learning. To perform this full process, given a source sentence F k , alignment A k , and model weights w we need to be able to efficiently calculate scores, calculate losses, and create parse forests for derivations D k , the details of which will be explained in the following sections. 

 Scoring Derivation Trees First, we must consider how to efficiently assign scores S(D|F, w) to a derivation or forest during parsing. The most standard and efficient way to do so is to create local features that can be calculated based only on the information included in a single node d in the derivation tree. The score of the whole tree can then be expressed as the sum of the scores from each node: S(D|F, w) = ? d?D S(d|F, w) = ? d?D ? i w i ? i (d, F ). Based on this restriction, we define a number of features that can be used to score the parse tree. To ease explanation, we represent each node in the derivation as d = s, l, c, c + 1, r , where s is the node's symbol (str, inv, or term), while l and r are the leftmost and rightmost indices of the span that d covers. c and c + 1 are the rightmost index of the left child and leftmost index of the right child for non-terminal nodes. All features are intersected with the node label s, so each feature described below corresponds to three different features (or two for features applicable to only non-terminal nodes). ? ? lex : Identities of words in positions f l , f r , f c , f c+1 , f l?1 , f r+1 , f l f r , and f c f c+1 . ? ? class : Same as ? lex , but with words abstracted to classes. We use the 50 classes automatically generated by Och (1999)'s method that are calculated during alignment in standard SMT systems. ? ? balance : For non-terminals, features indicating whether the length of the left span (c ? l + 1) is lesser than, equal to, or greater than the length of the right span (r ? c). ? ? table : Features, bucketed by length, that indicate whether "f l . . . f r " appears as a contiguous phrase in the SMT training data, as well as the log frequency of the number of times the phrase appears total and the number of times it appears as a contiguous phrase (DeNero and Uszkoreit, 2011). Phrase length is limited to 8, and phrases of frequency one are removed. ? ? pos : Same as ? lex , but with words abstracted to language-dependent POS tags. ? ? cf g : Features indicating the label of the spans f l . . . f r , f l . . . f c , and f c+1 . . . f r in a supervised parse tree, and the intersection of the three labels. When spans do not correspond to a span in the supervised parse tree, we indicate "no span" with the label "X"  (Zollmann and Venugopal, 2006) . Most of these features can be calculated from only a parallel corpus, but ? pos requires a POS tagger and ? cf g requires a full syntactic parser in the source language. As it is preferable to have a method that is applicable in languages where these tools are not available, we perform experiments both with and without the features that require linguistic analysis tools. 

 Finding Losses for Derivation Trees The above features ? and their corresponding weights w are all that are needed to calculate scores of derivation trees at test time. However, during training, it is also necessary to find model parses according to the loss-augmented scoring function S(D|F, w)+L(D|F, A) or oracle parses according to the loss L(D|F, A). As noted by  Taskar et al. (2003) , this is possible if our losses can be factored in the same way as the feature space. In this section, we demonstrate that the loss L(d|F, A) for the evaluation measures we defined in Section 4 can (mostly) be factored over nodes in a fashion similar to features. 

 Factoring Kendall's ? For Kendall's ? , in the case of terminal nodes, L t (d = term, l, r |F, A) can be calculated by performing the summation in Equation (1). We can further define this sum recursively and use memoization for improved efficiency L t (d|F, A) =L t ( term, l, r ? 1 |F, A) + r?1 ? j=l ?(r(f j ) > r(f r )). (3) For non-terminal nodes, we first focus on straight non-terminals with parent node d = str, l, c, c + 1, r , and left and right child nodes d l = s l , l, lc, lc+1, c and d r = s r , c+1, rc, rc+ 1, r . First, we note that the loss for the subtree rooted at d can be expressed as L t (d|F, A) =L t (d l |F, A) + L t (d r |F, A) + c ? j 1 =l r ? j 2 =c+1 ?(r(f j 1 ) > r(f j 2 )). In other words, the subtree's total loss can be factored into the loss of its left subtree, the loss of its right subtree, and the additional loss contributed by comparisons between the words spanning both subtrees. In the case of inverted terminals, we must simply reverse the comparison in the final sum to be ?(r(f j 1 ) < r(f j 2 )). 

 Factoring Chunk Fragmentation Chunk fragmentation loss can be factored in a similar fashion. First, it is clear that the loss for the terminal nodes can be calculated efficiently in a fashion similar to Equation (3). In order to calculate the loss for non-terminals d, we note that the summation in Equation (  2 ) can be divided into the sum over the internal bi-grams in the left and right subtrees, and the bi-gram spanning the reordered trees L c (d|F, A) =L c (d l |F, A) + L c (d r |F, A) + discont(f c , f c+1 ). However, unlike Kendall's ? , this equation relies not on the ranks of f c and f c+1 in the original sentence, but on the ranks of f c and f c+1 in the reordered sentence. In order to keep track of these values, it is necessary to augment each node in the tree to be d = s, l, c, c + 1, r, tl, tr with two additional values tl and tr that indicate the position of the leftmost and rightmost words after reordering. Thus, a straight nonterminal parent d with children d l = s l , l, lc, lc+ 1, c, tl, tlr and d r = s r , c+1, rc, rc+1, r, trl, tr will have loss as follows L c (d|F, A) =L c (d l |F, A) + L c (d r |F, A) + discont(f tlr , f trl ) with a similar calculation being possible for inverted non-terminals. 

 Parsing Derivation Trees Finally, we must be able to create a parse forest from which we select model and oracle parses. As all feature functions factor over single nodes, it is possible to find the parse tree with the highest score in O(J 3 ) time using the CKY algorithm. However, when keeping track of target positions for calculation of chunk fragmentation loss, there are a total of O(J 5 ) nodes, an unreasonable burden in terms of time and memory. To overcome this problem, we note that this setting is nearly identical to translation using synchronous CFGs with an integrated bigram LM, and thus we can employ cube-pruning to reduce our search space  (Chiang, 2007) . 

 Experiments Our experiments test the reordering and translation accuracy of translation systems using the proposed method. As reordering metrics, we use Kendall's ? and chunk fragmentation  comparing the system F and oracle F calculated with manually created alignments. As translation metrics, we use BLEU  (Papineni et al., 2002) , as well as RIBES  (Isozaki et al., 2010a) , which is similar to Kendall's ? , but evaluated on the target sentence E instead of the reordered sentence F . All scores are the average of three training runs to control for randomness in training  (Clark et al., 2011) . For translation, we use Moses  (Koehn et al., 2007)  with lexicalized reordering   of pre-ordering: original order with F ? F (orig), pre-orderings learned using the 3-step process of DeNero and Uszkoreit (2011) (3step), and the proposed model with latent derivations (lader). 7 Except when stated otherwise, lader was trained to minimize chunk fragmentation loss with a cube pruning stack pop limit of 50, and the regularization constant of 10 ?3 (chosen through cross-validation). We test our systems on Japanese-English and English-Japanese translation using data from the Kyoto Free Translation Task  (Neubig, 2011) . We use the training set for training translation and language models, the development set for weight tuning, and the test set for testing (Table  1 ). We use the designated development and test sets of manually created alignments as training data for the reordering models, removing sentences of more than 60 words. As default features for lader and the monolingual parsing and reordering models in 3-step, we use all the features described in Section 5.  2 7 Available open-source: http://phontron.com/lader except ? pos and ? cf g . In addition, we test systems with ? pos and ? cf g added. For English, we use the Stanford parser  (Klein and Manning, 2003)  for both POS tagging and CFG parsing. For Japanese, we use the KyTea tagger  for POS tagging, 8 and the EDA word-based dependency parser  (Flannery et al., 2011)  with simple manual head-rules to convert a dependency parse to a CFG parse. 

 Effect of Pre-ordering Table  2  shows reordering and translation results for orig, 3-step, and lader. It can be seen that the proposed lader outperforms the baselines in both reordering and translation. 9 There are a number of reasons why lader outperforms 3-step. First, the pipeline of 3-step suffers from error propogation, with errors in monolingual parsing and reordering resulting in low overall accuracy. 10 Second, as Section 5.1 describes, lader breaks ties between oracle parses based on model score, allowing easyto-reproduce model parses to be chosen during training. In fact, lader generally found trees that followed from syntactic constituency, while 3-step more often used terminal nodes  that spanned constituent boundaries (as long as the phrase frequency was high). Finally, as Section 6.2 shows in detail, the ability of lader to maximize reordering accuracy directly allows for improved reordering and translation results. It can also be seen that incorporating POS tags or parse trees improves accuracy of both lader and 3-step, particularly for English-Japanese, where syntax has proven useful for pre-ordering, and less so for Japanese-English, where syntactic pre-ordering has been less successful  (Sudoh et al., 2011b) . We also tested Moses's implementation of hierarchical phrase-based SMT  (Chiang, 2007) , which achieved BLEU scores of 23.21 and 19.30 for English-Japanese and Japanese-English respectively, approximately matching lader in accuracy, but with a significant decrease in decoding speed. Further, when pre-ordering with lader and hierarchical phrase-based SMT were combined, BLEU scores rose to 23.29 and 19.69, indicating that the two techniques can be combined for further accuracy improvements. 

 Effect of Training Loss Table  3  shows results when one of three losses is optimized during training: chunk fragmentation (L c ), Kendall's ? (L t ), or the linear interpolation of the two with weights chosen so that both losses contribute equally (L t + L c ). In general, training successfully maximizes the criterion it is trained on, and L t + L c achieves good results on both measures. We also find that L c and L c +L t achieve the best translation results, which is in concert with , who find chunk fragmentation is better correlated with translation accuracy than Kendall's ? . This is an important result, as methods such as that of  Tromble and Eisner (2009)   word comparisons equivalent to L t , which may not be optimal for translation. 

 Effect of Automatic Alignments Table  4  shows the difference between using manual and automatic alignments in the training of lader. lader is able to improve over the orig baseline in all cases, but when equal numbers of manual and automatic alignments are used, the reorderer trained on manual alignments is significantly better. However, as the number of automatic alignments is increased, accuracy improves, approaching that of the system trained on a smaller number of manual alignments. 

 Conclusion We presented a method for learning a discriminative parser to maximize reordering accuracy for machine translation. Future work includes application to other language pairs, development of more sophisticated features, investigation of probabilistic approaches to inference, and incorporation of the learned trees directly in tree-to-string translation. Figure 2 : 2 Figure 2: An example of (a) the ranking function r(f j ), (b) loss according to Kendall's ? , (c) loss according to chunk fragmentation. 
