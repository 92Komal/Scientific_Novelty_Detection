title
Paraphrase Generation as Zero-Shot Multilingual Translation: Disentangling Semantic Similarity from Lexical and Syntactic Diversity

abstract
Recent work has shown that a multilingual neural machine translation (NMT) model can be used to judge how well a sentence paraphrases another sentence in the same language ; however, attempting to generate paraphrases from such a model using standard beam search produces trivial copies or near copies. We introduce a simple paraphrase generation algorithm which discourages the production of n-grams that are present in the input. Our approach enables paraphrase generation in many languages from a single multilingual NMT model. Furthermore, the amount of lexical diversity between the input and output can be controlled at generation time. We conduct a human evaluation to compare our method to a paraphraser trained on the large English synthetic paraphrase database ParaBank 2  (Hu et al., 2019c)  and find that our method produces paraphrases that better preserve meaning and are more gramatical, for the same level of lexical diversity. Additional smaller human assessments demonstrate our approach also works in two non-English languages.

Introduction Paraphrase generation is the task of producing a fluent output sentence which is semantically similar to the input sentence while being syntactically and/or lexically different from it  (Bhagat and Hovy, 2013) . Paraphrasing has been of longstanding interest in the NLP community  (McKeown, 1983)  and has been used for data augmentation in question answering  (Dong et al., 2017; Gan and Ng, 2019) , machine translation (MT)  (Hu et al., 2019a; Khayrallah et al., 2020) , task oriented dialog  Bansal, 2018, 2019) , and MT metrics  (Banerjee and Lavie, 2005; Zhou et al., 2006; Denkowski and Lavie, 2010; .  recently released the Prism MT metric, which uses a multilingual neural MT (NMT) model as a paraphraser to score paraphrastic pairs; they treat paraphrasing as a zero-shot translation task (e.g., "translation" from English to English) and force-decode and score MT system outputs conditioned on their respective human translations. They denote their paraphraser as lexically/syntactically unbiased as it does not prefer output that differs lexically or syntactically from the input; this is advantageous for an MT metric as it assigns the highest score to an MT output which matches or nearly matches a human reference, but generating from the Prism model using standard beam search produces trivial copies or near copies. We introduce a simple method to enable paraphrase generation from a multilingual NMT model.  1  Our method discourages the model from producing n-grams that match n-grams in the input sentence. This serves to lexically bias the output away from the input sentence, resulting in nontrivial paraphrases. When considered together with Prism model of , our paraphrase generation approach offers several potential advantages over the common technique of training a paraphrase model on synthetic paraphrases generated by translating one side of bitext into the language of the other side  (Wieting et al., 2017; Hu et al., 2019c ): ? The fluency/semantic similarity vs lexical diversity trade-off can be controlled at generation time. ? The approach works in many languages, with a single model. ? The approach addresses an inherent shortcoming in creating synthetic paraphrases from bi-text in which ambiguities in one language can create errorful synthetic paraphrases in the other (see ?6). ? Separating the fluency and semantic similarity model from the lexical and/or syntactic diversity model allows them to be developed and evaluated with less interdependencies. We conduct human evaluations to compare our proposed method to a strong English baseline paraphraser trained on the ParaBank 2 dataset  (Hu et al., 2019c) , which consists of 50 million synthetic examples generated by translating the Czech side of Czech-English bitext into English and pairing it with the original English. We find that our method outperforms this baseline-both in terms of semantic similarity and grammaticality-when our system is adjusted to match the lexical diversity of the baseline. We also present small scale evaluations that suggest our method is effective in other languages. 

 Related Work Paraphrase Generation Machine translation techniques can be used to train paraphrase models  (Quirk et al., 2004) . Another method to generate a paraphrase is to translate a text to a different language and then back again . Multiple pivot languages can be used to lessen the effect of inherent ambiguities  (Aziz and Specia, 2013) , at the expense of complication. Several works have focused on training on paraphrase data, including synthetic data created by starting with bitext and translating one side into the language of the other side to create synthetic paraphrases  (Wieting et al., 2017; Hu et al., 2019c) . Ideas such as adversarial training  (Iyyer et al., 2018) , reinforcement learning , and variational autoencoders  (Gupta et al., 2018; Chen et al., 2019b)  have also been explored in the context of paraphrase generation. 

 Diversity in Generation Creating paraphrases which differ from their input in non-trivial ways is a challenging problem.  Hu et al. (2019c)  used constrained decoding  (Hokamp and Liu, 2017)  in conjunction with a set of constraints (e.g., avoiding certain words which are present in the input) when creating synthetic paraphrases from bitext. Kajiwara (2019) also used hard constraints, but at decoding time. Our work is similar but uses "soft" constraints (i.e., down-weighting tokens which com-plete n-grams in the input, but not disallowing them all together). Another approach is to control generation with syntactic examples  (Iyyer et al., 2018;  or codes  (Shu et al., 2019) . Multilingual NMT Multilingual NMT  (Dong et al., 2015)  has been shown to enable zero-shot translation-that is, translation between languages pairs not included in training (e.g., translating from Spanish?Arabic at test time when the model was trained on Spanish?English and English?Arabic, but not Spanish?Arabic)  (Johnson et al., 2017; Gu et al., 2018; Pham et al., 2019) .  Zhou et al. (2019)  also explored incorporating paraphrase data into training to improve multilingual NMT performance. Tiedemann and Scherrer (2019) explored using paraphrase recognition to test the semantic abstraction of a fairly small multilingual NMT system trained on Bibles and also demonstrate the model's ability to paraphrase in English. However, they did not perform a human evaluation of paraphrase quality, and  found that simply generating via beam search from a multilingual NMT model trained on a large general domain corpus results in trivial copies most of the time. We build upon Tiedemann and Scherrer (2019) by using a larger, general domain model, introducing a novel generation algorithm to produce output with lexical diversity, and performing human evaluations. Paraphrastic similarity Similarity between intermediate representations produced by multilingual NMT encoders has been used to measure semantic similarity and/or paraphrastic similarity  (Schwenk and Douze, 2017; Wieting et al., 2019; Raganato et al., 2019) . Similarly, Prism (Thompson and Post, 2020) use a multilingual NMT model as a lexically/syntactically unbiased paraphraser for scoring MT system outputs conditioned on their associated human reference translations. We build on this by introducing a lexical bias away from the input at generation time, enabling the use of a multilingual NMT model as a generative paraphraser. 

 Method Let x and y be sentences, let M(x) represent the meaning of x, and let S(x, y) measure the lexical and/or syntactic similarity between the two sentences. Formally, we can state the problem of para-Algorithm 1 Before paraphrasing a sentence, buildPenalties() is called to construct a mapping of word prefixes to subwords that require penalties. Then, penalize() is called to modify the model prediction targetLogProbs at every decoder timestep. def buildPenalties(source): penalties = defaultdict(list) for n in  [1, 2, 3, 4] : for ngram of size n in subwords2words(source): prefix, word = ngram[0:-1], ngram[-1] for subword in targetVocab: if word.lower().startsWith(subword.lower()): penalties  [prefix] .append(subword) return penalties def penalize(history, penalties, targetLogProbs): for n in [1, 2, 3, 4]: prefix = subwords2words(history)[-(n-1):] for subword in penalties[prefix]: targetLogProbs[id(subword)] -= alpha * (n ** beta) phrase generation as finding ?: ? = argmax y [p(y | M(x)) ? ?S(x, y)] (1) where ? controls the semantic similarity and fluency vs lexical and/or syntactic diversity trade-off. 

 Lexically/Syntactically Unbiased Paraphraser The intralingual probability p(y | M(x)) can be viewed as a lexically/syntactically unbiased paraphraser. This model is responsible for producing output which is both semantically similar to the input and fluent, but has no notion of lexical and/or syntactic diversity. We use the multilingual NMT system released with Prism to model p(y | M(x)). 

 Lexical Bias We choose n-gram overlap as our measure of lexical and/or syntactic similarity S(x, y), and propose a simple n-gram overlap measure that penalizes the production of n-grams matching n-grams in the input sequence to enable the paraphrase generation. Our proposed algorithm begins by constructing a set of all (word) n-grams, 1 ? n ? 4, from the input. 2 At each decoding step, the algorithm checks whether any of the target vocabulary subwords begin the last word of an input n-gram. 3 All such subwords are penalized by subtracting ?n ? from the output log probabilities of the NMT model before selecting candidates to extend the beam, where n is the n-gram length, ? is the user-specified trade-off between semantic similarity and lexical diversity, and ? is another user-defined hyperparameter. We experimented with penalizing 1-, 2-, 3-, and 4-grams equally but found it produced disfluent output, as the algorithm tended to avoid all words in the input. The exponential weight allows us to penalize the decoder for producing larger overlapping n-grams more harshly than small ones. All experiments in this work use ? = 4, as this produced output in English which appeared fluent to the authors. Finally, the NMT model's vocabulary contains case variants (e.g., "his" and "His") and we do not want to add variation by trivially changing the case of words, so we penalize all case variants of the next tokens. Pseudocode for our approach is provided in Algorithm 1. Note that this method is much simpler than the method used to generate training data for ParaBank 2, which including hand-written constraints, scoring, filtering, and clustering. 

 Diversity Control The ? parameter in Equation 1 provides the user with a knob to control how strongly the output is "pushed" away from the input, in lexical space, during generation. In contrast to positive and negative hard lexical lexical constraints  (Hokamp and Liu, 2017; Post and Vilar, 2018; Hu et al., 2019c) , our method requires no user-defined constraints, making it simpler and perhaps more language agnostic. 4 

 Development and Evaluation Paraphrase evaluation is complicated by the fact that many different aspects of paraphrases can be evaluated including semantic similarity between input and output, fluency, grammatical correctness, lexical diversity between input and output, and syntactic diversity between input and output. The relative importance of these aspects is not intuitively obvious and is likely determined by downstream tasks. Modeling semantic similarity and lexical/syntactic diversity separately has the potential to somewhat lessen the burden of evaluation in several ways: 1. There are several potential ways to automatically evaluate the model p(y | M(x)). One option is to evaluate perplexity on a test set consisting of human paraphrases. (Thompson and  found that their multilingual NMT model assigned higher probability to both copies of the input and human paraphrases of the input, compared to a model trained on ParaBank 2.) Another option is to test models of p(y | M(x)) on pairs of paraphrases where one paraphrase has been deemed to better preserve the semantic meaning of the input. Such datasets already exist, in about a dozen languages, due to the annotation efforts undertaken at the annual WMT evaluations.  5  In other words, we can simply treat a model of p(y | M(x)) as an MT metric in order to judge its quality. In other words, we can simply treat a model of p(y | M(x)) as an MT metric in order to judge its quality. 2. By applying the lexical/syntactic bias in generation, development of the generation algorithm can be conducted without the time/cost of re-training a model, and multiple generation schemes can be directly compared using the same p(y | M(x)) model, such as the freely available Prism model . 3. Being able to control the amount of lexical and/or syntactic diversity at inference time allows for easier comparison with prior paraphrasing work, as the diversity can be adjusted to match that of a prior method. (We employ this approach in ?4.3.1.) 4 Experimental Setup 

 Primary Model We use the multilingual NMT model released with Prism , which uses a Transformer  (Vaswani et al., 2017)  architecture with approximately 750 million parameters. The model was trained in fairseq  (Ott et al., 2019) . The authors take several steps to encourage the encoder and decoder to be language agnostic, including specifying the target language as the first token in the target, so that the encoder does not know the target language, and training on several datasets that include a large number of different language pairs. The model was trained on several open source datasets including WikiMatrix  (Schwenk et al., 2019)   

 Baseline Model As a baseline, we train an English-only paraphraser in fairseq on the ParaBank 2 dataset  (Hu et al., 2019c)  with approximately 253M parameters and a SentencePiece vocabulary of 16k tokens. We train a Transformer with an 8-layer encoder, 8-layer decoder, 1024 dimensional embeddings, embedding sizes of 1024, feed-forward size of 4096, and 16 attention heads. Dropout is set to 0.3, label smooth- ing to 0.1, and learning rate to 0.0005, and batch size was 31200 tokens. Other parameters match the fairseq defaults. The model trained for approximately 6 weeks (33 epochs) on 4 Nvidia 2080 GPUs. 

 Evaluation We conduct a manual evaluation in English using Mechanical Turk workers and conduct smaller scale manual evaluations in German and Spanish, with the help of colleagues who are native speakers. We perform human evaluations following  (Hu et al., 2019b) , described more detail below. 

 English Evaluation In this work, we focus on evaluation of semantic similarity, grammatical correctness, and lexical diversity. For the model trained on ParaBank 2, the trade-off between these dimensions is fixed and built into the model. To make a fair comparison, we adjust our overlap penalty (?) such that the output of our method matches the lexical diversity of the model trained on ParaBank 2. Following  Hu et al. (2019c) , we use uncased BLEU  (Papineni et al., 2002) , computed between input and output, to estimate the lexical diversity of the paraphraser. We evaluate in English using Mechanical Turk workers who were selected from a curated list of previously vetted workers. Annotators were presented with a reference sentence and four paraphrases: three paraphrases from our proposed method (at three different operating points) and one from the model trained on ParaBank 2, presented in random order. For each paraphrase, the annotators were asked to (1) rate the paraphrase as (i) grammatical, (ii) having one or two small grammatical errors, or (iii) ungrammatical, and (2) rate the semantic similarity between the input and the paraphrase using an analog slider bar from 1-100. We randomly select 200 sentences from the English side of the WMT19 German-English test set  (Barrault et al., 2019 ) and obtain ratings from three annotators, for each sentence at each paraphrase system/setting combination. Annotators were paid 0.50 USD per HIT. For our proposed method, we choose three operating points: ? = 0.0005, ?=0.003, and ?=0.006 (Figure  1 ). The middle point of ?=0.003 was chosen so as to produce output with the same lexical diversity as the paraphraser trained on ParaBank 2, as described above. We decode with a beam size of 5, using the fairseq defaults. 

 German & Spanish Evaluation We also collect human judgments in German and Spanish. We follow the evaluation procedure described above for the English paraphraser except that annotations were done by colleagues who were native speakers in these languages. For Spanish, we used the target side of the WMT 2013 English-Spanish test set  (Bojar et al., 2013) . For German, we used the target side of the WMT 2019 English-German test set  (Barrault et al., 2019) . We obtained 50 judgments per set of 3 paraphrases by one German annotator, and 150 judgments per set of 3 paraphrases by three Spanish annotators, both on a random sample of sentences. Multiple paraphrases from our proposed method at different operating points (i.e., different values of ?) were shown to the annotator, in random order. 

 Results 

 English Results Human evaluation results in English are shown in Figure  2 . We find that ? is negatively correlated with grammaticality and semantic similarity between the input and output and positively correlated with lexical diversity of the output with respect to the input, as expected. We find that at the operating point ? = 0.003, which was chosen such that our method has the same lexical diversity as the model trained on Para-Bank 2, the paraphrases from our method were judged to be both more semantically similar to the input and grammatical (slightly) more often. 

 German & Spanish Results The human evaluation results in German and Spanish, along with English for reference, are shown Figure  2 : Human judgments of English paraphrases for semantic similarity (rated 1-100) and the percentage of produced which were rated as grammatical, both as a function of lexical/syntactic diversity (measured via uncased BLEU between input and output). We evaluated our generation method at three operating points (?=0.0005, ?=0.003, and ?=0.006). ?=0.003 was chosen to match such that the proposed method had the same diversity as the model trained on Paracrawl2. At that operating point, humans rated output of our method to be more semantically similar to the reference (87.5 vs. 81.0), and grammatical slightly more often (95.0% vs. 94.5%). in Figure  3 . Note that we have no way to normalize between annotators in different languages, thus the results should not be used to draw conclusions about the relative performance of the paraphraser of these languages. However, we find the trends are similar across all three languages, and that semantic similarity and grammaticality judgements for Spanish and German are both reasonably high. 

 Discussion We hypothesize that our method outperforms the baseline because it does not suffer from a fundamental shortcoming in creating synthetic paraphrase data from bitext: namely that inherent ambiguities present in one language (but not the other) can cause erroneous synthetic paraphrases in the other language (Aziz and Specia, 2013). For the sake of discussion we consider gender 8 as an ambiguity. Suppose we create synthetic English paraphrases from Turkish-English data, and our bitext contains the following (valid) sentence pair: ("O magazaya gitti.", "She went to the store.") Turkish is a gender-neutral language, so when we translate Turkish side to English it is perfectly valid to translate the sentence to "He went to the store." Pairing the original English translation with the translation results in the synthetic paraphrase example ("She went to the store.", "He went to the store."). Since English is gendered, this results in an invalid synthetic paraphrase. In contrast, consider what happens if "She went to the store." is paraphrased by our method. First, the sentence is converted to an intermediate representation by encoder. If the encoder were from an English?Turkish system, it is plausible that the encoder would discard gender information, as it is not needed in the target language. However, our encoder comes from a multilingual system which can produce output in many different languages. Thus, as long as the model has seen a sufficient number of training examples between English and at least one other gendered language, we can reasonably expect that the intermediate representation will preserve gender. Thus, when this representation is passed to the decoder and English is requested as the target language, the model should put low probability on any output for which the subject is male. An alternative way to address pivot language ambiguities is to use multiple pivot languages, as proposed by  Aziz and Specia (2013) . However, it is not clear how best to extend this idea to neural sequence-to-sequence models, or to a multilingual paraphraser. Combining synthetic paraphrases for training using several different pivot languages would mitigate the errors due to ambiguities from any one pivot language, at the expense of errors due to ambiguities in other pivot languages. To really address such errors would require combining models of different language pairs; see  for one such solution. 

 Conclusions We treat paraphrasing as a zero-shot translation task and present a method to control the lexical 8 Czech is, of course, gendered, so we would not expect the ParaBank 2 dataset (which was created from Czech-English bitext) to have gender errors. But the logic presented here should generalize to other ambiguities. diversity of paraphrases generated from a multilingual NMT model, enabling paraphrase generation in many languages. Our approach gives a user finegrained control over the amount of lexical diversity at generation time, and also allows models and generation algorithms to be developed and evaluated with less interdependencies. There are likely many other ways that the output could be controlled to vary other aspects, such as syntactic diversity  (Shu et al., 2019) ; we would like to explore such methods in future work. Our work outperforms an English baseline trained on a large synthetic paraphrase dataset  (Hu et al., 2019b) . This improvement in performance may be because our method does not suffer from the issue that ambiguities in the pivot language used to create synthetic paraphrase data can cause errors in synthetic data. Small experiments indicate our method also performs well in other languages. Multilingual NMT is an active research area and we are optimistic that this approach will pave the way for even stronger paraphrase generation in the future, as multilingual NMT methods continue to improve and models are publicly released. Figure 1 : 1 Figure 1: Example English paraphrase for the three ? values used in this work. 

 Figure 3 : 3 Figure 3: Human judgments of German (De) and Spanish (Es) paraphrases, with English (En) shown for reference, plotted against uncased BLEU computed between the paraphraser input and output. The judgement criteria and ? values match English settings. ? decreases from left to right in all plots. 

			 We release our code at https://github.com/ thompsonb/prism 

			 In this work, we assume words are separated by whitespace. For languages which do not denote word boundaries, our method could likely be applied after tokenizing the input, or by simply treating each SentencePiece token as a word. 

			 We apply the penalty at the start of the generation of the last word of an input n-gram so that the decoder is not encouraged to produce an unnatural completion to an alreadybegun word. 

			 One concern with hard constraints is that there are sometimes words or phrases (e.g., proper nouns) that should not be paraphrased, as doing so would change the meaning of the sentence. Thus heuristics are often used to determine which words/phrases should be constrained.5  In particular, the relative ranking judgements collected through 2016 (Bojar et al., 2016)  are probably the most relevant. 

			 http://casmacat.eu/corpus/ global-voices.html 7 http://nlp.ffzg.hr/resources/corpora/ setimes/
