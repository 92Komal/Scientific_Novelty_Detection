title


abstract


Introduction This volume contains papers describing systems submitted to the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies and an overview paper summarizing the task, its features, evaluation methodology for the main and additional metrics, and some interesting observations about the submitted systems and the task as a whole. This Shared Task (http://universaldependencies.org/conll17/) can be seen as an extension of the CoNLL 2007 Shared Task on parsing, but there are many important differences that make this year's task unique with several "firsts". Most importantly, the data for this task come from the Universal Dependencies project (http://universaldependencies.org), which provides annotated treebanks for a large number of languages using the same annotation scheme for all of them. In the shared task setting, this allows for more meaningful comparison between systems as well as languages, since differences are much more likely due to true parser differences rather than differences caused by annotation schemes. In addition, the number of languages for which training data were available is unprecedented for a single shared task: a total of 64 treebanks in 45 languages have been provided for training the systems. Additional data have been provided too, as were some baseline systems for those who wanted to try only some particular aspect of parsing. Overall, the task can be described as "closed", since only pre-approved data could be used. For evaluation, there were 81 datasets (standard datasets for the treebank languages provided for training, plus more test sets in known languages, but based on a specially created and annotated parallel corpus, and four surprise language test sets). Participants had to process all the test sets. The TIRA platform has been used for evaluation, as was the case already for the CoNLL 2015 and 2016 Shared Tasks, meaning that participants had to provide their code on a designated virtual machine to be run by the organizers to produce official results. However, test data have been published after the official evaluation period, and participants could run their systems at home to produce additional results they were allowed to include in the system description papers. There was one main evaluation metric -Labeled Attachment Score -for the main ranking table evaluating dependency parsing performance, plus additional metrics for tokenization, word and sentence segmentation, POS tagging, lemmatization and disambiguation of morphological features, and separate metrics computed for interesting subsets of the evaluation data. A total of 32 systems ran successfully and have been ranked (http://universaldependencies. org/conll17/results.html). While there are clear overall winners, we would like to thank all participants for working hard on their submissions and adapting their systems not only to the datasets available, but also to the evaluation platform. We would like to thank all of them for their effort, since it is the participants who are the core of any shared task's success.  Table of Contents of CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies Daniel Zeman, Martin Popel, Milan Straka, Jan Hajic, Joakim Nivre, Filip Ginter, Juhani Luotolahti, Sampo Pyysalo, Slav Petrov, Martin Potthast, Francis Tyers, Elena Badmaeva, Memduh Gokirmak, Anna Nedoluzhko, Silvie Cinkova, Jan Hajic jr., Jaroslava Hlavacova, V?clava Kettnerov?, Zdenka Uresova, Jenna Kanerva, Stina Ojala, Anna Missil?, Christopher D. Manning, Sebastian Schuster, Siva Reddy, Dima Taji, Nizar Habash, Herman Leung, Marie-Catherine de Marneffe, Manuela Sanguinetti, Maria Simi, Hiroshi Kanayama, Valeria dePaiva, Kira Droganova, H?ctor Mart?nez Alonso, ?agr? ?ltekin, Umut Sulubacak, Hans Uszkoreit, Vivien Macketanz, Aljoscha Burchardt, Kim Harris, Katrin Marheinecke, Georg Rehm, Tolga Kayadelen, Mohammed Attia, Ali Elkahky, Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael Mandl, Jesse Kirchner, Hector Fernandez Alcalde, Jana Strnadov?, Esha Banerjee, Ruli Manurung, Antonio Stella, Atsuko Shimada, Sookyoung Kwak, Gustavo Mendonca, Tatiana Lando, Rattima Nitisaroj and Josie Li . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Stanford's Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task Timothy Dozat, Peng Qi and Christopher D. Manning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Combining Global Models for Parsing Universal Dependencies Tianze Shi, Felix G. Wu, Xilun Chen and Yao Cheng . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 IMS at the CoNLL 2017 UD Shared Task: CRFs and Perceptrons Meet Neural Networks Anders Bj?rkelund, Agnieszka Falenska, Xiang Yu and Jonas Kuhn . . . . . . . . . . . . . . . . . . . . . . . . . 40 The HIT-SCIR System for End-to-End Parsing of Universal Dependencies Wanxiang Che, Jiang Guo, Yuxuan Wang, Bo Zheng, Huaipeng Zhao, Yang Liu, Dechuan Teng and Ting Liu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 A System for Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations KyungTae Lim and Thierry Poibeau . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 Adversarial Training for Cross-Domain Universal Dependency Parsing Motoki Sato, Hitoshi Manabe, Hiroshi Noji and Yuji Matsumoto . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 Parsing with Context Embeddings ?mer K?rnap, Berkay Furkan ?nder and Deniz Yuret . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe Milan Straka and Jana Strakov? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 UParse: the Edinburgh system for the CoNLL 2017 UD shared task Clara Vania, Xingxing Zhang and Adam Lopez . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 Multi-Model and Crosslingual Dependency Analysis Johannes Heinecke and Munshi Asadullah . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 TurkuNLP: Delexicalized Pre-training of Word Embeddings for Dependency Parsing Jenna Kanerva, Juhani Luotolahti and Filip Ginter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 The parse is darc and full of errors: Universal dependency parsing with transition-based and graphbased algorithms Kuan Yu, Pavel Sofroniev, Erik Schill and Erhard Hinrichs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
