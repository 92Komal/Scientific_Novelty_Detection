title
Towards Universal Dialogue State Tracking

abstract
Dialogue state tracking is the core part of a spoken dialogue system. It estimates the beliefs of possible user's goals at every dialogue turn. However, for most current approaches, it's difficult to scale to large dialogue domains. They have one or more of following limitations: (a) Some models don't work in the situation where slot values in ontology changes dynamically; (b) The number of model parameters is proportional to the number of slots; (c) Some models extract features based on hand-crafted lexicons. To tackle these challenges, we propose StateNet, a universal dialogue state tracker. It is independent of the number of values, shares parameters across all slots, and uses pre-trained word vectors instead of explicit semantic dictionaries. Our experiments on two datasets show that our approach not only overcomes the limitations, but also significantly outperforms the performance of state-of-the-art approaches.

Introduction A task-oriented spoken dialogue system (SDS) is a system that can continuously interact with a human to accomplish a predefined task through speech. It usually consists of three modules: input, output, and control. The control module is also referred to as dialogue management  Yu et al., 2014) . It has two missions: dialogue state tracking (DST) and decision making. At each dialogue turn, a state tracker maintains the internal state of the system based on the information received from the input module. Then a machine action is chosen based on the dialogue state according to a dialogue policy to direct the dialogue . The dialogue state is an encoding of the machine's understanding of the whole conversation. Traditionally, it is usually factorized into three distinct components  (Young et al., 2013) : the user's goal, the user's action, and the dialogue history. Among them, the user's goal is most important, which is often simply represented by slot-value pairs. In this paper, we focus on the tracking of the user's goal. Recently, the dialogue state tracking challenges (DSTCs)  Henderson et al., 2014a,d)  are organized to provide shared tasks for comparing DST algorithms. A various of models are proposed, e.g. rule-based models  (Wang and Lemon, 2013; Sun et al., 2014a; Yu et al., , 2016 Sun et al., 2016b) , generative statistical models  Young et al., , 2013 , and discriminative statistical models  (Lee and Eskenazi, 2013; Lee, 2013; Sun et al., 2014b; Xie et al., 2015; Sun et al., 2016a; Xie et al., 2018) . And the state-of-the-art one is the deep learning-based approach. However, most of these models have some limitations. First, some models can only work on a fixed domain ontology, i.e. the slots and values are defined in advance, and can't change dynamically. However, this is not flexible in practice  (Xu and Hu, 2018) . For example, in the tourist information domain, new restaurants or hotels are often added, which results in the change of the ontology. Second, in many approaches the models for every slot are different. Therefore, the number of parameters is proportional to the number of slots. Third, some models extract features based on text delexicalisation  (Henderson et al., 2014b) , which depends on predefined semantic dictionaries. In large scale domains, it's hard to manually construct the semantic dictionaries for all slots and values . To tackle these challenges, here we propose a universal dialogue state tracker, StateNet. For each state slot, StateNet generates a fixed-length representation of the dialogue history, and then compares the distances between this representation and the value vectors in the candidate set for making prediction. The set of candidate values (3) the literal names of the slots and the values. The manually-tagging of the user utterance is not needed as a part of the data. StateNet shares parameters among all slots, through which we can not only transfer knowledge among slots but also reduce the number of parameters. 

 StateNet: A Universal Dialogue State Tracker For each dialogue turn, StateNet takes the multiple n-gram user utterance representation, r n u , the n-gram machine act representation, r n a , the value set, V s , and the word vector of the slot, s, as the input. Then StateNet applies the Long Short-Term Memory (LSTM)  (Hochreiter and Schmidhuber, 1997)  to track the inner dialogue states among the dialogue turns. And for each slot, StateNet outputs a corresponding probability distribution, p s , over the set of possible values, V s , at each of the dialogue turn, p s = StateNet(r n u , r n a , s, V s ). The general model architecture is shown in Figure  1 . 

 User Utterance Representation At the t-th dialogue turn, the user utterance, U t , may consist of l number of words, u i , with their corresponding word vectors, u i , (1 ? i ? l). The user utterance may also have its corresponding mbest ASR hypotheses with the normalized confidence scores  (Chen et al., 2017) , q j ,(1 ? j ? m). In this case, we can calculate the weighted word vectors, u i , u i = m j=1 q j u i,j , where u i,j represents the word vector u i presented at the j-th ASR hypothesis, and the zero vectors are padded at the end of all the hypotheses that are shorter than the longest one to have a same length of the utterance. Based on the weighted word vectors generalizing the information from the ASR hypothesis, we can then construct the n-gram weighted word vectors, as proposed by , u n i = u i ? ... ? u i+n?1 , where ? is the concatenation operator between the word vectors. An n-gram user utterance representation is then constructed through a sum of the n-gram weighted word vectors, For each gram k of the user utterance representation, r k u , (1 ? k ? n), the Multi-scale Receptors Layer has c number of linear neural networks (with the same number of neurons, N c ). Each of them takes the representation as input and is expected to work as the specialized receptor to amplify the signals from some of the word vectors in the utterance representation, r n u = l?n+1 i=1 u n i . 

 Multi-scale Receptors Layer rk u = ? c j=1 (W j k r k u + b j k ), where W j k means the weight of the j-th linear layer, b j k means the corresponding bias, and ? is the concatenation operator between the neurons of these linear layers. Note that each receptor does not necessarily has to be a single linear neural network and can be sophisticated with multiple layers and non-linearity for better detection performance. Here we only use the linear layer to provide a baseline of this kind of structure design. These c number of linear layers (or receptors) for different grams (or scales) of the representation rk u is then summed together to be layer-normalized  (Ba et al., 2016) . After that, the ReLU activation function is applied, followed by a linear layer with the size N c that maps all the receptors to a user feature vector, f u , f u = Linear(ReLU(LayerNorm( n k=1 rk u ))). 

 Machine Act Representation We represent the machine act in the m order ngram of bag of words, r m a , based on the vocabularies generalized from the machine acts in the training set of a given data set. The machine act feature, f a , is then simply generated through a linear layer of size N c with the ReLU activation function, f a = ReLU(Linear(r m a )). 

 Slot Information Decoding Since a slot, e.g. area or food, is usually indicated as a word or a short word group, then it can be represented as a single word vector (with multiple word vectors summed together), s. A single linear layer with the size 2N c is applied to the word vector s, followed by the ReLU non-linear layer, f s = ReLU(Linear(s)). The turn-level feature vector, i s , is then generated through a point-wise multiplication ? between the slot feature and the concatenation of the user feature and the machine act feature, i s = f s ? (f u ? f a ). In this way, the turn-level feature vector is intended to amplify the large magnitude signals that are from both the user and machine act feature vector and the slot feature vector. 

 Fixed-length Value Prediction Given the turn-level feature vector, i s , we can now track the dialogue state throughout the dialogue turns by LSTM. For the current turn t, the LSTM takes the i s and the previous hidden state, q t?1 , as the input. We can then obtain a fixed-length value prediction vector, o s , whose length is equal to N w , i.e. the dimension of the word vectors which are fed into the model, o s = ReLU(Linear(LSTM(i s , q t?1 ))), where the linear layer has N w neurons. In this way, the prediction of the model is independent of the number of the given values, so it is possible for the model to perform parameter sharing among each of the slots. The fixed-length prediction can somehow be interpreted as a word vector that is ready for the calculation of the similarity between the prediction and the true value label. 

 2-Norm Distance For a specific semantic slot, since there may be no corresponding value in a given dialogue turn, thus we always add a literally "none" value to the value set for the model to track this state. For the evaluation of the similarity between the prediction and the value, we calculate the 2-Norm distance between the prediction vector and each of the word vectors of the values in the value set. Softmax function is performed with respect to all the negative relative distances to give a distribution of probabilities for the values, v i ? V s , p s (v i ) = Softmax(?||o s ? v i ||), where v i is the representation vector of v i . If the slot value v i consists of more than one word, v i will then be the summation of all corresponding word vectors. When training the model, we minimize the Cross-Entropy (CE) loss between the output probabilities and the given label. StateNet requires the user utterance, the semantic slots, and slot values to be able to be expressed in words and have their corresponding word vectors. We use the fixed word embedding for every word, and do not fine-tune the word embeddings in the model. Since the word embeddings are distributed on a fixed-dimension vector space and hold rich semantic information, StateNet may have the ability to track the dialogue state for any new slot or value, as long as the corresponding word embedding can be found. This is the reason why we call the StateNet a universal dialogue state tracker. 

 Experiments Experiments are conducted to assess the performance on joint goal. Two datasets are used by us for training and evaluation. One is the second Dialogue State Tracking Challenge (DSTC2) dataset  (Henderson et al., 2014a) , and the other is the second version of Wizard-of-Oz (WOZ 2.0) dataset . Both of them are the conversations between users and a machine system. The user's goal is to find a suitable restaurant around Cambridge. The ontology of these two datasets is identical, which is composed of three informable slots: food, pricerange and area. The main difference between them is that in WOZ 2.0, users typed instead of using speech directly. This means the users can use far more sophisticated language than they can in the DSTC2, which is a big challenge for the language understanding ability of the model. Thus, it allows WOZ 2.0 to be more indicative of the model's actual performance since it is immune to ASR errors. Based on the model structure as described in Section 2, we implement three kinds of dialogue state tracker. The difference among them lies in the utilization of parameter sharing and parameter initialization. The hyperparameters are identical for all three models, N c = 128, N w = 300, n = 2, m = 3. We use c = 4 for the number of the receptors for each slot, where the number is determined through the grid search. The word embeddings used by us is the semantically specialised Paragram-SL999 vectors  (Wieting et al., 2015)  with the dimension of 300, which contain richer semantic contents compared to other kinds of word embeddings. Implemented with the MXNet deep learning framework of Version 1.1.0, the model is trained with a batch size of 32 for 150 epochs on a single NVIDIA GTX 1080Ti GPU. The results in Table  1  show the effectiveness of parameter sharing and initialization. StateNet PS outperforms StateNet, and StateNet PSI performs best among all 3 models. It is because the parameter sharing can not only prevent the model diverging from the right learning process but also transfer necessary knowledge among different slots. And the parameter initialization provides the model with the opportunity to gain some basic while essential semantic information at the very beginning since the food slot is the most important and difficult one. Besides, StateNet PSI beats all the mod-DST Models Joint Acc. DSTC2 Joint Acc. WOZ 2.0 Delexicalisation-Based (DB) Model  69.1 70.8 DB Model + Semantic Dictionary  72.9 83.7 Scalable Multi-domain DST  (Rastogi et al., 2017)  70.3 -MemN2N  (Perez and Liu, 2017)  74.0 -PtrNet  (Xu and Hu, 2018)  72.1 -Neural Belief Tracker: NBT-DNN  72.6 84.4 Neural Belief Tracker: NBT-CNN  73 els reported in the previous literature, whether the model with delexicalisation  (Henderson et al., 2014b,c; Rastogi et al., 2017)  or not  Perez and Liu, 2017; Xu and Hu, 2018; Ramadan et al., 2018; Zhong et al., 2018) . We also test StateNet PSI with different pre-trained models, as shown in Table  2 . The fact that the food initialization has the best performance verifies our selection of the slot with the worst performance for pre-training. This is because the good performance on joint goal requires a model to make correct predictions on all of the slots. A slot on which the model has the worst accuracy, i.e. the most difficult slot, will dramatically limit the overall model performance on the metric of the joint goal accuracy. Thus, the initialization with a model pre-trained on the most difficult slot can improve the performance of the model on its weakness slot and boost the joint goal accuracy, while the initialization of a strength slot may not help much for the overall accuracy but in turn causes the over-fitting problem of the slot itself. 

 Initialization 

 Conclusion In this paper, we propose a novel dialogue state tracker that has the state-of-the-art accuracy as well as the following three advantages: 1) the model does not need manually-tagged user utterance; 2) the model is scalable for the slots that need tracking, and the number of the model parameters will not increase as the number of the slots increases, because the model can share parameters among different slots; 3) the model is independent of the number of slot values, which means for a given slot, the model can make the prediction on a new value as long as we have the corresponding word vector of this new value. If there are a great number of values for a certain slot, to reduce the computational complexity, we can utilize a fixed-size candidate set  (Rastogi et al., 2017) , which dynamically changes as the dialogue goes on. Experiment results demonstrate the effectiveness of parameter sharing & initialization. Our future work is to evaluate the performance of our models in the scenario where there are new slots and more unobserved slot values, and to evaluate the domain-transferring ability of our models. Figure 1 : 1 Figure 1: General model architecture of StateNet. 
