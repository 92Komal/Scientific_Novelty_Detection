title
Knowledge Diffusion for Neural Dialogue Generation

abstract
End-to-end neural dialogue generation has shown promising results recently, but it does not employ knowledge to guide the generation and hence tends to generate short, general, and meaningless responses. In this paper, we propose a neural knowledge diffusion (NKD) model to introduce knowledge into dialogue generation. This method can not only match the relevant facts for the input utterance but diffuse them to similar entities. With the help of facts matching and entity diffusion, the neural dialogue generation is augmented with the ability of convergent and divergent thinking over the knowledge base. Our empirical study on a real-world dataset proves that our model is capable of generating meaningful, diverse and natural responses for both factoid-questions and knowledge grounded chi-chats. The experiment results also show that our model outperforms competitive baseline models significantly.

Introduction Dialogue systems are receiving more and more attention in recent years. Given previous utterances, a dialogue system aims to generate a proper response in a natural way. Compared with the traditional pipeline based dialogue system, the new method based on sequence-to-sequence model  (Shang et al., 2015; Vinyals and Le, 2015; Cho et al., 2014)  impressed the research communities with its elegant simplicity. Such methods are usually in an end-to-end manner: utterances are encoded by a recurrent neural network while responses are generated sequentially by another (sometimes identical) recurrent neural network. However, due to lack of universal background knowledge and common senses, the endto-end data-driven structure inherently tends to generate meaningless and short responses, such as "haha" or "I don't know." To bridge the gap of the common knowledge between human and computers, different kinds of knowledge bases ( e.g., the freebase  (Google, 2013)  and DBpedia  (Lehmann et al., 2017)  ) are leveraged. A related application of knowledge bases is question answering, where the given questions are first analyzed, followed by retrieving related facts from knowledge bases (KBs), and finally the answers are generated.The facts are usually presented in the form of "subject-relationobject" triplets, where the subject and object are entities. With the aid of knowledge triplets, neural generative question answering systems are capable of answering facts related inquiries  (Yin et al., 2016; Zhu et al., 2017; He et al., 2017a) , WH questions in particular, like "who is Yao Ming's wife ?". Although answering enquiries is essential for dialogue systems, especially for task-oriented dialogue systems  (Eric et al., 2017) , it is still far behind a natural knowledge grounded dialogue system, which should be able to understand the facts involved in current dialogue session (socalled facts matching), as well as diffuse them to other similar entities for knowledge-based chitchats (i.e. entity diffusion): 1) facts matching: in dialogue systems, matching utterances to exact facts is much harder than explicit factoid inquiries answering. Though some utterances are facts related inquiries, whose subjects and relations can be easily recognized, for some utterances, the subjects and relations are elusive, which leads the trouble in exact facts matching.    1  shows an example: Item 1 and 2 are talking about the film "Titanic", Unlike item 1, which is a typical question answering conversation,item 2 is a knowledge related chit-chat without any explicit relation. It is difficult to define the exact fact match for item 2. 2) entity diffusion: another noticeable phenomenon is that the conversation usually drifts from one entity to another. In Table  1 , utterances in item 3 and 4 are about entity "Titanic", however, the entity of responses are other similar films. Such entity diffusion relations are rarely captured by the current knowledge triplets. The response in item 3 shows that the two entities "Titanic" and "Waterloo Bridge" are relevant through "love stories". Item 4 suggests another similar shipwreck film of "Titanic". To deal with the aforementioned challenges, in this paper, we propose a neural knowledge diffusion (NKD) dialogue system to benefit the neural dialogue generation with the ability of both convergent and divergent thinking over the knowledge base, and handle factoid QA and knowledge grounded chit-chats simultaneously. NKD learns to match utterances to relevant facts; the matched facts are then diffused to similar entities; and finally, the model generates the responses with respect to all the retrieved knowledge items. In general, our contributions are as follows: ? We identify the problem of incorporating knowledge bases and dialogue systems as facts matching and entity diffusion. ? We manage both facts matching and entity diffusion by introducing a novel knowledge diffusion mechanism and generate the responses with the retrieved knowledge items, which enable the convergent and divergent thinking over the knowledge base. ? The experimental results show that the proposed model effectively generate more diverse and meaningful responses involving more accurate relevant entities compared with the state-of-the-art baselines. The corpus will be released upon publication. 2 Model Given the input utterance X = (x 1 , x 2 , ..., x N X ), NKD produces a response Y = (y 1 , y 2 , ..., y N Y ) containing the entities from the knowledge base K. N X and N Y are the number of tokens in the utterance and response respectively. The knowledge base K is a collection of knowledge facts in the form of triplets (subject, relation, object). In particular, both subjects and objects are entities in this work. As illustrated in Figure  1 , the model mainly consists of four components: 1. An encoder encodes the input utterance X into a vector representation. 2. A context RNN keeps the dialogue state along a conversation session. It takes the utterance representation as input, and outputs a vector guiding the response generation each turn. 3. A decoder generates the final response Y . 4. A knowledge retriever performs the facts matching and diffuses to similar entities at each turn. Our work is built on hierarchical recurrent encoder-decoder architecture  (Sordoni et al., 2015a) , and a knowledge retriever network integrates the structured knowledge base into the dialogue system. 

 Encoder The encoder transforms discrete tokens into vector representations. To capture information at different aspects, we learn utterance representations with two independent RNNs resulting with two hidden state sequences H C = (h C 1 , h C 2 , ..., h C N X ) and H K = (h K 1 , h K 2 , ..., h K N X ) respectively. One final hidden state h C N X is used as the input of context RNN to track the dialogue state. The other final hidden state h K N X is utilized in knowledge retriever and is designed to encode the knowledge entities and relations within the input utterances. For instance, in Figure  1 , "director" and "Titanic" in X 1 are knowledge elements. 

 Knowledge Retriever Knowledge retriever extracts a certain number of facts from knowledge base and specifies their importance. It enables the knowledge grounded neural dialogue system with convergent and divergent thinking ability through facts matching and entity diffusion. Figure  2  illustrates the process. 

 Facts Matching Given the input utterance X and h K N X , relevant facts are extracted from both the knowledge base and the dialogue history. A predefined number of relevant facts F = {f 1 , f 2 , ..., f N f } are obtained through string matching, entity linking or named entity recognition. As shown in Figure  2 , in the first sentence, "Titanic" is recognized as an entity, all the relevant knowledge triplets are extracted. Then, these entities and knowledge triplets are transformed into fact representations h f = {h f 1 , h f 2 , ...h f N f } by averaging the entity embedding and relation embedding. The relevance coefficient r f between a fact and the input utterances, ranging from 0 to 1, is calculated by a nonlinear function or a sub neural network. Here, we apply a multi-layer perceptron (MLP): r f k = M LP ([h K N X , h f k ]). For the multi-turn conversation, entities in previous utterances are also inherited and reserved as depicted in Figure  2  the dotted lines. For instance, in the second sentence of Figure  2  (right one), no new fact is extracted from the input utterance. Thus it is necessary to record the history entities "Titanic" and "James Cameron". We summarize the facts as relevant fact representation C f through a weighted average of fact representations h f : C f = N f k=1 r f k h f k N f k=1 r f k . 

 Entity Diffusion To retrieve other relevant entities, which are typically not mentioned in the dialogue utterance, we diffuse the matched facts. We calculate the similarity between the entities (except the entities that have occurred in previous utterances) in the knowledge base and the relevant fact representation through a multi-layer perceptron, resulting with a similarity coefficient r e , ranging from 0 to 1: r e k = M LP ([h K N X , C f , e k ]) , where e k is the entity embedding. The top N e number of entities E = {e 1 , e 2 , ..., e Ne } are selected as similar entities. Then, the similar entity representation C s is formalized as: C s = Ne k=1 r e k e k Ne k=1 r e k . Back to the example in Figure  2 , in the first turn, the matched fact of the input utterance (T itanic, direct by, JamesCameron) is of a high relevance coefficient in "facts matching" as expected. When a fact getting matched, intuitively it is not necessary for entity diffusion. In such case, from the Figure  2 , we observe that the entities in "entity diffusing" are of low similarities. In the second turn, there is no triplets matched to the utterance, while the entity "Titanic" achieves a much higher relevance score. Then in "entity diffusion", the similar entities "Waterloo Bridge" and "Poseidon" get relatively higher similarity weights than in the first turn. 

 Context RNN Context RNN records the utterance level dialogue state. It takes in the utterance representation and the knowledge representations. The hidden state of the context RNN is updated as: h T t = RN N (h C t , [C f , C s ], h T t?1 ). h T t is then conveyed to the decoder to guide the response generation. 

 Decoder The decoder generates the response sequentially through a word generator conditioned on h T t , C f and C s . Let C denotes the concatenation of h T t , C f and C s . Knowledge items coefficient R is the concatenation of relevance coefficient r f and similarity coefficient r e . We introduce two variants of word generator: Vanilla decoder simply generates the response Y = (y 1 , y 2 , ..., y Ny ) according to C, R. The    (Yin et al., 2016)  to indicate whether the t th word is generated from common vocabulary or knowledge entities. The probability of generating the t th word is given by: p(y t |y t?1 , s t , C, R; ?) =p(z t = 0|s t ; ?)p(y t |y t?1 , s t , C, R, z t = 0; ?) +p(z t = 1|s t ; ?)p(y t |R, z t = 1; ?), where p(z t |s t ; ?) is computed by a logistic regression, p(y t |R, z t = 1; ?) is approximated with the knowledge items coefficient R, and ? is the model parameter. During response generation, if an entity is overused, the response diversity will be reduced. Therefore, once a knowledge item occurred in the response, the corresponding coefficient should be reduced in case that an item occurs multiple times. To keep tracking the coverage of knowledge items, we update the knowledge items coefficient R at each time step. We also explore two coverage tracking mechanisms: 1) Mask coefficient tracker directly reduces the coefficient of the chosen knowledge item to 0 to ensure it can never be selected as the response word again. 2) Coefficient attenuation tracker calculates an attenuation score i t based on s t , R 0 , R t?1 and y t?1 : i t = DN N (s t , y t?1 , R 0 , R t?1 ), and then update the coefficient as: R t = i t ? R t?1 , where i t ranges from 0 to 1 to gradually decrease the coefficient. 

 Training The model parameters include the embedding of vocabulary, entities, relations, and all the model components. The model is differential and can be optimized in an end-to-end manner using backpropagation. Given the training data D = {(X N d 1 , Y N d 1 , F N d 1 , E N d 1 )} where N d is the max turns of a dialogue, F denotes the set of relevant knowledge and E denotes the set of similar knowledge in response, the objective function is to minimize the negative loglikelihood: (D, ?) = ? N D i=1 log p(Y i |X i , F i , E i ) 3 Experiment 

 Dataset Most existing knowledge related datasets are mainly focused on single-turn factoid question answering  (Yin et al., 2016; He et al., 2017b) . We here collect a multi-turn conversation corpus grounded on the knowledge base, which includes not only facts related inquiries but also knowledge-based chit-chats. The data is publicly available online 1 . We first obtain the element information of each movie, including the movie's title, publication time, directors, actors and other attributes from https://movie.douban.com/, a popular Chinese social network for movies. Then, entities and relations are extracted as triplets to build the knowledge base K. To collect the question-answering dialogues, we crawled the corpus from a question-answering forum https://zhidao.baidu.com/. To gather the knowledge related chit-chat corpus, we mined the dataset from the social forum https://www.douban.com/group/. Users post their comments, feedbacks, and impressions of films and televisions on it. The conversations are grounded on the knowledge using NER, string match, and artificial scoring and filtering rules. The statistical information of the dataset is shown in Table  2 . We observed that the conversations follow the long tail distribution, where famous films and televisions are discussed repeatedly and the low rating ones are rarely mentioned. 

 Experiment Detail The total 32977 conversations consisting of 104567 utterances are divided into training (32177) and testing set (800). Bi-directional LSTM  (Schuster and Paliwal, 1997)    

 Baselines We compare our neural knowledge diffusion model with three state-of-the-art baselines: ? Seq2Seq: a sequence to sequence model with vanilla RNN encoder-decoder  (Shang et al., 2015; Vinyals and Le, 2015) . ? HRED: a hierarchical recurrent encoderdecoder model. ? GenDS: a neural generative dialogue system that is capable of generating responses based on input message and related knowledge base (KB)  (Zhu et al., 2017)  . Three variants of the neural diffusion dialogue generation model are implemented to verify different configurations of decoders. ? NKD-ori is the original model with a vanilla decoder and a mask coefficient tracker. ? NKD-gated is augmented with a probabilistic gated decoder and a mask coefficient tracker. ? NKD-atte utilizes a vanilla decoder and the coefficient attenuation tracker. 

 Evaluation Metric Both automatic and human evaluation metrics are used to analyze the model's performance. To validate the effectiveness of facts matching and diffusion, we calculate entity accuracy and recall on factoid QA data set as well as the whole data set. Human evaluation rates the model in three aspects: fluency, knowledge relevance and correctness of the response. All these metrics range from 0 to 3, where 0 represents complete error, 1 for partially correct, 2 for almost correct, 3 for absolutely correct. 

 Experiment Result Table  3  displays the accuracy and recall of entities on factoid question answering dialogues. The performance of NKD is slightly better than the specific QA solution GenDS, while LSTM and HRED which are designed for chi-chat almost fail in this task. All the variants of NKD models are capable of generating entities with an accuracy of 60% to 70%, and NKD-gated achieves the best performance with an accuracy of 77.6% and a recall of 77.3%. Table  4  lists the accuracy and recall of entities on the entire dataset including both the factoid QA and knowledge grounded chit-chats. Not surprisingly, both NKD-ori and NKD-gated outperform GenDS on the entire dataset, and the relative improvement over GenDS is even higher than the improvement in QA dialogues. It confirms that although NKD and GenDS are comparable in answering factoid questions, NKD is better at introducing the knowledge entities for knowledge grounded chit-chats. All the NKD variants in accuracies and recalls. We also noticed that NKDgated achieves the highest accuracy and recall, but generates fewer entities compared with NKDori and NKD-gated, whereas NKD-atte generates more entities but also with relatively low accuracies and recalls.This demonstrates that NKDgated not only learns to generate more entities but also maintains the quality ( with a relatively high accuracy and recall ). The results of human evaluation in Table 5 also validate the superiority of the proposed model, especially on appropriateness. Responses generated by LSTM and HRED are of high fluency, but are simply repetitions, or even dull responses as "I don't know.", "Good.". NKD-gated is more adept at incorporating the knowledge base with respect to appropriateness and correctness, while NKDatte generates more fluent responses. NKD-ori is a compromise, and obtains the best correctness in completing an entire dialogue. Four evaluators rated the scores independently. The pairwise Cohen's Kappa agreement scores are 0.67 on fluency, 0.54 on appropriateness, and 0.60 on entire correctness, which indicate a strong annotator agreement. To our surprise, one of the variant model of NKD, which utilized both probabilistic gated decoder and coefficient attenuation tracker does not perform well on entire dataset. The accuracy of the model is quite high, but the recall is very low compared to others. We speculate that this is due to the method of minimizing negative log-likelihood during the training process, which makes the model tend to generate completely correct answers, and therefore reduces the number of generated entities. 

 Case Study Table  6  shows typical examples of the generated responses. Both Item 1 and 2 are based on facts relevant utterances. NKD handles these questions by facts matching. Item 3 asks for a recommen-dation. NKD obtains similar entities by diffusing the entities. For item 4, 5 and 6, no explicit entity appears in the utterances. NKD is able to output appropriate recommendations through entity diffusion. The entities are recorded during the whole dialogue session, so NKD keeps recommending for several turns. Item 7 fails to generate an appropriate response because the entity in the golden response does not appear in the training set, which suggests the future work for out-ofvocabulary cases. 

 Related Work The successes of sequence-to-sequence architecture  (Cho et al., 2014; Sutskever et al., 2014)  motivated investigation in dialogue systems that can effectively learn to generate a response sequence given the previous utterance sequence  (Shang et al., 2015; Sordoni et al., 2015b; Vinyals and Le, 2015) . The model is trained to minimize the negative log-likelihood of the training data. Despite the current progress, the lack of response diversity is a notorious problem, where the model inherently tends to generate short, general responses in spite of different inputs.  Li et al. (2016a) ;  Serban et al. (2017) ;  Cao and Clark (2017)  suggested that theses boring responses are common in training data and shorter responses are more likely to be given a higher likelihood. To tackle the problem,  Li et al. (2016a)  introduced a maximum mutual information training objective.  Serban et al. (2017) ,  Cao and Clark (2017)  and  Chen et al. (2018)  used latent variables to introduce stochasticity to enhance the response diversity.  Vijayakumar et al. (2016) ,  Shao et al. (2017)  and  Li et al. (2016b)  recognized that the greedy search decoding process, especially beam-search with a wide beam size, leads the short responses possess higher likelihoods. They reserved more diverse candidates during beam-search decoding. In this paper, we present that the absence of background knowledge and common sense is another source of lacking diversity. We augment the knowledge base to endto-end dialogue generation. Another research line comes from the utilizing of knowledge bases. A typical application is question-answering (QA) systems. The end-toend QA also resort to the encoder-decoder framework  (Yin et al., 2016; He et al., 2017a) .  Yin et al. (2016)  enquired the knowledge-base to achieve one fact and answer the simple factoid questions by referring to the fact.  He et al. (2017a)  extended this approach by augmenting the copying mechanism and enabled the output words to copy from the original input sequence.  Eric et al. (2017)  noticed that neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base and they addressed the problem by augmenting the end-to-end structure with a key-value retrieval mechanism where a separate attention is performed over the key of each entry in the KB.  Ghazvininejad et al. (2017)  represented the unstructured text as bag of words representation and also performed soft attention over the facts to retrieve a facts vector.  Zhu et al. (2017)  generated responses with any number of answer entities in the structured KB, even when these entities never appear in the training set.  Dhingra et al. (2017)  proposed a multi-turn dialogue agent which helps users search knowledge base by soft KB lookup. In our model, we perform not only facts matching to answer factoid inquiries, but also entity diffusion to infer similar entities. Given previous utterances, we retrieve the relevant facts, diffuse them, and generate responses based on diversified rele-vant knowledge items. 

 Conclusion In this paper, we identify the knowledge diffusion in conversations and propose an end-to-end neural knowledge diffusion model to deal with the problem. The model integrates the dialogue system with the knowledge base through both facts matching and entity diffusion, which enable the convergent and divergent thinking over the knowledge base. Under such mechanism, the factoid question answering and knowledge grounded chitchats can be tackled together. Empirical results show the proposed model is able to generate more meaningful and diverse responses, compared with the state-of-the-art baselines. In future work, we plan to introduce reinforcement learning and knowledge base reasoning mechanisms to improve the performance. is my favorite film! ? B: The love inside it is so touching. ? 3 A: Is there anything like the Titanic? ? B: I think the love story in film Waterloo Bridge is beautiful, too. ? 4 A: Is there anything like the Titanic? ? B: Poseidon is also a classic marine film. ? 
