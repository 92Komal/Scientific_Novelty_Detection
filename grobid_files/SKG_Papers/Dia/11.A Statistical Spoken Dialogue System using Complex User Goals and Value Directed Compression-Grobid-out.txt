title
A Statistical Spoken Dialogue System using Complex User Goals and Value Directed Compression

abstract
This paper presents the first demonstration of a statistical spoken dialogue system that uses automatic belief compression to reason over complex user goal sets. Reasoning over the power set of possible user goals allows complex sets of user goals to be represented, which leads to more natural dialogues. The use of the power set results in a massive expansion in the number of belief states maintained by the Partially Observable Markov Decision Process (POMDP) spoken dialogue manager. A modified form of Value Directed Compression (VDC) is applied to the POMDP belief states producing a near-lossless compression which reduces the number of bases required to represent the belief distribution.

Introduction One of the main problems for a spoken dialogue system (SDS) is to determine the user's goal (e.g. plan suitable meeting times or find a good Indian restaurant nearby) under uncertainty, and thereby to compute the optimal next system dialogue action (e.g. offer a restaurant, ask for clarification). Recent research in statistical SDSs has successfully addressed aspects of these problems through the application of Partially Observable Markov Decision Process (POMDP) approaches  (Thomson and Young, 2010; Young et al., 2010) . However POMDP SDSs are currently limited by the representation of user goals adopted to make systems computationally tractable. Work in dialogue system evaluation, e.g.  Walker et al. (2004)  and  Lemon et al. (2006) , shows that real user goals are generally sets of items, rather than a single item. People like to explore possible trade offs between the attributes of items.  Crook and Lemon (2010)  identified this as a central challenge for the field of spoken dialogue systems, proposing the use of automatic compression techniques to allow for extended accurate representations of user goals. This paper presents a proof of concept of these ideas in the form of a complete, working spoken dialogue system. The POMDP dialogue manager (DM) of this demonstration system uses a compressed belief space that was generated using a modified version of the Value Directed Compression (VDC) algorithm as originally proposed by  Poupart (2005) . This demonstration system extends work presented by  Crook and Lemon (2011)  in that it embeds the compressed complex user goal belief space into a working system and demonstrates planning (and acting) in the compressed space. 

 Complex User Goals The type of SDS task that we focus on is a limiteddomain query-dialogue, also known as a "slot filling" task. The spoken dialogue system has knowledge about some set of objects where these objects have attributes and these attributes can take several values. An object can thus be described by a conjunction of attribute-value pairs. A dialogue progresses with the system obtaining requirements from the user which are specified in terms of attribute values. The system should eventually present objects (search results) based upon its understanding of the user's requirement. The dialogue ends when the user accepts one of the domain objects. Prior work on POMDP SDSs has assumed that a user has a narrowly constrained goal (as speci- fied in terms of the domain objects) and thus the role of the DM is one of reducing uncertainty until its belief is strongly focused on a particular domain object. This has the unfortunate effect of forcing users to select one domain object in order to progress the dialogue, see Table  1 . Note that the example given is problematic not only because the user wants two different food types but because they have different requirements associated with each, i.e. Thai restaurants should be in the centre and cheap, while any French restaurants should be expensive 1 and can be located anywhere. To our knowledge such a combination of goals with different attribute values cannot be straightforwardly handled by comparable state-of-the-art statistical SDSs which appear in the literature.  Crook and Lemon (2011)  suggest that rather than the DM assuming that the user has a single narrowly constrained goal in mind, it should assume that they want any possible sub-set of the complete set of domain objects. Thus, instead of maintaining the POMDP belief over individual domain objects, it should be maintained over the power set of domain objects. As an example see Table  3  which is the power set for a domain with three objects that can take two attributes u, v with associated values u1, u2, u3 and v1 respectively. The power set representation allows the demonstration system to straightforwardly handle previously problematic dialogues. See Table  2 . Of course this approach significantly expands the 1 Interpreted as non-budget by the system since its database only classifies restaurants as budget or non-budget. state space of possible user goals, with the number of goal sets being equal to 2 |domain objects| . 

 Automatic Compression Even considering limited domains, POMDP state spaces for SDSs grow very quickly. Thus the current state-of-the-art in POMDP SDSs uses a variety of handcrafted compression techniques, such as making several types of independence assumption as discussed above. Crook and Lemon (2010) propose replacing handcrafted compressions with automatic compression techniques. The idea is to use principled statistical methods for automatically reducing the dimensionality of belief spaces, but which preserve useful distributions from the full space, and thus can more accurately represent real user's goals. 

 VDC Algorithm The VDC algorithm  (Poupart, 2005)  uses Krylov iteration to compute a reduced state space. It finds a set of linear basis vectors that can reproduce the value 2 of being in any of the original POMDP states. Where, if a lossless VDC compression is possible, the number of basis vectors is less than the original number of POMDP states. The intuition here is that if the value of taking an action in a given state has been preserved then planning is equally as reliable in the compressed space as the in full space. The VDC algorithm requires a fully specified POMDP, i.e. S, A, O, T, ?, R where S is the set state goal set meaning: user's goal is s 1 ? (empty set) none of the domain objects s 2 u = u1 ? v = v1 domain object 1 s 3 u = u2 ? v = v1 domain object 2 s 4 u = u3 ? v = v1 domain object 3 s 5 (u = u1 ? v = v1) ? (u = u2 ? v = v1) domain objects 1 or 2 s 6 (u = u1 ? v = v1) ? (u = u3 ? v = v1) domain objects 1 or 3 s 7 (u = u2 ? v = v1) ? (u = u3 ? v = v1) domain objects 2 or 3 s 8 (u = u1 ? v = v1) ? (u = u2 ? v = v1) ? (u = u3 ? v = v1 ) any of the domain objects Table  3 : Example of complex user goal sets. of states, A is the set of actions, O is the set of observations, T conditional transition probabilities, ? conditional observation probabilities, and R is the reward function. Since it iteratively projects the rewards associated with each state and action using the state transition and observation probabilities, the compression found is dependent on structures and regularities in the POMDP model. The set of basis vectors found can be used to project the POMDP reward, transition, and observation probabilities into the reduced state space allowing the policy to be learnt and executed in this state space. Although the VDC algorithm (Poupart, 2005) produces compressions that are lossless in terms of the states' values, the set of basis vectors found (when viewed as a transformation matrix) can be ill-conditioned. This results in numerical instability and errors in the belief estimation. The compression used in this demonstration was produced using a modified VDC algorithm that improves the matrix condition by approximately selecting the most independent basis vectors, thus improving numerical stability. It achieves near-lossless state value compression while allowing belief estimation errors to be minimised and traded-off against the amount of compression. Details of this algorithm are to appear in a forthcoming publication. 3 System Description 

 Components Input and output to the demonstration system is using standard open source and commercial components. FreeSWITCH (Minessale II, 2012) provides a platform for accepting incoming Voice over IP calls, routing them (using the Media Resource Control Protocol (MRCP)) to a Nuance 9.0 Automatic Speech Recogniser  (Nuance, 2012) . Output is similarly handled by FreeSWITCH routing system responses via a CereProc Text-to-Speech MRCP server  (CereProc, 2012)  in order to respond to the user. The heart of the demonstration system consists of a State-Estimator server which estimates the current dialogue state using the compressed state space previously produced by VDC, a Policy-Executor server that selects actions based on the compressed estimated state, and a template based Natural Language Generator server. These servers, along with FreeSWITCH, use ZeroC's Internet Communications Engine (Ice) middleware (ZeroC, 2012) as a common communications platform. 

 SDS Domain The demonstration system provides a restaurant finder system for the city of Edinburgh (Scotland, UK). It presents search results from a real database of over 600 restaurants. The search results are based on the attributes specified by the user, currently; location, food type and budget/non-budget. 

 Interface The demonstration SDS is typically accessed over the phone network. For debugging and demonstration purposes it is possible to visualise the belief distribution maintained by the DM as dialogues progress. The compressed version of the belief distribution is not a conventional probability distribution 3 and its visualisation is uninformative. Instead we take advantage of the reversibility of the VDC compression and project the distribution back onto the full state space. For an example of the evolution of the belief distribution during a dialogue see Figure  1 .    

 Conclusions We present a demonstration of a statistical SDS that uses automatic belief compression to reason over complex user goal sets. Using the power set of domain objects as the states of the POMDP DM allows complex sets of user goals to be represented, which leads to more natural dialogues. To address the massive expansion in the number of belief states, a modified form of VDC is used to generate a compression. It is this compressed space which is used by the DM for planning and acting in response to user utterances. This is the first demonstration of a statistical SDS that uses automatic belief compression to reason over complex user goal sets. VDC and other automated compression techniques reduce the human design load by automating part of the current POMDP SDS design process. This reduces the knowledge required when building such statistical systems and should make them easier for industry to deploy. Such compression approaches are not only applicable to SDSs but should be equally relevant for multi-modal interaction systems where several modalities are being combined in user-goal or state estimation. 

 Future Work The current demonstration system is a proof of concept and is limited to a small number of attributes and attribute-values. Part of our ongoing work involves investigation of scaling. For example, increasing the number of attributevalues should produce more regularities across the POMDP space. Does VDC successfully exploit these? We are in the process of collecting corpora for the Edinburgh restaurant domain mentioned above with the aim that the POMDP observation and transition statistics can be derived from data. As part of this work we have launched a long term, public facing outlet for testing and data collection, see http:\\www.edinburghinfo. co.uk. It is planned to make future versions of the demonstration system discussed in this paper available via this public outlet. Finally we are investigating the applicability of other automatic belief (and state) compression techniques for SDSs, e.g. E-PCA (Roy and  Gordon, 2002) . after second user utterance. 

 Figure 1 : 1 Figure1: Evolution of the belief distribution for the example dialogue in Table2. The horizontal length of each bar corresponds to the probability of that complex user goal state. Note that the x-axis uses a logarithmic scale to allow low probability values to be seen. The y-axis is the set of complex user goals ordered by probability. Lighter shaded (green) bars indicate complex user goal states corresponding to "cheap, central Thai" and "cheap, central Thai or expensive French anywhere" in figures (b) and (c) respectively. The count '#' indicates the number of states in those groups. 

 Table 1 : 1 Example dialogue using simple user goals. S=System, U=User. '-' indicates the user barged in. User goal: cheap central Thai or expensive French S: Hello, how can I help you? U: I'm looking for a cheap central Thai restaurant. S: You're looking for budget, city centre, Thai restaurants. - U: Or an expensive French restaurant anywhere. S: You're looking for non-budget French restaurants. What - U: And cheap, city centre, Thai. S: You're looking for budget, city centre, Thai restaurants. What about - U: (SIGH) And French. S: You're looking for budget, city centre, French restaurants. What about - U: (HANG UP) 

 Table 2 : 2 What about the Plumed Horse in Leith ? ? The Plumed Horse is a Michelin starred French ... Example dialogue using complex user goals. S=System, U=User. ? Old Town is part of the city centre. ? Leith is outside the centre. User goal: cheap central Thai or expensive French S: Hello, how can I help you? U: I'm looking for a cheap central Thai restaurant. S: You're looking for budget, city centre, Thai restaurants. - U: Or an expensive French restaurant anywhere. S: You're looking for budget, city centre, Thai restaurants or non-budget French. What about Chang Thai in Old Town  ? ? Chang Thai's set lunch price is ? 7.95 - U: What alternatives do you have? S: 

 Table 2 2 . The horizontal length of each bar corresponds to the probability of that com- plex user goal state. Note that the x-axis uses a log- arithmic scale to allow low probability values to be seen. The y-axis is the set of complex user goals or- dered by probability. Lighter shaded (green) bars indi- cate complex user goal states corresponding to "cheap, central Thai" and "cheap, central Thai or expensive French anywhere" in figures (b) and (c) respectively. The count '#' indicates the number of states in those groups. 

			 The sum of discounted future rewards obtained through following some series of actions. 

			 The values associated with the basis vectors are not confined to the range [0 ? 1].
