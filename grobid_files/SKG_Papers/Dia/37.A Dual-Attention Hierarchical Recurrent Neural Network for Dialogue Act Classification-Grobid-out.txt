title
A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act Classification

abstract
Recognising dialogue acts (DA) is important for many natural language processing tasks such as dialogue generation and intention recognition. In this paper, we propose a dualattention hierarchical recurrent neural network for DA classification. Our model is partially inspired by the observation that conversational utterances are normally associated with both a DA and a topic, where the former captures the social act and the latter describes the subject matter. However, such a dependency between DAs and topics has not been utilised by most existing systems for DA classification. With a novel dual task-specific attention mechanism, our model is able, for utterances, to capture information about both DAs and topics, as well as information about the interactions between them. Experimental results show that by modelling topic as an auxiliary task, our model can significantly improve DA classification, yielding better or comparable performance to the state-of-the-art method on three public datasets.

Introduction Dialogue Acts (DA) are semantic labels of utterances, which are crucial to understanding communication: much of a speaker's intent is expressed, explicitly or implicitly, via social actions (e.g., questions or requests) associated with utterances  (Searle, 1969) . Recognising DA labels is important for many natural language processing tasks. For instance, in dialogue systems, knowing the DA label of an utterance supports its interpretation as well as the generation of an appropriate response  (Searle, 1969; Chen et al., 2018) . In the security domain, being able to detect intention in conversational texts can effectively support the recognition of sensitive information exchanged in emails or other communication channels, which is critical to timely security intervention  (Verma et al., 2012) . A wide range of techniques have been investigated for DA classification. Early works on DA classification are mostly based on general machine learning techniques, framing the problem either as multi-class classification (e.g., using SVMs  (Liu, 2006)  and dynamic Bayesian networks  (Dielmann and Renals, 2008) ) or a structured prediction task (e.g., using Conditional Random Fields  (Kim et al., 2010; Chen et al., 2018; Raheja and Tetreault, 2019, CRF) ). Recent studies to the problem of DA classification have seen an increasing uptake of deep learning techniques, where promising results have been obtained. Deep learning approaches typically model the dependency between adjacent utterances  (Ji et al., 2016; Lee and Dernoncourt, 2016) . Some researchers further account for dependencies among both consecutive utterances and consecutive DAs, i.e., both are considered factors that influence natural dialogue  (Kumar et al., 2018; Chen et al., 2018) . There is also work exploring different deep learning architectures (e.g., hierarchical CNN or RNN/LSTM) for incorporating context information for DA classification  (Liu et al., 2017) . It has been observed that conversational utterances are normally associated with both a DA and a topic, where the former captures the social act (e.g., promising) and the latter describes the subject matter  (Wallace et al., 2013) . It is also recognised that the types of DA associated with a conversation are likely to be influenced by the topic of the conversation  (Searle, 1969; Wallace et al., 2013) . For instance, conversations relating to topics about customer service might be more frequently associated with DAs of type Wh-question (e.g., Why my mobile is not working?) and a complaining statement  (Bhuiyan et al., 2018) ; whereas meetings covering administrative topics about resource allocation are likely to exhibit significantly more defending statements and floor grabbers (e.g., Well I mean -is the handheld really any better?)  (Wrede and Shriberg, 2003) . However, such a reasonable source of information, surprisingly, has not been explored in the deep learning literature for DA classification. We assume that modelling the topics of utterances as additional contextual information may effectively support DA classification. In this paper, we propose a dual-attention hierarchical recurrent neural network with a CRF (DAH-CRF) for DA classification. Our model is able to account for rich context information with the developed dual-attention mechanism, which, in addition to accounting for the dependencies between utterances, can further capture, for utterances, information about both topics and DAs. Topic is a useful source of context information which has not previously been explored in existing deep learning models for DA classification. Second, compared to the flat structure employed by existing models  (Khanpour et al., 2016; Ji et al., 2016) , our hierarchical recurrent neural network can represent the input at the character, word, utterance, and conversation levels, preserving the natural hierarchical structure of a conversation. To capture the topic information of conversations, we propose a simple automatic utterance-level topic labelling mechanism based on LDA  (Blei et al., 2003) , which avoids expensive human annotation and improves the generalisability of our model. We evaluate our model against several strong baselines (  Wallace et al., 2013; Ji et al., 2016; Kumar et al., 2018; Chen et al., 2018; Raheja and Tetreault, 2019)  on the task of DA classification. Extensive experiments conducted on three public datasets (i.e., Switchboard Dialog Act Corpus (SWDA), DailyDialog (DyDA), and the Meeting Recorder Dialogue Act corpus (MRDA)) show that by modelling the topic information of utterances as an auxiliary task, our model can significantly improve DA classification for all datasets compared to a base model without modelling topic information. Our model also yields better or comparable performance to state-of-the-art deep learning method  (Raheja and Tetreault, 2019)  in classification accuracy. To summarise, the contributions of our paper are three-fold: (1) we propose to leverage topic information of utterances, a useful source of con-textual information which has not previously been explored in existing deep learning models for DA classification; (2) we propose a dual-attention hierarchical recurrent neural network with a CRF which respects the natural hierarchical structure of a conversation, and is able to incorporate rich context information for DA classification, achieving better or comparable performance to the stateof-the-art; (3) we develop a simple topic labelling mechanism, showing that using the automatically acquired topic information for utterances can effectively improve DA classification. 

 Related Work Broadly speaking, methods for DA classification can be divided into two categories: multiclass classification (e.g., SVMs  (Liu, 2006)  and dynamic Bayesian networks  (Dielmann and Renals, 2008) ) and structured prediction tasks including HMM  (Stolcke et al., 2000)  and CRF  (Kim et al., 2010) . Recently, deep learning has been widely applied in many NLP tasks, including DA classification.  Kalchbrenner and Blunsom (2013)  proposed to model a DA sequence with a RNN where sentence representations were constructed by means of a convolutional neural network (CNN).  Lee and Dernoncourt (2016)  tackled DA classification with a model built upon RNNs and CNNs. Specifically, their model can leverage the information of preceding texts, which can effectively help improve the DA classification accuracy. A latent variable recurrent neural network was developed for jointly modelling sequences of words and discourse relations between adjacent sentences  (Ji et al., 2016) . In their work, the shallow discourse structure is represented as a latent variable and the contextual information from preceding utterances are modelled with a RNN.  Kumar et al. (2018)  proposed a hierarchical Bi-LSTM model with a CRF for DA classification, where the inter-utterance and intra-utterance information are encoded by a hierarchical Bi-LSTM and the dependency between DA labels is captured by a CRF.  Chen et al. (2018)  developed a CRF-Attentive Structured Network (CRF-ASN) for DA classification. They applied structured attention network to the CRF layer in order to model contextual utterances and corresponding DAs together.  Raheja and Tetreault (2019)  achieved the state-of-the-art performance on the SWDA dataset by employing a self-attention mechanism, a CRF layer and character-level embeddings. In addition to modelling dependency between utterances, various contexts have also been explored for improving DA classification or joint modelling DA under multi-task learning. For instance,  Wallace et al. (2013)  proposed a generative joint sequential model to classify both DA and topics of patient-doctor conversations. Their model is similar to the factorial LDA model  (Paul and Dredze, 2012) , which generalises LDA to assign each token a K-dimensional vector of latent variables. We would like to emphasise that the model of  Wallace et al. (2013) , only assumed that each utterance is generated conditioned on the previous and current topic/DA pairs. In contrast, our model is able to model the dependencies of all preceding utterances of a conversation, and hence can better capture the effect between DAs and topics. 

 Methodology Given a training corpus D = (C n , Y n , Z n ) N n=1 , where C n = u n t T t=1 is a conversation contain- ing a sequence of T utterances, Y n = y n t T t=1 and Z n = z n t T t=1 are the corresponding labels of DA and topics for C n , respectively. Each utterance u t = w i t K i=1 of C n is a sequence of K words. Our goal is to learn a model from D, such that, given an unseen conversation C u , the model can predict the DA labels of the utterances of C u . Figure  1  gives an overview of the proposed Dual-Attention Hierarchical recurrent neural network with a CRF (DAH-CRF). A shared utterance encoder encodes each word w i t of an utterance u t into a vector h i t . The DA attention and topic attention mechanisms capture DA and topic information as well as the interactions between them. The outputs of the dual-attention are then encoded in the conversation-level sequence taggers (i.e., g t and s t ), based on the corresponding utterance representations (i.e., l t and v t ). Finally, the target labels (i.e., y t and z t ) are predicted in the CRF layer. 

 Shared Utterance Encoder In our model, we adopt a shared utterance encoder to encode the input utterances. Such a design is based on the rationale that the shared encoder can transfer parameters between two tasks and reduce the risk of overfitting  (Ruder, 2017) . Specifically, the shared utterance encoder is implemented using the bidirectional gated recurrent unit  (Cho et al., 2014, BiGRU) , which encodes each utter- ance u t = w i t K i=1 of a conversation C n as a se- ries of hidden states h i t K i=1 . Here, i indicates the timestamp of a sequence, and we define h i t as follows h i t = ? ? h i t ? ? ? h i t (1) where ? is an operation for concatenating two vectors, and ? ? h i t and ? ? h i t are the i-th hidden state of the forward gated recurrent unit  (Cho et al., 2014, GRU)  and backward GRU for w i t , respectively. Formally, the forward GRU ? ? h i t is computed as follows ? ? h i t = GRU( ? ? h i?1 t , e i t ) (2) where e i t is the concatenation of the word embedding and the character embedding of word w i t . Finally, the backward GRU encodes u t from the reverse direction (i.e. w K t ? w 1 t ) and generates ? ? h i t K i=1 following the same formulation as the forward GRU. 

 Task-specific Attention Recall that one of the key challenges of our model is to capture for each utterance, information about both DAs and topics, as well as information about the interactions between them. We address this challenge by incorporating into our model a novel task-specific dual-attention mechanism, which accounts for both DA and topic information extracted from utterances. In addition, DAs and topics are semantically relevant to different words in an utterance. With the proposed attention mechanism, our model can also assign different weights to the words of an utterance by learning the degree of importance of the words to the DA or topic labelling task, i.e., promoting the words which are important to the task and reducing the noise introduced by less important words. For each utterance u t , the DA attention calculates a weight vector ? i t K i=1 for h i t K i=1 , the hidden states of u t . u t can then be represented as an attention vector l t computed as follows l t = K i=1 ? i t h i t (3) In contrast to the traditional attention mechanism  (Bahdanau et al., 2015) , which only depends on one set of hidden vectors from the Seq2Seq decoder, the DA attention of our model relies on two sets of hidden vectors, i.e., g t?1 of the conversation-level DA tagger and s t?1 of the conversation-level topic tagger, where dual attention mechanism can capture, for utterances, information about both DAs and topics as well as the interaction between them. Specifically, the weights ? i t K i=1 for the DA attention are calculated as follows: ? i t = softmax(o i t ) (4) o i t = w a tanh W (act) (s t?1 ? g t?1 ? h i t ) + b (act) (5) The topic attention layer has a similar architecture to the DA attention layer, which takes as input both s t?1 and g t?1 . The weight vector ? i t K i=1 for the topic attention output v t can be calculated similar to Eq. 3 and Eq. 4. Note that w a , W  (act)  , and b (act) are vectors of parameters that need to be learned during training. 

 Conversational Sequence Tagger CRF sequence tagger for DA. The conversational CRF sequence tagger for DA predicts the next DA y t conditioned on the conversational hidden state g t and adjacent DAs (c.f. Figure  1 ). Formally, this conditional probability of the whole conversation can be formulated as p (y 1:T |C; ?) = T t=1 ? (y t?1 , y t , g t ; ?) Y T t=1 ? (y t?1 , y t , g t ; ?) (6) ? (y t?1 , y t , g t ; ?) = ? emi (y t , g t ) ? tran (y t?1 , y t ) = g t [y t ] P yt,y t?1 (7) Here the feature function ?(?) includes two score potentials: emission and transition. The emission potential ? emi regards utterance representation g t as the unary feature. The transition potential ? tran is a pairwise feature constructed from a T ?T state transition matrix P, where T is the number of DA classes, and P yt,y t?1 is the probability of transiting from state y t?1 to y t . C = u t T t=1 is the sequence of all utterances seen so far, ? is the parameters of the CRF layer. g t is calculated in a BiGRU similar to Eq. 1 and Eq. 2: g t = ? ? g t ? ? ? g t (8) ? ? g t = GRU( ? ? g t?1 , l t ) (9) CRF sequence tagger for topic. The conversational CRF sequence tagger for topic is designed to predict topic z t conditioned on v t and adjacent topics, which can be calculated similar to the formulation of the CRF tagger for DA. Training the model. Let ? be all the model parameters that need to be estimated for DAH-CRF. ? then is estimated based on D = (C n , Y n , Z n ) N n=1 (i.e., a corpus with N conversations) by maximising the following objective function L = N n=1 [log (p (y n 1:T |C n ; ?)) +? log (p (z n 1:T |C n ; ?))] (10) The hyper-parameter ? controls the contribution of the conversational topic tagger towards the objective function. In our experiments, ? = 0.5 is determined using the validation datasets. During the test, the optimal DA or topic sequence is calculated using the Viterbi algorithm  (Viterbi, 1967) . Y = arg max y 1:T ?Y p(y 1:T |C, ?) (11) 

 Automatically Acquiring Topic Labels To avoid expensive human annotation and to improve the generalisability of our model, we propose to label the topic of each utterance of the datasets using LDA  (Blei et al., 2003) . While perplexity has been widely used for model selection for LDA  (Lin, 2011; He et al., 2012) , we employ a topic coherence measure proposed by  (R?der et al., 2015)  to determine the optimal topic number for each dataset, which combines the indirect cosine measure with the normalised pointwise mutual information  (Bouma, 2009, NPMI)  and the Boolean sliding window. Empirically, we found the latter yields much better topic clusters than perplexity for supporting DA classification. We treat each conversation as a document and train topic models using Gensim with topic number settings ranging from 10 to 100 (using an increment step of 10). Gibbs sampling is used to estimate the model posterior and for each model we run 1,000 iterations. For each trained model, we calculate the averaged coherence score of the extracted topics using Gensim 1 , an implementation following  (R?der et al., 2015) . Figure  2  shows the topic coherence score for each topic number setting for all datasets, from which we determine that the optimal topic number setting for SWDA, DyDA, and MRDA are 60, 30, and 30, respectively. Based on the optimal models (i.e., a trained LDA model using the optimal topic number setting), we assign topic labels to the datasets with two different strategies, i.e., conversation-level labelling (conv) and utterance-level labelling (utt). For conversation-level labelling, we assign the topic label with the highest marginal probability to the conversation based on the corresponding per-document topic proportion estimated by LDA. Every utterance of the conversation then shares the same topic label of the conversation. For utterance-level labelling, there is an additional step to perform inference on every utterance based on corresponding optimal model (e.g., for every utterance of SWDA, we do inference using the LDA trained on SWDA with 60 topics), and assign the topic label with the highest marginal probability to the utterance. Therefore, the topic labels of the utterances of the same conversation could be different for utterance-level labelling. 4 Experimental Settings 

 Datasets We evaluate the performance of our model on three public DA datasets with different characteristics, namely, Switchboard Dialog Act Corpus  (Jurafsky, 1997, SWDA) , Dailydialog  (Li et al., 2017, DyDA) , and the Meeting Recorder Dialogue Act corpus  (Shriberg et al., 2004, MRDA) . SWDA 2 consists of 1,155 two-sided telephone conversations manually labelled with 66 conversation-level topics (e.g., taxes, music, etc.) and 42 utterance-level DAs (e.g., statementopinion, statement-non-opinion, wh-question). DyDA 3 contains 13,118 human-written daily conversations, manually labelled with 10 conversation-level topics (e.g., tourism, politics, finance) as well as four utterance-level DA classes, i.e., inform, question, directive and commissive. The former two classes are information transfer acts, while the latter two are action discussion acts. MRDA 4 contains 75 meeting conversations anno-tated with 5 DAs, i.e., Statement (S), Question (Q), Floorgrabber (F), Backchannel (B), and Disruption (D). The average number of utterances per conversation is 1,496. There are no manually annotated topic labels available for this dataset. 

 Implementation Details For all experimental datasets, the top 85% highest frequency words were indexed. For SWDA and MRDA, we split training/validation/testing datasets following  (Stolcke et al., 2000; Lee and Dernoncourt, 2016) . For DyDA, we used the standard split from the original dataset  (Li et al., 2017) . The statistics of the experimental datasets are summarised in Table  1 . We represented input data with 300-dimensional Glove word embeddings  (Pennington et al., 2014)  and 50-dimensional character embeddings  (Ma and Hovy, 2016) . We set the dimension of the hidlayers (i.e., h i t , g t and s t ) to 256 and applied a dropout layer to both the shared encoder and the sequence tagger at a rate of 0.2. The Adam optimiser (Kingma and Ba, 2015) was used for training with an initial learning rate of 0.001 and a weight decay of 0.0001. Each utterance in a minibatch was padded to the maximum length for that batch, and the maximum batch-size allowed was 50. 

 Baselines We compare the proposed DAH-CRF model incorporating utterance-level topic labels extracted by LDA (denoted as DAH-CRF+LDA utt ) against five strong baselines and two variants of our own models: JAS 5 : A generative joint, additive, sequential model of topics and speech acts in patient-doctor communication  (Wallace et al., 2013) ; DRLM-Cond 6 : A latent variable recurrent neural network for DA classification  (Ji et al., 2016) ; Bi-LSTM-CRF 7 : A hierarchical Bi-LSTM with a CRF to classify DAs  (Kumar et al., 2018) ; CRF-ASN: An attentive structured network with a CRF for DA classification  (Chen et al., 2018) ; SelfAtt-CRF: A hierarchical Bi-GRU with selfattention and CRF  (Raheja and Tetreault, 2019) ; DAH-CRF+MANUAL conv : Use the manually annotated conversation-level topic labels (i.e., each utterance of the conversation shares the same  

 Experimental Results 

 Dialogue Acts Classification Table  2  shows the DA classification accuracy of our models and the baselines on three experimental datasets. We fine-tuned the model parameters for JAS, DRLM-Cond and Bi-LSTM-CRF in order to make the comparison as fair as possible. The implementation of CRF-ASN and SelfAtt-CRF are not available so we can only report their results for SWDA and MRDA based on the original papers  (Chen et al., 2018; Raheja and Tetreault, 2019) . It can be observed that by jointly modelling DA and topics, DAH-CRF+LDA utt outperforms the two best baseline models SelfAtt-CRF and CRF-ASN around 1% on the MRDA dataset. Our model also gives similar performance to SelfAtt-CRF, the baseline which achieved the state-ofthe-art performance on the SWDA dataset (i.e., 82.3% vs. 82.9%). While both manually annotated and automatically acquired topic labels are effective, we see that DAH-CRF+LDA utt outperforms both DAH-CRF+MANUAL conv and DAH-CRF+LDA conv , i.e., with over 1.6% gain on DyDA and over 1.4% on SWDA (significant; paired t-test p < .01). It is also ob- served that DAH-CRF+MANUAL conv and DAH-CRF+LDA conv perform very similar to each other. 

 Ablation Study Results We conducted ablation studies (see Table  3 ) in order to evaluate the contribution of the components of our DAH-CRF+LDA utt model, and more importantly, the effectiveness of leveraging topic information for supporting DA classification. DAH-CRF+LDA utt (without Dual-Att) removes the dual-attention component from DAH-CRF+LDA utt , and DAH+LDA utt removes the CRF from DAH-CRF+LDA utt but retaining the dual-attention component. SAH is a Single-Attention Hierarchical RNN model without a CRF, i.e., a simplified version of DAH+LDA utt that only models DAs with topical information omitted. As can be seen in Table  3 , DAH+LDA utt achieves over 3% averaged gain on all datasets when compared to SAH, which clearly shows that leveraging topic information can effectively support DA classification. It is also observed that both the dual-attention mechanism and the CRF component are beneficial, but are more effective on the SWDA and DyDA datasets than MRDA. In summary, while all the analysed model components are beneficial, the biggest gain is obtained by jointly modelling DAs and topics. 

 Analysing the Effectiveness of Joint Modelling Dialogue Act and Topic In this section, we provide detailed analysis on why DAH-CRF+LDA utt can yield better performance than SAH-CRF by jointly modelling DAs and topics. Due to the page limit, our discussion focuses on SWDA and DyDA datasets. Figure  4  shows the normalized confusion matrix derived from 10 DA classes of SWDA for both SAH-CRF and DAH-CRF+LDA utt models. It can be observed that DAH-CRF+LDA utt yields improvement on recall for many DA classes compared to SAH-CRF, e.g., 23.8% improvement on bk and 11.7% on sv. For bk (Response Acknowledge) which has the highest improvement level, we see that the improvement largely comes from the reduction of misclassifing bk to b (Acknowledge Backchannel). The key difference between bk and b is that an utterance labelled with bk has to be produced within a question-answer context, whereas b is a "continuer" simply representing a response to the speaker  (Jurafsky, 1997) . It is not surprising that SAH-CRF makes poor prediction on the utterances of these two DAs: they share many syntactic cues, e.g., indicator words such 'okay', 'oh', and 'uh-huh', which can easily confuse the model. When comparing the topic distribution of the utterances under the bk and b categories (cf. Figure  3 ), we found topics relating to personal leisure (e.g., buying cars, music, and exercise) are much more prominent in bk than b. By leveraging the topic information, DAH-CRF+LDA utt can better handle the confusion cases and hence improve the prediction for bk significantly. There are also cases where DAH-CRF+LDA utt performs worse than SAH-CRF. Take the DA pair of qo (Open Question) and qw (wh-questions) as an example. qo refers to questions like 'How about you?' and its variations (e.g., 'What do you think?'), whereas qw represents wh-questions which are much  more specific in general (e.g. 'What other long range goals do you have?'). SAH-CRF gives quite decent performance in distinguishing qw and qo classes. This is somewhat reasonable, as linguistically the utterances of these two classes are quite different, i.e., the qw utterance expresses very specific question and is relatively lengthy, whereas qo utterances tends to be very brief. We see that DAH-CRF+LDA utt performs worse than SAH-CRF: a greater number of qw utterances are misclassified by DAH-CRF+LDA utt as qo. This might be attributed to the fact that topic distributions of qw and qo are similar to each other (see Figure  3 ), i.e., incorporating the topic information into DAH-CRF may cause these two DAs to be less distinguishable for the model. We also conducted a similar analysis on the DyDA dataset. As can be seen from the confusion matrices shown in Figure  4  Finally, Figure  5  shows the DA attention visualisation examples of SAH-CRF and DAH-CRF+LDA utt for an utterance from SWDA and DyDA. For SWDA, it can be seen that SAH-CRF gives very high weight to the word "because" and de-emphasizes other words. However, DAH-CRF+LDA utt can capture more important words (e.g., "if", "reasonable", etc.) and correctly predicts the DA label as sd. For DyDA, SAH-CRF only focuses on "me" and "your", but DAH-CRF+LDA utt captures more words relevant to Directive, such as "please", "tell", etc. To summarise, DAH-CRF+LDA utt can capture more significant words related to the corresponding DA, by modelling both DAs and topic information with the dual-attention mechanism. 

 Conclusion In this paper, we developed a dual-attention hierarchical recurrent neural network with a CRF for DA classification. With the proposed taskspecific dual-attention mechanism, our model is able to capture information about both DAs and topics, as well as information about the interactions between them. Moreover, our model is generalised by leveraging an unsupervised model to automatically acquire topic labels. Experimental results based on three public datasets show that modelling utterance-level topic information as an auxiliary task can effectively improve DA classification, and that our model is able to achieve better or comparable performance to the state-of-the-art deep learning methods for DA classification. We envisage that our idea of modelling topic information for improving DA classification can be adapted to other DNN models, e.g., to encode topic labels into word embeddings and then concatenate with the utterance-level or conversationlevel hidden vectors of our baselines, e.g. SelfAtt-CRF. It will also be interesting to explicitly take into account speaker's role in the future. Figure 1 : 1 Figure 1: Overview of the dual-attention hierarchical recurrent neural network with a CRF. 
