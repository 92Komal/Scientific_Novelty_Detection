title
Identifying Sentiment Words Using an Optimization-based Model without Seed Words

abstract
Sentiment Word Identification (SWI) is a basic technique in many sentiment analysis applications. Most existing researches exploit seed words, and lead to low robustness. In this paper, we propose a novel optimization-based model for SWI. Unlike previous approaches, our model exploits the sentiment labels of documents instead of seed words. Several experiments on real datasets show that WEED is effective and outperforms the state-of-the-art methods with seed words.

Introduction In recent years, sentiment analysis  (Pang et al., 2002)  has become a hotspot in opinion mining and attracted much attention. Sentiment analysis is to classify a text span into different sentiment polarities, i.e. positive, negative or neutral. Sentiment Word Identification (SWI) is a basic technique in sentiment analysis. According to  (Ku et al., 2006)   (Chen et al., 2012)   (Fan et al., 2011) , SWI can be applied to many fields, such as determining critics opinions about a given product, tweeter classification, summarization of reviews, and message filtering, etc. Thus in this paper, we focus on SWI. Here is a simple example of how SWI is applied to comment analysis. The sentence below is an movie review in IMDB database: ? Bored performers and a lackluster plot and script, do not make a good action movie. In order to judge the sentence polarity (thus we can learn about the preference of this user), one must recognize which words are able to express sentiment. In this sentence, "bored" and "lackluster" are negative while "good" should be positive, yet its polarity is reversed by "not". By such analysis, we then conclude such movie review is a negative comment. But how do we recognize sentiment words? To achieve this, previous supervised approaches need labeled polarity words, also called seed words, usually manually selected. The words to be classified by their sentiment polarities are called candidate words. Prior works study the relations between labeled seed words and unlabeled candidate words, and then obtain sentiment polarities of candidate words by these relations. There are many ways to generate word relations. The authors of  (Turney and Littman, 2003)  and  (Kaji and Kitsuregawa, 2007)  use statistical measures, such as point wise mutual information (PMI), to compute similarities in words or phrases.  Kanayama and Nasukawa (2006)  assume sentiment words successively appear in the text, so one could find sentiment words in the context of seed words  (Kanayama and Nasukawa, 2006) . In  (Hassan and Radev, 2010)  and  (Hassan et al., 2011) , a Markov random walk model is applied to a large word relatedness graph, constructed according to the synonyms and hypernyms in WordNet  (Miller, 1995) . However, approaches based on seed words has obvious shortcomings. First, polarities of seed words are not reliable for various domains. As a simple example, "rise" is a neutral word most often, but becomes positive in stock market. Second, manually selection of seed words can be very subjective even if the application domain is determined. Third, algorithms using seed words have low robustness. Any missing key word in the set of seed words could lead to poor performance. Therefore, the seed word set of such algorithms demands high completeness (by containing common polarity words as many as possible). Unlike the previous research work, we identify sentiment words without any seed words in this paper. Instead, the documents' bag-of-words in-formation and their polarity labels are exploited in the identification process. Intuitively, polarities of the document and its most component sentiment words are the same. We call such phenomenon as "sentiment matching". Moreover, if a word is found mostly in positive documents, it is very likely a positive word, and vice versa. We present an optimization-based model, called WEED, to exploit the phenomenon of "sentiment matching". We first measure the importance of the component words in the labeled documents semantically. Here, the basic assumption is that important words are more sentiment related to the document than those less important. Then, we estimate the polarity of each document using its component words' importance along with their sentiment values, and compare the estimation to the real polarity. After that, we construct an optimization model for the whole corpus to weigh the overall estimation error, which is minimized by the best sentiment values of candidate words. Finally, several experiments demonstrate the effectiveness of our approach. To the best of our knowledge, this paper is the first work that identifies sentiment words without seed words. 

 The Proposed Approach 

 Preliminary We formulate the sentiment word identification problem as follows. Let D = {d 1 , . . . , d n } denote document set. Vector ? l = ? ? ? l 1 . . . l n ? ? ? represents their labels. If document d i is a positive sample, then l i = 1; if d i is negative, then l i = ?1. We use the notation C = {c 1 , . . . , c V } to represent candidate word set, and V is the number of candidate words. Each document is formed by consecutive words in C. Our task is to predict the sentiment polarity of each word c j ? C. 

 Word Importance We assume each document d i ? D is presented by a bag-of-words feature vector ? f i = ? ? ? f i1 . . . f iV ? ? ?, where f ij describes the importance of c j to d i . A high value of f ij indicates word c j contributes a lot to document d i in semantic view, and vice versa. Note that f ij > 0 if c j appears in d i , while f ij = 0 if not. For simplicity, every ? f i is normalized to a unit vector, such that features of different documents are relatively comparable. There are several ways to define the word importance, and we choose normalized TF-IDF  (Jones, 1972) . Therefore, we have f ij ? T F ?IDF (d i , c j ), and ? ? f i ? = 1. 

 Polarity Value In the above description, the sentiment polarity has only two states, positive or negative. We extend both word and document polarities to polarity values in this section. Definition 1 Word Polarity Value: For each word c j ? C, we denote its word polarity value as w(c j ). w(c j ) > 0 indicates c j is a positive word, while w(c j ) < 0 indicates c j is a negative word. |w(c j )| indicates the strength of the belief of c j 's polarity. Denote w(c j ) as w j , and the word polar- ity value vector ? w = ? ? ? w 1 . . . w V ? ? ?. For example, if w("bad") < w("greedy") < 0, we can say "bad" is more likely to be a negative word than "greedy". Definition 2 Document Polarity Value: For each document d i , document polarity value is y(d i ) = cosine( ? f i , ? w) = ? f i T ? ? w ? ? w? . (1) We denote y(d i ) as y i for short. Here, we can regard y i as a polarity estimate for d i based on ? w. To explain this, Table  1  shows an example. "MR1", "MR2" and "MR3" are three movie review documents, and "compelling" and "boring" are polarity words in the vocabulary. we simply use TF to construct the document feature vectors without normalization. In the table, these three vectors, ? f 1 , ? f 2 and ? f 3 , are (3, 1), (2, 1) and (1, 3) respectively. Similarly, we can get ? w = (1, ?1), indicating "compelling" is a positive word while "boring" is negative. After normalizing ? f 1 , ? f 2 and ? f 3 , and calculating their cosine similarities with ? w, we obtain y 1 > y 2 > 0 > y 3 . These inequalities tell us the first two reviews are positive, while the last review is negative. Furthermore, we believe that "MR1" is more positive than "MR2". "compelling" "boring" MR1 3 1 MR2 2 1 MR3 1 3 w 1 -1 Table  1 : Three rows in the middle shows the feature vectors of three movie reviews, and the last row shows the word polarity value vector ? w. For simplicity, we use TF value to represent the word importance feature. 

 Optimization Model As mentioned above, we can regard y i as a polarity estimate for document d i . A precise prediction makes the positive document's estimator close to 1, and the negative's close to -1. We define the polarity estimate error for document d i as: e i = |y i ? l i | = | ? f i T ? ? w ? ? w? ? l i |. (2) Our learning procedure tries to decrease e i . We obtain ? w by minimizing the overall estimation error of all document samples n ? i=1 e 2 i . Thus, the optimization problem can be described as min ? w n ? i=1 ( ? f i T ? ? w ? ? w? ? l i ) 2 . ( 3 ) After solving this problem, we not only obtain the polarity of each word c j according to the sign of w j , but also its polarity belief based on |w j |. 

 Model Solution We use normalized vector ? x to substitute ? w ? ? w? , and derive an equivalent optimization problem: min ? x E(? x) = n ? i=1 ( ? f i T ? ? x ? l i ) 2 s.t. ? x? = 1. (4) The equality constraint of above model makes the problem non-convex. We relax the equality constraint to ? x? ? 1, then the problem becomes convex. We can rewrite the objective function as the form of least square regression: E(? x) = ?F ? ? x ? ? l? 2 , where F is the feature matrix, and equals to ? ? ? ? ? f 1 T . . . ? f n T ? ? ? ? . Now we can solve the problem by convex optimization algorithms  (Boyd and Vandenberghe, 2004) , such as gradient descend method. In each iteration step, we update ? x by ? x = ? ? (?E) = 2? ? (F T ? l ? F T F ? x) , where ? > 0 is the learning rate. 

 Experiment 

 Experimental Setup We leverage two widely used document datasets. The first dataset is the Cornell Movie Review Data 1 , containing 1,000 positive and 1,000 negative processed reviews. The other is the Stanford Large Dataset 2  (Maas et al., 2011) , a collection of 50,000 comments from IMDB, evenly divided into training and test sets. The ground-truth is generated with the help of a sentiment lexicon, MPQA subjective lexicon 3 . We randomly select 20% polarity words as the seed words, and the remaining are candidate ones. Here, the seed words are provided for the baseline methods but not for ours. In order to increase the difficulty of our task, several non-polarity words are added to the candidate word set.  In order to demonstrate the effectiveness of our model, we select two baselines, SO-PMI  (Turney and Littman, 2003)  and COM  (Chen et al., 2012) . Both of them need seed words. 

 Top-K Test In face of the long lists of recommended polarity words, people are only concerned about the topranked words with the highest sentiment value. In this experiment we consider the accuracy of the top K polarity words. The quality of a polarity word list is measured by p@K = N right,K K , where N right,K is the number of top-K words which are correctly recommended.  Figure  1  shows the final result of p@K, which is the average score of the positive and negative list. We can see that in both datasets, our approach highly outperforms two baselines, and the precision is 14.4%-33.0% higher than the best baseline. p@10s of WEED for Cornell and Stanford datasets reach to 93.5% and 89.0%, and it shows the top 10 words in our recommended list is exceptionally reliable. As the size of K increases, the accuracy of all methods falls accordingly. This shows three approaches rank the most probable polarity words in the front of the word list. Compared with the small dataset, we obtain a better result with large K on the Stanford dataset. 

 Case Study We conduct an experiment to illustrate the characteristics of three methods. Table  3  shows top-10 positive and negative words for each method, where the bold words are the ones with correct polarities. From the first two columns, we can see the accuracy of WEED is very high, where positive words are absolutely correct and negative word list makes only one mistake, "plot". The other columns of this table shows the baseline methods both achieve reasonable results but do not perform as well as WEED. Our approach is able to identify frequently used sentiment words, which are vital for the applications without prior sentiment lexicons. The sentiment words identified by SO-PMI are not so representative as WEED and COM. For example, "skillfully" and "giddy" are correctly classified but they are not very frequently used. COM tends to assign wrong polarities to the sentiment words although these words are often used. In the 5 th and 6 th columns of Table  3 , "bad" and "horror" are recognized as positive words, while "pretty" and "fun" are recognized as negative ones. These concrete results show that WEED captures the generality of the sentiment words, and achieves a higher accuracy than the baselines. 

 Conclusion and Future Work We propose an effective optimization-based model, WEED, to identify sentiment words from the corpus without seed words. The algorithm exploits the sentiment information provided by the documents. To the best of our knowledge, this paper is the first work that identifies sentiment words without any seed words. Several experiments on real datasets show that WEED outperforms the stateof-the-art methods with seed words. Our work can be considered as the first step of building a domain-specific sentiment lexicon. Once some sentiment words are obtained in a certain domain, our future work is to improve WEED by utilizing these words. Figure 1: Top-K Test 
