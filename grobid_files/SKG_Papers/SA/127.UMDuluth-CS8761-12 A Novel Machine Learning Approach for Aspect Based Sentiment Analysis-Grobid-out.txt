title
UMDuluth-CS8761-12: A Novel Machine Learning Approach for Aspect Based Sentiment Analysis

abstract
This paper provides a detailed description of the approach of our system for the Aspect-Based Sentiment Analysis task of SemEval-2015. The task is to identify the Aspect Category (Entity and Attribute pair), Opinion Target and Sentiment of the reviews. For the In-domain subtask that is provided with the training data, the system is developed using a supervised technique Support Vector Machine and for the Out-of-domain subtask for which the training data is not provided, it is implemented based on the sentiment score of the vocabulary. For In-domain subtask, our system is developed specifically for restaurant data.

Introduction With the increase in usage of internet, most of the users record their experiences of a particular product or item in the form of online reviews. Users might express their opinion about many different aspects of an item in a review. While most of existing systems try to extract the overall polarity of a sentence, Semeval 2015 conducted a task on Aspect-Based Sentiment Analysis and the requirement was to extract entities (e.g., Food, Price, Service for Restaurant data), attributes(e.g., Quality, Style) for each sentence and then to determine the polarity for each entityattribute pair. The fajitas were delicious, but expensive. In the above example, there are two opinions.The first opinion has FOOD#QUALITY as the entityattribute pair with positive polarity and second has FOOD#PRICES with negative polarity. The target for both these opinions is fajitas. Since there are two opinions with two different polarities, it is useful to identify entities, attributes and targets for each sentence. Our system tries a new approach of trying to split the sentence to find out more than one opinion in a sentence. Initially, all the unnecessary words are removed and then sentences are split in a way such that each split sentence has an opinion. These split sentences are given to a classifier for identifying entities and attributes. Later, these entities are used to extract opinion targets. Polarity is found using a classifier and voting mechanisms. The rest of the paper is structured as follows: Section 2 presents the description of SemEval-Task Aspect-Based Sentiment Analysis. Section 3 presents the description of our system. Section 4 discusses the results of our system and analyze them. Section 5 presents a conclusion to the paper. 

 SemEval Task Description The SemEval Task is divided into two subtasks. 

 Subtask 1 Following are the slots in the Subtask 1 

 Slot 1 -Aspect Category (Entity and Attribute) It specifies the category of the domain to which the review refers. Aspect Category contains the Entity#Attribute pair of the review. Entity is the aspect of the domain for which an opinion is expressed in the given review. Attribute is the quality or feature the review refers to and this is dependent on the Entity. Great for a romantic evening, but over-priced. {Entity#Attribute} ->{Ambience#General, Restaurant#Prices} 

 Slot 2 -Opinion Target Expression Opinion target is the target word in the review on which an opinion is expressed. The Shrimp was awesome, but over-priced. {Entity#Attribute, Target} ->{Food#Quality, "Shrimp"}, {Food#Prices, "Shrimp"} 

 Slot 3 -Sentiment Polarity Every Entity#Attribute pair obtained from sentence should be assigned a polarity of either positive, negative, or neutral depending on the sentiment expressed by the user. 

 Subtask 2 The task is to find out the polarity for each entity, attribute pair of the review which will be provided in the test data. No training data is provided for this task. Further details of the task description are provided in  (SemEval, 2015) . 

 System Description This system has been developed specifically for Restaurant data for subtask 1 and it is constrained for subtask1, unconstrained for subtask2. The different stages in which the system proceeds are described in respective subsections. Most of them use an SVM classifier for predictions. This classifier is described extensively in subsection 3.9. 

 Subjectivity Classification There are two types of sentences: Subjective and Objective. Subjective sentences are based on personal opinions. Objective sentences are factual and observable. Linear SVM classifier is used to categorize the subjective and objective sentences. Training: Training sentences that have opinions are given a constant value and that do not have opinions are given another constant value. Using this binary classification model, a Linear SVM classifier is trained using unigram Bag of words feature for the given training dataset. Testing: The trained Linear SVM classifier is used in predicting the test sentences with subjective information. Only these predicted subjective test sentences are considered for further processing. 

 Clean the Sentence The main functionality of this module is to remove unnecessary words and modify the sentence in a way that helps in splitting of the sentence in next stage. Specifically, clean the sentence to remove the articles (a, an, and the) and append ',' before 'but', 'at', and 'with' words. This addition of ',' will help to split the sentence in the next processing stage. A ',' is prepended to 'at' if it is preceded by an adjective and to 'with' if any adjective exists in any of the three previous words. These rules are extracted by observing the training data. The food is great and they have a good selection of wines at reasonable prices. In the above example, 'at' will be prepended with ',' and 'a' will be removed. 

 Split the Sentence Each sentence may contatin multiple opinions and we believe that divison of sentence into subsentences will help in making these predictions better. Observations from the training data led to the understanding that ',' and 'and' are used frequently to express multiple opinions in one sentence and hence these tokens are used to divide the sentence. Some words like 'at', 'but', 'with' are also being used to express multiple opinions and as ',' has been appended in the previous stage this helps in splitting these sentences also properly. 

 Below are some examples on this splitting The food is great and they have a good selection of wines, at reasonable prices. Split sentences: 1) The food is great 2) they have a good selection of wines 3) wines at reasonable prices Thalia is a beautiful restaurant, with beautiful people serving you, but the food doesn't quite match up Split sentences: 1) Thalia is a beautiful restaurant 2) with beautiful people serving you 3) but the food doesn't quite match up If a split sentence has an adjective but does not have a noun, then the noun(s) in the previous split sentence will be appended to current split sentence. Similarly, if the split sentence has a noun but does not have an adjective, then the adjective from the previous split sentence will be appended to current split sentence. We love food, drinks, and atmosphere Split sentences: 1) we love the food 2) love drinks 3) love atmosphere In contrast, if a split sentence does not have both noun and adjective then append this split sentence to the previous split sentence. 

 Identify Entities In this section, we use the output from the split sentences. Since there can be multiple split sentences and entities, each split sentence has to be matched with it's corresponding entity. For Example: Pizza is delicious, ambience is bad. This example has two different entities: Food, Ambience. After splitting the sentences, assigning an entity to its respective part of sentence is important: Pizza is delicious-Food ambience is bad -Ambience To assign each split sentence with it's respective entity, Wordnet is used. Find the similarities between the words in each split sentence and each entity using wordnet. For each entity, assign a split sentence to which the most similar word for that entity belongs to. After each split sentence has been assigned to it's respective entity, the words from that split sentence whose parts of speech are among nouns, verbs, adjectives or adverbs are extracted and given as input to SVM. Use the linear SVM model as described in subsection 3.9 to predict the entity. 

 Identify Attributes All the nouns, verbs, adjectives, adverbs for each particular attribute are extracted from the training data. Each attribute along with their respective extracted words are given as input to the SVM Classifier. Use the linear SVM model as described in subsection 3.9 to predict the entity. Apart from this process some predefined lexicons from the training data are extracted manually. For example, if there are words like money or price in the sentence then it is likely that the sentence is talking about the attribute price. Words like these will, in almost all of the cases, belong to attribute 'price', these were extracted manually from training data as only a few of them were present. Upon the encounter of such words in the test data, the attribute associated with them is assigned. If none of these predefined words are encountered, then SVM classifier is used as described above. 

 Extract Opinion Targets In order to extract opinion targets, The following procedure is applied for finding targets where the entities extracted in previous section are among 'Food', 'Restaurant', 'Drinks', 'Location'. Training: Targets are found out based on Entities and most of them are nouns with a few being adjectives. Each entity has some nouns that will not be the targets. For example, a noun such as 'food' will not be the target for the 'restaurant' entity. In the training data, for each entity, identify all the nouns, adjectives that are not targets. Also, identify the target words for each entity. All these extracted words are used for finding the targets in a test sentence. Testing: If a given test sentence has one of target words extracted in training, return that target. If not, remove all the non-targets in the sentence that were extracted from training. After this removal, if there are no more nouns in the sentence, then return the target as NULL. If more nouns exist in the sentence, then return the largest substring of the consecutive nouns and adjectives. If the entity is restaurant then return the proper noun as the target if it is preceded with 'at' or 'to'. For Entities (Ambience and Service): For sentences that has Ambience and Service as the identified entities, a different approach is employed to extract opinion targets: A vocabulary of targets is constructed from the training data and is given as input to a classifier along with the corresponding sentences and their labels. This classifier is described in subsection 3.9 

 Sentiment Polarity From the given sentence, all noun(s), adjective(s), adverb(s), and verb(s) are extracted and given as input to the classifier to predict the polarity as either positive, negative or neutral. Usually classifiers can have multiple parameters. So, using the grid search method from Scikit Learn package, different parameters such as unigrams, bigrams and trigrams are tested and it was observed that trigrams resulted in better performance of the classifier. Hence trigrams are used whenever needed. Two different techniques are tried for the classification of the given training data: 1. All unique tri-grams in the training sentences are identified and TF-IDF values are calculated for these trigrams. Count Vectorizer and TF-IDF transformer from 'Scikit Learn' package are used to extract the BoW features from the sentences. 2. Categorical Probability Proportion Difference (CPPD)  (CPPD, 2012)  When compared to CPPD, BoW features resulted in higher accuracy. But, CPPD model might work good for other domains. To predict the polarity for test sentences, voting  (Brill et al., 2001)  among classifiers is used. The classifiers used in the voting procedure are Naive Bayes, Linear SVC, and Logistic Regression. By experimentation it is observed that Naive Bayes has a good "negative recall" when compared to voting. This experiment was helpful in deciding the polarity of a sentence. If Naive Bayes predicts negative, then the polarity for that sentence is assigned as negative, else it is assigned as the value predicted from voting. 

 Out-of-Domain In the out-of-domain subtask, no training data or knowledge about the domain would be provided or used to predict the polarity of the given test sentence. The steps taken in this task are: 1. Splitting of the test sentence into sub sentences is done based on the number of opinions it has. From the split sentences, words with parts of speech tag as noun, verb, adjective, or adverb are extracted. 2. Polarity is predicted using two tools Sentiwordnet and Pattern. The nearest opinion word (adjective, adverb, or verb) to the target word is identified and polarity is found out for this word and is set as the polarity for the sentence. If this word does not have polarity, then the average polarity score for the remaining opinion words in the sentence is calculated and is set as the polarity for the sentence. Apart from these two predictions, Pattern tool is also used to predict the polarity for the complete sentence. 3. Voting is applied to these three predictions and the output of this would be the final polarity for the sentence. 

 Linear SVM Model The steps involved in training the Linear SVM classifier for our system are described below: Features are extracted using unigram Bag of words (BoW), Tf-Idf, Univariate feature selection model  (Scikitlearn, 2011 ). An optimized regularization parameter (C value) is also used. Train the Classifier: With the help of all the above mentioned parameters, the classifier is trained for the given training dataset. Linear SVM model with BoW as features is trained using the multi-class classification method for the given training dataset. Predict the Label: The Linear SVM classifier predicts the output label for each test sentence by using the C value identified in the Cross-validation step. 

 Results and Analysis Our system was trained on 1314 review sentences and tested on 685 review sentences for sub task 1. Evaluations are done for slot 1, slot 2, slot 1 and slot 2, slot 3, and subtask 2. The results for each of them are provided in the tables. Each table has the scores of the best team, our system and the SemEval baseline. Table1 provides the results for slot 1 in which our system is ranked 2nd among all the constrained systems participated in the task and is ranked 3rd among all the participating systems. As our system for subtask 1 is constrained, all our scores are compared only with the best constrained system. For subtask 2, the best score among all systems is considered. As evident from the results, extraction of opinion targets can be attributed to the failure of both slot 2 and slot 1 & slot 2. We suspect that the reason behind this could be our concentration on finding those words that are non-targets rather than on trying to find words that should be targets. If a noun is not a target in one sentence, it doesnt mean that it cannot be a target in any sentence having similar entity. 

 Conclusion Overall, our system performed well especially in slot 1 and slot 3. Identifying the number of opinions that each sentence might express is an important step to be taken, which we have achieved by splitting the sentence so that each split sentence can express an opinion. Applying supervised machine learning techniques on these split sentences resulted in a much better predictions compared to the complete sentences. Banko, Michele, and Eric Brill Scaling to very very large corpora for natural language disambiguation. Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, 2001. Table 1 : 1 Slot 1. Team F1-Score Best 61.94 UMDuluth-CS8761-12 57.20 Baseline 51.32 Team F1-Score Best 66.91 UMDuluth-CS8761-12 50.36 Baseline 48.06 
