title
ASTD: Arabic Sentiment Tweets Dataset

abstract
This paper introduces ASTD, an Arabic social sentiment analysis dataset gathered from Twitter. It consists of about 10,000 tweets which are classified as objective, subjective positive, subjective negative, and subjective mixed. We present the properties and the statistics of the dataset, and run experiments using standard partitioning of the dataset. Our experiments provide benchmark results for 4 way sentiment classification on the dataset.

Introduction Arabic sentiment analysis work is gaining large attention nowadays. This is mainly due to the need of a product that can utilize natural language processing technology to track and analyze the public mood through processing social data streams. This calls for using standard social sentiment analysis datasets. In this work we present ASTD (Arabic Sentiment Tweets Dataset) an Arabic social sentiment analysis dataset gathered from Twitter. We discuss our method for gathering and annotating the dataset, and present its properties and statistics through the following tasks: (1) 4 way sentiment classification (2) Two stage class classification; and (3) sentiment lexicon generation. The contributions in this work can be summarized as: 1. We present an Arabic social dataset of about 10k tweets for subjectivity and sentiment analysis gathered from. 2. We investigate the properties and the statistics of the dataset and provide standard splits for balanced and unbalanced settings of the dataset. 3. We present a set of benchmark experiments to the dataset to establish a baseline for future comparisons. 4. We make the dataset and the used experiments publicly available 1 . 

 Related Work The detection of user sentiment in texts is a recent task in natural language processing. This task is gaining a large attention nowadays due to the explosion in the number of social media platforms and the number of people using them. Some Arabic sentiment datasets have been collected (see Table  1 ).  proposed the SAMAR system that perform subjectivity and sentiment analysis for Arabic social media where they used different multi-domain datasets collected from Wikipedia TalkPages, Twitter, and Arabic forums.  (Aly and Atiya, 2013)    3 Twitter Dataset 

 Dataset Collection We have collected over 84,000 Arabic tweets. We downloaded the tweets over two stages: In the first stage we used SocialBakers 2 to determine the most active Egyptian Twitter accounts. This gave us a list of 30 names. We got the recent tweets of these accounts till November 2013, and this amounted to about 36,000. In the second stage we crawled EgyptTrends 3 , a Twitter page for the top trending hash tags in Egypt. We got about 2500 distinct hash tags which are used again to download the tweets. We ended up obtaining about 48,000 tweets. After filtering out the non-Arabic tweets, and performing some pre-processing steps to clean up unwanted content like HTML, we ended up with 54,716 Arabic tweets. 

 Dataset Annotation We used Amazon Mechanical Turk (AMT) service to manually annotate the data set through an API called Boto 4 . We used four tags: objective, subjective positive, subjective negative, and subjective mixed. The tweets that are assigned the same rating from at least two raters were considered as conflict free and are accepted for further processing. Other tweets that have conflict from all the three raters were ignored. We were able to label around 10k tweets. Table  2  summarizes the statistics for the conflict free ratings tweets. 

 Dataset Properties The dataset has 10,006 tweets. Table  2  contains some statistics gathered from the dataset. The histogram of the class categories is shown in Fig.  1 ,   where we notice the unbalance in the dataset, with much more objective tweets than positive, negative, or mixed. Fig.  2  shows some examples from the data set, including positive, negative, mixed ,and objective tweets. 

 Dataset Experiments In this work, we performed a standard partitioning to the dataset then we used it for the sentiment polarity classification problem using a wide range of standard classifiers to perform 4 way sentiment classification. 

 Data Preparation We partitioned the data into training, validation and test sets. The validation set is used as a minitest for evaluating and comparing models for possible inclusion into the final model. The ratio of the data among these three sets is 6:2:2 respectively. Fig.  4  and Table  4  show the number of tweets for each class category in the training, test, and validation sets for both the balanced and unbalanced settings. Fig.  3  also shows the number of n-gram counts for both the balanced and unbalanced settings. 

 4 Way Sentiment Classification We explore using the dataset for the same set of experiments presented in  (Nabil et al., 2014 ) by ap-  plying a wide range of standard classifiers on the balanced and unbalanced settings of the dataset. The experiment is applied on both the token counts and the Tf-Idf (token frequency inverse document frequency) of the n-grams. Also we used the same accuracy measures for evaluating our results which are the weighted accuracy and the weighted F1 measure. Table  5  shows the result for each classifier after training on both the training and the validation set and evaluating the result on the test set (i.e. the train:test ratio is 8:2). Each cell has numbers that represent weighted accuracy / F1 measure where the evaluation is performed on the test set. All the experiments were implemented in Python using Scikit Learn 5 . Also the experiments were performed on a machine with Intel? Core? i5-4440  From table  5  we can make the following observations: 1. The 4 way sentiment classification task is more challenging than the 3 way sentiment classification task. This is to be expected, since we are dealing with four classes in the former, as opposed to only three in the latter. 2. The balanced set is more challenging than the unbalanced set for the classification task. We believe that this because the the balanced set contains much fewer tweets compared to the unbalanced set. Since having fewer training examples create data sparsity for many ngrams and may therefore leads to less reliable classification. 3. SVM is the best classifier and this is consistent with previous results in  (Aly and Atiya, 2013)  suggesting that the SVM is reliable choice. 

 Conclusion and Future Work In this paper we presented ASTD an Arabic social sentiment analysis dataset gathered from twitter. We presented our method of collecting and annotating the dataset. We investigated the properties and the statistics of the dataset and performed two set of benchmark experiments: (1) 4 way sentiment classification; (2) Two stage classification. Also we constructed a seed sentiment lexicon from the dataset. Our planned next steps include: 1. Increase the size of the dataset. 2. Discuss the issue of unbalanced dataset and text classification. 3. Extend the generated method either automated or manually. Figure 1 : 1 Figure 1: Tweets Histogram: The number of tweets for each class category. Notice the unbalance in the dataset, with much more objective tweets than positive, negative, or mixed. 
