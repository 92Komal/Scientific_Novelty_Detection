title
Day 124: NLP Papers Summary -TLDR: Extreme Summarization of Scientific Documents -Ryan Ong

abstract


TLDR and title generation to adapt our pre-trained language model BART. This has shown to outperform extractive and abstractive baselines. 

 Introduction to TLDR Generation Task The TLDR generation task aims to generate TLDRs that leave out background or methodology details and focus more on key aspects such as the contributions of the paper. This requires the model to have background knowledge as well as the ability to understand domain-speci c language. Figure below showcase an example of the TLDR task as well as a list of categories of the type of information that appears in TLDR.  

 SCITLDR Dataset 

 RESULTS The extractive oracle provides an upper bound performance. In   

 Conclusion and Future Work key difference here is that authors and peer reviews are writing TLDR based on reviewer comments and not the original research paper. This method assumes readers to have a good background ? ? 21/02/2022, 22:04 Day 124: NLP Papers Summary -TLDR: Extreme Summarization of Scientific Documents -Ryan Ong https://ryanong.co.uk/2020/05/03/day-124-nlp-papers-summary-tldr-extreme-summarization-of-scientific-documents/ 3/10 knowledge to follow the general research areas and so our TLDRs can leave out common concepts. In addition, the reviewer comments are written by experts in the eld and so they are high quality summaries. Figure below showcase an example of the annotation process. One of the uniqueness of SCITLDR is that each paper in the test set is map to multiple groundtruth TLDRs, one written by the original author and the rest by peer reviews. This would a) allow us to better evaluate our generated summaries as there are now multiple ground-truth summaries to compute ROUGE scores for, and b) having both the author and reader's TLDR allows us to capture the variation in summaries based on the reader's perspective. DATASET ANALYSIS First of, SCITLDR is a much smaller dataset, with only 3.2K papers due to manual data collection and annotations. Secondly, SCITLDR has an extremely high compression ratio compared to other datasets. The average document length is 5009 and it's being compressed into an average summary length of 19. This makes the summarisation very challenging. Table 3 showcase these summary statistics. SCITLDR has at least two ground-truth TLDRs for each paper in the test set and so we investigate the ROUGE score difference between different ground-truth TLDRs. There is a low ROUGEE-1 overlap (27.40) between author-generated TLDRs and PR-generated TLDRs. Author-generated TLDRs has a ROUGE-1 of 34.1 with the title of the paper. PR-generated TLDRs only has ROUGE-1 of 24.7. This showcase the importance of multiple ground-truth TLDRs in summarisation as one source document could have multiple relevant summaries. NLP Papers Summary -TLDR: Extreme Summarization of Scientific Documents -Ryan Ong https://ryanong.co.uk/2020/05/03/day-124-nlp-papers-summary-tldr-extreme-summarization-of-scientific-documents/ 4/10 Experimental Setup and Results MODEL TRAINING We netuned BART model to generate TLDR. However, there are few limitations. First of, the size of our training data. We have a small dataset for training neural networks. This has led us to collect additional 20K paper-title pairs from arXiv and up sampling our SCITLDR to match the new volume. The reason we are collecting titles is because it often contains important information about the paper and we believe if we train the model to perform title generation too, it will learn how to select important information from the paper. With the new information, we are ready to train our model. First, we train BART-large model on XSUM dataset, which it's an extreme summarisation dataset on general news domain. Then, we would netune our BART model on our SCITLDR and title dataset. The second limitation we face is that BART has a limitation on input length and so Extractive models. PACSUM (unsupervised extension of TextRank) and BERTSUMEXT Papers Summary -TLDR: Extreme Summarization of Scientific Documents -Ryan Ong https://ryanong.co.uk/2020/05/03/day-124-nlp-papers-summary-tldr-extreme-summarization-of-scientific-documents/ 5/10 2. Abstractive models. Different variations of BART We used the ROUGE metric for evaluation. We would compute the ROUGE score for each ground-truth TLDRs and select the maximum. 
