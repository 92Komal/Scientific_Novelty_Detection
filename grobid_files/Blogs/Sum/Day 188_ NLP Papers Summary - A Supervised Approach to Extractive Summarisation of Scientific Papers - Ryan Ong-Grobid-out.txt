title


abstract


HighlightROUGE and AbstractROUGE 

 SAF + F and S+F Ensemblers. The ensemble methods use weighted average of the output of two different models. SAF + F is the ensemble of SAFNet and FNet and S+F is the ensemble of SNet and FNet 

 Results 

 MOST RELEVANT SECTIONS TO A SUMMARY We created a 10148 computer science extractive summarisation dataset. The publications were collected from ScienceDirect and are grouped into 27 domains. Each paper in the dataset has a title, abstract, author written highlight statements and author de ned keywords. The highlight statements are the gold summary statements. See the gure below for an example. We created two different version of the dataset: CSPubSum and CSPubSumExt. The summary statistics of the two datasets are shown in the gure below. The CSPubSum consists of positive and negative examples for each paper. The positive examples are highlight statements ? ? 21/02/2022, 21:34 Day 188: NLP Papers Summary -A Supervised Approach to Extractive Summarisation of Scientific Papers -? https://ryanong.co.uk/2020/07/06/day-188-nlp-papers-summary-a-supervised-approach-to-extractive-summarisation-of-scienti? 3/13 whereas the negative examples are randomly sampled from the bottom 10% of sentences based on ROUGE-L. The test set consists of 150 full papers and it's the set we used to evaluate the quality of summaries. The CSPubSumExt is where we used HighlightROUGE to nd sentences similar to the highlights from the full paper. This allows us to extend the dataset to 263K instances for training set and 131K instances for test set. 

 The HighlightROUGE is used to generate more training data. It takes the gold summary and the text from the research papers and nds sentences that yield the best ROUGE-L score in relation to the highlights. We selected the top 20 sentences as positive instances and the bottom 20 sentences as negative instances. Note that we excluded extracting sentences from the abstracts as there are already a summary. AbstractROUGE is a new summarisation feature that measures the ROUGE-L score between the sentence and the abstract. The idea is that sentences which are good summaries of the abstract are also likely to be good summaries of the highlights. Methodology We experimented with two different sentence encoding methods: average word embeddings and RNN encoding. We have also selected 8 different summariser features to help encode the local and global context of each sentence: 1. AbstractROUGE. 2. Location. We assign integer location based on 7 different sections of the paper: Highlight, NLP Papers Summary -A Supervised Approach to Extractive Summarisation of Scientific Papers -? https://ryanong.co.uk/2020/07/06/day-188-nlp-papers-summary-a-supervised-approach-to-extractive-summarisation-of-scienti? 4/13 3. Numeric Count. Measure the number of numbers in a sentence. The idea is that sentences with heavy maths are unlikely to be good summaries 4. Title Score. Measure the overlap between the non-stopwords of each sentence and the title of the paper 5. Keyphrase Score. Measure how many author-de ned keywords appear in the sentence. The idea is that important sentences will contain more keywords 6. TFIDF. TFIDF was calculated for each word and averaged over the sentence. We ignored stopwords 7. Document TFIDF. Same as TFIDF except the count of words in a sentence is the TF and the count of words in the rest of the paper is the background corpus, which allows us to measure how important a word is in a sentence relative to the rest of the document 8. Sentence Length. The idea is that short sentences are very unlikely to be good summaries MODELS Our models could take in any combination of the four possible inputs: 1. The sentence encoded with RNN (S) 2. Vector representation of the abstract (A) 3. The 8 features from previous section (F) 4. Average non-stopword word embeddings in the sentence (Word2Vec) We experimented with 7 different models as listed below: 1. Single Feature Models. Model that only use one feature (we exclude sentence length, numeric count, and section) 2. FNet. A single layer NN that uses all 8 features to classify each sentence 3. Word2Vec and Word2VecAF. Both are single layer networks where Word2Vec takes in sentence average vector and Word2VecAF takes in the sentence average vector, abstract average vector, and handcrafted features 4. SNet. Feed the sentence vectors into bidirectional RNN with LSTM 5. SFNet. Processes the sentence with LSTM and passes the output to a fully connected layer with dropout. The handcrafted features are used as a separate inputs to a fully connected ? ? 21/02/2022, 21:34 Day 188: NLP Papers Summary -A Supervised Approach to Extractive Summarisation of Scientific Papers -? https://ryanong.co.uk/2020/07/06/day-188-nlp-papers-summary-a-supervised-approach-to-extractive-summarisation-of-scienti? 5/13 layer. The outputs of the LSTM and features hidden layer are concatenated and output the binary prediction 6. SAFNet. Extend SFNet by encoding abstract too. This is shown in the gure below. 

 First Figure 6 below showcase the performance of 4 models trained with and without AbstractROUGE. We observed that AbstractROUGE does improve the performance of summarisation techniques and that sentence encoding and features engineering lead to a more stable model.
