title
abstract
to in the question and detect it and should have some common-sense knowledge to answer it .
For instance , in the first image , and for the question " What is the mustache made of ? " : our AI system should be able to figure out that the subject being referenced to is the women 's face , more specifically the region around her lips , and should be able to detect the banana .
Business Problem :
As humans , it is easy for us to see an image and answer any question about it using our commonsense knowledge .
However , there are also scenarios , for instance , a visuallyimpaired user or an intelligence analyst , where they want to actively elicit visual information given an image .
Get started Open in app Hence , we build an AI system , which takes as input an image and a free-form , openended , or natural language question about the image and produces a natural language answer as the output .
The system will answer a question similar to humans in the following aspects : 1 . it will learn the visual and textual knowledge from the inputs ( image and question respectively ) 2 . combine the two data streams 3 . use this advanced knowledge to generate the answer
Understanding the data : VQA is a dataset containing open-ended questions about images .
These questions require an understanding of vision , language and commonsense knowledge to answer .
Performance Metric :
We evaluate our AI system by the number of questions it answers correctly .
The following accuracy metric is used : Constraints :
There are no strict latency requirements .
For each level of the question representation in this hierarchy , joint question and image co-attention maps are constructed , which are then combined recursively to ultimately predict a distribution over the answers .
Understanding the model :
Method :
The paper proposes two co-attention mechanisms that differ in the order in which 82,783 images ( COCO train images )
At least 3 questions ( 5.4 questions on average ) per image ( 443,757 questions ) 10 ground - truth answers per question ( 443,7570 answers ) from unique workers 4 . Mapping the real-world problem to an ML / DL problem : Type of Machine Learning Problem :
We pose the problem at hand as a K-class classification problem ; where K is the number of a fixed set of answer types in the dataset .
Let 's try to understand the method proposed in the paper " Hierarchical Question - Image Co-Attention for Visual Question Answering " .
Paper Overview : source : https://arxiv.org/pdf/1606.00061
All the papers on VQA before this , focused mainly on visual attention .
This paper proposes to focus on question attention too .
Specifically , this paper presents a novel multi-modal attention model for VQA with the following two unique features : 1 . Co-Attention :
This paper proposes a novel mechanism that jointly reasons for visual attention and question attention , which is referred to as co-attention .
More specifically , the image representation is used to guide the question attention and the question representation ( s ) are used to guide image attention .
2 . Question Hierarchy : Builds a hierarchical architecture that co-attends to the image and questions at three levels : ( a ) word- level , ( b ) phrase level , and ( with Deep Learning | by Tulrose Deori | Towards Data Science https://towardsdatascience.com/visual-question-answering-with-deep-learning-2e5e7cbfdcd4 6/14 ) question level .
a)
At the word level , the words are embedded in a vector space through an embedding matrix . b)
At the phrase level , 1 - dimensional convolution neural networks are used on the word representations with temporal filters of varying support , to capture the information contained in unigrams , bigrams , and trigrams , and then combine the various n-gram responses by pooling them into a single phrase - level representation .
c)
At the question level , a recurrent neural network is used to encode the entire question .
image and question attention maps are generated .
The first mechanism , which is called parallel co-attention , it generates image and question attention simultaneously .
The second mechanism is called alternating co-attention , it sequentially alternates between generating image and question attentions .
These co-attention mechanisms are executed at all three levels of the question hierarchy .
In this blog , we will discuss the implementation of the Parallel Co-Attention model .
with Deep Learning | by Tulrose Deori | Towards Data Science https://towardsdatascience.com/visual-question-answering-with-deep-learning-2e5e7cbfdcd4 7/14 source : https://arxiv.org/pdf/1606.00061
Parallel co-attention attends to the image and question simultaneously .
The image and question are connected by calculating the similarity between image and question features at all pairs of image-locations and question -locations .
Specifically , given an image feature map V? R^( d? N ) , and the question representation Q? R^( d? T ) , we calculate something called affinity matrix C? R^ ( T?N ) as follows :
Considering this affinity matrix C as a feature , image and question attention maps are predicted in the following way :
Based on the above attention weights , the image and question attention vectors are calculated as the weighted sum of the image features and question features , i.e. ,
The parallel co-attention is done at each level in the hierarchy , leading to v? and q? where r ? { w , p , s}. started Open in app
