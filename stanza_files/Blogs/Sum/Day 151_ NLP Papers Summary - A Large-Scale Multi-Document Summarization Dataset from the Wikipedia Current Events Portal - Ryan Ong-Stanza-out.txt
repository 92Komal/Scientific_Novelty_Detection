title
Day 151 : NLP Papers Summary - A Large-Scale Multi-Document Summarization Dataset From The Wikipedia Current Events Portal Objective and Contribution
abstract
Presented a large dataset for multi-document summarisation ( MDS ) built from Wikipedia Current Events Portal ( WCEP ) that contains 10200 document clusters and each document cluster has 235 articles on average .
Our dataset uses concise and neutral human-written summaries of news events , with links to external source articles .
We extended the number of source articles by looking at related articles of the source articles in Common Crawl archive as ?
Natural Language Processing 365 ? ? ? ? ? ? ?
Ryan
MEASURING EXTRACTIVENESS OF OUR SUMMARIES
Experiments and Results
We only considered 100 articles per cluster ( WCEP - 100 ) due to scalability and the fact that performance starts to plateau after 100 articles .
Our evaluation metrics are the F1 score and
RESULTS
The table below showcase 21/02/2022 , 21:38 Day 151 : NLP Papers Summary - A Large -Scale Multi-Document Summarization Dataset from the Wikipedia ?
https://ryanong.co.uk/2020/05/30/day-151-nlp-papers-summary-a-large-scale-multi-document-summarization-dataset-from-th?
2/10 shown in the example below .
We applied various supervised and unsupervised MDS models to establish baseline results for future research .
Dataset Construction
The dataset construction has three steps : 1 . Wikipedia Current Events Portal .
WCEP lists out daily news events whereby each news event has a human summary with at least one external news articles 2 . Obtaining Articles Linked on WCEP .
Each individual events contain a list of URLs to external source articles which we extracted all of it 3 .
Additional Source Articles .
Additionally , we extended the input articles for each of the ground -truth summaries by searching for similar articles in the Common Crawl News dataset .
We do this by training a simple logistic regression classi er to decide whether to assign an article to a summary .
Our logistic regression has four different features NLP Papers Summary - A Large-Scale Multi-Document Summarization Dataset from the Wikipedia ?
https://ryanong.co.uk/2020/05/30/day-151-nlp-papers-summary-a-large-scale-multi-document-summarization-dataset-from-th?
3/10
Overall , our nal dataset consists of a ground -truth summary and a cluster of original source articles and related articles .
The gure below showcase the summary statistics of the WCEP dataset and the statistics for individual clusters .
QUALITY OF ADDITIONAL ARTICLES
To ensure that our additional articles from Common Crawl are related to our source articles , we manually annotated 350 additional articles .
We compare the article title with the rst three sentences of the assigned summary and label the following :
1 . On-topic .
When the article focuses on the event described in the summary 2 . Related .
When the article mentions the event but focuses on other things ? ? 21/02/2022 , 21:38 Day 151 : NLP Papers Summary - A Large -Scale Multi-Document Summarization Dataset from the Wikipedia ?
https://ryanong.co.uk/2020/05/30/day-151-nlp-papers-summary-a-large-scale-multi-document-summarization-dataset-from-th?
4/10 3 . Unrelated .
When the article has no mention of the event
We have 52 % on-topic and 30 % related additional articles from the 350 articles .
Here , we aim to measure how extractive our summaries are by using the coverage and density metrics .
Coverage measures the number of words from the summary that 's extracted from all the articles in a cluster whereas the density measures how well a summary can be described as a series of extractions .
The results of the two measures are shown below .
The WCEP dataset shows high coverage if articles are included from Common Crawl .
This means that copy mechanisms would be useful for generating summaries .
NLP Papers Summary - A Large-Scale Multi-Document Summarization Dataset from the Wikipedia ?
https://ryanong.co.uk/2020/05/30/day-151-nlp-papers-summary-a-large-scale-multi-document-summarization-dataset-from-th?
5/10 Recall score of ROUGE -1 , ROUGE - 2 , and ROUGE -L .
We considered different oracles and baseline models to allows us to a ) measure the upper bound of our performance and b ) evaluate our dataset using common SOTA models .
the results .
As shown , there 's still a wide margin between the oracle results and the best performaing model , indicating more research needs to be done .
In addition , the supervised methods seem to outperformed the unsupervised methods but only by a small margin .
The high single document oracle result tells us that it is important to select relevant articles before summarisation .
Lastly , the dataset does n't support lead summaries like other summarisation dataset as demonstrated by the low performance of RANDOM LEAD .
NLP Papers Summary - A Large-Scale Multi-Document Summarization Dataset from the Wikipedia ?
https://ryanong.co.uk/2020/05/30/day-151-nlp-papers-summary-a-large-scale-multi-document-summarization-dataset-from-th?
6/10 Conclusion and Future Work Potential work involves how to scale deep learning models to the huge MDS corpus and how to close the gap between existing methods and the oracle results .
Source : https://arxiv.org/pdf/2005.10070.pdf ?
