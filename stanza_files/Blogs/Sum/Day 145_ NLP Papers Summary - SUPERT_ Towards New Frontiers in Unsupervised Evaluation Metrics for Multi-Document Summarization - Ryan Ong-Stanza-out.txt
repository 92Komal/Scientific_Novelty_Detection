title
Day 145 : NLP Papers Summary - SUPERT : Towards New Frontiers In Unsupervised Evaluation Metrics For Multi-Document Summarization
abstract
Objective and Contribution Proposed SUPERT , an unsupervised evaluation metric for evaluating multi-document summary by measuring the semantic similarity between the summary and the pseudo reference summary .
The pseudo reference summary is generated by selecting salient sentences from the source documents using contextualised embeddings and soft token alignment .
SUPERT was able to achieve a better correlation with human evaluation of 18 - 39 % .
We used SUPERT with an reinforcement learning summariser and it yielded a strong performance in comparison to ?
Natural Language Processing 365 ? ? ? ? ? ? ?
The table below showcase the results of the position - agnostic and position - aware graphs .
All the methods ( except SC_G ) outperformed the baseline models in table 1 above .
Our positionagnostic graphs underperformed the position - aware graphs .
In addition , our position - aware graphs underperformed simple sentence extraction method of selecting top N sentences in table 3 .
This shows us that the position bias is very strong in news and it remains the most effective approach in selecting the positive information .
GUIDING REINFORCEMENT LEARNING
Secondly , we explored two graph- based approach to building pseudo references : positionagnostic and position - aware graphs .
For position - agnostic graphs , we extended LexRank using SBERT ( SLR ) to measure the cosine similarity .
We also explore the af nity propagation clustering algorithm ( SC ) which clusters the sentences and the center of each cluster is selected to build pseudo reference .
This clustering algorithm does n't require us to preset the number of clusters .
For SLR and SC , we have two variations : individual graph and global graph .
The individual graph builds a graph for each source document and selects top K sentences .
The global graph builds a graph using all the sentences from all the source documents of the same topic and selects the top M sentences .
For position - aware graphs , we extended PacSum using SBERT ( SPS ) to measure sentences similarity and similarly , consider both individual and global - graph versions .
PacSum selects sentences that are semantically central meaning it has high average similarity with succeeding sentences and low average similarity with preceding sentences .
In addition , we also proposed Top + Clique ( TC ) , which selects top N sentences and semantically central sentences to build pseudo references .
Here 's how TC works : 1 . Label top N sentences from each document as salient 2 .
Build a graph that connects highly similar non-top - N sentences 3 . Identify the cliques from the graph and select the semantically central sentence from each clique as potential salient sentences 4 . For each potential salient sentence , compare it to the top N sentences and label it as salient if it 's not highly similar to the top N sentences ? ? 21/02/2022 , 21:39 Day 145 : NLP Papers Summary - SUPERT : Towards New Frontiers in Unsupervised Evaluation Metrics for Mu?
https://ryanong.co.uk/2020/05/24/day-145-nlp-papers-summary-supert-towards-new-frontiers-in-unsupervised-evaluation-metri?
6/9
We use our new unsupervised evaluation metric to guide the training of a RL - based multidocument summariser , Neural Temporal Difference ( NTD ) .
We considered three unsupervised reward functions : JS , REAPER , and SUPERT ( SP ) .
SUPERT selects the top 10 - 15 sentences from each source document as pseudo references and uses SBERT to measure semantic similarity between summaries and pseudo references .
The results are shown below and NTD with SUPERT yielded the strongest results .
? ?
