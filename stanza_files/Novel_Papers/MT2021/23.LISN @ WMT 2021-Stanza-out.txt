title
LISN @ WMT 2021
abstract
This paper describes LISN 's submissions to two shared tasks at WMT '21 .
For the biomedical translation task , we have developed resource -heavy systems for the English - French language pair , using both out -ofdomain and in-domain corpora .
The target genre for this task ( scientific abstracts ) corresponds to texts that often have a standardized structure .
Our systems attempt to take this structure into account using a hierarchical system of sentence - level tags .
Translation systems were also prepared for the News task for the French - German language pair .
The challenge was to perform unsupervised adaptation to the target domain ( financial news ) .
For this , we explored the potential of retrieval - based strategies , where sentences that are similar to test instances are used to prime the decoder .
Introduction
This paper describes LISN 's 1 submissions to the translation shared tasks at WMT ' 21 , where we took part in two shared tasks .
For the biomedical translation tasks , we have developed resource -heavy systems for the English - French language pair , using a diversity of out - of- domain and in-domain corpora , thus continuing the efforts reported in ( Abdul Rauf et al. , 2020 ) .
Like for previous years shared task , the target genre ( scientific abstract ) corresponds to texts that often have a standardized structure comprising typical subsections of one to five lines .
Standard subsections report the OBJECTIVE , the METHOD , or the RESULTs of the study .
Our systems for this year attempt to take this structure into account using sentence - level tags , with the hope to capture some of the document structure and the phraseology of the domain into account .
These systems are documented in Section 2 .
1 LISN [ Laboratoire Inderdisciplinaire des Sciences du Num?rique ] is the new name of the laboratory formerly known as LIMSI .
Translation systems were also prepared for the News task for the French - German language pair .
The challenge this year was to perform unsupervised adaptation to the target domain ( financial news ) , with no further detail regarding the test data .
In particular , the organizers did not release any development data to tune systems .
In this setting , we explored the potential of using a retrieval - based strategy , where sentences that are similar to the test instances are used to help the decoding .
In this approach , introduced in ( Bulte and Tezcan , 2019 ) and further explored in Pham et al. , 2020 ) , translation is a two-step process : a retrieval phase , which identifies sentences that resemble the source test sentence in parallel corpora .
These sentences and their translation are then used to prime the decoder : inserting relevant translations examples in the decoder 's context should help to select the right translations , especially for words and terms from the test domain .
These systems are described in Section 3 .
MT for biomedical texts
In this section , we describe our participation to the biomedical task for WMT ' 21 , in which we participated in both English to French and French to English directions .
English - French is a reasonably resourced language pair with respect to biomedical parallel corpora , allowing us to train our Neural Machine Translation ( NMT ) systems ( Vaswani et al. , 2017 ) with in- domain corpora as well as large outof-domain data that exists for this language pair .
Like for last year ( Abdul Rauf et al. , 2020 ) , our first goal is to make the best of all the available data , including supplementary in-domain monolingual data .
Our corpora are described in Section 2.1 .
For this year 's participation , we also attempt to take the internal structure of biomedical abstracts into account .
Many of these abstracts follow what is often refered to as the " IMRAD format " , comprising the following subparts : INTRODUCTION , METHODS , RESULTS , and DISCUSSION ( Sollaci and Pereira , 2004 ) .
This structure can be explicit in documents through dedicated headings or remain implicit .
Our experiments aim to explore how to use this information in NMT and to measure the correlated impact .
We notably expect that by informing the system with sub-document information , it will learn the typical style and phraseology of sentences occurring in each part .
For this purpose , we identified in our data all the abstracts that were conforming to this basic structure and worked to make this structure as explicit and standardized as possible .
This notably implied to normalize the mains headings , as some variation was observed : for instance , ANALYSIS may be replaced with DISCUSSION , and additional subparts ( OBJECTIVES , CONCLUSION ) are also be observed .
To incorporate the standard IMRaD format we mapped each subheading to the corresponding IMRaD subpart using a system of tags .
Details regarding this process are given in Section 2.2 .
All systems are based on the Transformer architecture of Vaswani et al . ( 2017 ) .
We were able to achieve appreciable gains both from backtranslation and document structure processing .
The results are discussed in Section 2.4 .
Corpus and preprocessing
We trained our baseline systems on a collection of in domain biomedical texts as well as out-ofdomain parallel corpus .
Table 1 details the corpora used in training .
Parallel corpora
We gathered parallel and monolingual corpora available for English - French in the biomedical domain .
The former included the biomedical texts provided by the WMT '20 organizers : Edp , Medline abstracts and titles ( Jimeno Yepes et al. , 2017 ) , Scielo ( Neves et al. , 2016 ) and the Ufal Medical corpus 2 consisting of Cesta , Ecdc , Emea ( OpenSubtitles ) , PatTR Medical and Subtitles .
In addition , we used the Cochrane bilingual parallel corpus ( Ive et al. , 2016 ) 3 , the Taus Corona Crisis corpus 4 and the Mlia Covid corpus .
5
We finally experimented with additional in-domain data selected using Information Retrieval ( IR ) techniques from general domain corpora including News - Commentary , Books and Wikipedia corpus obtained from the Open Parallel Corpus ( OPUS ) ( Lison and Tiedemann , 2016 ) .
These were selected using the data selection scheme described in ( Abdul - Rauf and Schwenk , 2009 ) .
Medline titles were used as queries to find relevant sentences .
We used the 2 - best sentences returned from the IR pipeline as additional corpus .
Our out - of- domain corpora include the parallel data provided by the WMT14 campaign for French - English : Gigafr-en , Common Crawl , Europarl , News Commentary and the UN corpora .
For development purposes , we used Medline test sets of WMT '18 and 19 , while Medline 20 was used as internal test data .
6
Monolingual sources
The back - translation of monolingual sources has often been effectively used to cater for parallel corpus shortage in the Biomedical domain in ( Stojanovski et al. , 2019 ; Peng et al. , 2019 ) .
We also adopt this approach here .
Supplementary French data from three monolingual sources were collected from public archives : abstracts of medical papers published by Elsevier from the Lissa portal 7 and from the national IS - TEX archive 8 ; a collection of research articles collected from various sources 9 henceforth referred to as Med_Fr ( Maniez , 2009 ) .
These documents were automatically translated into English with an NMT system trained on biomedical corpora , with a BLEU score of 33.6 on Medline20 testset .
The English side of Medline German and Spanish corpora is used as supplementary English data for back translation .
Duplicate documents were removed based on the document id .
For these , the internal structure of documents is often available and has been tagged as for the parallel data .
These texts were then split into sentences 10 and translated into French using a NMT system trained on all Biomedical corpora with a BLEU score of 36.4 on Medline20 testset .
All back - translated data is tagged using the proposal of Caswell et al . ( 2019 ) .
Parallel and monolingual data are further processed using SentencePiece ( Kudo and Richardson , 2018 ) tokenisation and detokenisation scheme to segment texts into subword units using a vocabulary of 32 K subwords .
These units were learned on all the in-domain corpora .
2.2 Sentence tagging : a three - level scheme
Tagging domains and corpora
As explained above , our training data is diverse , comprising in - domain parallel , out - of - domain parallel , and in-domain monolingual that is automatically back -translated .
Some are made of lists of isolated sentences , while others retain the document information .
Even within the in-domain data , some texts precisely match the genre of the testset ( scientific abstracts ) - this is the case for instance tools and are shared at https://github.com/fyvo/ WMT - Biomed -Test . 7 https://www.lissa.fr/dc/#env=lissa
8 https://www.istex.fr/ 9 https://crtt.univ-lyon2.fr/ les-corpus-medicaux-du-crtt-613310.kjsp 10 https://pypi.org/project/ sentence-splitter / of Medline and to a lesser extent , Cochrane ; while others are more remote ( eg. the Ufal collection , or the Mlia corpus ) .
In order to reflect this diversity , we designed a three - level sentence tagging scheme that is used for the experiments in Section 2.4.2 .
These tags appear as prefix of each source sentence .
The first level of tags distinguishes between outof-domain data ( < G > ) , and in- domain data ( tagged < M > ) .
The second level of tag aims to distinguish between data sources , hence the use of one dedicated tag for each corpus , except for the monolingual data , which is simply tagged with < BT >.
Tagging sections within documents
The third level of annotation is indented to enhance the translation context with information regarding the position of a sentence within the abstract .
The structure of scientific abstracts in the medical domain often obey the IMRAD structure , and the third tag aims to include this structural information as an additional document - level context .
Document level information is necessary to model long-range dependencies between words , phrases , or sentences , or document parts .
For a translation system , the ability to model the context may notably improve certain translation decisions , e.g. a better or most consistent lexical choice ( Kuang et al. , 2018 ) or a better translation of anaphoric pronouns ( Voita et al. , 2018 ; Bawden et al. , 2019 ) .
A recent review of these themes is in ( Maruf et al. , 2021 ) .
For this purpose , we further pre-processed 6 corpora containing scientific abstracts .
These corpora had different subheadings and structures as given below , which were mapped to a restricted set of section tags listed in Table 2 : 1 . Medline and Scielo : Abstracts and sub headings often without title .
We identified a total of 189 subheadings including spelling variations .
Examples include : Presenting Concerns of the Patient , Sources of Information , Novel finding , Study Selection etc .
2 . Edp : Abstracts and sub headings mostly contain titles .
45 subheadings where found , such as : Case report , Observation , Subjects and Methods , Commentary , Pedagogical objectives etc .
3 . Cochrane : only 10 different subheadings were found , including :
Abs selection criteria , abs search strategy , abs data collection , summary title etc .
The identification and standardization of subheading information was a tedious process , involving a lot of rule- based processed to take the variability of sub-headings into account .
In order to reconstruct fully parallel versions with subheadings , we also had to reinsert explicit headings in the source or the target files .
Also note that this information was not available for all abstracts .
After preprocessing files for which the full subheading information was available , we obtained the 6 fullytagged corpora ( see statistics in Table 3 ) .
A similar process was used for test sets ( see Table 4 ) .
Finally , we also introduced a third tag in all other documents as follows : sentences within an abstract where tagged as < ABS > , while all remaining sentences from other corpora where simply tagged as " unspecified subheading " ( < US > ) .
Translation framework
Our translation systems mostly used the basic Transformer models , while a few contrastive systems used the large version ( Vaswani et al. , 2017 ) .
They all rely on Facebook 's seq -2- seq library ( fairseq ) with parameters settings borrowed from transformer_wmt_de_en .
11 . The ReLU activation function was used in all encoder and decoder layers .
We optimize with Adam ( Kingma and Ba , 2015 ) , set up with a maximum learning rate of 0.0005 and an inverse square root decay schedule , as well as 4000 warmup updates .
We share the decoder input and output embedding matrices .
Models are trained with mixed precision and a batch size of 4096 tokens on 4 V100 GPUs for 300k updates .
Systems were trained until convergence based on the BLEU score on the development sets .
Evaluation was performed using SacreBleu ( Post , 2018 ) .
Scores are chosen based on the best score on the development set ( Medline 18 , 19 ) and the corresponding scores for that checkpoint are reported on Medline 20 test set .
For fine- tuned systems , the process starts with models trained to convergence , based on BLEU score on dev sets .
Training then resumes using a selected portion of the training corpus using the same parameters and criterion as for the base systems .
In our results corresponding systems are post-fixed with * - ft .
Results
We present our results for the two directions in two tables , Table 5 and 6 , differentiating the normal versus the tag-based systems .
Base systems are given on the left , ( ? ) identifies the derived ( finetuned ) systems .
Regular MT systems Results for the untagged systems are reported in Table 5 and are denoted by X * , with E * and F * representing the English to French and French to English systems respectively .
We first built baseline systems .
X0 denotes the systems built using only the in-domain data provided by the organizers .
X1 are our baseline systems built using all in- domain parallel data .
We see good improvement in both directions amounting to 4.2 and 4.8 BLEU points , which is obtained by adding around 1 M sentences of additional Cochrane and Taus corpora to the already available 3.4 M sentences from WMT '20 .
This hints at the relevance of the additional in-domain parallel corpora used .
We used the X1 systems as strong in domain baselines to study the effect of adding backtranslated in domain data .
These appear as X2 and X3 in Table 5 . Adding around 0.8M French to English and around 0.2M English to French back translated sentences did not help as much as we were expecting .
We saw similar results last year and increased the amount of back translations this Table 6 : Results for systems with sentences tagged with our 3 level tagging scheme .
Test sets are decoded 3 times , where the third tag is varied from the more specific ( < SUBHEAD > ) to the more generic ( < US > ) .
Superscripts * n denote the runs submitted .
year .
X3 denote systems built using the tagging scheme proposed by Caswell et al . ( 2019 ) , where back translations are prefixed with the < BT > tag on the source side .
Indicating that a training sentence is backtranslated allows the model to separate the helpful and harmful signal .
This proved particularly true for English into French where adding tag to back translations improved the BLEU score by 0.8 points ; but it was not helpful in the reverse direction where the amount of back translated data was may be too small ( 0.2 M lines ) .
back - translations as compared to the baseline corpora .
Finally , systems were built by initialising the parameters from huge out - of- domain corpora and later fine tuned on in- domain corpora ( X4 ) , where in - domain sub words learned from all the Biomedical data are used to segment the out-of- domain data .
The initial systems were trained for 4 epochs on general domain WMT14 EN - FR corpora .
The FR -EN system ( F4 ) is the best system in this direction , reaching a BLEU score of 35.8 .
Tagged Systems
As our 3 - level tagging scheme , described in Section 2.2 , is adding information about the domain of each sentence , we specifically focused on larger systems by using all the available in - and out - of- domain corpora .
Results are summarized in Table 6 with TE * representing the Tagged English to French systems and TF * representing the French to English systems .
TE1 is the baseline system for EN - FR built with all the available in domain and out-domain data .
TE4 is the corresponding baseline using a Large Transformer 12 .
We then fine- tune these systems with all the in-domain data including the back translations , these are represented by TE2 and TE5 respectively .
This gives an appreciable gain of 2.5 and 2.3 BLEU points for Transformer and Transformer large systems .
As we saw no major difference in scores for Transformer versus Transformer large , so we continue the rest of experiments with the simple Transformer architecture .
Fine-tuning further with just abstracts from Cochrane and Medline did not yield any further improvement .
French to English results display similar trends .
The baseline ( TF1 ) using all available ( in domain + out-of- domain ) data tagged with our 3 level scheme yielded a BLEU score of 32.1 .
Fine-tuning it further with all in- domain data ( TF2 ) gives an improvement of 3.6 BLEU points which does not improve further when fine-tuning continues with just Cochrane and Medline abstracts ( TF3 ) .
To measure whether the model learned document domain and / or sentence origin information , we tested by tagging the test set with three different tags in the third position , using either the exact subheading , or abstract or UnSpecified for sentences for which the sub-section is unknown .
Table 6 reports the scores for the three cases .
Though the difference in scores for the three cases is minute , in - domain systems { TE2 , TE3 , TE5 } and { TF2 , TF3 } achieve their best results when the test set is tagged with the subheading or the abstract tag , typical feature of the biomedical corpora .
Conversely , for out - of- domain systems { TE1 , TE4 , TF1 } , the best scores are always for the test set tagged with < US >.
This strongly hints that the system is using the extra-information provided by the tag .
These observations need to be confirmed using other metrics , as BLEU may not properly reflect these differences .
For English to French direction we got better scores with the tagged systems , with the best system ( TE2 = 38.7 ) achieving 2.1 BLEU points more than the best un-tagged system ( E3 = 12 hidden size of 1024 and a feed forward size of 4096 .
Rest of the parameters same as for other systems .
36.6 ) .
This was however not the case for French - English where both tagged and un-tagged systems had more or less similar scores .
Systems in Tables 5 and 6 have different baselines , thus to establish a fair comparison we report numbers for comparable systems in Table 7 . Systems { E2,E3 , F2,E3 } are copied from Table 5 , whereas { TE and TF } are the corresponding systems using our tagging scheme on the sole biomedical data .
We see here a clear gain for French - English when we use a 3 - level tagging scheme ( TF ) compared to just adding the < BT > tag ( F3 ) ; results for the reverse direction are more even and having one or three tags does not make a difference .
EN -FR
Conclusion
In this section , we have presented our work for the biomedical task .
We notably have tried to incorporate document origin and structure information and improve strong baseline systems that were using a wealth of in- domain and out-of- domain data .
.
Overall , our systems for this year are significantly better than last year 's , even though the benefits of adding document structures as tags need to be confirmed by more experiments and analyses .
