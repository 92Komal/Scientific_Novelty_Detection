title
ChrEnTranslate : CherokeeEnglish Machine Translation Demo with Quality Estimation and Corrective Feedback
abstract
We introduce ChrEnTranslate , an online ma chine translation demonstration system for translation between English and an endangered language Cherokee .
It supports both statistical and neural translation models as well as pro vides quality estimation to inform users of re liability , two user feedback interfaces for ex perts and common users respectively , exam ple inputs to collect human translations for monolingual data , word alignment visualiza tion , and relevant terms from the Cherokee English dictionary .
The quantitative evalu ation demonstrates that our backbone trans lation models achieve stateoftheart transla tion performance and our quality estimation well correlates with both BLEU and human judgment .
By analyzing 216 pieces of expert feedback , we find that NMT is preferable be cause it copies less than SMT , and , in gen eral , current models can translate fragments of the source sentence but make major mistakes .
When we add these 216 expertcorrected paral lel texts into the training set and retrain mod els , equal or slightly better performance is ob served , which demonstrates indicates the po tential of humanintheloop learning .
1
Introduction
Machine translation is a relatively mature natural language processing technique that has been de ployed to realworld applications .
For instance , Google Translate currently supports translations between over 100 languages .
However , a lot of lowresource languages are out there without the support of modern technologies , which might ac celerate their vanishing .
In this work , we focus on one of those languages , Cherokee .
Cherokee is one of the most wellknown Native American languages , however , is identified as an " endan gered " language by UNESCO .
Cherokee nations have carried out language revitalization plans ( Na tion , 2001 ) and established language immersion programs and k12 language curricula .
Chero kee language courses are offered in some universi ties , including UNC Chapel Hill , the University of Oklahoma , Stanford University , Western Carolina University .
A few pedagogical books have been published ( Holmes and Smith , 1976 ?
Joyner , 2014 ?
Feeling , 2018 and a digital archive of historical Cherokee language documents has been built up ( Bourns , 2019 ?
Cushman , 2019 .
However , there are still very limited resources available on the In ternet for Cherokee learners ?
meanwhile , first lan guage speakers and translators of Cherokee are mostly elders and would likely benefit from ma chine translation 's assistance .
This motivates us to develop the first online CherokeeEnglish machine translation demonstration system .
Extending our previous works ( Frey , 2020 ?
Zhang et al. , 2020 , we develop the backbone statistical and neural ma chine translation systems ( SMT and NMT ) on a larger parallel dataset ( 17 K ) and obtain the state oftheart CherokeeEnglish ( ChrEn ) and English Cherokee ( EnChr ) translation performance .
Besides translation , our system also supports quality estimation ( QE ) for both SMT and NMT .
QE is an important ( missing ) component of ma chine translation systems , which is used to inform users of the reliability of machinetranslated con tent ( Specia et al. , 2010 ) .
Since our models are trained on a very limited number of parallel sen tences , it is expected that the translations will be poor in most cases when used by Internet users .
Therefore , QE is essential for avoiding misuse and warning users of potential risks .
Existing best performance QE models are usually trained under supervision with quality ratings from professional translators ( Fomicheva et al. , 2020a ) .
However , we are unable to easily collect a lot of human rat ings for Cherokee , due to its state of endanger ment .
Nonetheless , we test both supervised and unsupervised QE methods : ( 1 ) Supervised : we use BLEU ( Papineni et al. , 2002 ) as the quality rat ing proxy and train a BLEU regressor ?
( 2 ) Unsu pervised : following the uncertain estimation lit erature ( Lakshminarayanan et al. , 2017 ) , we use the ensemble model 's output probability as the es timation of quality .
Furthermore , to evaluate how well the QE models perform , we collect 200 human quality ratings ( 50 ratings for SMT ChrEn , SMT EnChr , NMT ChrEn , and NMT EnChr , respec tively ) .
We show that our methods obtain mod erate to strong correlations with human judgment ( Pearson correlation coefficient ? ? 0.44 ) .
One main purpose of our system is to allow humanintheloop learning .
Since limited paral lel texts are available , it is important to involve humans , especially experts , in the loop to give feedback and then improve the models accord ingly .
We develop two different user feedback interfaces for experts and common users , respec tively ( shown in Figure 2 ) .
We ask experts to pro vide quality rating , to correct the modeltranslated content , and to leave openended comments ?
for common users , we allow them to rate how help ful the translation is and to provide openended comments .
Upon submission , we collected 216 pieces of feedback from 4 experts .
We find that experts favor NMT more than SMT because SMT excessively copies from source sentences ?
accord ing to their ratings and comments , current transla tion systems can translate fragments of the source sentence but make major mistakes .
Our naive humanintheloop learning , by adding these 216 expertcorrected parallel texts back to the training set , obtains equal or slightly better translation re sults .
Plus , the expert comments shine a light on where the model often makes mistakes .
Besides , our demo allows users to input text or choose an ex ample input to translate ( shown in Figure 1 ) .
These examples are from our monolingual databases , so that experts will annotate them by providing trans lation corrections .
Finally , to support an interme diate interpretation of the model translations , we visualize the word alignment learned by the trans lation model and link to cherokeedictionary to pro vide relevant terms from the dictionary .
Our code is hosted at ChrEnTranslate and our online website is at chren.cs.unc.edu .
Common users need to accept agreement terms before us ing our service to avoid misuse ?
access the ex pert page chren.cs.unc.edu /expert requires autho rization .
We encourage fluent Cherokee speakers to contact us and contribute to our humaninthe loop learning procedure .
A demonstration video of our website is at YouTube .
In summary , our demo is featured by ( 1 ) offering the first online machine translation system for translation between Cherokee and English , which can assist both pro fessional translators or Cherokee learners ? ( 2 ) doc umenting human feedback , which , in the long run , expands Cherokee data corpus and allows human intheloop model development .
Additionally , our website can be easily adapted to any other low resource translation pairs .
System Description
Translation Models
As shown in Figure 1 , our system allows users to choose statistical or neural model ( SMT or NMT ) .
SMT is more effective for outofdomain transla tion between Cherokee and English ( Zhang et al. , 2020 ) .
We implement phrasebased SMT model via Moses ( Koehn et al. , 2007 ) , where we train a 3 gram KenLM ( Heafield et al. , 2013 ) and learn word alignment by GIZA ++ ( Och and Ney , 2003 ) .
Model weights are tuned on a development set by MERT ( Och , 2003 ) .
NMT has better indomain performance and can generate more fluent texts .
We implement the global attentional model proposed by Luong et al . ( 2015 ) .
Detailed hyperparameters can be found in Section 3.1 .
Note that we do not use Trans former because it empirically works worse ( Zhang et al. , 2020 ) .
And we find that the multilingual techniques we explored only significantly improve indomain performance when using multilingual Bible texts , so we suspect that it biases to Bible style texts .
Hence , we also do not apply multilin gual techniques and just train the backbone models with our CherokeeEnglish parallel texts .
We use a 3 model ensemble as our final working model .
Quality Estimation Supervised QE .
The QE ( Specia et al. , 2010 ) task in WMT campaign provides thousands of modeltranslated texts plus corresponding human ratings , which allow participants to train super vised QE models .
Fomicheva et al. ( 2020a ) show that supervised models work significantly better than unsupervised ones .
Since we are unable to collect thousands of human ratings , we use BLEU ( Papineni et al. , 2002 ) as the quality rating .
For NMT , we use : ? 1 Lt ? Lt i=1 ? Ls j=1 ? ij log ? ij , where L s is the length of source text , and ? ij is the attention weight between target token i and source to ken j .
Finally , we use XGBoost ( Chen and Guestrin , 2016 ) as the BLEU regressor .
2
As shown in Fig ure 1 , we use 5 stars to show QE , therefore , we rescale the estimated quality to 05 by dividing the predicted BLEU score ( 0100 ) by 20 .
Unsupervised QE .
Even though supervised QE works better ( Fomicheva et al. , 2020a ) , we suspect that the advantage cannot generalize to open do main scenarios unless we have a large amount of humanrated data to learn from .
Hence , we also explore unsupervised QE methods .
Unsupervised QE is closely related to uncertainty estimation .
We can use how uncertain the model is to quantify how lowquality the model output is .
Though it is intu itive to use the output probability as model 's con fidence , Guo et al . ( 2017 ) point out that the output probability is often poorly calibrated , so that they propose to recalibrate the probability on the devel opment set .
However , this method is designed for classification tasks and not applicable for language generation .
Gal and Ghahramani ( 2016 ) show that " dropout " can be a good uncertainty estimator , in spired by which Fomicheva et al . ( 2020 b ) propose the dropout features .
However , the multiple for ward passes are not preferable for an online system .
Lakshminarayanan et al. ( 2017 ) demonstrate that the ensemble model 's output probability can bet ter estimate the model 's uncertainty than dropout .
We find that this method is simple yet effective for NMT .
Note that we normalize the output probabil ity by the sentence length .
Similarly , we rescale the normalized probability ( 01 ) to 05 by multi plying it by 5 .
Human Quality Rating .
So far , our QE devel opment and evaluation are all based on BLEU .
To better evaluate QE performance , we collect 200 hu man ratings ( all rated by Prof.
Benjamin Frey 3 ) , 50 ratings for ChrEn SMT , EnChr SMT , ChrEn NMT , and EnChr NMT , respectively .
We fol low the direct assessment setup used by FLoRes ( Guzm ? n et al. , 2019 ) , 4 and thus each translated sentence receives a 0100 quality rating .
3 Benjamin Frey is a proficient secondlanguage Cherokee speaker and a citizen of the Eastern Band of Cherokee Indians .
4 0 - 10 : represents a translation that is completely incorrect and inaccurate ?
11 - 29 represents a translation with a few cor rect keywords , but the overall meaning is different from the source ?
30 - 50 represents a translation that contains translated fragments of the source string , with major mistakes ?
51 - 69 represents a translation that is understandable and conveys the overall meaning of source string but contains typos or gram matical errors ?
70 - 90 represents a translation that closely pre serves the semantics of the source sentence ?
90 - 100 range rep
User Feedback & Example Inputs
Enlarging the parallel texts is a fundamental ap proach to improve the translation model 's per formance .
Besides compiling existing translated texts , it is important to newly translate English texts to Cherokee by translators .
Our system is de signed to not only assist these translators but also document their feedback and postedited correct translation , so that model can be improved by us ing this feedback , i.e. , humanintheloop learning .
To achieve this goal , we design two kinds of user feedback interfaces .
One is for common users , in which users can rate how helpful the translation is ( in 5 point Likert scale ) and leave openended comments , as shown in Figure 2 Figure 1 , besides inputting text , users can also choose an example input to translate .
These ex amples are from our Cherokee or English mono lingual databases .
On the one hand this provides users with more convenience ?
on the other hand , whenever experts submit translation corrections of an example , we will updated its status as " labeled " .
Hence , we can gradually collect human transla tions for the monolingual data .
Other Features
As shown in Figure 3 , to make model prediction more interpretable to users , we visualize the word alignment learned by the translation model .
For SMT , we visualize the hard wordtoword align ment ?
for NMT , we visualize the soft attention map between source and target tokens .
Additionally , to provide users with some oracle and handy ref erences from the dictionary , we link to cherokee dictionary .
We use each of the source and target tokens as a query and list up to 15 relevant terms on our web page .
Evaluation
Implementation Details Data .
To train translation models , we use the 14 K parallel data collected by our previous work ( Zhang et al. , 2020 ) plus 3 K newly complied par allel texts .
We randomly sample 1 K as our devel opment set and treat the rest as the training set .
The data is opensourced at ChrEn / data / demo .
To col lect human quality ratings , we randomly sample 50 examples from the development set , and for each of them , we collect 4 ratings for ChrEn / EnChr SMT and ChrEn / EnChr NMT , respectively .
Setup .
We implement SMT models via Moses ( Koehn et al. , 2007 ) .
After training and tuning , we run it as a server process .
5
We develop our NMT models via OpenNMT ( Klein et al. , 2017 ) .
For both ChrEn and EnChr NMT models , we use 2layer LSTM encoder and decoder , general attention ( Luong et al. , 2015 ) , hidden size = 1024 , label smoothing ( Szegedy et al. , 2016 ) equals to 0.2 , dynamic batching with 1000 tokens .
Differ ently , the ChrEn NMT model uses dropout = 0.3 , BPE tokenizer ( Sennrich et al. , 2016 ) , and mini mum word frequency = 10 ?
the EnChr NMT model uses dropout =0.5 , Moses tokenizer , and minimum word frequency=0 .
We train each NMT model with three random seeds ( 7 , 77 , 777 ) and use the 3 model ensemble as the final translation model , and we use beam search ( beam size=5 ) to gener ate translations .
We implement the supervised QE model with XGBoost .
6 XGBoost has three impor tant hyperparameters : max depth , eta , the number of rounds .
Tuned on the development set , we set them as ( 5 , 0.1 , 100 ) for ChrEn SMT , ( 3 , 0.1 , 80 ) for EnChr SMT , ( 4 , 0.5 , 40 ) for ChrEn NMT , and Table 2 : The performance of translation models . ( 5 , 0.1 , 40 ) for EnChr NMT .
Lastly , the backend of our demonstration website is based on the Flask framework .
Metrics .
We evaluate translation systems by BLEU ( Papineni et al. , 2002 ) calculated via Sacre BLEU 7 ( Post , 2018 ) .
Supervised QE models are developed by minimizing the mean square error of predicting BLEU , but all QE models are evaluated by the correlation with BLEU on development set and the correlation with human ratings .
We use Pearson correlation ( Benesty et al. , 2009 ) .
Quantitative Results Translation .
Table 2 shows the translation per formance on our 1 K development set , which are significantly better than the singlemodel in domain translation performance reported in our previous work ( Zhang et al. , 2020 ) and thus achieves the stateoftheart results .
In addition , the 3 model NMT ensemble further boosts the per formance .
to strong ( ? ? 0.5 ) ( Cohen , 1988 ) 2 .
To tackle the archaic English issue , we simply replace archaic English terms ( " thy " , " thou " ) with new English terms ( " your " , " you " ) .
QE .
Conclusion & Future Work
In this work , we develop a CherokeeEnglish Machine Translation demonstration system that intends to demonstrate and support automatic translation between Cherokee and English , col lect user feedback / translations , allow humanin theloop development , and eventually contribute to the revitalization the endangered Cherokee language .
Future work involves inviting more ex perts and common users to test / use our system and proposing more efficient and effective humanin theloop learning methods .
