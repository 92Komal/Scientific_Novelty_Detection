title
Cross Attention Augmented Transducer Networks for Simultaneous Translation
abstract
This paper proposes a novel architecture , Cross Attention Augmented Transducer ( CAAT ) , for simultaneous translation .
The framework aims to jointly optimize the policy and translation models .
To effectively consider all possible READ - WRITE simultaneous translation action paths , we adapt the online automatic speech recognition ( ASR ) model , RNN -T , but remove the strong monotonic constraint , which is critical for the translation task to consider reordering .
To make CAAT work , we introduce a novel latency loss whose expectation can be optimized by a forward - backward algorithm .
We implement CAAT with Transformer while the general CAAT architecture can also be implemented with other attention - based encoder-decoder frameworks .
Experiments on both speech - to- text ( S2T ) and text - to- text ( T2T ) simultaneous translation tasks show that CAAT achieves significantly better latency - quality trade - offs compared to the state - of - the - art simultaneous translation approaches .
1
Introduction Simultaneous translation , which starts to translate input sentences before they are finished , is of importance to many real-life applications such as teleconference systems and time -sensitive spoken document analysis and conversion .
While a substantial progress has been made on offline machine translation ( Wu et al. , 2016 ; Vaswani et al. , 2017 ; Hassan et al. , 2018 ) , more research on simultaneous translation is yet highly desirable .
Central to the task is performing high-quality low-latency translation , which involves the key challenges of developing optimal policies for the READ-WRITE action paths 1 The code is available at https://github.com/ danliu2 / caat. as well as generating high-quality target sequences based only on partial source sequences .
This paper aims to optimize the policy and translation model jointly , by expanding target sequences with blank symbols for READ actions .
The loss function can be defined as negative loglikelihood ( NLL ) of marginal distribution through all expanded paths .
A similar problem in automatic speech recognition ( ASR ) has been tackled with RNN -T ( Recurrent Neural Network Transducer ) ( Graves , 2012 ) by an efficient forward - backward algorithm .
However , RNN -T is trained based on the monotonic alignment between source and target sequences , which is not suitable for simultaneous translation , as it cannot properly consider reordering .
On the other hand , the forward - backward algorithm is not available for attention - based encoderdecoder ( Bahdanau et al. , 2015 ) architectures , including Transformer ( Vaswani et al. , 2017 ) , due to the deep coupling between source contexts and target history contexts .
To solve this problem , we separate the cross attention mechanism from target history representation in attention - based encoder-decoder , which can also be viewed as RNN -T with the joiner being augmented by cross attention mechanism , resulting in Cross Attention Augmented Transducer ( CAAT ) .
However , cross attention mechanism removes the alignment constraint in RNN -T which originally encourages an appropriate latency .
To ensure latency under control , jointly minimizing a latency loss is required .
Both the NLL loss and latency loss can be efficiently optimized by a forward - backward algorithm .
The main contributions of this paper are threefold : ( 1 ) We propose a novel architecture , Cross Attention Augmented Transducer , which jointly optimizes the policy and translation model by considering all possible READ - WRITE simultaneous translation action paths .
( 2 ) We introduce a novel latency loss whose expectation can be optimized by a forward - backward algorithm .
Training with this latency loss ensures the latency of CAAT simultaneous translation model to be under control .
( 3 )
The proposed model achieves significantly better latency - quality trade - offs compared to the state- ofthe - art simultaneous translation approaches .
Related Work Recent work on simultaneous translation falls into two categories .
The first category uses a fixed policy for the READ / WRITE actions .
Cho and Esipova ( 2016 ) propose simultaneous translation with the wait - if -* policy for an offline model .
Ma et al. ( 2019 ) propose a wait -k policy for both the training and inference period .
The second category includes models with a flexible policy learned and / or adaptive to current context .
Gu et al. ( 2017 ) introduce an agent trained by reinforcement learning from the interaction with a pre-trained offline neural machine translation model .
Zheng et al. ( 2019a ) train the agent by supervise learning with label sequences generated via the rank of golden target words given partial input .
A special subcategory of flexible policy jointly optimize policy and translation by monotonic attention customized to translation model , e.g. , Monotonic Infinite Lookback ( MILk ) attention ( Arivazhagan et al. , 2019 ) on RNN encoder-decoder ( Bahdanau et al. , 2015 ) and Monotonic Multihead Attention ( MMA ) ( Ma et al. , 2020c ) on Transformer ( Vaswani et al. , 2017 ) .
End-to- end speech - to- text ( S2T ) simultaneous translation has been investigated in ( Ma et al. , 2020 b , d ; Ren et al. , 2020 ) , among which Ma et al . ( 2020 b ) adapt latency metrics from T2T simultaneous translation to S2T simultaneous translation , and experiment with both the fixed and flexible policy .
Ma et al. ( 2020d ) study the effect of speech block processing on S2T simultaneous translation .
Ren et al . ( 2020 ) experiment with the wait -k policy based on a source language CTC segmenter .
In our work , we optimize the marginal distribution of all expanded paths motivated by RNN -T ( Graves , 2012 ) .
Unlike RNN -T , the CAAT model removes the monotonic constraint , which is critical for considering reordering in machine translation tasks .
The optimization of our latency loss is motivated by Sequence Discriminative Training in ASR ( Povey , 2005 ) .
Preliminaries
Notations and formulation
Let x and y denote the source sequence and target sequence , and f and g the encoder and decoder function , respectively .
For simultaneous translation , let a j denotes the length of source sequence processed when deciding the target y j .
The policy of simultaneous translation is denoted as an action sequence p ? { R , W } | x |+ |y | where R denotes the READ action and W the WRITE action .
If the READ action is replaced with a blank symbol ? , the policy can also be represented by the expanded target sequence ? ? ( V ? {?} ) |x |+|y | , where V is the vocabulary of the target language .
Note that removing all ? in ? results in the original target sequence y .
The mapping from y to sets of all possible expansion ? is denoted as H( x , y ) .
Recurrent Neural Network Transducer RNN -T ( Graves , 2012 ) draws condition probability Pr( y|x ) by marginalizing all possible alignment paths as : Pr ( y|x ) = ?H( x , y ) Pr( ?|x ) = ?H( x , y ) |x |+|y | k=1 Pr ( ?
k | i k , j k ) ( 1 ) where i k and j k denote the source and target position of the k-th element in ? , respectively , and ? = (? 1 , ?2 , ... , ?|x|+|y | ) ? H( x , y ) ? { V ? ?} |x |+|y | corresponds to a possible expansion path which yields y after removing the blank symbol ?.
As shown in Figure 1 ( b ) , to calculate P ( ?
k |h i k , y <j k ) , RNN -T divides decoder into predictor and joiner , where the predictor , denoted f pred , produces target history representation ( Eq. ( 2 ) ) , and the joiner products output probability Pr( y |i , j ) by joint representations from predictor and encoder ( Eq. ( 3 ) ) .
h pred j = f pred ( y <j ) ( 2 ) Pr( y |i , j ) = sof tmax ( W h h i + W p h pred j ) ( 3 ) Though named as RNN Transducer , other sequence processing architectures work well as the encoder or predictor , e.g. , Transformer Yeh et al. , 2019 ) .
Online decoding is natural for RNN -T if the encoder works with streaming input , which makes RNN -T widely adopted in both the online and offline ASR tasks .
One drawback of RNN -T is that it is based on a monotonic alignment between the input and output sequence , making it unsuitable for sequenceto-sequence tasks with reordering , e.g. , machine translation .
4 The Proposed Method
The goal of simultaneous translation is to achieve high translation quality and low latency .
A natural loss function hence measures the NLL loss of marginal conditional distribution and expectation of latency metric through all possible expanded paths : L( x , y ) = L N LL ( x , y ) + L latency ( x , y ) = ? log ? Pr ( ?|x ) + E ?l( ? ) = ? log ? Pr ( ?|x ) + ? Pr(?|y , x )l ( ? ) ( 4 ) where Pr( ?|y , x ) = Pr( ?|x ) ? ?H ( x , y ) Pr( ? |x ) , ? ? H ( x , y ) is one of the expanded paths of the target sequence y , and l ( ? ) is the latency loss for path ?.
As the total number of expanded paths is exponential with regard to | x | + | y | , computing the marginal probability ?H( x , y ) Pr ( ?|x ) is non-trivial .
RNN -T solves this with a forwardbackward algorithm ( Graves , 2012 ) , which inherently requires paths in the graph to be mergeable .
That is , the representations of the same location in different paths should be identical .
Conventional attention - based encoder-decoder architectures as shown in Figure 1 ( a ) , however , do not satisfy this requirement .
Take Figure 2 as an example , the decoder hidden states for the red path ?1 and the blue path ?2 are described below ( we denotes s n i as the representation of the i-th decoder step in the expanded path ?n ) : s 1 2 = g( s 1 1 , h ?2 ) = g( g( s 0 , h ?2 ) , h ?2 ) ( 5a ) s 2 2 = g( s 2 1 , h ?2 ) = g( g( s 0 , h ?1 ) , h ?2 ) ( 5 b )
The decoder states at output step 2 with different history paths , s 1 2 and s 2 2 , are not identical .
This is due to the coupling of source and previous target representation by the attention mechanism in the decoder .
The same problem exists in Transformer , from the coupling of self-attention and encoderdecoder cross attention in each block .
To solve this , we separate the cross attention mechanism from the target history representation , which is similar to the joiner and predictor in RNN -T .
The novel architecture , as shown in Figure 1 ( c ) , can be viewed as an extended version of RNN -T with the joiner augmented by cross attention mechanism , and is named as Cross Attention Augmented Transducer ( CAAT ) .
Different from RNN -T , the joiner in CAAT is a complex architecture with attention mechanisms as in Eq. ( 6 ) : s i , j = s( attn ( h pred j , h enc ?i ) , h pred j ) ( 6 ) Note that s i , j is independent of previous nodes s i , j in path ? , and the same location from different paths in Figure 2 produces the same state representation .
By analyzing the diffusion of the output probability through the lattice in Figure 2 , we can find that Pr( y|x ) is equal to the sum of probabilities over any top-right to bottom- left diagonal nodes .
Defining the forward variable ?( i , j ) as the probability of outputting y [ 1:j ] during x [ 1 :i ] , and the backward variable ?( i , j ) as the probability of outputting y [ j + 1:|y | ] during x [ i :| x | ] , we can draw the marginal likelihood Pr( y |x ) as : Pr( y |x ) = ( i , j ) : i+ j=m ?( i , j ) ? ?( i , j) L N LL ( x , y ) = ? log Pr(y|x ) ( 7 ) where 1 ? m ? | x | + |y |.
The detailed derivation of NLL loss of CAAT can be found in Appendix A.1 .
The proposed CAAT can be implemented with a variety of attention - based encoder-decoder frameworks .
In this paper , we implemented CAAT with Transformer , by dividing Transformer 's decoder into the predictor and joiner module .
As shown in Figure 3 , the predictor and joiner share the same number of transformer blocks as the conventional transformer decoder , but there are no crossattention blocks in the predictor module and no self-attention blocks in the joiner .
Multi-Step Decision
The CAAT architecture gains the ability of handling source-target reordering at the cost of an expensive joiner .
The complexity of joiner is O ( | x | ? | y | ) during training .
For RNN -T , the joiner is efficient because only softmax operates at O ( | x | ? | y | ) .
But for CAAT , joiner takes up half of the parameters of decoder , which means the complexity of CAAT is about | x| 4 times higher than the conventional encoder-decoder framework during training .
RNN -T needs to ensure the output timing of y j is the corresponding source frame a j = align ( x , y j ) .
However , based on attention mechanism , CAAT only needs to ensure output timing to be after the corresponding position ( a j ? align ( x , y j ) ) .
Therefore , it is no longer necessary to make decision each encoder frame ; the decision step size d > 1 is appropriate for CAAT , which reduces the complexity of the joiner from O ( | x | ? | y | ) to O |x|?|y | d .
Besides , the decision step size is also an effective way to adjust latency - quality trade- off .
Latency Loss CAAT relaxes the restriction of output timing by attention mechanism , which means all source step i ? align( x , y j ) should be appropriate for output y j , including the offline path ( ? j : a j = | x | ) .
To avoid the CAAT model bypassing online policy by choosing the offline path , the latency loss L latency ( x , y ) as defined in Eq. ( 4 ) is required .
( Povey , 2005 ) , we optimize the latency loss with the forward - backward algorithm .
To calculate the expectation of latency loss through all paths ? , mergeable is also a requirement to the latency loss definition , which means the latency loss through path ? may be defined as l( ? ) = |x |+|y | k=1 l( ? k ) and l(? k ) is independent of l (? k =k ) .
However , both Average Lagging ( Ma et al. , 2019 ) and Differentiable Average Lagging ( Arivazhagan et al. , 2019 ) do not meet this requirement .
We hence introduce a novel latency function as follows :
Motivated by Sequence Criterion Training in ASR l( i , j ) = 1 |y | max i ? j ? | x| |y | , 0 ( 8 ) l( ? k ) = 0 if ?k = ? l( i k , j k ) else ( 9 ) l( ? ) = |?| k=1 l( ? k ) ( 10 ) where i k = k k =1 I ( ?
k = ? ) and j k = k k =1 I ( ?
k = ? ) denote the number of READ and WRITE actions before ?k , respectively .
The maximization operation is used to avoid encouraging over-aggressive decision paths .
This latency definition is not rigorous enough to be an evaluation metric for the under-estimation after source ended , as analyzed in ( Arivazhagan et al. , 2019 ) , but it can still be used as a loss function .
By defining the forward latency variable ? lat ( i , j ) as the expectation of latency of outputting y [ 1:j ] during x [ 1 ,2 , ? , i ] , and the backward latency variable beta lat ( i , j ) as the expectation of latency of outputting y [ j + 1:| y | ] during decision steps x [ i , ? , |x | ] , the latency loss can be drawn as : c( i , j ) = ? lat ( i , j ) + ? lat ( i , j ) L latency ( x , y ) = E ?H ( x , y ) l( ? ) = ( i , j ) :i+j=m ?( i , j ) ?( i , j ) c ( i , j ) Pr( y |x ) where 1 ? m ? | x | + |y |.
The detailed derivation of latency loss of CAAT can be found in Appendix A.2 .
Offline Auxiliary Loss
We add the negative log-likelihood loss of the offline translation path as an auxiliary loss to CAAT model training for two reasons .
First , we hope the CAAT model falls back to offline translation in the worst case ; second , the CAAT translation is carried out in accordance with offline translation when a source sentence finishes .
The final loss function for CAAT training is defined as follows : L( x , y ) = L N LL ( x , y ) + ? latency L latency ( x , y ) + ? of f line L of f line ( x , y ) = ? log ? Pr ( ?|x ) + ? latency ? Pr (?|y , x )l ( ? ) ? ? of f line log P of f line ( y|x ) ( 11 ) where ? latency and ? of f line are the scaling factors corresponding to L latency and L of f line , respectively .
And we set ? latency = ? of f line = 1.0 if not specified .
Streaming Encoder Unidirectional Transformer encoder ( Arivazhagan et al. , 2019 ; Ma et al. , 2020 c ) is not effective for speech data processing , because of the close relatedness to the right context for speech feature x i .
Block processing ( Dong et al. , 2019 ; is introduced for online ASR , but it lacks direct observation to infinite left context .
We process the streaming encoder for speech data by block processing with the right context and infinite left context .
First , input representations h is divided into overlapped blocks with block shift step m and block size m + r. Each block consists of two parts , the main context m n = h m *
n+ 1 , ? ? ? , h m * ( n+ 1 ) and the right con- text r n = h ( n+ 1 ) * m+1 , ? ? ? , h ( n+ 1 ) * m+r .
The query , key , and value of block b n in self-attention can be described as follows : Q = W q [ m n , r n ] ( 12 ) K = W k [ m 1 , ? ? ? , m n , r n ] ( 13 ) V = W v [ m 1 , ? ? ? , m n , r n ] ( 14 )
By reorganizing the input sequence and designed self-attention mask , training is effective by reusing conventional transformer encoder layers .
And unidirectional transformer can be regarded as a special case of our method with {m = 1 , r = 0 } .
Note that the look - ahead window size in our method is fixed , which enables us to increase transformer layers without increasing latency .
We set the main context size and right context size to 8 and 4 , respectively , for our experiments on speech - to - text simultaneous translation , and conventional unidirectional transformer encoder {m = 1 , r = 0 } for experiments on text - to - text simultaneous translation .
Inference of CAAT Simultaneous Translation
The online inference for CAAT is adapted from beam search for RNN -T ( Graves , 2012 ) , and the changes are as follows 2 : ( 1 ) We only merge paths between decision steps , as the cost of the joiner of CAAT is significantly more expensive than that of RNN -T. ( 2 We use SentencePiece ( Kudo and Richardson , 2018 ) to generate a unigram vocabulary of size 20,000 for the source and target language jointly .
Our experiments on speech - to - text simultaneous translation are based on Transformer ( Vaswani et al. , 2017 ) .
Since the variance of the length of speech frames is more significant than that of text length , we use both cosine positional embedding ( Vaswani et al. , 2017 ) and relative positional attention ( Shaw et al. , 2018 ) for speech encoder , and only cosine positional embedding for the decoder .
Detailed hyper-parameters of our models can be found in Appendix C.1 .
Training and Inference Training speech translation models is often regarded to be more difficult than training text machine translation or ASR models .
We use two methods to improve the performance and stability of model training .
The first is to pre-train encoder with ASR task ( Ma et al. , 2020 b ) , and the second is to leverage sequence - level knowledge distillation with text machine translation model ( Ren et al. , 2020 ) .
Training CAAT models require significantly larger GPU memory than that used in conventional Transformer due to the spatial complexity O ( | x ||y | d ) of the joiner module ; we solve this by splitting hidden states into small pieces before sending them into the joiner and recombining them during backpropagation .
Our implementation is based on the Fairseq library ( Ott et al. , 2019 ) ; the NLL and latency loss for CAAT are implemented based on warp-rnnt 4 . Evaluation
We evaluate our models with SimulEval ( Ma et al. , 2020a ) .
Translation quality is measured by detokenized case-sensitive BLEU ( Papineni et al. , 2002 ) ; latency is measured with the adapted version of word-level Average Lagging ( AL ) ( Ma et al. , 2020a ) .
Results
We compare CAAT to the current state - of - the - art model in speech - to - text simultaneous translation ( Ma et al. , 2020 b ) , which uses wait -k with a fixed pre-decision step size of 320 ms .
All our simultaneous speech translation models , both wait -k and CAAT are trained with encoder pretrained on ASR task and sequence - level knowledge distillation with text translation model .
Two inference methods are used for wait -k , conventional beam search only on target tail ( when source finishes ) and speculative beam search ( SBS ) ( Zheng et al. , 2019 b ) , both with a beam size of 5 ; the forecast steps in SBS is set to be 2 .
For CAAT we set the intra-decision beam size b 1 = 5 and inter-decision beam size b 2 = 1 as described in Sec. 4.3 .
The latency -quality curves of CAAT are produced by varying decision step size d ? { 8 , 16 , 32 , 48 , 64 , 80 , +?} , and wait -k by varying k ? { 1 , 2 , 4 , 6 , 8 , 10 , 12 , +?}. The AL - BLEU curves on the MuST -C EN ?DE and EN ?ES test sets are shown in Figure 4 . 5 From the figure we can observe that : ( 1 ) In general CAAT significantly outperforms wait -k ( with and without SBS ) in both the EN?DE and EN ?ES task .
Especially in the low-latency region ( AL < 1000 ms ) ( Ansari et al. , 2020 ) , CAAT outperforms wait -k with SBS by more than 3 BLEU points .
( 2 ) The Offline models of CAAT and wait -k obtain similar BLEU , suggesting that the adapted architecture of CAAT performs comparably with conventional Transformer in an offline scenario .
( 3 ) With the same wait step k , SBS can produce lower latency .
This is due to the word- level latency metrics we used requires an additional token to ensure complete word submitted , which can be offset by the forward exploration in SBS .
Ablation Study
Effectiveness of Streaming Encoder
The performance of our offline models with full-sentence encoder compared to the state - of - the - art offline speech translation systems Inaguma et al. , 2020 ) are demonstrated in Table 1 .
We also show the ablation analyses on sequencelevel knowledge distillation with text translation model ( KD ) and pretrain encoder with ASR task ( Pretrain ) .
Model EN?DE EN?ES 22.7 27.2 ( Inaguma et al. , 2020 ) 22.9
We further compare offline translation models with streaming encoders to those with the conventional full-sentence encoder .
As shown in Table 1 , the performance of the translation model with a unidirectional encoder drops 2 - 3 BLEU points compared to that with a full-sentence encoder , and the gap is gradually narrowed by the increase of main block size m and introduction of right context .
Considering the effect on latency , we choose {m = 8 , r = 4 } .
Effectiveness of ? latency and ? of f line
The effectiveness of ? of f line is demonstrated in Table 3 . Furthermore , as shown in Figure 5 , though ?
latency may affect the trade- off between translation quality and latency , varying ?
latency is not as effective as varying the decision step size d , and we found the model training will be unstable when ? latency ? 2.0 .
Effectiveness of Beam Search
The effectiveness of the intra-decision beam size b 1 and interdecision beam size b 2 on simulation translation performance is shown in Table 4 .
We can find that beam search in one decision step brings an improvement of about 0.7 BLEU over the greedy search .
And if we allow multiple hypothesizes between decision steps we may get another 0.5 BLEU improvement at the cost of latency ( AL increases from 1114.9 to 2433.5 ) .
However , this may be useful in the scenarios where revision is allowed ( Arivazhagan et al. , 2020 ) , e.g. , simultaneous translation for subtitle .
b Case Study
We perform case study to demonstrate the advantages of CAAT model over wait -k with SBS , we compare wait -k k = 2 with CAAT d = 32 for they have similar AL latency .
As shown in Figure 7 , wait -k generates meaningless translation by ' predict ' in the place of pauses and changes in speech rate , while CAAT does not suffer from this problem .
As a result , CAAT outperforms waitk with SBS .
Text - to - Text Simultaneous Translation
We further performed experiments on the text-totext simultaneous translation task .
Experiments are carried out on the WMT15 German-English ( DE?EN ) dataset with newstest2013 as the validation set and newstest2015 as the test set .
We strictly follow the same settings of ( Arivazhagan et al. , 2019 ) properly designed latency loss incorporated to ensure latency to be under control .
Experiments demonstrate that CAAT achieves better latencyquality trade- offs compared to the state - of - the - art approaches in speech - to - text and text - to - text simultaneous translation tasks .
We provide detailed analyses to demonstrate how CAAT works and improves the performance .
A Derivation of CAAT Losses A.1 Derivation of CAAT NLL loss Given the encoder representation h n , where 1 ? n ? | x| , the predictor vector h pred j , where 0 ? j ?
J and J = |y |. and decision step size d ?
1 . The maximum decision step is I = | x | d , and the output logits at decision step i , target position j should be s( i , j ) = g h < i * d , h pred j ( 15 ) s ( i , j ) is a vector of | V |+1 dimension corresponding to V and blank symbol ?. s( k , i , j ) denotes the k-th dimension of s( i , j ) .
The conditional output distribution can be yielded as : Pr( k | i , j ) = e s( k , i , j ) k e s( k , i , j ) ( 16 )
To simplify notation , define y( i , j ) := Pr(y j+1 | i , j ) ?( i , j ) := Pr ( ?|i , j ) ( 17 ) Define the forward variable ?( i , j ) as the probability of outputting y [ 1:j ] during decision steps [ 1 , 2 , ? ? ? , i ] .
The forward variables for all 1 ? i ?
I and 0 ? j ? | y | can be calculated recursively using ?( i , j) = ?( i ? 1 , j ) ? ?( i ? 1 , j ) + ?( i , j ? 1 ) ? y( i , j ? 1 ) ( 18 ) with initial condition ?( 1 , 0 ) = 1 .
The total output sequence probability is equal to the forward variable at the terminal node : Pr( y |x ) = ?( I , J ) ? ?( I , J ) ( 19 )
Define the backward variable ?( i , j ) as the probability of outputting y [ j + 1:J ] during decision steps [ i , ? ? ? , I ] .
Then : ?( i , j ) = ?( i + 1 , j ) ? ?( i , j ) + ?( i , j + 1 ) ? y( i , j ) ( 20 ) with initial condition ?( I , J ) = ?( I , J ) . Pr( y |x ) is equal to the sum of ?( i , j ) ? ( i , j ) over any topright to bottom-left diagonal through the nodes .
That is , ?m : 1 ? m ? I + J Pr(y|x ) = ( i , j ) :i+ j=m ?( i , j ) ? ?( i , j ) ( 21 ) From Eqs. 18 , 20 and 21 , we can draw the derivation of loss function L = ? log Pr(y |x ) as ?L ? Pr( k |i , j ) = ?( i , j) Pr( y |x ) ? ? ? ? ? ?( i , j + 1 ) if k = y j+1 ?( i + 1 , j ) if k = ?
0 otherwise ( 22 ) A.2 Derivation of CAAT Latency Loss
To calculate the marginal expectation in Eq. 23 , we define forward latency variable ? lat ( n , j ) as the expectation latency of outputting y [ 1:j ] during decision steps [ 1 , 2 , ? ? ? , i ] , and backward latency variable beta lat ( i , j ) as the expectation latency of outputting y [ j + 1:J ] during decision steps [ i , i + 1 , ? ? ? , i ] .
Here we denote l(n , j ) as the latency function for output y j at source position n. L latency ( x , y ) = E ?H ( x , y ) l( ? ) = ? Pr (?|y , x )l ( ? ) ( 23 )
The forward latency variables can be calculated recursively using ? lat ( i , j ) = p 1 ( i , j ) ? f 1 ( i , j ) + p 0 ( i , j ) ? f 0 ( i , j ) ( 24 ) with initial condition ? lat ( 1 , 0 ) = 0 .
Where p 1 ( i , j ) = ?( i , j ? 1 ) ? y( i , j ) ?( i , j) p 0 ( i , j ) = ?( i ? 1 , j ) ? ?( i ? 1 , j ) ?( i , j) f 1 ( i , j ) = ? lat ( i , j ? 1 ) + l( i , j ?
1 ) f 0 ( i , j ) = ? lat ( i ? 1 , j ) ( 25 )
For backward latency variables ? lat ( i , j ) = q 1 ( i , j ) ? b 1 ( i , j ) + q 0 ( i , j ) ? b 0 ( i , j ) ( 26 ) with initial condition ? lat ( I , J ) = 0 .
Where q 1 ( i , j ) = ?( i , j + 1 ) ? y( i , j ) ?( i , j) q 0 ( i , j ) = ?( i + 1 , j ) ? ?( i , j ) ?( i , j) b 1 ( i , j ) = ? lat ( i , j + 1 ) + l( i , j ) b 0 ( i , j ) = ? lat ( i + 1 , j ) ( 27 )
To simplify notation , define the latency expectation of all paths go through grid ( n , j ) as c( i , j ) = ? lat ( i , j ) + ? lat ( i , j ) c( i , j , 0 ) = ? lat ( i , j ) + ? lat ( i + 1 , j ) c( i , j , 1 ) = ? lat ( i , j ) + l( i , j ) + ? lat ( i , j + 1 ) ( 28 )
The expectation latency for all paths ? ? H ( x , y ) is equal to the expectation through diagonal nodes .
That is , ?m : 1 ? m ? N + J : ? = c ( I , J ) = ( i , j ) :i+ j=m ?( i , j ) ?( i , j ) c ( i , j ) Pr( y | x ) ( 29 )
And the latency loss L latency ( x , y ) = ?.
From Eqs. 24 , 26 , 28 and 29 , it follows that : r( i , j ) = ? ? ? ? ? ?( i , j + 1 ) ( c( i , j , 1 ) ? ? ) if k = y j+1 ?( i + 1 , j ) ( c ( i , j , 0 ) ? ? ) if k = ?
0 otherwise ?L latency ? Pr( k |n , j ) = ?( i , j ) Pr( y |x ) r( i , j ) ( 30 )
B Beam Search Algorithm for CAAT
The pseudo code of beam search algorithm for CAAT is described in Algorithm 1 . C Hyper-parameters Figure 1 : 1 Figure 1 : The difference between Attention - based Encoder-Decoder , RNN -T and CAAT .
Figure 2 : 2 Figure 2 : Expanded paths in simultaneous translation
Figure 3 : 3 Figure 3 : Architecture of CAAT Transformer
)
We extract common prefix of existing hypotheses as determined target output at each decision time step .
( 3 ) Different beam sizes are introduced for intra-decision ( b 1 ) and inter-decision ( b 2 ) pruning , to ensure timely determination of outputs .
b 1 and b 2 are set to be 5 and 1 , respectively , if not otherwise specified .
We use the MuST - C v1.0 3 ( Di Gangi et al. , 2019 ) English ?
German ( EN?DE ) and English ?
Spanish ( EN?ES ) speech translation datasets in our experiments .
We use the dev set for validation and report performance on the tst-COMMON set .
The 80 dimensional log- Mel filter bank features are extracted for speech feature with a 25 ms window size and a 10 ms window shift ; SpecAugment ( Park et al. , 2019 ) were performed on the training data .
Figure 4 : 4 Figure 4 : Translation quality vs. Average Lagging on the EN?DE and EN ?ES speech translation test set .
The y-axis is BLEU and x-axis Average Laggging ( AL ) .
Figure 5 : 5 Figure 5 : AL - BLEU curves drawn by varying the decision step size d and latency loss scale ? latency on the MuST -C EN ?
DE test set .
varying d means setting d = { 8 , 16 , 32 , 48 , 64 , 80 } with ? latency = 1.0 ; varying ? latency means setting ? latency = { 2 , 1.5 , 1 , 0.5 , 0 } with decision step size d = 32 .
Figure 6 : 6 Figure 6 : Translation quality vs. Average Lagging on the WMT15 DE ?EN text translation test set .
The yaxis is BLEU and x-axis Average Laggging ( AL ) .
Figure 7 : 7 Figure 7 : An example from the EN ?DE test set , which demonstrate that CAAT outperforms wait -k with close latency .
The five components from top to bottom : speech , source transcription ( aligned to speech audio ) , reference translation , hypothesis from CAAT , and hypothesis from wait -k with SBS .
Figure 8 : 8 Figure 8 : Translation quality against latency ( AL , AP and DAL ) on the MuST -C EN ?DE and EN ?ES speech translation test sets .
Figure 9 : 9 Figure 9 : Translation quality against latency ( AL , AP and DAL ) on the WMT15 DE ?EN text translation test set .
Table 2 : 2 Effect of the number of joiner layers on quality and latency on the MuST -C EN ?
DE test set .
# Joiner layers d AL BLEU 0 1 2715.7 9.74 0 32 2154.4 9.42 1 32 1156.2 20.94 4 32 1141.2 21.78 6 32 1114.9 21.81 Effectiveness of Joiner Layers
The perfor- mance of CAAT models with different numbers of joiner layers are shown in Table 2 .
Note that in the table , the first two rows ( # joiner layers =0 ) cor- responds to the conventional Transducer without cross attention , in which encoder representations are downsampled d times using average - pooling and then directly fused with predictor outputs by addition .
We can find that the introduction of the cross attention mechanism significantly improves the performance of simultaneous translation , and the BLEU scores are close when the number of joiner layers is greater than 4 . ? of f line AL BLEU 0 1111.6 19.84 0.5 1106.5 20.83 1 1114.9 21.81 1.5 1144.0 21.77 2.0 1176.5 21.87
Table 3 : 3 Effect of the ? of f line on quality and latency on the MuST -C EN ?
DE test set .
Table 4 : 4 Performance of CAAT models with different b 1 and b 2 on the EN ?DE test set , all with the decision step d = 32 .
1 b 2 AL BLEU 1 1 1116.0 21.18 3 1 1109.0 21.75 5 1 1114.9 21.81 10 1 1126.2 21.86 5 2 1929.7 22.1 5 3 2433.5 22.3
Table 5 : 5 Complete results on the MuST -C EN ?
DE speech translation test set .
BLEU AL AP DAL BLEU AL AP DAL k wait -k k wait -k 1 18.1 1147.0 0.75 1571.1 1 20.0 932.1 0.74 1499.3 2 18.8 1394.9 0.78 1760.6 2 21.5 1203.9 0.77 1713.1 4 20.7 1911.6 0.84 2220.6 4 23.1 1727.5 0.82 2170.3 6 21.8 2377.4 0.88 2652.0 6 25.2 2232.7 0.86 2633.2 8 22.2 2792.5 0.91 3034.5 8 26.0 2676.5 0.89 3033.0 10 22.2 3155.7 0.929 3383.0 10 26.4 3074.3 0.92 3396.6 12 22.5 3477.3 0.94 3674.0 12 26.6 3428.9 0.94 3721.1 +? 23.0 5431.6 1.00 5431.6 +? 27.8 5997.1 1.00 5997.1 k wait -k with SBS k wait -k with SBS 1 18.7 866.6 0.70 1310.9 1 20.4 614.6 0.69 1230.8 2 19.6 1125.8 0.74 1515.3 2 21.5 903.0 0.73 1453.0 4 21.0 1649.2 0.81 1985.2 4 23.0 1437.7 0.79 1914.1 6 22.0 2134.0 0.86 2426.7 6 25.6 1969.6 0.84 2397.4 8 22.3 2571.4 0.89 2835.3 8 26.0 2437.5 0.88 2826.7 10 22.7 2967.9 0.92 3205.5 10 26.6 2865.0 0.91 3214.4 12 22.7 3310.8 0.94 3524.1 12 26.9 3241.9 0.93 3557.9 +? 23.0 5431.6 1.00 5431.6 +? 27.8 5997.1 1.00 5997.1 d CAAT d CAAT 8 20.5 508.1 0.64 1100.4 8 24.0 355.9 0.64 1146.3 16 21.4 813.8 0.68 1335.3 16 25.8 623.2 0.67 1359.4 32 21.8 1114.9 0.74 1758.1 32 26.3 955.9 0.72 1785.0 48 22.2 1443.4 0.78 2193.6 48 26.4 1275.9 0.77 2231.4 64 22.4 1800.6 0.82 2633.5 64 26.6 1647.7 0.81 2680.7 80 22.6 2137.8 0.86 3025.4 80 27.1 1977.3 0.84 3083.7 +? 23.2 5431.6 1.00 5431.6 +? 27.5 55997.1 1.00 5997.1
Table 6 : 6 Complete results on the MuST -C EN ?ES speech translation test set .
BLEU AL AP DAL k wait -k 2 19.7 1.57 0.59 3.12 4 23.6 3.38 0.65 4.69 6 26.4 5.29 0.72 6.42 8 28.2 7.24 0.77 8.19 10 28.5 9.02 0.81 9.95 12 29.5 10.77 0.85 11.64 16 29.8 13.95 0.90 14.71 +? 30.6 27.90 1.00 27.90 k wait -k with SBS 2 21.1 2.16 0.60 3.16 4 24.5 3.81 0.66 4.67 6 26.9 5.58 0.72 6.41 8 28.9 7.39 0.77 8.19 10 28.8 9.14 0.81 9.94 12 29.9 10.84 0.85 11.64 16 30.0 13.99 0.90 14.72 +? 30.6 27.90 1.00 27.90 ? avg MMA-IL 0.8 21.1 3.26 0.63 4.65 0.6 23.9 3.74 0.65 5.24 0.4 24.7 4.47 0.68 6.87 0.2 27.5 8.72 0.81 13.0 0.1 26.6 21.37 0.97 24.48 0. 29.5 27.49 1.0 27.49 d CAAT 1 26.8 2.67 0.60 4.96 2 27.8 3.27 0.63 5.79 4 28.1 4.23 0.67 7.20 8 29.2 6.07 0.73 9.85 12 29.3 8.00 0.79 12.58 16 29.6 10.02 0.83 15.23 20 29.9 12.16 0.87 17.64 +? 30.2 27.90 1.00 27.90
Table 7 : 7 Complete results on the WMT15 DE ?EN test translation test set .
Details of inference algorithm can be found in Appendix C.3 https://ict.fbk.eu/must-c/
https://github.com/1ytic/warp-rnnt
5 Full-size graphs for all latency metrics ( AL , AP , and DAL ) along with the corresponding numeric scores are available in Appendix D.
https://github.com/pytorch/fairseq/ tree/master/examples/ simultaneous_ translation
7 Limited by GPU memory , we failed to train CAAT with d < 4 , so we just set d = { 1 , 2 } in inference on model trained with d = 4.8 Full-size graphs for all latency metrics along with the corresponding numeric scores are available in Appendix D.
https://github.com/pytorch/fairseq/ tree/master/examples/simultaneous_ translation/models/transformer_ monotonic_attention.py
