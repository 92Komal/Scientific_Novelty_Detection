title
Action - Based Conversations Dataset : A Corpus for Building More In -Depth Task - Oriented Dialogue Systems
abstract
Existing goal-oriented dialogue datasets focus mainly on identifying slots and values .
However , customer support interactions in reality often involve agents following multi-step procedures derived from explicitly - defined company policies as well .
To study customer service dialogue systems in more realistic settings , we introduce the Action - Based Conversations Dataset ( ABCD ) , a fully - labeled dataset with over 10 K human-to-human dialogues containing 55 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success .
We propose two additional dialog tasks , Action State Tracking and Cascading Dialogue Success , and establish a series of baselines involving large-scale , pre-trained language models on this dataset .
Empirical results demonstrate that while more sophisticated networks outperform simpler models , a considerable gap ( 50.8 % absolute accuracy ) still exists to reach human-level performance on ABCD .
1
Introduction
The broad adoption of virtual assistants and customer service chatbots in recent years has been driven in no small part by the usefulness of these tools , whereby actions are taken on behalf of the user to accomplish their desired targets ( Amazon , 2019 ; Google , 2019 ) .
Research into taskoriented dialogue has concurrently made tremendous progress on natural language understanding of user needs ( Wu et al. , 2019 ; Rastogi et al. , 2020 b ; Liang et al. , 2020 ) .
However , selecting actions in real life requires not only obeying user requests , but also following practical policy limitations which may be at odds with those requests .
For example , while a user may ask for a refund on their purchase , an agent should only honor such a request if it is valid with regards to the store 's return policy .
Described in actions , before an agent 1 All code and data will be available at this location .
can [ Offer Refund ] , they must first [ Validate Purchase ] .
Furthermore , resolving customer issues often concerns multiple actions completed in succession with a specific order since prior steps may influence future decision states .
( See Figure 1 ) To more closely model real customer service agents , we present the Action - Based Conversations Dataset ( ABCD ) consisting of 10,042 conversations containing numerous actions with precise procedural requirements .
These actions differ from typical dialogue acts because tracking them necessitates striking a balance between external user requests and internally - imposed guidelines .
Thus , the major difference between ABCD and other dialogue datasets , such as Mul-tiWOZ ( Budzianowski et al. , 2018 ) , is that it asks the agent to adhere to a set of policies while simultaneously dealing with customer requests .
While the prevalent data collection paradigm involves Wizard - of - Oz techniques , our situation containing asymmetric speakers compelled the design of a novel Expert Live Chat system .
Our dataset includes asymmetric speakers because , unlike customers , agents must undergo extensive training to be able to navigate the Agent Guidelines during real -time conversations .
This makes a naive pairing process untenable since arbitrary matching might lead to chats containing two users who share the same role .
Based on the unique aspects of ABCD , we propose two new tasks .
To start , Action State Tracking ( AST ) closely mirrors the format of Dialogue State Tracking where the user intent is inferred from the dialogue history .
AST then differs since the correct state must also be reconciled with the requirements outlined in the Agent Guidelines .
As a second task , Cascading Dialogue Success ( CDS ) extends this notion across the entire conversation .
At each turn , the agent decides to take an action , respond with an utterance or end the chat .
As needed , the agent should also predict the right action or select the best utterance .
For each task , we build various models to establish baseline performance and to highlight the importance of each constraint .
Experiments show that in addition to conversation history , conditioning on the Agent Guidelines further boosts performance , with top models relying on both aspects to reach 31.9 % accuracy .
Additional results show removing action context hurts performance , implying the importance of taking into account the sequential nature of actions .
Lastly , human evaluation reaches 82.7 % , demonstrating ample room for future improvement .
The contribution of this work is three - fold : ( 1 ) We provide a novel , large-scale dataset containing context-dependent , procedural actions along with corresponding Agent Guidelines .
( 2 ) We establish a new technique called Expert Live Chat for capturing natural dialogue between two unequal interlocutors .
( 3 ) We propose two metrics , Action State Tracking and Cascading Dialogue Success , for measuring dialogue comprehension with policy constraints .
Finally , we build on pretrained neural models to serve as baselines for these tasks .
Related Work Traditional Dialogue Datasets
In recent years , dialogue datasets have grown in size from hundreds of conversations to the tens of thousands ( Henderson et al. , 2014 ; Budzianowski et al. , 2018 ; Peskov et al. , 2019 ) .
Unlike opendomain chatbots often built for entertainment , task - oriented dialogue systems trained on such datasets are intended for solving user issues .
The resolution of these issues implicitly requires taking actions , where an action is a non-utterance decision that depends on both user and system inputs .
Despite the tremendous number of dialogues , examples in previous benchmarks fixate on the single knowledge base ( KB ) lookup action where the agent searches for an item that matches the user 's desires and is available in the KB .
By sticking to this sole interaction , conversations can be generated through rules ( Weston et al. , 2016 ) , paraphrased from templates ( Byrne et al. , 2019 ) or taken from static text scenarios ( Zhang et al. , 2018 ) , leading to dialogues that are predominantly homogeneous in nature .
Many datasets have scaled to more domains as well Budzianowski et al. , 2018 ; Peskov et al. , 2019 )
Since each new domain introduces a KB lookup requiring different slotvalues , the number of unique actions grows as a linear function of the number of domains covered .
Rather than expanding wider , ABCD instead focuses deeper by increasing the count and diversity of actions within a single domain .
Exploring Other Avenues Multiple aspects are explored by conversational datasets attempting to mimic reality .
Rashkin et al. ( 2019 ) studies the ability of a dialogue model to handle empathy , while Zhou et al . ( 2018 ) focuses on commonsense reasoning .
Another approach is to augment dialogues with multi-modality including audio ( Castro et al. , 2019 ) or visual ( Das et al. , 2017a ) components .
Other researchers have explored grounding conversations with external data sources such as personas ( Zhang et al. , 2018 ) , online reviews ( Ghazvininejad et al. , 2018 ) or large knowledge bases ( Dinan et al. , 2019 ) .
Intricate dialogues can also appear when studying collaboration ( He et al. , 2017 ; or negotiation ( Lewis et al. , 2017 ; He et al. , 2018 ) which strongly encourage interaction with the other participant .
In comparison , ABCD aims to make dialogue more realistic by considering distinct constraints from policies .
Dialogues with Policies Procedural actions following strict guidelines naturally emerge in dialogue research geared towards real-world appli-Subflows recover-username , 1 recover - password , 1 reset - 2 fa , 1 status - service - added , 2 status - service - removed , 2 statusshipping -question , 2 status - credit-missing , 2 manage - change - address , 2 manage - change- name , 2 manage - changephone , 2 manage - payment - method , 2 status - mystery - fee , 3 status - delivery - time , 3 status - payment - method , 3 statusquantity , 3 manage - upgrade , 3 manage - downgrade , 3 manage - create , 3 manage - cancel , 3 refund-initiate , 4 refundupdate , 4 refund-status , 4 return-stain , 4 return-color , 4 return-size , 4 bad-price- competitor , 5 bad-price- yesterday , 5 out - of- stock - general , 5 out - of- stock - one- item , 5 promo-code- invalid , 5 promo-code- out - of - date , 5 mistimed - billingalready - returned , 5 mistimed - billing - never- bought , 5 status , 6 manage , 6 missing , 6 cost , 6 boots , 7 shirt , 7 jeans , 7 jacket , 7 pricing , 8 membership , 8 timing , 8 policy , 8 status - active , 9 status - due-amount , 9 status - due-date , 9 manage - pay - bill , 9 manage -extension , 9 manage - dispute- bill , 9 credit-card , 10 shopping - cart , 10 search - results , 10 slow-speed 10 Actions verify - identity , ask - the-oracle , validate - purchase , make - password , promo-code , subscription -status , offer-refund , make - purchase , record-reason , enter-details , shipping -status , update-order , pull- up- account , update- account , sendlink , notify - team , membership , search - faq , try -again , log-out - in , instructions , search - jeans , search - shirt , searchboots , search - jacket , search - pricing , search -membership , search-timing , search - policy , select- faq Table 1 : Full ontology of Agent Guidelines decomposable into high - level flows describing the overall category and subflows defining a unique set of intents .
All actions are also shown .
Upper script numeral indicates the flow that the subflow belongs to .
1 : account access , 2 : manage account , 3 : order issue , 4 : product defect , 5 : purchase dispute , 6 : shipping issue , 7 : single item query , 8 : storewide query , 9 : subscription inquiry , 10 : troubleshoot site cations .
Hybrid Code Networks encode business logic through masking templates since various behaviors become nonsensical in certain situations ( Williams et al. , 2017 ) . Research from Moiseeva et al. ( 2020 ) studies multi-purpose virtual assistants that attempt to distinguish among thirteen explicit actions .
The closest prior work to ABCD is the Schema Guided Dialogue ( SGD ) dataset , which contains dozens of API calls that can be interpreted as individual actions sending commands to a SQL engine ( Rastogi et al. , 2020 b ) .
The functionality of these actions is occasionally restricted to reflect constraints of real-life services .
The action restrictions within ABCD are made explicit by the Agent Guidelines manual .
Action - Based Conversation Dataset
In this section , we describe the task setting of ABCD by following along with the example dialog shown in Figure 1 .
Customer During data collection , customers are given a simple prompt ( such as " You want to keep your subscription another year . " ) instead of step-by-step instructions , which reflects how real-world customers innately understand their own issue , but only have a rough idea of how to resolve said issue .
Accordingly , customers within ABCD remain oblivious towards what values apply to which actions , nor are they aware that actions exist in first place .
This ambiguity forces the agent and customer to collaboratively uncover the correct latent intent through back and forth communication , naturally leading to longer dialogues .
Customer Service Agent Following the standard dialog setup , the agent starts by parsing the dialogue history to capture the customer intent , which in Figure 1 is a subscription extension .
ABCD then diverges as the next step involves interpreting the Agent Guidelines , a document representing the internal policies of a company in the online retail domain ( See Table 1 ) .
Using the guidelines , the trained agent should find the one unique subflow corresponding to the customer intent .
Each subflow in turn is defined by exactly one unique sequence of actions .
While identifying a subflow may seem straightforward , information asymmetry prevents the customers from directly revealing the name of their intent .
For example , a customer might inquire about the status of their recent purchase , but an agent has over a dozen different subflows related to order statuses , so selecting the right one suddenly becomes highly non-trivial .
In our case , the agent eventually figures out the correct subflow and begins to execute actions , which consists of recording values given by the customer , namely the customer 's full name or account ID in order to [ Pull up Account ] .
As the third action , the guidelines instruct the agent to ask for the customer 's membership level .
After the customer supplies this information , the agent enters the " guest " value into the agent dashboard by clicking the [ Membership ] button .
Buttons have variable slots that may or may not need to be filled , depending on the context ( See Table 1 for a full list ) .
Dialogue success demands that agents execute a chain of such actions in the right order with the right values , while simultaneously engaging the customer in natural language conversation .
There are three reasons that make carrying out a series of actions more difficult than the task lets on .
To start , the permitted actions in a given state are determined not only by Agent Guidelines , but also by the user 's desire , which may be in conflict .
For example , the customer in Figure 1 wanted to extend their subscription , but the guidelines prevented the agent from doing so .
Secondly , actions must be completed in order .
This procedural requirement comes from the realization that completing actions out of order ( or with missing steps ) do not make sense in many real-world scenarios .
For example , it is critical to [ Verify Identity ] before resetting someone 's password , not after .
Finally , actions themselves induce stochastic outcomes , preventing agents from memorizing patterns of subflow resolution .
As an example , [ Ask the Oracle ] often determines if a customer complaint was valid .
In the case of a company error , the agent is compelled to immediately resolve the issue , whereas a misunderstanding made by the customer warrants a different set of responses .
Data Collection Methodology
This section outlines how we collect and annotate our dataset with context-dependent actions .
Agent Training Managing complex guidelines requires filtering for top agents , which we do by certifying Mechanical Turk ( MTurk ) workers through an extensive 20 - question quiz touching on all aspects of task completion .
Keeping the bar high , we set a minimum threshold of 80 % accuracy of the quiz which resulted in a low 20 % pass rate .
After passing the exam , we offered the answer key to agents which further improved understanding .
We also created short , 10 - minute tutorial videos to showcase how to handle the most difficult aspects of the task .
A group chat app was also deployed to offer live feedback for agents , simulating how supervisors coach customer service representatives in real life .
Finally , we carefully designed an incentive structure that rewards agents for correctly identifying the user intent to encourage clarification behavior .
( Appendix A covers more details . )
Expert Live Chat Rather than utilizing Wizard - of - Oz techniques ( such as in MultiWOZ ) , we developed Expert Live Chat which contains three unique aspects : ( 1 ) Conversations are conducted continuously in real-time .
( 2 ) Users involved are not interchangeable .
( 3 ) Players are informed that all participants are human - no wizard behind the scenes .
Synchronous Two -person Dialogue Normal human conversations occur in real-time , but coordinating multiple users in this manner is resource -intensive , so other datasets often employed workarounds to avoid this difficulty .
For example , other works have applied rules ( Bordes et al. , 2017 ) , templates ( Byrne et al. , 2019 ) or paraphrasing ( Shah et al. , 2018 ) to produce conversations .
Wizard-of- Oz ( WoZ ) techniques incorporate humans into the mix by allowing one of them to play the system role as a wizard behind the scenes ( Kelley , 1984 ) .
In particular , ( Budzianowski et al. , 2018 ) decomposed dialogues into individual turns , where for each turn a new author is responsible for reading the context and generating the next plausible response .
Despite the time - consuming nature , some datasets have produced synchronous dialogues between two humans ( Lewis et al. , 2017 ) .
However , the skill sets of ABCD workers are notably unequal , exacerbating the matching problem .
Pairing Users of Unequal Capability Expert Live
Chat matches a highly trained agent with a knowledgeable , yet otherwise average customer in real-time .
Since the backgrounds are uneven , unlike other datasets with concurrent users ( Lewis et al. , 2017 ; Zhang et al. , 2018 ; Das et al. , 2017 b ) , incoming Turkers cannot simply be randomly assigned a role .
In other words , having twenty participants does not necessarily equate to ten conversations since it 's possible that only a quarter of them are qualified as agents .
When such an imbalance inevitably arises , one group must wait until someone from the other side becomes available .
However , leaving either side waiting for too long leads to serious consequences since idle time directly affects their pay rate .
To minimize the likelihood of such an outcome , we first ensure that a reasonable pool of agents are always available .
Then , we increase the number of active customers by methodically inviting a subset of customers one batch at a time .
To do so , we established a qualification exam for customers to ensure their availability during a specified time period .
Finally , we also redesigned the chat application to make the waiting room experience more palatable .
( See Appendix B for full breakdown . )
With these changes , we successfully increased the pairing rate from 18 out of 80 active users up to 72 out of 83 , an increase of nearly 400 % , while maintaining wait times under 10 minutes .
Interaction Framework Besides pairing , we increased the likelihood of collecting rich dialogues without the need for extensive instructions by optimizing the chat experience itself .
In particular , we observed the greatest gains by grounding the conversation to the relatable scenario of online shopping , which provided immediate context to participants without requiring any extra training .
For example , the Agent Dashboard was arranged to closely reflect actual agent workspaces ( Figure 2 ) .
On the customer side , scenarios in the Customer Panel included an image of the product being discussed , along with other meta-data such as the brand or price to match a true shopping experience as much as possible ( Appendix H ) .
We also explicitly told customers the other speaker was human to encourage natural responses over confined commands meant for machines .
Most importantly , customers were given dynamically generated , natural - language prompts that did not include information about the values needed to resolve their issue .
As a general framework , Ex-pert Live Chat can be applied in any real-world scenario involving an expert and novice .
Indeed , increasing the verisimilitude of the experience is precisely what allowed higher quality dialogues to be generated by the workers .
Annotation of Actions and Values
The flows and subflows are automatically annotated since we have the provenance of each intent when generating the customer prompt .
Additionally , given the ground truth subflow of each conversation , we can deterministically map them to the correct section within the Agent Guidelines outlining the correct actions .
Calculating accuracy then becomes a simple exercise to align the predicted actions with the ones required by the manual .
In this way , we capture a key benefit of machine - generated text ( Shah et al. , 2018 ) without sacrificing the benefit of engaging real users .
Dataset Statistics and Analysis
We validate all dialogues to pass quality thresholds such as including a minimum number of actions and avoiding copy / paste behavior .
After filtering , we end up with 10,042 total conversations with an average of 22.1 turns - the highest turn count among all compared datasets .
Unsurprisingly , ABCD includes more actions per dialogue than other datasets , by at least a factor of two .
ABCD also contains a lower absolute number of tokens , but also has the highest variance in the number of tokens per turn .
( See Table 2 .)
Since each subflow represents a unique customer intent , ABCD contains 55 user intents evenly distributed through the dataset .
By interpreting buttons as domains , the dataset contains 30 domains and 231 associated slots , compared to 7 domains and 24 slots within Multi-WOZ ( Budzianowski et al. , 2018 ) .
By grounding to the relatable scenario of chatting with customer support of an online retail company , speakers often showcase various forms of natural dialogue , such as offering diverse reasons for shopping or asking detailed follow - up questions .
Furthermore , the unconstrained nature of Expert Live Chat allows users to chat with each other in a free-form style .
Dialogues exhibited normal texting behavior such as users speaking for many turns in a row or fixing typos with a star in the subsequent line .
Other examples of linguistic phenomenon can be observed in Table 5 .
ABCD as a Dialogue Benchmark
The novel features in ABCD brings two new dialog tasks , Action State Tracking and Cascading Dialogue Success .
We also build baseline systems that are variants of standard dialogue models and report their results on ABCD .
Action State Tracking Action State Tracking ( AST ) aims at detecting the pertinent intent by interpreting customer utterances while taking into account constraints from the Agent Guidelines , an aspect not considered in traditional dialog state tracking ( DST ) .
For example , a conceivable dialogue task might entail helping a customer [ Reset Password ] once this intent has been identified .
In contrast , the appropriate next step within AST is governed by the Agent Guidelines , which might require [ Verify Identity ] of the customer first , or any number of other actions , before executing the password reset .
Each series of actions is considered a unique subflow that belongs to a number of high - level conversational flows .
Each individual action includes the active button b to click and its corresponding slots s and values v .
The task consists of executing an action , which constitutes a single agent turn .
More specifically , given a context C t = [ x 1 , x 2 , . . . , x t ] where x t can be a customer utterance x c t , an agent utterance x a t , or a prior action x b t , a model should predict the button of the current action as well as the relevant slots and values , if any exist { x b t+1 = ( b , s , v ) ? B ? S ? V}.
This structure is designed to mimic DST where each user intent is broken down into domains , slots and values ( d , s , v ) .
For both AST and DST , the higher level domain or button can have vary - ing slots .
The reverse is also true - a given slot can be associated with multiple domains or buttons .
Lastly , both contain values that can be enumerable ( i.e. payment types or shipping statuses ) or non-enumerable ( phone numbers or email addresses ) .
Following the pattern set by Rastogi et al . ( 2020 b ) , enumerable values are given in the ontology to be accessible by a model , whereas the non-enumerable items are not .
Despite the similar structure , AST deviates from DST since predicting the right action requires not only parsing the customer utterance , but also adhering to Agent Guidelines .
Suppose a customer is entitled to a discount which will be offered by issuing a [ Promo Code ] .
The customer might request 30 % off , but the guidelines stipulate only 15 % is permitted , which would make " 30 " a reasonable , but ultimately flawed slot-value .
To measure a model 's ability to comprehend such nuanced situations , we adopt overall accuracy as the evaluation metric for AST .
Cascading Dialogue Success
Since the appropriate action often depends on the situation , we propose the Cascading Dialogue Success ( CDS ) task to measure a model 's ability to understand actions in context .
Whereas AST assumes an action occurs in the current turn , CDS gives an agent the additional options of responding with an utterance or ending the conversation .
Moreover , proficiency is no longer measured as success over isolated turns but rather as success over sequences of consecutive turns .
Formally , given C t = [ x 1 , x 2 , . . . , x t ] as a context composed of utterances x c , x a ?
U and actions x b ?
A , a model should predict all remaining steps x >t along with their realized forms .
Pos-sible next steps are to take an action , respond with text or end the task .
When the next step is an action x b t +1 , the model should predict the button with its slots and values as in AST .
If the agent speaks in the next step x a t+1 , the model should rank the true utterance highest , as measured by recall metrics .
1 Finally , the model should recognize when to end the conversation .
Rewarding the model only when it predicts every step correctly is counter -productive because minor variations in sentence order do not alter overall customer satisfaction .
Therefore , CDS is scored using a variation on Cascading Evaluation ( Suhr et al. , 2019 ) .
Rather than receiving a single score for each conversation , cascaded evaluation allows the model to receive " partial credit " whenever it successfully predicts each successive step in the chat .
This score is calculated on every turn , and the model is evaluated based on the percent of remaining steps correctly predicted , averaged across all available turns .
( See Appendix C for more details . )
Baseline Models
We also run several baselines on these new tasks .
The backbone of all our baseline systems is a pre-trained Transformer - based model acting as a context encoder .
More specifically , given the dialogue history as a series of utterances , we first join the utterances together with a [ SEP ] token and then tokenize the entire input using Word-Piece ( Schuster and Nakajima , 2012 ) .
Next , we feed the entire input into a BERT model and perform a learned pooling on the hidden states in the final layer , which results in a fixed - length latent vector h enc ?
R 128 ( Wolf et al. , 2019 ) .
Afterwards , we attach a variety of prediction heads conditioned on the h enc vector to generate the final output .
Details of the prediction heads for the two proposed tasks are described next .
We break down Action State Tracking ( AST ) into two sub-problems , button-slot prediction and value-filling .
Given the ontology , button prediction is a straightforward classification task over 231 known options , so the prediction head is just a linear classifier with a softmax activation for normalization : P b?slot = Softmax ( W a h enc + b a ) .
To handle value-filling , we further decompose 1 Sentences with similar semantics may be formulated in several ways , so we opt for response retrieval over text generation since common metrics ( i.e. BLEU score ) tend to become unreliable in these situations ( Liu et al. , 2016 ) . the task into predicting enumerable and nonenumerable values .
The ontology lists out all | E | enumerable values , so the prediction head p enum simply maps the hidden state h enc into the appropriate dimensions .
To handle non-enumerable values , we follow the insight from ( Ma et al. , 2019 ) which notes that practically all such values are stated by the customer in conversation , so a model can copy these values from the tokenized context .
During pre-processing , we extract up to | N | unique tokens from the natural language customer utterances , where p copy then represents the distribution over these possible options .
2
We imitate the TRADE architecture from ( Wu et al. , 2019 ) , where conditioned on the action , the model chooses to either copy from the context p copy or select from the enumerable entities p enum based on a gating mechanism .
The gate is conditioned on the hidden state h enc as well as a learned context vector c i .
Concretely , p enum = Softmax ( W e h enc + b e ) ?
R |E | p copy = Softmax ( W c h enc + b c ) ?
R |N | c i = W c ? p copy ?
R hid p gate = ?( W g ? [ h enc ; c i ] ) ?
R 1 P val = [ p gate ?
p copy ; ( 1 ? p gate ) ? p enum ] ? R |E+N | where ? represents the Sigmoid function and [ ? ; ?] is the concatenation operation .
The final value predictions are the argmax of P val which merge the probabilities of p enum and p copy together .
For Cascading Dialogue Success ( CDS ) , we also tackle next step selection , utterance ranking , and intent classification .
Next step selection is a choice between retrieve utterance , take action and end conversation .
Intent classification consists of choosing from the 55 available subflows .
Given this basic setting , both tasks use the same setup of a linear layer followed by a softmax , albeit with their own respective weights W N S ? R 3 ? hid and W IC ? R 55 ? hid .
When the next step is to take action , the AST model is reused to determine the button-slot and value .
When end conversation is selected , all future predictions are ignored , much like an < EOS > symbol signifies stopping .
This leaves us with utterance ranking , which is only evaluated when retrieve utterance is chosen as the next step .
Our ranker reproduces the design from ( Guu et al. , 2020 ) , where the encoded context h ctx is compared against each encoded candidate response h cand to produce a ranking score .
To embed each j th candidate d j we first create its input d input j .
Following standard practice , we prepend the candidate text d j with [ CLS ] , separate the individual utterances u i within the candidate response using a [ SEP ] token , and append a final [ SEP ] token afterwards .
( Devlin et al. , 2019 ) .
This input d input j is then fed into a static pretrained BERT model to get an initial hidden state , which is finally projected using a learned weight W d j ? R 128 ? hid to produce h cand .
To obtain h ctx we start with the hidden state h enc from before and apply a projection matrix W U R ? R 128 ? hid to reach the desired dimensionality .
d input j = [ CLS ] u 1 [ SEP ] u 2 [ SEP ] ... [ SEP ] u n [ SEP ] h cand = W d j BERT base ( d input j ) ?
R 128 h ctx = W U R h enc ?
R 128 f ( x i , d j ) = h ctx h cand P rank j = exp ( f ( x i , d j ) ) ?
d j exp f ( x i , d j )
The final rank is given by normalizing each j th score against all other candidate scores .
We use the training objective from ( Henderson et al. , 2019 ) to calculate the loss : J = M = 100 j=1 P ( x i , d j ) ?
M i=1 log M j=1 exp f ( x i , d j ) where M is the size of the total candidate set .
Experiments
We performed experiments on the two newly proposed tasks , AST and CDS .
AST consists of two subtasks , button-slot prediction and value-filling , while CDS builds on this with three additional subtasks of next step selection , utterance ranking , and intent classification .
For both tasks , we experimented with two types of frameworks , a pipeline version and an end-to - end version .
The pipeline version trains each subtask separately while the end-to - end optimizes all tasks jointly ( Liang et al. , 2020 ; Rastogi et al. , 2020a ; Ham et al. , 2020 ) .
The pipeline model uses a BERT model trained with the RAdam optimizer .
To test the performance of different pretrained models under the end-to - end framework , we experiment with three additional encoders , Al - BERT ( Lan et al. , 2020 ) , RoBERTa ( Liu et al. , 2019 ) and RoBERTa - Large .
AlBERT model has an inter-sentence coherence task and a lighter memory footprint compared to BERT , while RoBERTa model has substantially more data and hyper-parameter tuning in pretraining than BERT .
In the future , we also plan to include GPT - based models , such as DialoGPT ( Zhang et al. , 2020 ) in our comparison .
Results
For both tasks , moving from the pipeline architecture to a jointly trained method displayed noticeable improvement in accuracy .
As hinted at in prior works ( Liang et al. , 2020 ) , we suspect the group effort gives each subtask extra supervision from other subtasks for more data efficient training .
In the AST task , we found steady improvements as we move from the older to the newer models with vanilla BERT at 59.5 % accuracy and RoBERTa doing the best at 65.8 % .
For the CDS task , we found a similar trend where RoBERTa - Large outperforms BERT , but only by a mere 0.6 % .
We hypothesize this small gap between models is due to the fact that none were particularly trained on dialogue data which impacts their ability to produce a useful encoding ( Wu and Xiong , 2020 ) .
Separately , we evaluate CDS subtask difficulty by asking human volunteers to select the correct label from a list of possible options .
As an example , workers would be presented with 55 different classes for Intent Classification and asked to choose the right one .
Since humans typically struggle when choosing from large collections of items , fine -tuned models performed roughly on par or better compared to humans in this unnatural setting .
On the other hand , human evaluation for the overall CDS task was judged by measuring the success rate in a standard conversational scenarios where behavioral instincts are activated , so humans were able to excel on this environment .
Ablation Study
We perform an ablation study to test the significance of the key features in ABCD .
Recall , actions are characterized by their dual nature of requiring signals from both the customer and the company guidelines .
To that end , we provided the ground truth intent to measure the impact of the customer side .
Conversely , we also test the company side by masking out invalid buttons based on the insight that the Agent Guidelines are useful for narrowing down the range of possible actions .
In both situations , we would expect that providing such oracle guidance would boost performance .
Lastly , note that the appropriate action depends on the outcomes of prior actions , so for a final experiment we removed prior actions and their explanations from the context to test their impact on task success .
( See Appendix E for details . )
We observe that supplying the intent information to the BERT model causes a noticeable boost in dialog success , bringing the score to 32.3 % .
However , augmenting the model with knowledge of the guidelines unexpectedly dropped performance down to 30.6 % .
Further analysis revealed the imperfect intent classifier would occasionally mask out valid buttons , leaving only incorrect ones to choose from .
As a result , the downstream action predictor would be prevented from doing its job , causing errors to accumulate .
To test this hypothesis , we ran another model ( Intent + Guide ) which had access to guidelines along with an oracle intent classifier .
This model reached the peak observed performance of 32.7 % , highlighting the importance of both components .
As a final result , removing action information away from actionbased conversations unsurprisingly causes a major performance drop ( Table 4 ) .
Conclusion and Future Work
In conclusion , we have presented ABCD which includes over 10 K dialogues that incorporate procedural , dual- constrained actions .
Additionally , we established a scalable method for collecting live human conversations with unequal partners .
We found that pre-trained models perform decent on Action State Tracking , but there is a large gap between humans agents and the top systems for Cascading Dialogue Success .
We plan to incorporate GPT - related models ( Hosseini - Asl et al. , 2020 ) , as alternate forms of preprocessing have shown promise in other NLP tasks .
Other techniques could also be used to incorporate speaker info , action semantics and other meta-data .
Wholly new systems that attend to the Agent Guidelines in a fully differentiable manner are also worth exploring .
By grounding dialogues to in- depth scenarios with explicit policies , we hope to have pushed towards a better understanding of dialogue success .
