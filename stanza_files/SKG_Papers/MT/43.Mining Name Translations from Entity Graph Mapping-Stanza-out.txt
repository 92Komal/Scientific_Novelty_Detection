title
Mining Name Translations from Entity Graph Mapping * Gae-won You † Seung-won Hwang † Young - In Song ‡
abstract
This paper studies the problem of mining entity translation , specifically , mining English and Chinese name pairs .
Existing efforts can be categorized into ( a ) a transliterationbased approach leveraging phonetic similarity and ( b ) a corpus-based approach exploiting bilingual co-occurrences , each of which suffers from inaccuracy and scarcity respectively .
In clear contrast , we use unleveraged resources of monolingual entity co-occurrences , crawled from entity search engines , represented as two entity - relationship graphs extracted from two language corpora respectively .
Our problem is then abstracted as finding correct mappings across two graphs .
To achieve this goal , we propose a holistic approach , of exploiting both transliteration similarity and monolingual co-occurrences .
This approach , building upon monolingual corpora , complements existing corpus-based work , requiring scarce resources of parallel or comparable corpus , while significantly boosting the accuracy of transliteration - based work .
We validate our proposed system using real-life datasets .
Introduction Entity translation aims at mapping the entity names ( e.g. , people , locations , and organizations ) in source language into their corresponding names in target language .
While high quality entity translation is essential in cross-lingual information access and trans-lation , it is non-trivial to achieve , due to the challenge that entity translation , though typically bearing pronunciation similarity , can also be arbitrary , e.g. , Jackie Chan and ( pronounced Cheng Long ) .
Existing efforts to address these challenges can be categorized into transliteration - and corpusbased approaches .
Transliteration - based approaches ( Wan and Verspoor , 1998 ; Knight and Graehl , 1998 ) identify translations based on pronunciation similarity , while corpus-based approaches mine bilingual co-occurrences of translation pairs obtained from parallel ( Kupiec , 1993 ; Feng et al. , 2004 ) or comparable ( Fung and Yee , 1998 ) corpora , or alternatively mined from bilingual sentences ( Lin et al. , 2008 ; Jiang et al. , 2009 ) .
These two approaches have complementary strength - transliteration - based similarity can be computed for any name pair but cannot mine translations of little ( or none ) phonetic similarity .
Corpus- based similarity can support arbitrary translations , but require highly scarce resources of bilingual co-occurrences , obtained from parallel or comparable bilingual corpora .
In this paper , we propose a holistic approach , leveraging both transliteration - and corpus-based similarity .
Our key contribution is to replace the use of scarce resources of bilingual co-occurrences with the use of untapped and significantly larger resources of monolingual co-occurrences for translation .
In particular , we extract monolingual cooccurrences of entities from English and Chinese Web corpora , which are readily available from entity search engines such as PeopleEntityCube 1 , deployed by Microsoft Research Asia .
Such engine automatically extracts people names from text and their co-occurrences to retrieve related entities based on co-occurrences .
To illustrate , Figure 1 ( a ) demonstrates the query result for " Bill Gates , " retrieving and visualizing the " entity - relationship graph " of related people names that frequently co-occur with Bill in English corpus .
Similarly , entity - relationship graphs can be built over other language corpora , as Figure 1 ( b ) demonstrates the corresponding results for the same query , from Renlifang 2 on Chinese Web corpus .
From this point on , for the sake of simplicity , we refer to English and Chinese graphs , simply as G e and G c respectively .
Though we illustrate with English - Chinese pairs in the paper , our method can be easily adapted to other language pairs .
In particular , we propose a novel approach of abstracting entity translation as a graph matching problem of two graphs G e and G c in Figures 1 ( a ) and ( b ) .
Specifically , the similarity between two nodes v e and v c in G e and G c is initialized as their transliteration similarity , which is iteratively refined based on relational similarity obtained from monolingual cooccurrences .
To illustrate this , an English news article mentioning " Bill Gates " and " Melinda Gates " evidences a relationship between the two entities , which can be quantified from their co-occurrences in the entire English Web corpus .
Similarly , we can mine Chinese news articles to obtain the relationships between " ? " and " ? " .
Once these two bilingual graphs of people and their relationships are harvested , entity translation can leverage these parallel relationships to further evidence the mapping between translation pairs , as Figure 1 ( c ) illustrates .
To highlight the advantage of our proposed approach , we compare our results with commercial machine translators ( 1 ) Engkoo 3 developed in Microsoft Research Asia and ( 2 ) Google Translator 4 .
In particular , Figure 2 reports the precision for two groups -" heads " that belong to top - 100 popular people ( determined by the number of hits ) , among randomly sampled 304 people names 5 from six graph pairs of size 1,000 each , and the remaining " tails " .
Commercial translators such as Google , leveraging bilingual co-occurrences that are scarce for tails , show significantly lower precision for tails .
Meanwhile , our work , depending solely on monolingual co-occurrences , shows high precision , for both heads and tails .
Ours
Our focus is to boost translation accuracy for long tails with non-trivial Web occurrences in each monolingual corpus , but not with much bilingual cooccurrences , e.g. , researchers publishing actively in two languages but not famous enough to be featured in multi-lingual Wikipedia entries or news articles .
As existing translators are already highly accurate for popular heads , this focus well addresses the remaining challenges for entity translation .
To summarize , we believe that this paper has the following contributions : ?
We abstract entity translation problem as a graph mapping between entity -relationship graphs in two languages . ?
We develop an effective matching algorithm leveraging both pronunciation and cooccurrence similarity .
This holistic approach complements existing approaches and enhances the translation coverage and accuracy . ?
We validate the effectiveness of our approach using various real-life datasets .
The rest of this paper is organized as follows .
Section 2 reviews existing work .
Section 3 then develops our framework .
Section 4 reports experimental results and Section 5 concludes our work .
In this section , we first survey related efforts , categorized into transliteration - based and corpus-based approaches .
Our approach leveraging both is complementary to these efforts .
Transliteration - based Approaches
Many name translations are loosely based on phonetic similarity , which naturally inspires transliteration - based translation of finding the translation with the closest pronunciation similarity , using either rule- based ( Wan and Verspoor , 1998 ) or statistical ( Knight and Graehl , 1998 ; Li et al. , 2004 ) approaches .
However , people are free to designate arbitrary bilingual names of little ( or none ) phonetic similarity , for which the transliteration - based approach is not effective .
Corpus-based Approaches Corpus-based approach can mine arbitrary translation pairs , by mining bilingual co-occurrences from parallel and comparable bilingual corpora .
Using parallel corpora ( Kupiec , 1993 ; Feng et al. , 2004 ) , e.g. , bilingual Wikipedia entries on the same person , renders high accuracy but suffers from high scarcity .
To alleviate such scarcity , ( Fung and Yee , 1998 ; Shao and Ng , 2004 ) explore a more vast resource of comparable corpora , which share no parallel document - or sentence - alignments as in parallel corpora but describe similar contents in two languages , e.g. , news articles on the same event .
Alternatively , ( Lin et al. , 2008 ) extracts bilingual cooccurrences from bilingual sentences , such as annotating terms with their corresponding translations in English inside parentheses .
Similarly , ( Jiang et al. , 2009 ) identifies potential translation pairs from bilingual sentences using lexical pattern analysis .
Holistic Approaches
The complementary strength of the above two approaches naturally calls for a holistic approach , such as recent work combining transliterationand corpus-based similarity mining bilingual cooccurrences using general search engines .
Specifically , ( Al - Onaizan and Knight , 2002 ) uses transliteration to generate candidates and then web corpora to identify translations .
Later , ( Jiang et al. , 2007 ) enhances to use transliteration to guide web mining .
Our work is also a holistic approach , but leveraging significantly larger corpora , specifically by exploiting monolingual co-occurrences .
Such expansion enables to translate " long-tail " people entities with non-trivial Web occurrences in each monolingual corpus , but not much bilingual co-occurrences .
Specifically , we initialize name pair similarity using transliteration - based approach , and iteratively reinforces base similarity using relational similarity .
Our Framework Given two graphs G e = ( V e , E e ) and G c = ( V c , E c ) harvested from English and Chinese corpora respectively , our goal is to find translation pairs , or a set S of matching node pairs such that S ? V e ? V c .
Let R be a | V e |- by -|V c | matrix where each R ij denotes the similarity between two nodes i ?
V e and j ?
V c .
Overall , with the matrix R , our approach consists of the following three steps , as we will discuss in the following three sections respectively :
We initialize the translation similarity R ij as the transliteration similarity .
This section explains how to get the transliteration similarity between English and Chinese names using an unsupervised approach .
Formally , let an English name N e = ( e 1 , e 2 , ? ? ? , e n ) and a Chinese name N c = ( c 1 , c 2 , ? ? ? , c m ) be given , where e i is an English word and N e is a sequence of the words , and c i is a Chinese character and N c is a sequence of the characters .
Our goal is to compute a score indicating the similarity between the pronunciations of the two names .
We first convert N c into its Pinyin representation P Y c = ( s 1 , s 2 , ? ? ? , s m ) , where s i is the Pinyin representation of c i .
Pinyin is the romanization representation of pronunciation of Chinese character .
For example , the Pinyin representation of N e = ( " Barack " , " Obama " ) is P Y c = ( " ba " , " la " , " ke " , " ao " , " ba " , " ma " ) .
The Pinyin representations of Chinese characters can be easily obtained from Chinese character pronunciation dictionary .
In our experiments , we use an in-house dictionary , which contains pronunciations of 20 , 774 Chinese characters .
For the Chinese characters having multiple pronunciations , we only use the most popular one .
Calculation of transliteration similarity between N e and N c is now transformed to calculation of pronunciation similarity between N e and P Y c .
Because letters in Chinese Pinyins and English strings are pronounced similarly , we can further approximate pronunciation similarity between N e and P Y c using their spelling similarity .
In this paper , we use Edit Distance ( ED ) to measure the spelling similarity .
Moreover , since words in N e are transliterated into characters in P Y c independently , it is more accurate to compute the ED between N e and P Y c , i.e. , ED name ( N e , P Y c ) , as the sum of the EDs of all component transliteration pairs , i.e. , every e i in N e and its corresponding transliteration ( s i ) in P Y c .
In other words , we need to first align all s j 's in P Y c with corresponding e i in N e based on whether they are translations of each other .
Then based on the alignment , we can calculate ED name ( N e , P Y c ) using the following formula .
ED name ( N e , P Y c ) = ?
i ED( e i , es i ) ( 1 ) where es i is a string generated by concatenating all s i 's that are aligned to e i and ED ( e i , es i ) is the Edit Distance between e i and es i , i.e. , the minimum number of edit operations ( including insertion , deletion and substitution ) needed to transform e i into es i .
Because an English word usually consists of multiple syllables but every Chinese character consists of only one syllable , when aligning e i 's with s j 's , we add the constraint that each e i is allowed to be aligned with 0 to 4 s i 's but each s i can only be aligned with 0 to 1 e i .
To get the alignment between P Y c and N e which has the minimal ED name ( N e , P Y c ) , we use a Dynamic Programming based algorithm as defined in the following formula : EDname ( N 1 , i e , P Y 1 , j c ) = min( EDname ( N 1 , i?1 e , P Y 1 , j c ) + Len( ei ) , EDname ( N 1 , i e , P Y 1 , j?1 where , given a sequence X = ( x 1 , x 2 , ? ? ? ) such that x i is a word , X i , j is the subsequence ( x i , x i+ 1 , ? ? ? , x j ) of X and Len ( X ) is the number of letters except spaces in the sequence X. For instance , the minimal Edit Distance between the English name " Barack Obama " and the Chinese Pinyin representation " ba la ke ao ba ma " is 4 , as the best alignment is : " Barack " ?
" ba la ke " ( ED : 3 ) , " Obama " ?
" ao ba ma " ( ED : 1 ) .
Finally the transliteration similarity between N c and N e is calculated using the following formula .
Sim tl ( N c , N e ) = 1 ? ED name ( N e , P Y c ) Len( P Y c ) + Len( N e ) ( 2 ) For example , Sim tl ( " Barack Obama " , " ? " ) is 1 ? 4 11+ 12 = 0.826 .
Reinforcement Model
From the initial similarity , we model our problem as an iterative approach that iteratively reinforces the similarity R ij of the nodes i and j from the matching similarities of their neighbor nodes u and v .
The basic intuition is built on exploiting the similarity between monolingual co-occurrences of two different languages .
In particular , we assume two entities with strong relationship co-occur frequently in both corpora .
In order to express this intuition , we formally define an iterative reinforcement model as follows .
Let R t ij denote the similarity of nodes i and j at t-th iteration : R t+1 ij = ? ? ( u , v ) k ?B t ( i , j , ? ) R t uv 2 k + ( 1 ? ?) R 0 ij ( 3 )
The model is expressed as a linear combination of ( a ) the relational similarity ?
R t uv /2 k and ( b ) transliteration similarity R 0 ij . ( ? is the coefficient for interpolating two similarities . )
In the relational similarity , B t ( i , j , ? ) is an ordered set of the best matching pairs between neighbor nodes of i and ones of j such that ?( u , v) k ?
B t ( i , j , ? ) , R t uv ? ? , where ( u , v ) k is the matching pair with k-th highest similarity score .
We consider ( u , v ) with similarity over some threshold ? , or R t uv ? ? , as a matching pair .
In this neighbor matching process , if many - to - many matches exist , we select only one with the greatest matching score .
Figure 3 describes such matching process more formally .
N ( i ) and N ( j ) are the sets of neighbor nodes of i and j , respectively , and H is a priority queue sorting pairs in the decreasing order of similarity scores .
Meanwhile , note that , in order to express that the confidence for matching ( i , j ) progressively converges as the number of matched neighbors increases , we empirically use decaying coefficient 1/2 k for R t uv , because ? ? k=1 1/2 k = 1 .
Matching Extraction After ( West , 2000 ) .
In this paper , to speed up processing , we consider a greedy alternative with the following steps -( 1 ) choose the pair with the highest similarity score , ( 2 ) remove the corresponding row and column from the matrix , and ( 3 ) repeat ( 1 ) and ( 2 ) until their matching scores are over a specific threshold ?.
Experiments
This section reports our experimental results to evaluate our proposed approach .
First , we report our experimental setting in Section 4.1 .
Second , we validate the effectiveness and the scalability of our approach over a real-life dataset in Section 4.2 .
Experimental Settings
This section describes ( 1 ) how we collect the English and Chinese EntityCube datasets , ( 2 ) how to build ground - truth test datasets for evaluating our framework , and ( 3 ) how to set up three parameters ? , ? , and ?.
First , we crawled G e = ( V e , E e ) and G c = ( V c , E c ) from English and Chinese EntityCubes .
Specifically , we built a graph pairs ( G e , G c ) expanding from a " seed pair " of nodes s e ?
V e and s c ?
V c until the number of nodes for each graph becomes 1,000 6 .
More specifically , when we build a graph G e by expanding from s e , we use a queue Q .
We first initialize Q by pushing the seed node s e .
We then iteratively pop a node v e from Q , save v e into V e , and push its neighbor nodes in decreasing order of co-occurrence scores with v e .
Similarly , we can get G c from a counterpart seed node v c .
By using this procedure , we built six graph pairs from six different seed pairs .
In particular , the six seed nodes are English names and its corresponding Chinese names representing a wide range of occupation domains ( e.g. , ' Barack Obama , ' ' Bill Gates , ' ' Britney Spears , ' ' Bruno Senna , ' ' Chris Paul , ' and ' Eminem ' ) as Table 1 depicts .
Meanwhile , though we demonstrate the effectiveness of the proposed method for mining name translations in Chinese and English languages , the method can be easily adapted to other language pairs .
Second , we manually searched for about 50 " ground- truth " matched translations for each graph pair to build test datasets T i , by randomly selecting nodes within two hops 7 from the seed pair ( s e , s c ) , since nodes outside two hops may include nodes whose neighbors are not fully crawled .
More specifically , due to our crawling process expanding to add neighbors from the seed , the nodes close to the seed have all the neighbors they would have in the full graph , while those far from the node may not .
In order to pick the nodes that well represent the actual neighbors , we built test datasets among those within two hops .
However , this crawling is used for the evaluation sake only , and thus does not suggest the bias in our proposed framework .
Table 1 describes the size of such test dataset for each graph pair .
Lastly , we set up the three parameters ? , ? , and ? using 6 - fold cross validation with 6 test datasets T i 's of the graphs .
More specifically , for each dataset T i , we decide ?
i and ?
i such that average MRR for the other 5 test datasets is maximized .
( About MRR , see more details of Equation ( 4 ) in Section 4.2 . )
We then decide ?
i such that average F1 - score is maximized .
Figure 4 shows the average MRR for ?
i and ?
i with default values ? = 0.66 and ? = 0.2 .
Based on these results , we set ?
i with values { 0.2 , 0.15 , 0.2 , 0.15 , 0.2 , 0.15 } that optimize MRR in datasets T 1 , . . . T 6 , and similarly ?
i with { 0.67 , 0.65 , 0.67 , 0.67 , 0.65 , 0.67 } .
We also set ?
i with values { 0.63 , 0.63 , 0.61 , 0.61 , 0.61 , 0.61 } optimizing F1 - score with the same default values ? = 0.2 and ? = 0.66 .
We can observe the variances of optimal parameter setting values are low , which suggests the robustness of our framework .
Experimental Results
This section reports our experimental results using the evaluation datasets explained in previous section .
For each graph pair , we evaluated the effectiveness of ( 1 ) reinforcement model using MRR measure in Section 4.2.1 and ( 2 ) overall framework using precision , recall , and F1 measures in Section 4.2.2 .
We also validated ( 3 ) scalability of our framework over larger scale of graphs ( with up to five thousand nodes ) in Section 4.2.3 .
( In all experimental results , Bold numbers indicate the best performance for each metric . )
Effectiveness of reinforcement model
We evaluated the reinforcement model over MRR ( Voorhees , 2001 ) , the average of the reciprocal ranks of the query results as the following formula : MRR = 1 | Q| ? q?Q 1 rank q ( 4 ) Each q is a ground - truth matched pair ( u , v ) such that u ?
V e and v ?
V c , and rank q is the rank of the similarity score of R uv among all R uk 's such that k ?
V c .
Q is a set of such queries .
By comparing MRRs for two matrices R 0 and R ? , we can validate the effectiveness of the reinforcement model .
?
Baseline matrix ( R 0 ) : using only the transliteration similarity score , i.e. , without reinforcement ?
Reinforced matrix ( R ? ) : using the reinforced similarity score obtained from Equation ( 3 )
We empirically observed that the iterative model converges within 5 iterations .
In all experiments , we used 5 iterations for the reinforcement .
Table 2 summarizes our experimental results .
As these figures show , MRR scores significantly increase after applying our reinforcement model except for the set T 4 ( on average from 69 % to 81 % ) , which indirectly shows the effectiveness of our reinforcement model .
Effectiveness of overall framework Based on the reinforced matrix , we evaluated the effectiveness of our overall matching framework using the following three measures -( 1 ) precision : how accurately the method returns matching pairs , ( 2 ) recall : how many the method returns correct matching pairs , and ( 3 ) F1 - score : the harmonic mean of precision and recall .
We compared our approach with a baseline , mapping two graphs with only transliteration similarity .
?
Baseline : in matching extraction , using R 0 as the similarity matrix by bypassing the reinforcement step ?
Ours : using R ? , the similarity matrix converged by Equation ( 3 ) In addition , we compared ours with the machine translators of Engkoo and Google .
Table 3 summarizes our experimental results .
As this table shows , our approach results in the highest precision ( about 80 % on average ) without compromising the best recall of Google , i.e. , 61 % of Google vs. 63 % of ours .
Overall , our approach outperforms others in all three measures .
Meanwhile , in order to validate the translation accuracy over popular head and long-tail , as discussed in Section 1 , we separated the test data into two groups and analyzed the effectiveness separately .
Figure 5 plots the number of hits returned for the names from Google search engine .
According to the distribution , we separate the test data into top - 100 popular people with the highest hits and the remaining , denoted head and tail , respectively .
Table 4 shows the effectiveness with both datasets , respectively .
As difference of the effectiveness between tail and head ( denoted diff ) with respect to three measures shows , our approach shows stably high precision , for both heads and tails .
Scalability
To validate the scalability of our approach , we evaluated the effectiveness of our approach over the number of nodes in two graphs .
We built larger six graph pairs ( G e , G c ) by expanding them from the seed pairs further until the number of nodes reaches 5,000 .
Figure 6 shows the number of matched translations according to such increase .
Overall , the number of matched pairs linearly increases as the number of nodes increases , which suggests scalability .
The ratio of node overlap in two graphs is about between 7 % and 9 % of total node size .
Conclusion
This paper abstracted name translation problem as a matching problem of two entity - relationship graphs .
This novel approach complements existing name translation work , by not requiring rare resources of parallel or comparable corpus yet outperforming the state - of - the - art .
More specifically , we combine bilingual phonetic similarity and monolingual Web co-occurrence similarity , to compute a holistic notion of entity similarity .
To achieve this goal , we de -
Our evaluation results empirically validated the accuracy of our algorithm over real- life datasets , and showed the effectiveness on our proposed perspective .
Figure 2 : 2 Figure 2 : Comparison for Head and Tail datasets
