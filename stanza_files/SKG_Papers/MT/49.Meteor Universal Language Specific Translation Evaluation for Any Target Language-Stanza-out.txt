title
Meteor Universal : Language Specific Translation Evaluation for Any Target Language
abstract
This paper describes Meteor Universal , released for the 2014 ACL Workshop on Statistical Machine Translation .
Meteor Universal brings language specific evaluation to previously unsupported target languages by ( 1 ) automatically extracting linguistic resources ( paraphrase tables and function word lists ) from the bitext used to train MT systems and ( 2 ) using a universal parameter set learned from pooling human judgments of translation quality from several language directions .
Meteor Universal is shown to significantly outperform baseline BLEU on two new languages , Russian ( WMT13 ) and Hindi ( WMT14 ) .
Introduction Recent WMT evaluations have seen a variety of metrics employ language specific resources to replicate human translation rankings far better than simple baselines ( Callison - Burch et al. , 2011 ; Callison - Burch et al. , 2012 ; Mach?ek and Bojar , 2013 ; Snover et al. , 2009 ; Denkowski and Lavie , 2011 ; Dahlmeier et al. , 2011 ; Chen et al. , 2012 ; Wang and Manning , 2012 , inter alia ) .
While the wealth of linguistic resources for the WMT languages allows the development of sophisticated metrics , most of the world 's 7,000 + languages lack the prerequisites for building advanced metrics .
Researchers working on low resource languages are usually limited to baseline BLEU ( Papineni et al. , 2002 ) for evaluating translation quality .
Meteor Universal brings language specific evaluation to any target language by combining linguistic resources automatically learned from MT system training data with a universal metric parameter set that generalizes across languages .
Given only the bitext used to build a standard phrase - based translation system , Meteor Universal learns a paraphrase table and function word list , two of the most consistently beneficial language specific resources employed in versions of Meteor .
Whereas previous versions of Meteor require human ranking judgments in the target language to learn parameters , Meteor Universal uses a single parameter set learned from pooling judgments from several languages .
This universal parameter set captures general preferences shown by human evaluators across languages .
We show this approach to significantly outperform baseline BLEU for two new languages , Russian and Hindi .
The following sections review Meteor 's scoring function ( ?2 ) , describe the automatic extraction of language specific resources ( ?3 ) , discuss training of the universal parameter set ( ?4 ) , report experimental results ( ?5 ) , describe released software ( ? 6 ) , and conclude ( ?7 ) .
Meteor Scoring Meteor evaluates translation hypotheses by aligning them to reference translations and calculating sentence - level similarity scores .
For a hypothesisreference pair , the space of possible alignments is constructed by exhaustively identifying all possible matches between the sentences according to the following matchers :
Exact : Match words if their surface forms are identical .
Stem : Stem words using a language appropriate Snowball Stemmer ( Porter , 2001 ) and match if the stems are identical .
Synonym : Match words if they share membership in any synonym set according to the WordNet database ( Miller and Fellbaum , 2007 ) .
Paraphrase : Match phrases if they are listed as paraphrases in a language appropriate paraphrase table ( described in ?3.2 ) .
All matches are generalized to phrase matches with a span in each sentence .
Any word occurring within the span is considered covered by the match .
The final alignment is then resolved as the largest subset of all matches meeting the following criteria in order of importance :
1 . Require each word in each sentence to be covered by zero or one matches .
2 . Maximize the number of covered words across both sentences .
3 . Minimize the number of chunks , where a chunk is defined as a series of matches that is contiguous and identically ordered in both sentences .
4 . Minimize the sum of absolute distances between match start indices in the two sentences .
( Break ties by preferring to align phrases that occur at similar positions in both sentences . )
Alignment resolution is conducted as a beam search using a heuristic based on the above criteria .
The Meteor score for an aligned sentence pair is calculated as follows .
Content and function words are identified in the hypothesis ( h c , h f ) and reference ( r c , r f ) according to a function word list ( described in ?3.1 ) .
For each of the matchers ( m i ) , count the number of content and function words covered by matches of this type in the hypothesis ( m i ( h c ) , m i ( h f ) ) and reference ( m i ( r c ) , m i ( r f ) ) .
Calculate weighted precision and recall using matcher weights ( w i ...w n ) and contentfunction word weight ( ? ) : P = i w i ? (? ? m i ( h c ) + ( 1 ? ? ) ? m i ( h f ) ) ? ? |h c | + ( 1 ? ? ) ? |h f | R = i w i ? (? ? m i ( r c ) + ( 1 ? ? ) ? m i ( r f ) ) ? ? |r c | + ( 1 ? ? ) ? |r f |
The parameterized harmonic mean of P and R ( van Rijsbergen , 1979 ) is then calculated : F mean = P ? R ? ? P + ( 1 ? ? ) ? R
To account for gaps and differences in word order , a fragmentation penalty is calculated using the total number of matched words ( m , averaged over hypothesis and reference ) and number of chunks ( ch ) : P en = ? ? ch m ?
The Meteor score is then calculated : Score = ( 1 ? P en ) ?
F mean
The parameters ? , ? , ? , ? , and w i ...w n are tuned to maximize correlation with human judgments .
Language Specific Resources
Meteor uses language specific resources to dramatically improve evaluation accuracy .
While some resources such as WordNet and the Snowball stemmers are limited to one or a few languages , other resources can be learned from data for any language .
Meteor Universal uses the same bitext used to build statistical translation systems to learn function words and paraphrases .
Used in conjunction with the universal parameter set , these resources bring language specific evaluation to new target languages .
Function Word Lists
The function word list is used to discriminate between content and function words in the target language .
Meteor Universal counts words in the target side of the training bitext and considers any word with relative frequency above 10 ?3 to be a function word .
This list is used only during the scoring stage of evaluation , where the tunable ?
parameter controls the relative weight of content versus function words .
When tuned to match human judgments , this parameter usually reflects a greater importance for content words .
Paraphrase Tables Paraphrase tables allow many - to - many matches that can encapsulate any local language phenomena , including morphology , synonymy , and true paraphrasing .
Identifying these matches allows far more sophisticated evaluation than is possible with simple surface form matches .
In Meteor Universal , paraphrases act as the catch - all for nonexact matches .
Paraphrases are automatically extracted from the training bitext using the translation pivot approach ( Bannard and Callison - Burch , 2005 ) .
First , a standard phrase table is learned from the bitext ( Koehn et al. , 2003 ) .
Paraphrase extraction then proceeds as follows .
For each target language phrase ( e 1 ) in the table , find each source phrase f that e 1 translates .
Each alternate phrase ( e 2 = e 1 ) that translates f is considered a paraphrase with probability P ( f |e 1 ) ? P ( e 2 |f ) .
The total probability of e 2 being a paraphrase of e 1 is the sum over all possible pivot phrases f : P ( e 2 |e 1 ) = f P ( f |e 1 ) ? P ( e 2 |f )
To improve paraphrase precision , we apply several language independent pruning techniques .
The following are applied to each paraphrase instance ( e 1 , f , e 2 ) : ? Discard instances with very low probability ( P ( f |e 1 ) ? P ( e 2 |f ) < 0.001 ) .
?
Discard instances where e 1 , f , or e 2 contain punctuation characters .
?
Discard instances where e 1 , f , or e 2 contain only function words ( relative frequency above 10 ?3 in the bitext ) .
The following are applied to each final paraphrase ( e 1 , e 2 ) after summing over all instances : ?
Discard paraphrases with very low probability ( P ( e 2 |e 1 ) < 0.01 ) .
?
Discard paraphrases where e 2 is a sub-phrase of e 1 .
This constitutes the full Meteor paraphrasing pipeline that has been used to build tables for fully supported languages ( Denkowski and Lavie , 2011 ) .
Paraphrases for new languages have the added advantage of being extracted from the same bitext that MT systems use for phrase extraction , resulting in ideal paraphrase coverage for evaluated systems .
Universal Parameter Set Traditionally , building a version of Meteor for a new target language has required a set of humanscored machine translations , most frequently in the form of WMT rankings .
The general lack of availability of these judgments has severely limited the number of languages for which Meteor versions could be trained .
1 ) . Data for each language is scored using the same resources ( function word list and paraphrase table only ) and scoring parameters are tuned to maximize agreement ( Kendall 's ? ) over all judgments from all languages , leading to a single parameter set .
The universal parameter set encodes the following general human preferences : ?
Prefer recall over precision .
?
Prefer word choice over word order .
?
Prefer correct translations of content words over function words .
?
Prefer exact matches over paraphrase matches , while still giving significant credit to paraphrases .
For Russian , correlation is nearly double that of BLEU .
This provides substantial evidence that Meteor Universal will further generalize , bringing improved evaluation accuracy to new target languages currently limited to baseline language independent metrics .
For the WMT14 evaluation , we use the traditional language specific versions of Meteor for all language directions except Hindi .
This includes Russian , for which additional language specific resources ( a Snowball word stemmer ) help significantly .
For Hindi , we use the release version of Meteor Universal to extract linguistic resources from the constrained training bitext provided for the shared translation task .
These resources are used with the universal parameter set to score all system outputs for the English -Hindi direction .
Software Meteor Universal is included in Meteor version 1.5 which is publicly released for WMT14 .
Meteor 1.5 can be downloaded from the official webpage 1 and a full tutorial for Meteor Universal is available online .
Conclusion
This paper describes Meteor Universal , a version of the Meteor metric that brings language specific evaluation to any target language using the same resources used to build statistical translation systems .
Held out tests show Meteor Universal to significantly outperform baseline BLEU on WMT13 Russian and WMT14 Hindi .
Meteor version 1.5 is freely available open source software .
To use the resulting files to score translations with Meteor , use the new language option : $ java - jar meteor -* . jar test ref - new \ out / meteor-files Meteor 1.5 , including Meteor Universal , is free software released under the terms of the GNU Lesser General Public License .
