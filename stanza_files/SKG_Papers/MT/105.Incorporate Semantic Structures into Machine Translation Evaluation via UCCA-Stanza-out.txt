title
Incorporate Semantic Structures into Machine Translation Evaluation via UCCA
abstract
Copying mechanism has been commonly used in neural paraphrasing networks and other text generation tasks , in which some important words in the input sequence are preserved in the output sequence .
Similarly , in machine translation , we notice that there are certain words or phrases appearing in all good translations of one source text , and these words tend to convey important semantic information .
Therefore , in this work , we define words carrying important semantic meanings in sentences as semantic core words .
Moreover , we propose an MT evaluation approach named Semantically Weighted Sentence Similarity ( SWSS ) .
It leverages the power of UCCA to identify semantic core words , and then calculates sentence similarity scores on the overlap of semantic core words .
Experimental results show that SWSS can consistently improve the performance of popular MT evaluation metrics which are based on lexical similarity .
Introduction Machine Translation Evaluation ( MTE ) is to evaluate the quality of sentences produced by Machine Translation ( MT ) systems .
Most automatic MT evaluation metrics compare the candidate sentences from MT systems with reference sentences from human translation to produce a similarity score , in contrast some other reference -less metrics directly compare candidate sentences and source sentences .
According to the observation of well - translated sentences , we find out that there are certain words or phrases appearing in all good translations of one source text .
This phenomenon is consistent with the intuition of copying mechanism ( Gu et al. , 2016 ) , which has been widely used in lots of text generation tasks .
In the field of MT evaluation , Meteor ++ ( Guo et al. , 2018 ) firstly proposes the concept of copy knowledge to define the words with copy property , and it further incorporates the copy knowledge into Meteor ( Denkowski and Lavie , 2014 ) to improve its performance .
Specifically , it attempts to find copy words of references and candidate sentences , and uses the overlap of these words to modify the calculation of precision and recall of Meteor .
However , Meteor ++ uses named entities as an alternative to copy knowledge in its experiments , resulting in a limited range of selected copy words and a slight improvement .
In this work , we argue that words undertaking important semantic meanings should be exactly expressed during the translation procedure , which we define as semantic core words .
This concept is much more general and closer to linguistic intuition compared to the copy knowledge used in Meteor ++.
In order to apply semantic core words in the process of MT evaluation , we design a mechanism named Semantically Weighted Sentence Similarity ( SWSS ) illustrated in Figure 1 . Firstly , SWSS extracts semantic core words according to the annotated semantic labels in Universal Conceptual Cognitive Annotation ( UCCA ) ( Abend and Rappoport , 2013 ) , a multi-layered semantic representation .
UCCA is an appealing candidate for this mechanism as it includes a lot of fundamental semantic phenomena , such as verbal , nominal and adjectival argument structures and their inter-relations .
Also , semantic units in UCCA are anchored in the text , which simplifies the aligning procedure a lot .
With the assumption that all high-quality translations should have the same semantic core words , SWSS then calculates precision and recall based on the overlap of semantic core words between sentence pairs and their corresponding F1 scores .
Finally , we modify the F1 score according to the differences of two UCCA representations .
For example , Scenes are involved in the penalties , which are essential nodes in UCCA indicating actions and states of the sentences .
Our experimental results show that SWSS can be combined with other popular MT evaluation metrics to improve their performance significantly .
2 Related Work
Machine Translation Evaluation BLEU ( Papineni et al. , 2002 ) and Meteor are two most popular MT evaluation metrics .
BLEU measures n-grams overlapping between the candidate sentences and reference sentences , while Meteor aligns words and phrases to calculate a modified weighted F-score .
The two metrics are based on lexical similarity but somehow neglect semantic structure information of the sentences .
Efforts have been made to incorporate linguistic features and resources into MT evaluation .
RED ( Yu et al. , 2014 ) makes use of dependency tree and MEANT ( Lo et al. , 2012 ) makes use of semantic parser .
Categories such as part-ofspeech ( Avramidis et al. , 2011 ) and named entity ( Buck , 2012 ) also have their effects .
In order to complement WordNet ( Miller , 1998 ) and paraphrase table in Meteor , Meteor + + 2.0 ( Guo and Hu , 2019 ) applies syntactic -level paraphrase knowledge .
Semantic Representation Semantic representation focuses on how meaning is expressed in a sentence .
Some semantic representation frameworks such as UNL ( Uchida and Zhu , 2001 ) and AMR ( Banarescu et al. , 2013 ) use concept nodes to represent content words of sentence , and use directed edges with labels to indicate the semantic relation between nodes .
UCCA is a novel multi-layered semantic representation framework , which converts a sentence into a directed acyclic graph ( DAG ) .
Leaf nodes of UCCA graph correspond to words in the sentence , and a non-leaf node represents the combination of meanings of its child nodes .
A parent node and a child node are connected by a directed edge which demonstrates the semantic role of the child node in the meaning of the parent node .
Figure 2 is an example of UCCA representation .
Scene is an essential concept in UCCA .
A scene describes some movement , action or a state in the sentence .
Scene nodes in UCCA representation may be connected to the root node , or embedded in other scenes as arguments or modifiers .
A scene node has a main relation , either a Process or a State , and may have some Participants or some Adverbials .
These non-scene nodes may also have inner structure .
UCCA has been applied in many fields of Natural Language Processing .
SAMSA ( Sulem et al. , 2018 ) is a Text Simplification evaluation metric that defines minimal center of UCCA representation and compares simplified text with the minimal centers of original sentences .
It is also used in evaluation of faithfulness in Grammatical Error Correlation ( Choshen and Abend , 2018 ) and human MT evaluation ( Birch et al. , 2016 ) .
3 Proposed Method
Semantic Core Words
The most popular MT evaluation metrics such as BLEU and Meteor are based on lexical similarity .
This kind of metrics cannot obtain insight into semantic structure of the whole sentence .
Our proposed semantic core words are extracted from UCCA semantic structures and used to improve these lexical metrics as we expect them to play the role of copy words .
It is a linguistic intuition that some words carry more semantic information than other words in a sentence .
For example , a modifier is usually less important than the word it modifies .
In this paper , We define words that have important semantic information as semantic core words .
According to their semantic importance , they are expected to be accurately translated during translation .
Therefore , we assume that in all good translation results of a specific sentence , the set of semantic core words should be the same , behaving like copy words .
We extract semantic core words of a sentence from its UCCA semantic representation .
The lowest semantic role label in the representation for each word is considered , which also indicates the most basic semantic role of a word .
A word whose lowest semantic role is Process , State , Participant or Center is identified as semantic core words .
Figure 3 marks semantic core words of the example sentence .
The result is consistent with our intuition of which word has important meaning in this sentence .
Word Matching After semantic core words are extracted from UCCA representations , a word matching algorithm should be applied in order to match all words between the two sentences .
In this paper , we use a stemming algorithm .
Two words are matched if they have the same stem .
We count how many semantic core words in a candidate sentence can be matched to any semantic core words in the reference sentence , and compute the proportion as precision .
Similarly , we calculate the matched proportion of semantic core words in reference sentence as recall .
In our word matching algorithm , it is possible that a word in a sentence is matched to multiple words in the other sentence because they all have the same word stem .
However , just like what is conducted in BLEU , a word cannot be contained in multiple matching pairs .
The precision and recall are then used to calculate F1 score .
We use F1 score here to ensure that SWSS is symmetrical and can be directly used as a sentence similarity metric .
P = i w( h i ) ? m( h i ) i w( h i ) R = i w( r i ) ? m( r i ) i w( r i ) F 1 = 2P ? R P + R ( 1 ) Take the calculation of precision as an example .
h i means each semantic core word in the candidate sentence , and w(h i ) is its weight .
Though in this paper the weight is fixed to 1 , it can be fine-tuned or trained in future work .
If h i can be matched to any semantic core word in the reference sentence , m(h i ) is set to 1 , otherwise m(h i ) is set to 0 .
However , m(h i ) can also be different values related to matching type like the operation in Meteor , which might be conducted in future work .
A fact is that the UCCA parser we used might occasionally produce an analysis result in which there are no semantic core words in a sentence , which causes division by zero during calculation .
In these cases a fixed score ? is used as an alternative .
Penalty and Combination According to the intuition that good translation results of a specific sentence should have similar semantic structures , we introduce three penalties concerning statistical differences of two UCCA representations . ?
The ratio between counts of scenes of two representations .
Let S 1 , S 2 be the counts of scenes , the penalty P S is 1 ? min( S 1 , S 2 ) / max ( S 1 , S 2 ) . ?
The ratio between counts of nodes of two representations .
Let N 1 , N 2 be the counts of nodes , the penalty P N is 1 ? min( N 1 , N 2 ) / max ( N 1 , N 2 ) . ?
The ratio between counts of edges towards critical semantic roles of two representations , which are Process , State and Participant .
This count is the sum of count of scenes and count of all arguments in the sentence .
Let E 1 , E 2 be the counts of these edges , the penalty P E is 1 ? min( E 1 , E 2 ) / max( E 1 , E 2 ) .
The three penalties are set to 0 if the counts are equal and their upper bound is 1 .
Additionally , we also notice that the average word count of a sentence pair can act as another penalty Len .
Applying the four penalties , the final score is calculated by the equation below .
All parameters here are tunable .
Score = F 1 ? exp ( ? ? 1 ? P S ? ? 2 ? P N ? ? 3 ? P E ? ? 4 ? Len ) ( 2 ) The SWSS score is calculated independently .
Therefore , as a semantic structure - based component , it can be further combined with other MT evaluation metrics to obtain a more accurate evaluation metric .
For example , we can obtain a simple weighted model of SWSS and Meteor by tuning the weight ? below .
SW SS M eteor = M eteor + ? ? Score ( 3 ) 4 Experiments
Data SWSS is evaluated on WMT15 ( Stanojevi ?
et al. , 2015 ) and WMT16 metric task evaluation sets and is tuned on WMT17 metric task ( Bojar et al. , 2017 ) evaluation set .
The datasets are composed of pairs of system output sentences and reference sentences , and also corresponding human evaluation scores for the output sentences .
The evaluation set of WMT15 has 4 language pairs and each has 500 sentence pairs .
WMT16 dataset has 6 language pairs and WMT17 dataset has 7 language pairs , and each has 560 sentence pairs .
Performance of a metric is evaluated by Pearson correlation between scores provided by the metric and the human evaluation scores .
Settings
The parameters of SWSS are tuned on the dataset from WMT17 metric task and are listed in Table 2 .
We use SpaCy library 1 for word tokenization .
Word stems are extracted with Porter stemming algorithm ( Porter et al. , 1980 ) . UCCA representations are parsed with the pre-trained model of TUPA ( Hershcovich et al. , 2017 ) .
Results SWSS is combined with base models including BLEU , Meteor and Meteor ++. words is clearly a good and large-scale representation of copy words , according to the results .
We also conduct ablation study to figure out whether the penalties we have introduced are redundant or not .
The base model is the combination of SWSS and Meteor .
If we remove the representation penalties or the length penalty from the base model , it can be found out from Table 3 that the modified models have lower correlation than the complete model .
The result with p < 0.05 proves that these penalties have a positive effect on the mechanism .
Conclusion
In this paper , propose Semantically Weighted Sentence Similarity ( SWSS ) , which leverages the power of UCCA to identify semantic core words , and then calculates a similarity score for machine translation evaluation .
Inspired by copying mechanism used in sequence generation tasks , we argue that semantic core words , which carry important meaning in the sentence , should exist in all good translations .
Additionally , SWSS also uses penalties based on the differences between UCCA structures and sentence lengths , including the concept of Scene in UCCA , in order to make the output scores more accurate .
Experimental results show that SWSS can produce a higher correlation in MT evaluation when combined with lexical MT evaluation metrics such as BLEU and Meteor .
Figure 1 : 1 Figure 1 : An illustration of the process of SWSS .
