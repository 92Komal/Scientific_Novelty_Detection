title
Neural Machine Translation Using Extracted Context Based on Deep Analysis for the Japanese-English Newswire Task at WAT 2020
abstract
This paper describes the system of the NHK - NES team for the WAT 2020 Japanese - English newswire task .
There are two main problems in Japanese - English news translation : translation of dropped subjects and compatibility between equivalent translations and English news -style outputs .
We address these problems by extracting subjects from the context based on predicate - argument structures and using them as additional inputs , and constructing parallel Japanese - English news sentences equivalently translated from English news sentences .
The evaluation results confirm the effectiveness of our context-utilization method .
Introduction
The NHK and NHK -ES team ( NHK - NES ) participated in the Japanese - English newswire translation task at WAT 2020 ( Nakazawa et al. , 2020 ) .
Currently , there are two main problems in the machine translation of news from Japanese to English .
One problem is that , in Japanese , some subjects that can easily be guessed tend to be omitted , because of the context .
In contrast , in English , subjects are needed because grammatical rules do not allow them to be omitted .
These phenomena are caused by differences between the characteristics of the two languages .
The other problem is the compatibility between equivalent translations and English newsstyle outputs .
Parallel sentences extracted from Japanese news articles and English news articles are of low quality , in terms of bilingual equivalence , and contain substantial bilingual noise .
This is because producing an English news article from the content of a Japanese news article is not sentence - level translation .
Rather , it is news writing , in which the structure of the article may be changed because of differences between the structures of news in Japanese and English , and the content is often summarized and supplemented because of differences in the background knowledge of the target readers .
A neural machine translation ( NMT ) system trained on such data is supposed to output English sentences written in news style .
However , the input articles tend not to be translated equivalently because omissions frequently occur unintentionally .
At WAT 2019 , to realize equivalent translation , we constructed parallel sentence pairs - Japanese news sentences that were equivalently translated to English by translators - and used these pairs for training ( Mino et al. , 2019 ) .
We confirmed that this method improved the performance of translating input sentences equivalently and that it was effective in terms of adequacy .
However , the style of English produced by translators ( " translated English " ) was different from the style of English news ( " news English " ) .
The NMT system trained on these data output English sentences in the style of translated English , and the resulting outputs had low similarity ( BLEU score ) to the reference translations .
We aim to output text in the style of news English rather than translated English .
Therefore , our objective is to achieve both equivalent translation and output in the style of news English .
In this paper , we propose a method that analyzes the predicate - argument structures of the context of input sentences , extracts the topic in the context- based on the analyses - and uses it as the context of the input sentence to translate ( ? 2 ) .
We show the difference between the translated - English and news - English styles , and construct Japanese - English parallel news sentences that are equivalently translated from English news to Japanese , rather than from Japanese < delim > is used as the delimiter token .
news to English ( ? 3 ) .
We provide a brief overview of the WAT 2020 Japanese - English newswire task ( ? 4 ) and describe our system settings ( ? 5 ) .
We then present the evaluation results and confirm the effectiveness of the proposed method ( ? 6 ) .
2 Using Extracted Context Based on Predicate-Argument Structure
Some subjects that can easily be guessed tend to be omitted in Japanese .
In English , however , subjects cannot be omitted grammatically , except in the imperative form .
For this reason , it is necessary to insert the implicit subjects when translating from Japanese to English .
In news articles , the previous context often contains information that should be added .
Figure 1 shows an example of a Japanese news sentence with an omitted subject , and its context .
Implicit subjects of sentences can often be easily guessed from the context , especially from topics and subjects in the context .
Therefore , the preceding topics or subjects are thought to be useful as contextual information for translation .
An NMT method ( 2 - to - 1 ) uses context by concatenating the previous source sentence to the input sentence , with the insertion of a delimiter token ( Tiedemann and Scherrer , 2017 ) .
However , as shown in Figure 2 , a large amount of contextual information is input , and it is difficult to learn to identify and extract the necessary information by backpropagation from the target sentence .
1
There are methods of complementing subjects of input sentences for machine translation by inferring zero subjects and pre-editing the input sentences ( Taira et al. , 2012 ; Russo et al. , 2012 ; Kudo et al. , 2014 ; Wang et al. , 2016 ) .
However , these methods can also be problematic because pre-edit errors in the input sentences directly cause translation errors .
Subject complement is not easy and is not sufficiently accurate .
To alleviate the pre-edit error of input sentences , some methods have been proposed that use pre-edited source sentences as the targets of reconstruction ( Wang et al. , 2018a ( Wang et al. , , b , 2019 .
However , these methods cannot solve the problem because choosing an output that reproduces incorrect pre-edited inputs degrades the output quality .
Furthermore , in these methods , NMT - which is used to produce Nbest hypotheses - does not use context .
Therefore , NMT may not produce hypotheses that include appropriate contextual information .
We propose a method of extracting topics and subjects , which are sometimes useful as contextual information for translation , from context by analyzing syntactic and predicate - argument structure , and adding them to the input sentences as contextual information .
This avoids the difficulty - in learning to find and extract the necessary information from the context - that arises when NMT is trained by backpropagation .
NMT learns whether to utilize or ignore the extracted contextual information , and how to utilize it , using source and target language information .
Because the proposed method does not pre-edit input sentences , it avoids the problem that the errors of subject completion are directly reflected in the translation when input sentences are pre-edited .
The proposed method is described in detail below .
We use the following process to extract topics or subjects from context , up to the previous sentence , and add them as contextual information to the input sentence .
1 Extensions of the 2 - to - 1 method have also been proposed , in which the context used is increased or the neural network structure is changed ( Wang et al. , 2017 ; M?ller et al. , 2018 ; Kim et al. , 2019 ; Scherrer et al. , 2019 ; Maruf et al. , 2019 ; Li et al. , 2020 b ) .
However , from analysis of translation results , Kim et al . ( 2019 ) reported that 7.5 % of the cases in which the translation edit rate ( TER ) was improved could be interpreted as utilizing documentlevel context and the other cases were mostly general improvements in adequacy or fluency that were not related to the given context .
Li et al. ( 2020a ) reported that the context affected training as a noise generator .
1 . The context before the input sentence ( s ) is parsed , and the predicate - argument structure is analyzed .
2 . In each sentence of the context , the subject of the main clause is extracted .
If it is not extracted , the subject of the sub-clause that depends on the main clause with the parallel relation is extracted .
If it is still not extracted , the topic in the first bunsetsu 2 is extracted if the particle of the first bunsetsu is " ha " .
3 . The topics and subjects that are extracted from the context sentence nearest to the input sentence are added to the input as the context information with the delimiter token .
An example of the process is shown in Figure 3 .
The number of contextual sentences that can be used is not restricted .
If any topic or subject is not extracted from the sentence immediately preceding the input sentence , we use a topic or subject extracted from an earlier sentence .
For example , in the case that the sixth sentence of an article is an input sentence and any topic or subject is not extracted from the second to fifth sentences of the article , we use the topic or subject extracted from the first sentence .
2 Bunsetsu is a Japanese chunk unit .
3 Equivalent Japanese-English News Parallel Sentences Translated from English News
At WAT 2019 , we used 0.22 M pairs of Japanese news sentences and equivalently translated English sentences ( translated English ) ( Mino et al. , 2019 ) .
The evaluation confirmed that the translated sentences were highly adequate .
There were some differences in the characteristics ( style ) of the translated English and the English used in real news ( news English ) .
To examine the differences between the translated - English and news - English styles , we computed the test set perplexity of the two language models : one that was trained using translated - English sentences and one trained using news - English sentences .
We used the CMU - Cambridge Statistical Language Modeling Toolkit v2 3 with the settings of 4 - gram and Good- Turing discounting .
The models were trained with 6.0 M words of translated English and 7.3 M words of news English .
A test set comprising 48 K words of translated English and a test set comprising 57 K words of news English were used for the test .
The results are shown in Table 1 .
The test set perplexity ( 175.5 ) of the news - English test data was worse than that ( 131.7 ) of the translated - English test data for the model trained on the translated - English data .
Conversely , the test set perplexity ( 67.4 ) of the news - English test data was better than that ( 257.6 ) of the translated - English test data for the model trained on the news - English data .
This inversion of these test set perplexities demonstrates that there is a difference between the translated - English style and the news - English style .
To obtain translations in news - English style , we constructed equivalently translated parallel news sentences whose English style was news En- glish .
The construction method was that translators rewrote the Japanese news sentences to equivalently match the corresponding English news sentences in Japanese - English news articles , such articles contain substantial noise in the bilingual relationship .
We constructed the parallel news sentences using Jiji news ( provided by Jiji Press ) .
Our system used 98 K sentence pairs , constructed in this manner , for training .
This strategy made it possible to learn how to perform equivalent Japanese - English news translation in the news - English style .
Translation Task with Test Sentence Context
In this section , we provide a brief overview of the Japanese - English newswire translation task .
This task started at WAT 2017 .
Participants train the translation system on the training data and translate the test data .
They then submit their translations to the workshop and the workshop organizers evaluate the submitted translations .
At WAT 2020 , a new test set , which was extracted from Jiji news in Japanese and English , was added .
The new test set consists of test sentences , their reference sentences , and context data of the test sentences .
The context data are the articles from which the test sentences were extracted .
Participants can use the context data to translate test sentences .
The official dataset and their sizes are shown in Table 2 .
Training data other than that provided by the workshop can also be used for training .
System Setup
Data
The dataset used in the training are shown in Table 3 .
4 Here , all datasets , other than the official training data , are external resources .
As external resources , we used Jiji news in Japanese and English and Yomiuri news in Japanese and English .
The English Jiji news sentences and their equivalent Japanese translations are described in Section 3 .
Other external resources are described in .
We increased the number of Japanese Jiji news sentences and their equivalent English translations , compared with those in .
By inserting tags into the beginning of each source sentence , we controlled the equivalence and the English style in the output sentence .
The < equivalent > and < noise > tags correspond to the feature of the amount of bilingual noise , and the < news jiji > , < translation > , and < news yomiuri > tags correspond to the feature of English style .
The test sentences were tagged with " < equivalent > < news jiji > " to specify equivalent translations and to output text in news - English style .
Tokenization
We used the Moses tokenizer and de-tokenizer for English , and jumanpp - 2.0.0- rc3 5 for Japanese .
We used subword - nmt 6 for subwording by the bytepair-encoding method .
The vocabulary size was 32 K for the concatenation of the source and target training sentences .
We used knp - 4.20 7 for Japanese parsing and predicate - argument structure analysis .
NMT Configuration
We selected the Transformer model ( Vaswani et al. , 2017 ) for our NMT model , and used the sockeye - 1.18.106 toolkit 8 . We used the following settings : max-seq-len was 200 , weight - tying was trg softmax , label smoothing was 0.2 , beam-size was 30 , and four-ensemble used four models with different seeds .
For the other hyperparameters , we used the default parameters of the toolkit .
Context Utilization
For the training data , we applied the contextutilization method described in Section 2 to the source side of " Japanese Jiji news sentences and their equivalent English translations " and " English Jiji news sentences and their equivalent Japanese translations " in Table 3 .
For the test data , we applied the context-utilization method to the context data and added the extracted contextual information to the test sentences .
Results and Discussion
We submitted twe system outputs of the NMT system using context ( NMT with context ) and the NMT system not using context ( NMT without context ) .
Official results that were evaluated by the WAT 2020 organizers are shown in Table 4 .
For the JPO Adequacy evaluation , 200 sentences were evaluated by two human evaluators , based on the JPO Adequacy criterion .
In Table 4 , NMT official baseline represents the baseline system , prepared by the organizers , which was trained on the official data .
The BLEU scores and human scores of NMT without context were higher than those of NMT official baseline .
This improvement is mainly due to the contribution of our additional training data .
The BLEU scores and human scores of NMT with context were higher than those of NMT without context .
This demonstrates the effectiveness of the context-utilization method .
Next , for the 200 sentences officially assessed by human evaluators , we compared the results with and without the use of context .
For each out - put sentence , two adequacy scores were awarded by each of two evaluators .
We define win , loss , and tie by comparing the evaluators ' scores of NMT with context to those of NMT without context , as follows .
Win Both evaluators ' scores are better for NMT with context than for NMT without context , or one evaluator 's score is better and the other evaluator 's score is the same .
Loss Both evaluators ' scores are worse for NMT with context , or one evaluator 's score is worse and the other evaluator 's score is the same .
Tie Any combination other than the above .
Table 5 shows the results .
The number of wins was larger than that of losses .
We checked the 46 " win " results , and found complements from contexts for nine input sentences could be used to translate the corresponding input sentences .
For the other 37 input sentences , the complemented contexts were useless for translation .
However , these useless complemented contexts did not directly degrade the translation quality .
The number of remaining " win " ( 37 ) sentences was almost the same number of losses ( 36 ) .
We believe that , at this rate , the quality of the results depends not on the performance of the models , but on the variation of the model parameters .
Trump replied that he will have relevant officials discuss the matter .
Output ( NMTwithout context )
Trump replied that he will have related parties discuss the matter .
We evaluated the subject complement .
In Jiji news in Japanese , the subject tends to be omitted in the second sentence of each article .
Therefore , we examined the complements to the second sentences of each article .
We used 150 articles from the context of the test data .
Table 7 shows the results :
Subjects were omitted for 38 % of the sentences , whereas subjects were not omitted for the remaining 62 % of the sentences .
Of the 38 % of sentences whose subjects were omitted , 30.7 % of the subject complements were correct .
For comparison with the 2 - to - 1 method , we also conducted translation using that method .
The results are shown in Table 8 .
The BLEU score of 2 - to - 1 was higher than that of NMT without context , but lower than that of NMT with context .
The results confirmed that the proposed method was more effective in utilizing contextual information than the 2 - to - 1 method .
The submitted results are in news - English style .
We believe that this is not the optimal style for adequacy because there is more training data for equivalent translations in translated English than for equivalent translations in news English .
We added < equivalent > < translation > tags to the test sentences , instead of < equivalent > < news jiji > , to evaluate the output in the translated - English style .
We translated these test sentences using the NMT with context model .
NMT with context adequacy represents the outputs in the translated English style .
The results are shown in Tables 9 .
We submitted NMT with context adequacy to the WAT automatic evaluation server and published it .
The JPO adequacy in Table 9 was assessed by the same evaluators as the official evaluation , using the same criteria .
However , the conditions were not exactly the same as that of the official evaluation because the evaluation was conducted independently after the official evaluation .
Although the BLEU score of NMT with context adequacy was lower than that of NMT with context , the adequacy of NMT with context adequacy was higher than that of NMT with context .
From the results , we confirmed that adequacy was improved by translating to the translated - English style , compared to translating to the news - English style , using the current training data .
Conclusion
We described our method using context , the resources used for training , and the system setup for the Japanese - English newswire translation task at WAT 2020 .
We proposed the extraction of topics and subjects from context , based on deep analysis , and their use as the context of input sentences .
We also constructed a set of parallel Japanese - English news sentence pairs by equivalently translating English news sentences to Japanese sentences .
This resource enabled us to directly learn equivalent translation with the news - English style .
The evaluation results confirmed the effectiveness of our method .
Figure 1 : Figure 2 : 12 Figure
1 : Example of a news sentence with an omitted subject in Japanese .
