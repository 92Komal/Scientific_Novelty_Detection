title
Machine Translation of Spanish Personal and Possessive Pronouns Using Anaphora Probabilities
abstract
We implement a fully probabilistic model to combine the hypotheses of a Spanish anaphora resolution system with those of a Spanish - English machine translation system .
The probabilities over antecedents are converted into probabilities for the features of translated pronouns , and are integrated with phrase - based MT using an additional translation model for pronouns .
The system improves the translation of several Spanish personal and possessive pronouns into English , by solving translation divergencies such as ella ? she | it or su ? his | her | its | their .
On a test set with 2,286 pronouns , a baseline system correctly translates 1,055 of them , while ours improves this by 41 .
Moreover , with oracle antecedents , possessives are translated with an accuracy of 83 % .
Introduction
The divergencies of pronoun systems across languages require in many cases the understanding of the antecedent of a source pronoun to decide its correct translation .
For instance , Spanish 3rd person personal and possessive pronouns generally have more than one translation into English : ?l can be rendered by he or it depending on the humanness of the antecedent , while the possessive determiner su can be translated by his , her , its or their depending on the gender , number and humanness of the possessor .
In this paper , we provide a fully probabilistic integration of a Spanish anaphora resolution system into a phrase - based machine translation ( MT ) one , building upon a coreference - aware decoding model that we proposed earlier ( Luong and Popescu-Belis , 2016 ) .
We extend this model by using actual probabilities of antecedents instead of the best candidate only , and by applying the model to Spanish - English pronoun translation , which requires a larger range of antecedent features than English - French .
In addition , the test set is considerably larger than in the previous study , and includes possessive determiners ( also called adjectives or , as we do here , pronouns ) , which exhibit larger translation divergencies .
The paper is organized as follows .
After a review of related work ( Section 2 ) , we present in Section 3 the coreference - aware translation model , which is learned from texts with probabilistic anaphoric links hypothesized by a coreference resolution system .
This model is combined with a classic phrase - based MT model , as explained in Section 4 .
The results , presented in Section 5 , show an improvement in pronoun translation accuracy of 4 % when measured automatically , and reach 83 % correct translations with oracle antecedents of possessives .
Related Work Recent years have witnessed an increasing interest in improving machine translation of pronouns .
Several studies have attempted to integrate anaphora resolution with statistical MT ( Le Nagard and Koehn , 2010 ; Hardmeier and Federico , 2010 ; Guillou , 2012 ) , but have often been limited by the accuracy of anaphora resolutions systems , even on the best-resourced language , English .
For instance , Le Nagard and Koehn ( 2010 ) trained an English - French translation model on an annotated corpus in which each occurrence of the English pronouns it and they was annotated with the gender of its antecedent on the target side , but failed to improve over the baseline due to anaphora resolution errors .
Hardmeier and Federico ( 2010 ) in- tegrated a word dependency model into the SMT decoder as an additional feature , to keep track of pairs of source words acting respectively as antecedent and anaphor in a coreference link , and improved English - German MT over the baseline .
The recent shared tasks on pronoun-focused translation Guillou et al. , 2016 ) have promoted a pronoun correction task , which relies on information about the reference translation of the words surrounding the pronoun to be corrected , thus allowing automatic evaluation .
Several systems developed for this task avoid direct use of anaphora resolution , but still reach competitive performance .
Callin et al. ( 2015 ) designed a classifier based on a feed-forward neural network , which considered as features the preceding nouns and determiners along with their partsof-speech .
Stymne ( 2016 ) combined the local context surrounding the source and target pronouns ( lemmas and POS tags ) together with source -side dependency heads .
The winning systems of the WMT 2016 pronoun task used neural networks : Luotolahti et al. ( 2016 ) and Dabre et al . ( 2016 ) summarized the backward and forward local contexts and passed them to a deep Recurrent Neural Network to predict pronoun translation .
In this paper , we exploit anaphora resolution as the main knowledge source , building upon the model we have proposed earlier ( Luong and Popescu-Belis , 2016 ) , in which coreference features are directly used during the decoding process through an additional translation table .
However , we extend our previous model and use additional features , including the source word , and the gender , number and humanness of the antecedent candidates .
In addition , instead of training and testing an SMT system on the gender-marked datasets ( as did Le Nagard and Koehn ( 2010 ) ) , and use antecedents with absolute confidence , we model the probabilistic connection between a given pronoun and a given gender / number on the training set , and use the probabilistic scores of the antecedent within a coreference model , along with the translation and language models , when decoding .
We do not deal , however , with null pronouns , which raise different challenges , addressed e.g. by Wang et al . ( 2016 ) for Chinese- to - English MT and by Rios Gonzales and Tuggener ( 2017 ) for Spanishto-English MT .
Learning the Coreference Model
The coreference model is the essential component of the general framework we proposed earlier ( Luong and Popescu-Belis , 2016 ) .
The goal of the coreference model is to learn the probabilities of translating a given source pronoun , represented by the features of its antecedent , into a target pronoun .
Due to anaphora resolution errors and variability in translation , the coreference model is not deterministic , but contains probabilities of translations , which are later combined with those from the translation and language models .
We build a fully probabilistic coreference model , unlike our previous attempt , which relied only on the best candidate antecedent .
Building the model requires two stages , presented in 3.1 and 3.2 below .
The Spanish 3rd - person pronouns that we consider are : ( a ) the two singular subject pronouns ?l and ella ; ( b ) the two possessive determiners su and sus ; ( c ) the two singular possessive pronouns suyo and suya .
The possessive determiners agree in number with the possessed entity ( which they determine ) and refer to a possessor with unspecified gender and number , hence each of them can be translated by his , her , its or their .
The possessive pronouns refer both to a possessed entity ( with which they agree in gender and number ) and a possessor of unspecified gender and number .
Hence , they can be translated into English as his own ( one ) , her own , its own or their own - but not with plural , e.g. not his own ones .
Antecedent Identification using CorZu
The goal of the first stage is to identify candidate antecedents of each source pronoun in the training data with their probabilities .
The Spanish data is processed as follows .
More detailed descriptions of the annotations are given by Rios ( 2016 ) and Rios Gonzales and Tuggener ( 2017 ) who also make them public .
1 We use FreeLing 2 ( Padro and Stanilovsky , 2012 ) for morphological analysis and named entity recognition and classification , Wapiti 3 ( Lavergne et al. , 2010 ) for PoS tagging , and the MaltParser 4 ( Nivre et al. , 2006 ) for parsing .
The models for tagging , parsing and co-reference resolution are all trained on the AnCora-ES Spanish treebank ( Taul ?
et al. , 2008 ) . 5 The CorZu coreference resolution system ( Klenner and Tuggener , 2011 ; Tuggener , 2016 ) annotates the dependency trees with referential entities .
CorZu implements a variant of the entity -mention coreference model , and enforces morphological consistency in coreference chains .
For selecting antecedents of pronouns , CorZu uses a mention ranking approach : all antecedent candidates are considered at once , and each of them is given a score based on its features ( see Tuggener ( 2016 ) , Section 5.3.3 ) .
The features include standard ones ( distance , grammatical relations , etc. ) along with novel ones ( animacy , discourse status , morphology , etc. ) .
Their weights are learned using a Naive Bayes classifier .
Rather than selecting the candidate with the highest score as the antecedent , we retain a list of the most likely antecedents with their scores , namely all candidates with scores greater than 1 % of the highest one , keeping at least two of them ( if available ) .
For each candidate antecedent , we extract the following features ( obtained from FreeLing ) : gender ( masculine , feminine , or neuter ) , number ( singular or plural ) and human ( person vs. other ) .
The newly used ' human ' feature is intended to help with the English divergencies he / it , his / its , she / it and her / its .
Assignment of the Coreference Score
To build the coreference model , for each of the anaphoric links found by CorZu , we append to each Spanish pronoun ( noted P ) the feature values of the respective antecedent ( noted G , N , H ) .
Moreover , we consider the English side of the parallel corpus ( available with AnCora - ES ) , and using word- level alignments generated by GIZA ++ ( Och and Ney , 2003 ) we identify the translation of the Spanish pronoun .
This results in a set of weighted triples of the form ( P- G - N-H , pron EN , probability ) -e.g. , ( ella-femininesingular-person , she , 0.686453 ) - where probability results from the normalization of the current candidate score with respect to the total of the whole list .
We gather all possible triples over the training data .
If the candidates do not fully cover all possible P-G - N-H combinations , the remaining combinations will be generated , but with zero probability , and appended to the list in the coreference model .
Improving significantly on our previous study , we now compute the co-occurrence probability between each English pronoun ( p EN ) and a specific P-G - N-H combination by integrating probability scores from all triples in which they appear , with a normalization factor , as follows : P ( p EN | PGNH ) = score ( PGNH , p EN ) score ( PGNH )
If coreference resolution and word alignment were perfect , the resulting list would contain only trivial pairs , such as ( ella-feminine -singularperson , she , 1.0 ) , but this is far from being the case .
Indeed , even after filtering out triples with p < 10 ?5 , we are left with 13,584 triples in the coreference model .
The excerpt from the coreference model in Figure 1 shows other translation options for ellafeminine - singular-person : although there are several wrong triples as a consequence of alignment errors , they have small scores compared to that of the likely correct translation .
Using the Coreference Model for SMT
The Coreference Model ( CM ) is used within the Moses phrase - based SMT system ( Koehn et al. , 2007 ) as a second translation model , which will be called instead of the main model whenever the system encounters a Spanish pronoun that is marked as above with its G- N-H features ( hence in the form P - G - N - H ) .
We use the configuration declarations in the Moses environment ( Koehn et al. , 2007 ) , as we previously described ( Luong and Popescu-Belis , 2016 ) , to integrate the CM into the decoder as an additional translation model .
The weights of the CM are optimized on a held - out set , unlike our previous study ( Luong and Popescu-Belis , 2016 ) in which they were manually set .
Before decoding , we first perform anaphora resolution on the source document .
Then , the G -N- H features extracted from the best candidate antecedent are appended to the pronoun .
6
For instance , on the following example : " Mi hermana va a la escuela .
Su escuela est? detr ?s de la catedral . " , hermana ( sister ) is the antecedent of the possessive determiner su , and it is a singular , feminine and human noun .
Therefore , su in the second sentence is changed to : " Su-singular -femiminehuman escuela est ? detr ?s de la catedral . " and is given as an input to the MT system , which will use the CM to translate the first word .
Results and Analysis
Experimental Settings
The MT training set for Moses is a part of the News Commentary ( NC ) 2011 set from WMT , combined with part of NC 2010 , with a total of 250,000 ES - EN sentence pairs ( see Section 3.1 ) .
The parameters are tuned using MERT ( Och , 2003 ) on an NC 2011 development subset of 2,713 pairs .
Another subset of NC 2011 with 13,000 sentences is used for testing .
The language model is trained on an NC 2011 monolingual set with ca .
1.1 M sentences .
The test data contains 6,134 occurrences of the Spanish pronouns we study here , but CorZu found an antecedent only for 2,286 occurrences .
For all other pronouns , our method will not translate them differently from the baseline system , therefore we do not count them below .
We measure the Accuracy of Pronoun Translation ( APT ) by comparing the translated pronouns with those in the reference translation ( Miculicich Werlen and Popescu-Belis , 2016 ) .
The metric first aligns the pronouns in the MT output against a reference translation , using GIZA ++ ( Och and Ney , 2003 ) to align words and then a simple set of heuristics to refine the alignment of pronouns , based on position approximations and knowledge of expected tokens .
7
The APT software then com- putes several scores : the number of identical pronouns ( noted C1 ) and of different ones ( C3 ) , the number of untranslated pronouns in the candidate ( C4 ) , in the reference ( C5 ) or in both ( C6 ) .
8
The goal is to increase C1 and decrease all other scores .
APT was found to correlate well with human evaluation , but is stricter than it .
Results with CorZu Antecedents
The APT scores of the Moses baseline ( BL ) and our system ( CM ) are shown in Table 1 .
Our system outperforms the baseline by 41 pronouns ( net balance of improvements minus degradations ) , increasing the C1 score from 46 % to 48 % .
Besides , it leaves fewer pronouns untranslated ( C4 ) .
When examining the translation of the determiner su , the comparison of the first two confusion matrices in Table 2 shows that CM translates su more poorly than BL .
In particular , it misses many occurrences of su that should have been translated as its , rendering them generally by his .
This is likely due to the wrong labeling of the humanness feature on antecedents found by CorZu , in addition to anaphora resolution errors .
In contrast , the occurrences of su that should have been translated with human pronouns ( his , her ) are better translated by the CM .
Notably , despite its ambiguity , Example 1 SRC : no podr ?
sentirse en su-masc- sg- pers casa en ese pa?s CM : will not be able to be in his house in the country REF : he will scarcely be able to feel at home there Example 2 SRC : y si posible de la UE en su-masc- sg- other conjunto CM : if possible , and of the EU in its set REF : if not the EU as a whole su was often correctly linked by CorZu to a plural noun phrase , leading to a large improvement over the baseline for translations by their ( 220 vs. 148 ) .
One limitation of the CM system is exemplified in Figure 2 . Both mistakes ( in red ) are due to the CM not considering the context surrounding the pronoun su , i.e. the idiomatic expressions .
Indeed , " su casa " and " su conjunto " mean respectively " to feel at home " and " as a whole " as idiomatic expressions , yet they are wrongly translated into " to be in his house " and " in its set " by the coreference model , which simply uses the features assigned to su after the substitution .
Although the translations of su are correct in terms of features , the expressions should have been translated by the default translation model .
A different strategy to pass antecedent information to the decoder while still using the standard translation model should be found in the future .
Results Using Oracle Antecedents
To confirm the relevance of our model , and analyze the impact of coreference resolution errors , we selected a subset of 168 sentences with 64 occurrences of su .
A native Spanish speaker annotated the correct antecedents and the correspond -
C1 C3 C4 C5 C6 CM 31 ( 48 % ) 16 8 6 3 OR 53 ( 83 % ) 5 0 6 0 Table 3 : APT scores of CM and oracle systems .
C1 is the number of su identical to the reference .
Using oracle antecedents rather than CorZu ones significantly increases C1 .
ing gender-number -humanness features for each pronoun .
We then translated this data with our CM system , and compared it with the output of CM using CorZu antecedents , in Table 3 .
The accuracy when using oracle antecedents is 83 % , and among the 11 errors ( translations differing from the reference ) , 8 are in fact considered as correct by a human judge .
Oracle antecedents thus lead to nearly perfect translations , as confirmed by the confusion matrix , shown in the lower part of Table 2 .
Conclusion and Perspectives
We presented a method that uses the morphological and semantic features of antecedents to improve the translation of Spanish personal and possessive pronouns into English .
The method brings measurable improvements , and an oracle experiment indicates that better anaphora resolution should be even more beneficial to pronoun translation .
Future work should integrate coreference into the MT decoder as an additional feature function , so that the surrounding contexts of pronouns are properly considered .
In addition , we will attempt to improve the quality of the labels predicted by our resolver , we will use multiple hypotheses on antecedents when decoding , and finally consider the translation of null pronouns as well .
Figure 1 : 1 Figure 1 : Inside the coreference model : examples of ( P- G - N-H , pron EN , probability ) triples for the Spanish pronoun ella .
