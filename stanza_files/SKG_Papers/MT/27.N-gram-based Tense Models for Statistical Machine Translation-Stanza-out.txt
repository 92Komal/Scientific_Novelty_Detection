title
N- gram- based Tense Models for Statistical Machine Translation
abstract
Tense is a small element to a sentence , however , error tense can raise odd grammars and result in misunderstanding .
Recently , tense has drawn attention in many natural language processing applications .
However , most of current Statistical Machine Translation ( SMT ) systems mainly depend on translation model and language model .
They never consider and make full use of tense information .
In this paper , we propose n-gram - based tense models for SMT and successfully integrate them into a state - of - the - art phrase - based SMT system via two additional features .
Experimental results on the NIST Chinese - English translation task show that our proposed tense models are very effective , contributing performance improvement by 0.62 BLUE points over a strong baseline .
Introduction
For many NLP applications , such as event extraction and summarization , tense has been regarded as a key factor in providing temporal order .
However , tense information has been largely overlooked by current SMT research .
Consider the following example : SRC : ? ' B$ ?e?
( J , ? U ?N y3 oe ? , ? ? ?N ?I ? ? ? m ? ' X " REF :
The embargo is a result of the Cold War and does not reflect the present situation nor the partnership between China and the EU .
MOSES : the embargo is the result of the cold war , not reflect the present situation , it did not reflect the partnership with the european union .
Although the translated text produced by Moses 1 is understandable , it has very odd tense combination from the grammatical aspect , i.e. with tense inconsistency ( is / does in REF vs. is / did in Moses ) .
Obviously , slight modification , such as changing " is " into " was " , can much improve the readability of the translated text .
It is also interesting to note that such modification can much affect the evaluation .
If we change " did " to " does " , the BLEU - 4 score increases from 22.65 to 27.86 ( as matching the 4 - gram " does not reflect the " in REF ) .
However , if we change " is " to " was " , the BLEU score decreases from 22.65 to 21.44 .
The above example seems special .
To testify its impact on SMT in wider range , we design a special experiment based on the 2005 NIST MT data ( see section 6.1 ) .
This data has 4 references .
We choose one reference and modify its sentences with error tense 2 . After that , we use other 3 references to measure this reference .
The modified reference leads to a sharp drop in BLEU - 4 score , from 52.46 to 50.27 in all .
So it is not a random phenomenon that tense can affect translation results .
The key is how to detect tense errors and choose correct tenses during the translation procedure .
By carefully comparing the references with Moses output , we obtain the following useful observations , Observation ( 1 ) : to most simple sentences , coordinate verbs should be translated with the same tense while they have different tense in Moses output ; Observation ( 2 ) : to some compound sentences , 1 http://www.statmt.org/moses/
2
Such changes are small by mainly modifying one auxiliary verb for a sentence , such as " is ? was " , " has ? had " .
the subordinate clause should have the consistent tense with its main clause while Moses fails ; Observation ( 3 ) : the diversity of tense usage in a document is common .
However , in most cases , the neighbored sentences tends to share the same main tense .
In some extreme examples , one tense ( past or present ) , even dominates the whole document .
One possible solution to model above observations is using rules .
Dorr ( 2002 ) refers to six basic English tense structures and defines the possible paired combinations of " present , past , future " .
But the practical cases are very complicated , especially in news domain .
There are a lot of complicated sentences in news articles .
Our preliminary investigation shows that such six paired combinations can only cover limited real cases in Chinese -English SMT .
This paper proposes a simple yet effective method to model above observations .
For each target sentence in the training corpus , we first parse it and extract its tense sequence .
Then , a target - side tense n-gram model is constructed .
Such model can be used to estimate the rationality of tense combination in a sentence and thus supervise SMT to reduce tense inconsistency errors against Observations ( 1 ) and ( 2 ) in the sentence - level .
In comparison , Observation ( 3 ) actually reflects the tense distributions among one document .
After extracting each main tense for each sentence , we build another tense ngram model in the document-level .
For clarity , this paper denotes document- level tense as " inter-tense " and sentence - level tense as " intra-tense " .
After that , we propose to integrate such tense models into SMT systems in a dynamic way .
It is well known there are many errors in the current MT output ( David et al. , 2006 ) .
Unlike previously making trouble with reference texts , the BLEU - 4 score cannot be influenced obviously by modifying a small part of abnormal sentences in a static way .
In our system , both inter-tense and intra-tense model are integrated into a SMT system via additional features and thus can supervise the decoding procedure .
During decoding , once some words with correct tense can be determined , with the help of language model and other related features , the small component -" tense " - can affect surrounding words and improve the performance of the whole sentence .
Our experimental results ( see the examples in Sec-tion 6.4 ) show the effectiveness of this way .
Rather than the rule- based model , our models are fully statistical - based .
So they can be easily scaled up and integrated into either phrase - based or syntaxbased SMT systems .
In this paper , we employ a strong phrase - based SMT baseline system , as proposed in Gong et al . ( 2011 ) , which uses document as translation unit , for better incorporating documentlevel information .
The rest of this paper is organized as follows : Section 2 reviews the related work .
Section 3 and 4 are related to tense models .
Section 3 describes the preprocessing work for building tense models .
Section 4 presents how to build target - side tense models and discuss their characteristics .
Section 5 shows our way of integrating such tense models into a SMT system .
Session 6 gives the experimental results .
Finally , we conclude this paper in Section 7 .
Related Work
In this section , we focus on related work on integrating the tense information into SMT .
Since both interand intra-tense models need to analyze and extract tense information , we also give a brief overview on tense prediction ( or tagging ) .
Tense Prediction
The tense prediction task often needs to build a model based on a large corpus annotated with temporal relations and thus its focus is on how to recognize , interpret and normalize time expressions .
As a representative , Lapata and Lascarides ( 2006 ) proposed a simple yet effective data-intensive approach .
In particular , they trained models on main and subordinate clauses connected with some special temporal marker words , such as " after " and " before " , and employed them in temporal inference .
Another typical task is cross-lingual tense predication .
Some languages , such as English , are inflectional , whose verbs can express tense via certain stems or suffix , while others , such as Chinese often lack inflectional forms .
Take Chinese to English translation as example , if Chinese text contains particle word " ( Le ) " , the nearest Chinese verb prefers to be translated into English verb with the past tense .
Ye and Zhang ( 2005 ) , Ye et al. ( 2007 ) and Liu et al . ( 2011 ) focus on labeling the tenses for keywords in source-side language .
Ye and Zhang ( 2005 ) first built a small amount of manually - labeled data , which provide the tense mapping from Chinese text to English text .
Then , they trained a CRF - based tense classifier to label tense on Chinese documents .
Ye et al. ( 2007 ) further reported that syntactic features contribute most to the marking of aspectual information .
Liu et al. ( 2011 ) proposed a parallel mapping method to automatically generate annotated data .
In particular , they used English verbs to label tense information for Chinese verbs via a parallel Chinese - English corpus .
It is reasonable to label such source -side verb to supervise the translation process since the tense of English sentence is often determined by verbs .
The problem is that due to the diversity of English verb inflection , it is difficult to map such Chinese tense information into the English text .
To our best knowledge , although above works attempt to serve for SMT , all of them fail to address how to integrate them into a SMT system .
Machine Translation with Tense Dorr ( 1992 ) described a two -level knowledge representation model based on Lexical Conceptual Structures ( LCS ) for machine translation which integrates the aspectual information and the lexical -semantic information .
Her system is based on an inter-lingual model and does not belong to a SMT system .
Olsen et al. ( 2001 ) relied on LCS to generate appropriately - tensed English translations for Chinese .
In particular , they addressed tense reconstruction on a binary taxonomy ( present and past ) for Chinese text and reported that incorporating lexical aspect features of telicity can obtain a 20 % to 35 % boost in accuracy on tense realization .
Ye et al. ( 2006 ) showed that incorporating latent features into tense classifiers can boost the performance .
They reported the tense resolution results based on the best-ranked translation text produced by a SMT system .
However , they did not report the variation of translation performance after introducing tense information .
Preprocessing for Tense Modeling
In this paper , tense modeling is done on the targetside language .
Since our experiments are done on Chinese to English SMT , our tense models are learned only from the English text .
In the literature , the taxonomy of English tenses typically includes three basic tenses ( i.e. present , past and future ) plus their combination with the progressive and perfective aspects .
Here , we consider four basic tenses : present , past , future and UNK ( unknown ) and ignore the aspectual information .
Furthermore , we assume that one sentence has only one main tense but maybe has many subordinate tenses .
This section describes the preprocessing work of building tense models , which mainly involves how to extract tense sequence via tense verbs .
et al. ( 2006 ) used syntactic parse trees to find clauses connected with special aspect markers and collected them to train some special classifiers for temporal inference .
Inspired by their work , we use the Stanford parser 3 to parse tense sequence for each sentence .
Tense Verbs
Lapata
Take the following three typical sentences as examples , ( a ) is a simple sentence which contains two coordinate verbs , while ( b ) and ( c ) are compound sentences and ( b ) contains a quoted text .
( a) Japan 's constitution renounces the right to go to war and prohibits the nation from having military forces except for selfdefense .
( b) " We also hope Hong Kong will not be affected by diseases like the severe acute respiratory syndrome again ! " , added Ms. Yang . ( c ) Cheng said he felt at home in Hong Kong and he sincerely wished Hong Kong more peaceful and more prosperous .
Figure 1 shows the parse tree with Penn Treebank style for each sentence , which has strict level structures and POS tags for all the terminal words .
Here , the level structures mainly contribute to extract main tense for each sentence ( to be described in Section 3.2 ) and POS tags are utilized to detect tense verbs , i.e. verbs with tense information .
Normally , POS tags in the parse tree can distinguish five different forms of verbs : the base form ( tagged as VB ) , and forms with overt endings D for past tense , G for present participle , N for past participle , and Z for third person singular present .
It is worth noting that VB , VBG and VBN cannot determine the specific tenses by themselves .
In addition , the verbs with POS tag " MD " need to be specially considered to distinguish future tense from other tenses .
Algorithm 1 illustrates how to determine what tense a node has .
If the return value is not " UNK " , the node belongs to a tense verb .
Algorithm 1 Determine the tense of a node .
Input : The TreeNode of one parse tree , leaf node ; Output :
The tense , tense ; 1 : tense = " U N K 2 : Obtaining the POS tag lpostag from leaf node ; 3 : Obtaining the word lword from leaf node ; 4 : if ( lpostag in [ " V BP , " V BZ ] ) then 5 : tense = " present 6 : else if ( lpostag == " V BD ] ) then 7 : tense = " past 8 : else if ( lpostag == " M D ] ) then 9 : if ( lword in [ " will , " ll , " shall ] ) then end if 16 : end if 17 : return tense ;
Tense Extraction Based on Tense Verbs
As described in Section 1 , the inter-tense ( document- level ) refers to the main tense of one sentence and the intra-tense ( sentence - level ) corresponds to all tense sequence of one sentence .
This section introduces how to recognize the main tense and extract all useful tense sequence for each sentence .
The idea of determining the main tense is to find the tense verb located in the top level of a parse tree .
According to the Penn Treebank style , the method to determine the main tense can be described as follows : ( 1 ) Traverse the parse tree top-down until a tree node containing more than one child is identified , denoted as S m .
( 2 ) Consider each child of S m with tag " VP " , recursively traverse such " VP " node to find a tense verb .
If found , use it as the main tense and return the tense ; if not , go to step ( 3 ) .
( 3 ) Consider each child of S m with tag " S " , which actually corresponds to subordinate clause of this sentence .
Starting from the first subordinate clause , apply the similar policy of step ( 2 ) to find the tense verb .
If not found , search remaining subordinate clauses .
( 4 ) If no tense verb found , return " UNK " as the main tense .
Here , " VP " nodes dominated by S m directly are preferred over those located in subordinate clauses .
This is to ensure that the main tense is decided by the top-level tense verb .
Take Figure 1 as an example , the main tense of sentence ( a ) and ( b ) can be determined only by step ( 2 ) .
The tense verb of " ( VBZ renounces ) " dominated in the " VP " tag determines that ( a ) is in present tense .
Similarly the node " ( VBD added ) " indicates that ( b ) is in past tense .
Sentence ( c ) needs to be further treated by step ( 3 ) since there is no " VP " nodes dominated by S m directly .
The node " ( VBD said ) " located in the first subordinate clause shows its main tense is " past " .
The next task is to extract the tense sequence for each sentence .
They are determined by all tense verbs in this sentence according to the strict topdown order .
For example , the tense sequence of sentence ( a ) , ( b ) and ( c ) are { present , present} , { present , future , past } and { past , past , past} .
In order to explore whether the main tense of intra-tense model has an impact on SMT or not , we introduce a special marker " * " to denote the main tense .
So the tense sequence marked with main tense of ( a ) , ( b ) and ( c ) are { present * , present} , { present , future , past * } and { past * , past , past} .
It is worth noting , the intra-tense model ( see Section 4 ) based on the latter tense sequence is different to the former .
N-gram- based Tense Models
Tense N-gram Estimation
After applying the previous method to extract tense for an English text corpus , we can obtain a big tense corpus .
Given the current tense is indexed as t i , we call the previous n ?
1 tenses plus the current tense as tense n-gram .
Based on the tense corpus , tense n-gram statistics can be done according to the Formula 1 . P ( t i |t ( i?( n? 1 ) ) , ... , t ( i?1 ) ) = count ( t ( i?( n? 1 ) ) , . . . , t ( i?1 ) , t i ) count ( t ( i?( n? 1 ) ) , ... , t ( i?1 ) ) ( 1 ) Here , the function of " count " return the tense n-gram frequency .
In order to avoid doing specific smoothing work , we estimate tense n-gram probability using SRI language modeling ( SRILM ) tool ( Stolcke , 2002 ) .
To compute the probability of intra-tense n-gram , we first extract all tense sequence for each sentence and put them into a new file .
Based on this new file , we can get the intra-tense n-gram model via SRILM tool .
To compute the probability of inter-tense n-gram , we need to extract the main tense for each sentence at first .
Then , for each document , we re-organized the main tenses of all sentences into a special line .
After putting all these special lines into a new file , we can use SRILM to obtain the inter-tense n-gram model .
Characteristic of Tense N-gram Models
We construct n-gram- based tense models on English Gigaword corpus ( LDC2003T05 ) .
This corpus is used to build language model for most SMT systems .
It includes 30221 documents ( we remove such files : file size is less than 1 K or the number of continuous " UNK " tenses is greater than 5 ) .
Figure 2 shows the unigram and bigram probabilities ( Log10 -style ) for intra-tense and inter-tense .
The part ( a ) and ( c ) in Figure 2 refer to unigram .
The horizontal axis indicts tense type , and the vertical axis shows its probabilities .
The parts ( a ) and ( c ) also indicate " present " and " past " are two main tense types in news domain .
The part ( b ) and ( d ) refer to bigram .
The horizontal axis indicts history tense .
Each different colorful bar indicts one current tense .
The vertical axis shows the transfer possibilities from a history tense to a current tense .
The part ( b ) 4 reflects transfer possibilities of tense types in one sentence .
It also slightly reflects some linguistic information .
For example , in one sentence , the probability of co-occurrence of " present ? present " , " past ? past " and " future ? present " is more than other combinations , which can be against tense inconsistency errors described in Observation ( 1 ) and ( 2 ) ( see Section 1 ) .
However , it seems strange that " present ? past " exceeds " present ? future " .
We checked our corpus and found a lot of sentences like this -" the bill has been . . . , he said . " .
The part ( d ) shows tense type can be switched between two neighbored sentences .
However , it shows the strong tendency to use the same tense type for
Integrating N-gram- based Tense Models into SMT
In this section , we discuss how to integrate the previous tense models into a SMT system .
Basic phrase - based SMT system
It is well known that the translation process of SMT can be modeled as obtaining the best translation e of the source sentence f by maximizing following posterior probability ( Brown et al. , 1993 ) : e best = where P ( e|f ) is a translation model and P lm is a language model .
Our baseline is a modified Moses , which follows Koehn et al . ( 2003 ) and adopts similar six groups of features .
Besides , the log-linear model ( Och and Ney , 2000 ) is employed to linearly interpolate these features for obtaining the best translation according to the formula 3 : e best = arg max e M m=1 ? m h m ( e , f ) ( 3 ) where h m ( e , f ) is a feature function , and ?
m is the weight of h m ( e , f ) optimized by a discriminative training method on a held - out development data ( Och , 2003 ) .
The Workflow of Our System
Our system works as follows :
When a hypothesis has covered all source-side words during the decoding procedure , the decoder first obtains tense sequence for such hypothesis and computes intra-tense feature F s ( see Section 5.3 ) .
At the same time , it recognizes the main tense of this hypothesis and associate the main tense of previous sentence to compute inter-tense feature F m ( see Section 5.3 ) .
Next , the decoder uses such two additional feature values to re-score this hypothesis automatically and choose one hypothesis with highest score as the final translation .
After translating one sentence , the decoder caches its main tense and pass it to the next sentence .
When one document has been processed , the decoder cleans this cache .
In order to successfully implement above workflow , we should firstly design some related features , then resolve another key problem of determining tense ( especially main tense ) for SMT output .
They are described in Section 5.3 and 5.4 respectively .
Two Additional Features
Although the previous tense models show strong tendency to use the consistent tenses for one sentence or one document , other tense combinations also can be permitted .
So we should use such models in a soft and dynamic way .
We design two features : inter-tense feature and intra-tense feature .
And the weight of each feature is tuned by the MERT script in Moses packages .
Given main tense sequence of one document t 1 , . . . , t m , the inter-tense feature F m is calculated according to the following formula : F m = m i=2 P ( t i |t i ? ( n?1 ) , . . . , t ( i?1 ) ) ( 4 ) The P ( ? ) of formula 4 can be estimated by the formula 1 .
It is worth noting the first sentence of one document often scares tense information since it corresponds to the title at most cases .
To the first sentence , the P ( ? ) value is set to 1 4 ( 4 tense types ) .
Given tense sequence of one sentence s 1 , . . . , s e ( e > 1 ) , the intra-tense feature F s is calculated as follows : ( 5 ) F s = e?1
Here the square- root operator is used to avoid punishing translations with long tense sequence .
It is worth noting if the sentence only contains one tense , the P ( ? ) value of formula 5 is also set to 1 4 .
Since the average length of intra-tense sequence is about 2.5 , we mainly consider intra-tense bigram model and thus n equals to 2 .
5
Determining Tense For SMT Output
The current SMT systems often produce odd translations partly because of abnormal word ordering and uncompleted text etc .
For these abnormal translated texts , the syntactic parser cannot work well in our initial experiments , so the previous method to parse main tense and tense sequence of regular texts cannot be applied here too .
Fortunately , the solely utilization of Stanford POS tagger for our SMT output is not bad although it has the same issues described in Och et al . ( 2002 ) .
The reason may be that phrase - based SMT contains short contexts that POS tagger can utilize while the syntax parser fails .
Once obtaining a completed hypothesis , the decoder will pass it to the Stanford POS tagger and according to tense verbs to get all tense sequence for this hypothesis .
However , since the POS tagger can not return the information about level structures , the decoder cannot recognize the main tense from such tense sequence .
Liu et al. ( 2011 ) once used target - side verbs to label tense of source-side verbs .
It is natural to consider whether Chinese verbs can provide similar clues in an opposite direction .
Since Chinese verbs have good correlation with English verbs ( described in section 6.2 ) , we obtain Figure 3 : trees for parallel sentences main tense for SMT output according to such tense verb , which corresponds to the " VV " ( Chinese POS labels are different to English ones , " VV " refers to Chinese verb ) node in the top level of the source -side parse tree .
Take Figure 3 as an example , the English node " ( VBD announced ) " is a tense verb which can tell the main tense for this English sentence .
The Chinese verb " ( VV ? ? ) " in the top-level of the Chinese parse tree is just the corresponding part for this English verb .
So , before translating one sentence , the decoder first parses it and records the location of one Chinese " VV " node which located in the top-level , denotes this location as S area .
Once a completed hypothesis is generated , according to the phrase alignment information , the decoder can map S area into the English location T area and obtain the main tense according to the POS tags in T area .
If T area does not contain tense verb , such as the verb POS tags in the list of { VB , VBN , VBG } , which cannot tell tense type by themselves , our system permits to find main tense in the left / right 3 words neighbored to T area .
And the proportion that the top-level verb of Chinese has a verb correspondence in English can reach to 83 % in this way .
Experimentation
Experimental Setting for SMT
In our experiment , SRI language modeling toolkit was used to train a 5 - Gram general language model on the Xinhua portion of the Gigaword corpus .
Word alignment was performed on the training parallel corpus using GIZA ++ ( Och and Ney , 2000 ) in two directions .
For evaluation , the NIST BLEU script ( version 13 ) with the default setting is used to calculate the BLEU score ( Papineni et al. , 2002 ) , which measures case-insensitive matching of 4 - grams .
To see whether an improvement is statistically significant , we also conduct significance tests using the paired bootstrap approach ( Koehn , 2004 ) .
In this paper , " ** * " and " * * " denote p-values equal to 0.05 , and bigger than 0.05 , which mean significantly better , moderately better respectively .
1 shows the statistics of these data sets ( with document boundaries annotated ) .
The Correlation of Chinese Verbs and English Verbs
In this section , an additional experiment is designed to show English Verbs have close correspondence with Chinese Verbs .
We use the Stanford POS tagger to tag the Chinese and English sentences in our training corpus respectively at first .
Then we utilize Giza ++ to build alignment for these special Word - POS pairs .
According to the alignment results , we find the corresponding relation for some special POS tags in two languages .
The " Number " column of Table 2 shows the numbers of Chinese words with " VV " tag corresponding to English words with different verb POS tags .
We found Chinese verbs have more than 77 % possibilities to align to English verbs in total .
However , our method will fail when some special Chinese sentences only contain noun predicates .
Experimental Results
All the experiment results are showed on the table 3 . Our Baseline is a modified Moses .
The major modification is input and output module in order to translate using document as unit .
The performance of our baseline exceeds the baseline reported by Gong et al . ( 2011 ) Table 3 : The performance of using different feature combinations
The system denoted as " Baseline + F m " integrates the inter-tense feature .
The performance boosts 0.57 ( *** ) in BLEU score .
The system denoted as " Baseline + F s " integrates the intra-tense feature into the baseline .
The improvement is less than the inter-tense model , only 0.31 ( ** ) .
It seems the tenses in one sentence has more flexible formats than the document- level ones .
It is worth noting , this method can gain higher performance on the develop data than the one of " Baseline + F m " while fail to improve the test data .
Maybe the related weight is tuned over-fit .
The system denoted as " Baseline + F s ( * ) " is slightly different from " Baseline + F s " .
This experiment is to check whether the main tense has an impact on intra-tense model or not ( see Section 3.2 ) .
Here , the intra-tense model based on the tense sequence with main tense marker is slightly different to the model showed in Figure 2 .
The results are slightly better than the previous system by 0.13 .
Finally , we use the two features together ( Baseline + F m + F s ) .
The best way improved the performance by 0.62 ( *** ) in BLEU score over our baseline .
Discussion
Table 4 shows special examples whose intra-tenses are changed in our proposed system .
The example 1 and 2 show such modification can improve the BLEU score but the example 3 obtains negative impact .
From these examples , we can see not only tense verbs have changed but also their surrounding words have subtle variation .
No. BLEU Translation sentence 1 8.64
Baseline : the gulf countries , the bahraini royal family members by the military career of part of the banned to their marriage stories like children , have become the theme of television films .
19.71
Ours : the gulf country is a member of the bahraini royal family , a risk by military career risks part of the banned to their marriage like children , has become a story of the television and film industry . 2 17.16
Baseline : economists said that the sharp appreciation of the euro , in the recent investigation continues to have an impact on economic confidence , it is estimated that the economy is expected to rebound to pick up .
24.25
Ours : economists said that the sharp appreciation of the euro , in the recent investigation continued to have an impact on economic confidence and therefore no reason to predict the economy expected to pick up a rebound .
3 73.03
Baseline : the middle east news agency said that , after the concerns of all parties concerned in the middle east peace process , israel and palestine , egypt , the united states , russia and several european countries will hold a meeting in washington . 72.95
Ours : the middle east news agency said that after the concerns of all parties in the middle east peace process , israel and palestine , egypt , the united states , russia and several european countries held a meeting in washington .
Table 4 : Examples with tense variation using intra-tense model
From the results showed on Table 3 , the document - level tense model seems more effective than the sentence - level one .
We manually choose and analyzed 5 documents with significant improvement in the test data .
The part ( a ) of Figure 4 shows the main tense distributions of one reference .
The main tense distributions for the baseline and our proposed system are showed in the part ( b ) and ( c ) respectively .
These documents have different numbers of sentences but all less than 10 .
The vertical axis indicates different tense : 1 to " past " , 2 to " present " , 3 to " future " and 4 to " UNK " .
It is obvious that our system has closer distributions to the ones of this reference .
The examples in Table 5 indicate the joint impact of inter-tense and intra-tense model on SMT .
Sen-Src : 1 ) ? ? K ? ?^? ? ? , | AE ? " ? ; ? ? " 2 ) nVd " ) ? | "
+E Cnd ? ?O c ? ?W ? ?|? , ? ?L o c 5 ? ? ? g ON nV d " - ? + <? ?\ ? ! ? ; " Ref : 1 ) Israeli settlers blockaded a major road to protest a mortar attack on the settlement area .
2 ) PLO leader Abbas had also been allowed to go to the West Bank town of Bethlehem , which is the first time in the past four years Israeli authorities have allowed a senior Palestinian leader to attend Christmas celebrations .
Baseline : 1 ) israel has imposed a main road to protest by mortars attack .
2 ) the palestinian leader also visited the west bank cities and towns to bethlehem , which in the past four years , the israeli authorities allowed the palestinian leading figures attended the ceremony .
Ours : 1 ) israel has imposed a main road to protest against the mortars attack .
2 ) leader of the palestinian liberation organization have also been allowed to go to the west bank towns , bethlehem in the past four years . this is the first time the israeli authorities allow palestinian leading figures attended the ceremony .
Table 5 : the joint impact of inter-tense and intra-tense models on SMT tence 1 ) and 2 ) are two neighbored sentences in one document .
Both the reference and our output tend to use the same main tense type , but the former is in " past " tense and the latter is in " present " tense .
The baseline cannot show such tendency .
Although our main tense is different to the reference one , the consistent tenses in document level bring better translation results than the baseline .
And the tenses in sentence level also show better consistency than the baseline .
Conclusion
This paper explores document- level SMT from the tense perspective .
In particular , we focus on how to build document- level and sentence - level tense models and how to integrate such models into a popular SMT system .
Compared with the inter-tense model which greatly improves the performance of SMT , the intra-tense model needs to be further explored .
The reasons are many folds , e.g. the failure to exclude quoted texts when modeling intra-tense , since tenses in quoted texts behave much diversely from normal texts .
In the future work , we will focus on modeling intratense variation according to specific sentence types and using more features to improve it .
Figure 1 : 1 Figure 1 : The Stanford parse trees with Penn Treebank style
