title
Touch Editing : A Flexible One-Time Interaction Approach for Translation
abstract
We propose a touch - based editing method for translation , which is more flexible than traditional keyboard - mouse - based translation postediting .
This approach relies on touch actions that users perform to indicate translation errors .
We present a dual-encoder model to handle the actions and generate refined translations .
To mimic the user feedback , we adopt the TER algorithm comparing between draft translations and references to automatically extract the simulated actions for training data construction .
Experiments on translation datasets with simulated editing actions show that our method significantly improves original translation of Transformer ( up to 25.31 BLEU ) and outperforms existing interactive translation methods ( up to 16.64 BLEU ) .
We also conduct experiments on post-editing dataset to further prove the robustness and effectiveness of our method .
Introduction Neural machine translation ( NMT ) has made great success during the past few years ( Sutskever et al. , 2014 ; Bahdanau et al. , 2014 ; Wu et al. , 2016 ; Vaswani et al. , 2017 ) , but automatic machine translation is still far from perfect and cannot meet the strict requirements of users in real applications ( Petrushkov et al. , 2018 ) .
Many notable humanmachine interaction approaches have been proposed for allowing professional translators to improve machine translation results ( Wuebker et al. , 2016 ; Knowles and Koehn , 2016 ; Hokamp and Liu , 2017 ) .
As an instance of such approaches , post-editing directly requires translators to modify outputs from machine translation ( Simard et al. , 2007 ) .
However , traditional post-editing requires intensive keyboard interaction , which is inconvenient on mobile devices .
Grangier and Auli ( 2018 ) suggest a one-time interaction approach with lightweight editing ef-forts , QuickEdit , in which users are asked to simply mark incorrect words in a translation hypothesis for one time in the hope that the system will change them .
QuickEdit delivers appealing improvements on draft hypotheses while maintaining the flexibility of human-machine interaction .
Unfortunately , only marking incorrect words is far from adequate : for example , it does not indicate the missing information beyond the original hypothesis , which is a typical issue called under-translation in machine translation ( Tu et al. , 2016 ) .
In this paper , we propose a novel one-time interaction method called Touch Editing , which is flexible for users and more adequate for a system to generate better translations .
Inspired by human editing process , the proposed method relies on a series of touch - based actions including SUBSTITU - TION , DELETION , INSERTION and REORDERING .
These actions do not include lexical information and thus can be flexibly provided by users through various of gestures on touch screen devices .
By using these actions , our method is able to capture the editing intention from users to generate better translations : for instance , INSERTION indicates a word is missing at a particular position , and our method is expected to insert the correct word .
To this end , we present a neural network model by augmenting Transformer ( Vaswani et al. , 2017 ) with an extra encoder for a hypothesis and its actions .
Since it is impractical to manually annotate large-scale action dataset to train the model , we thereby adopt the algorithm of TER ( Snover et al. , 2006 ) to automatically extract actions from a draft hypothesis and its reference .
To evaluate our method , we conduct simulated experiments on translation datasets the same as in other works ( Denkowski et al. , 2014 ; Grangier and Auli , 2018 ) ,
The results demonstrate that our method can address the well - known challenging issues in machine translation including over - 2 QuickEdit Hypothesis y' travel far does not necessary to proctor for food supply .
Result travel far does not require to proctor food supplies .
Source x weite wege m?sse proctor f?r die nahrungsmittelbeschaffung nicht gehen .
Reference y proctor does not have to travel far to buy food .
Touch Editing Hypothesis y' travel far does not necessary to proctor for food supply .
Modified ?( y ' ) proctor does not necessary to travel far for < INS > food supply .
2 Touch Editing Approach
Actions QuickEdit allows translators to mark incorrect words which they expect the system to change ( Grangier and Auli , 2018 ) .
However , as shown in Figure 1 , the information is inadequate for a system to correct a translation hypothesis , especially when it comes to under-translation , in which the system is hardly to predict missing words into hypotheses .
To achieve better adequacy , we take human editing habits into consideration .
As shown in Figure 1 , a human translator may insert , delete , substitute or reorder some words to correct errors of undertranslation , over-translation , mis-translation and mis-ordering in an original translation hypothesis .
Based on human editing process , we define a set of actions to represent human editing intentions : ? INSERTION : a new word should be inserted into a given position .
? DELETION : a word at a specific position should be deleted .
? SUBSTITUTION : a word should be substituted by another word .
? REORDERING : a segment of words should be moved to another position .
In Touch Editing , these actions can be performed by human translators on a given machine hypothesis to indicate translation errors .
To keep the flexibility of interactions , for SUBSTITUTION and INSERTION actions , our method allows users to only indicate which word should be substitute or in which position a word should be inserted .
The light- weight interaction in Touch Editing is nonlexical , i.e. , it does not require any keyboard inputs , and thus can be adopted to mobile devices with touch screens .
Model
Our model seeks to correct translation errors of an original hypothesis y based on actions A provided by human translator .
To make full use of the actions , we firstly modify the original hypothesis by applying A on y to obtain A(y ) : A(y ) = m(y ) , a .
( 1 ) Specifically , as shown in Figure 1 , m(y ) is modified from y by reordering the segment in gray color and inserting a token INS , and thus the REORDERING actions is implicitly included in We then use a neural network model to generate a translation y for the source sentence x , the hypothesis y and the actions A : P (y | x , y , A ; ? ) = N n=1 P ( yn|y<n , x , m(y ) , a ; ? ) . ( 2 ) As shown in Figure 2 , the neural network model we developed is a dual encoder model based on Transformer similar to Tebbifakhr et al . ( 2018 ) .
Specifically , besides encoding the source sentence x with source encoder ( the left part of Figure 2 ) , our model additionally encodes A(y ) with an extra hypothesis encoder ( the right part of Figure 2 ) and integrates the encoded representations into decoding network using dual multi-head attention .
Encoding A(y )
As shown in the right part of Figure 2 , the hypothesis encoder firstly embeds m(y ) with length l in distributed space using the same word embedding as in decoder , which is de - noted as w = {w 1 , ? ? ? , w l }.
Then it encodes a = { a 1 , ? ? ? , a l } with learned positional embedding according to the specific actions .
As shown in Figure 3 , the action positional embedding includes four embedding matrixes corresponding to three action types and a none action for positions without any action .
For the ith position of a , the encoder chooses an embedding matrix based on the action type of a i and selects the ith row of the matrix as the positional embedding vector , which is denoted as p i : p i = ? ? ? ? ? ? ? P E INSERTION ( i ) if a i = I P E DELETION ( i ) if a i = D P E SUBSTITUTION ( i ) if a i = S P E None ( i ) if a i = - ( 3 )
Where P E * denote the action positional embedding matrixes in Figure 3 .
The learned action positional embedding is used in hypothesis encoder to replace the fixed sinusoids positional encoding in Transformer encoder .
Next , the encoder adds the word embedding w and the action positional embedding p to obtain input embedding e = {w 1 + p 1 , ? ? ? , w l + p l }.
The following part of hypothesis encoder lies the same as Transformer encoder .
Decoding
The output of hypothesis encoder , together with the output of source encoder , are fed into the decoder .
To combine both of the encoders ' outputs , we apply dual multi-head attention in each layer of decoder : the attention sub-layer attends to both encoders ' outputs by performing multi-head attention respectively : A src = MultiHead ( Q tgt , K src , V src ) A hyp = MultiHead ( Q tgt , K hyp , V hyp ) ( 4 )
Where Q tgt is coming from previous layer of the decoder , K src and V src matrixes are final representations of the source encoder while K hyp and V hyp matrixes are final representations of the hypothesis encoder .
The two attention vectors A src and A hyp are then averaged to replace encoder-decoder attention in Transformer , resulting in the input of next layer .
Training
The overall model , which includes a source encoder , a hypothesis encoder with action positional embedding , and a decoder , is jointly trained .
We maximize the log-likelihood of the reference sentence y given the source sentence x , the initial hypothesis y , and the corresponding actions A . By applying A on y , the training objective becomes : ? = arg max ?
D log P (y | x , m(y ) , a ; ? ) . ( 5 ) where D is the training dataset consists of quadruplets like ( source x , modified hypothesis m(y ) , action sequence a , target y ) .
We use Adam optimizer ( Kingma and Ba , 2014 ) , an extension of stochastic gradient descent ( Bottou , 1991 ) , to train the model .
After training , the model with parameter ? is then used in inference phase to generate refined translations for test data , which consists of triplets like ( source x , modified hypothesis m(y ) , action sequence a ) .
Automatic Data Annotation
The actions we defined in Section 2.1 can be provided by human translators in real applications .
However , it is impractical to manually collect a large scale annotated dataset for training our model .
Thus we resort to propose an approach to automatically extract editing actions from a machine translation hypothesis and its corresponding reference .
To make our method powerful , the number of editing actions which convert a hypothesis to its
We conduct simulated experiment on translation datasets .
Specifically , we translate the source sentences in translation datasets with a pre-trained Transformer model and build the training data with simulated human feedback using algorithm described in Section 3 .
Dataset and Settings
The experiment is conducted on three translation datasets : the IWSLT '14 English - German dataset ( Cettolo et al. , 2014 ) , the WMT '14 English - German dataset ( Bojar et al. , 2014 ) and the WMT '17 Chinese - English dataset ( Ondrej et al. , 2017 ) .
The IWSLT '14 English - German dataset consists of 170k sentence pairs from TED talk subtitles .
We use dev2010 as validation set which contains 887 sentent pairs , and a concatenation of tst2010 , tst2011 and tst2012 as test set which con - tains 4698 sentence pairs .
For WMT '14 English - German dataset , we use the same data and preprocessing as ( Luong et al. , 2015 ) .
The dataset consists of 4.5 M sentence pairs for training 1 .
We take newstest2013 for validation and newstest2014 for testing .
For Chinese to English dataset , we use CWMT portion which is a subset of WMT '17 training data containing 9 M sentence pairs .
We validate on newsdev2017 and test on newstest2017 .
As for vocabulary , the English and German datasets are encoded using byte-pair encoding ( Sennrich et al. , 2015 ) with a shared vocabulary of 8 k tokens for IWSLT '14 and 32 k tokens for WMT '14 .
For Chinese to English dataset , the English vocabulary is set to 30 k subwords , while the Chinese data is tokenized into character level and the vocabulary is set to 10 k characters .
Note that even with subword units or character units , the actions are marked in word level , i.e. all units from a given word share the same actions .
We train the models with two settings .
For the larger WMT English - German and English - Chinese dataset , we borrow the Transformer base parameter set of Vaswani et al . ( 2017 ) , which contains 6 layers for encoders and decoder respectively .
The multi-head attention of each layer contains 8 heads .
The word embedding size is set to 512 and the feedforward layer dimension is 2048 .
For the smaller IWSLT dataset , we use 3 layers for each component and multi-head attention with 4 heads in each layer .
The word embedding size is 256 and the feedforward layers ' hidden size is 1024 .
We also apply label smoothing ? ls = 0.1 and dropout p dropout = 0.1 during training .
All models are 1 We use the pre-processed data from https://nlp.
stanford.edu/projects/nmt/ trained from scratch with corresponding training data , e.g. , parallel data for Transformer baseline model and annotated data for Touch Editing .
Main Results
We report the results of different systems including Transformer and QuickEdit .
The Transformer model is tested on bitext data , i.e. , the model directly generates translations based on source sentences .
As for the QuickEdit , we followed the settings of Grangier and Auli ( 2018 ) , in which they mark all words in initial translation results that do not appear in the references as incorrect , and use the QuickEdit model to generate refined translations .
In Touch Baseline setting , we use the algorithm described in Section 3 to obtain the actions respect to initial translations and references , and then apply reordering and deletion actions to obtain refined translations .
The Touch Edit setting accesses the same information as Touch Baseline but uses the neural model described in Section 2.2 to handle the actions .
Note that the original QuickEdit model is based on ConvS2S , and thus we reimplement it based on Transformer to keep the fairness of comparison 2 .
As shown in Table 1 , our model strongly outperforms other systems .
As for BLEU score , our model achieves up to + 25.31 than Transformer and + 16.64 than QuickEdit .
Our model also significantly reduces TER by - 0.28 and - 0.18 comparing to Transformer and QuickEdit .
We also notice that the improvement on the smaller IWSLT ' 14 dataset ( up to 17.22 ) is not as significant as that on the larger WMT ' 14 dataset ( up to 24.74 ) and WMT '17 dataset ( up to 25.31 ) .
This observation is in consistent with QuickEdit , which also gains lower improvement on the smaller dataset .
The reason , as described in Grangier and Auli ( 2018 ) , is that the underlying machine translation model is overfitted on the smaller 170k dataset .
Thus the translation output requires less edits on which we build simulated editing action dataset .
The limited supervised data further impacts the model quality and final results .
Analysis
To further investigate the model capacity , we conduct four experiments on WMT '14 English to German dataset .
We analyze the factors that bring the remarkable improvement by modeling coverage , reordering quality and accuracy of each action type .
We also test our model with limited number of actions to evaluate the model usability with partial feedback .
Reordering
We evaluate the word reordering quality of our model , compared with Transformer and QuickEdit .
We adopt two automatic evaluation metrics .
One metric is based on monolingual alignment .
We firstly align model hypotheses and references with TER , and then count the number of words that should be reordered .
As shown by Reordering in Table 2 , the output of our model requires less word reorderings to align with reference .
The other metric is RIBES ( Isozaki et al. , 2010 ) , which is based on rank correlation .
As shown in As shown in Table 3 , our model achieves the accuracy of 99.15 % for deletion 3 , 36.32 % for insertion and 31.86 % for substitution .
The high deletion accuracy shows that our model indeed learns to delete over-translated words .
For insertion and substitution , the actions only indicate where to insert or substitute , and do not provide any ground truth .
Since the self-attention mechanism in Transformer is good at word sense disambiguation ( Tang et al. , 2018 a , b ) , our model is able to select correct words to insert or substitute .
Partial Feedback
The model we train and test is based on all actions , i.e. , all translation errors of the initial hypotheses are marked out .
However , a human translator may not provide all marks .
In fact , the feedback of human translators is hard to predict , and vary with different translators .
In this case , we test our model with simulated partial feedback .
We train our model with all actions and randomly select 0 % , 5 % , . . . 100 % of actions in test set to simulate human behavior .
To further investigate the effect of partial feedback 3
We do not explicitly remove words that marked as DELE - TION and the neural model is responsible for making final decision whether these words should be deleted .
It might slightly hurt BLEU and accuracy but potentially generates more fluent translations .
on different actions , we train three extra models with specific kinds of actions : INSERT , DELETE and SUBSTITUTE .
We then randomly select part of each kind of actions to test the model .
Note that the REORDERING actions are always enabled since they are operated on a segment of words and cannot be partially disabled .
To investigate the effect of REORDERING actions , we also train a model without reordering and partially select three kinds of actions to test the model .
As shown in Figure 4 , for the model trained with all actions , the BLEU scores increases from 29.43 ( with reordering only ) to 50.49 ( with all actions ) as more actions are provided .
For the models trained with specific kinds of actions and the model trained without reordering , the observation is similar .
Experiments on Post-Editing Data
In previous sections , our model is tested and analyzed on automatic machine translation datasets .
However , in post-editing scenarios , our model faces three major challenges : action inconsistency , data inconsistency and model inconsistency .
For action inconsistency , the editing actions to train our model are extracted from machine predictions and references .
The references in our training data are written by human from scratch , while in post-editing the references ( human post-edited results ) are revisions of machine translations , and thus the editing actions might be different .
For data inconsistency , our model is trained on dataset of News domain ( WMT ) or TED talks ( IWSLT ) .
However in real world , data may be from any other domains .
For model inconsistency , we use Transformer to build our training data while the translation model used in real applications may be different .
To investigate the performance facing the three challenges , we test our model on WMT English - German Automatic Post-Editing ( APE ) dataset in IT domain using data from WMT '16 ( Bojar et al. , 2016 ) and WMT '17 ( Ondrej et al. , 2017 ) .
The test data consists of triplets like ( source , machine translation , human post-edit ) , in which the machine translation is generated with a PBSMT system .
We use the algorithm of Section 3 to extract actions from machine translations and human post-edited sentences .
With the actions and original machine translations , we use the model trained on WMT '14 English - German dataset in Section 4 to generate refined translations .
To make a comparison , we also evaluate QuickEdit with the same setting .
Table 4 summarizes the results on post-editing dataset .
It is clear to see that even with the three kinds of inconsistency , our model still gains significant improvements of up to 20.05 BLEU than the raw machine translation system ( PBSMT ) .
As for QuickEdit , the improvement on post-editing dataset ( about 4 - 7 BLEU ) is smaller than that on translation dataset ( about 11 BLEU ) .
We conjecture that the stable improvement of our method is due to more flexible action types .
With the detailed editing actions , the model is competent to correct various of errors in draft machine translations , and thus leads to the robustness and effectiveness of our method .
Discussion on Real Scenarios
So far , the experiments we conducted are based on simulated human feedbacks , in which the actions are extracted from initial machine translation results and their corresponding references to simulate human editing actions .
Thus in our simulated setting , the references are used in inference phase to simulate human behavior , as in other interaction methods ( Denkowski et al. , 2014 ; Marie and Max , 2015 ; Grangier and Auli , 2018 ) .
These experiments show that our method can significantly improve the initial translation with similated actions .
However , whether the actions are convenient to perform is a key point in real applications .
To investigate the usability and applicable scenarios of our method , we implement a real mobile application on iPhone , in which the actions can be performed on multi-touch screens .
For a given source sentence , the application provides an initial machine translation .
The text area of translation can response to several gestures 4 : Tap indicated a missing word should be inserted into the nearest space between two words ;
Swipe on a word indicated that the word should be deleted ; Long - Press a word means the word should be substituted with other word ; Pan can drag a word to another position .
We conduct a free-use study with four participants , in which the participants are asked to translate 20 sentences randomly selected from LDC Chinese - English test set with ( 1 ) Touch Editing or ( 2 ) keyboard input after 5 minutes to get familiar with the application .
We observe that the users with Touch Editing tends to correct an error for multiple times when the system cannot predict a word they want , while the users with keyboard input tends to modify more content of initial translation and spend more time on choosing words .
We then conduct an unstructured interview on the usability of our method .
The result of the interview shows that Touch Editing is convenient and intuitive but lack of ability of generating final accurate translation .
It can be treated as a light - weight proofreading method , and suitable for Pre-Post- Editing ( Marie and Max , 2015 ) .
Related Work Post-editing is a pragmatic method that allows human translators to directly correct errors in draft machine translations ( Simard et al. , 2007 ) .
Comparing to purely manual translation , it achieves higher productivity while maintaining the human translation quality ( Plitt and Masselot , 2010 ; Federico et al. , 2012 ) .
Many notable works introduce different levels of human-machine interactions in post-editing .
Barrachina et al. ( 2009 ) propose a prefix-based interactive method which enable users to correct the first translation error from left to right in each iteration .
Green et al. ( 2014 ) implement a prefix-based interactive translation system and Huang et al . ( 2015 ) adopt the prefix constrained translation candidates into a novel input method for translators .
Peris et al. ( 2017 ) further extend this idea to neural machine translation .
The prefix- based protocol is inflexible since users have to follow the left-to- right order .
To overcome the weakness of prefix-based approach , Gonz?lez-Rubio et al . ( 2016 ) ; Cheng et al. ( 2016 ) introduce interaction methods that allow users to correct errors at arbitrary position in a machine hypothesis , while Weng et al . ( 2019 ) also preventing repeat mistakes by memorizing revision actions .
Hokamp and Liu ( 2017 ) propose grid beam search to incorporate lexical constraints like words and phrases provided by human translators and force the constraints to appear in hypothesis .
Recently , some researchers resort to more flexible interactions , which only require mouse click or touch actions .
For example , Marie and Max ( 2015 ) ; Domingo et al. ( 2016 ) propose interactive translation methods which ask user to select correct or incorrect segments of a translation with mouse only .
Similar to our work , Grangier and Auli ( 2018 ) propose a mouse based interactive method which allows users to simply mark the incorrect words in draft machine hypotheses and expect the system to generate refined translations .
Herbig et al . ( 2019 Herbig et al. ( , 2020 propose a multi-modal interface for post-editors which takes pen , touch , and speech modalities into consideration .
The protocol that given an initial translation to generate a refined translation , is also used in polishing mechanism in machine translation ( Xia et al. , 2017 ; Geng et al. , 2018 ) and automatic post-editing ( APE ) task Pal et al. , 2016 ) .
The idea of multi-source encoder is also widely used in the field of APE research ( Chatterjee et al. , 2018 ( Chatterjee et al. , , 2019 .
In human-machine interaction scenarios , the human feedback is used as extra information in polishing process .
Conclusion
In this paper , we propose Touch Editing , a flexible and effective interaction approach which allows human translators to revise machine translation results via touch actions .
The actions we introduce can be provided with gestures like tapping , panning , swiping or long pressing on touch screens to represent human editing intentions .
We present a simulated action extraction method for constructing training data and a dual-encoder model to handle the actions to generate refined translations .
We prove the effectiveness of the proposed interaction approach and discuss the applicable scenarios with a free-use study .
For future works , we plan to conduct large scale real world experiments to evaluate the productivity of different interactive machine translation methods .
Figure 2 : Figure 3 : 23 Figure 2 : Model architecture .
We add a hypothesis encoder ( the right part ) into Transformer which differs from source encoder ( the left part ) in positional embedding .
We use learned action positional embedding instead of the sinusoids .
