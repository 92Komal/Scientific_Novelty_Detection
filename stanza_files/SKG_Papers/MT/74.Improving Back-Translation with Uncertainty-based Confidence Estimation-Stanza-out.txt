title
Improving Back -Translation with Uncertainty - based Confidence Estimation
abstract
While back - translation is simple and effective in exploiting abundant monolingual corpora to improve low-resource neural machine translation ( NMT ) , the synthetic bilingual corpora generated by NMT models trained on limited authentic bilingual data are inevitably noisy .
In this work , we propose to quantify the confidence of NMT model predictions based on model uncertainty .
With word - and sentence - level confidence measures based on uncertainty , it is possible for back -translation to better cope with noise in synthetic bilingual corpora .
Experiments on Chinese-English and English - German translation tasks show that uncertainty - based confidence estimation significantly improves the performance of backtranslation .
1
Introduction
The past several years have witnessed the rapid development of end-to - end neural machine translation ( NMT ) ( Sutskever et al. , 2014 ; Bahdanau et al. , 2015 ; Vaswani et al. , 2017 ) , which leverages neural networks to map between natural languages .
Capable of learning representations from data , NMT has significantly outperformed conventional statistical machine translation ( SMT ) ( Koehn et al. , 2003 ) and been widely deployed in large-scale MT systems in the industry Hassan et al. , 2018 ) .
Despite the remarkable success , NMT suffers from the data scarcity problem .
For most language pairs , large-scale , high-quality , and widecoverage bilingual corpora do not exist .
Even for the top handful of resource - rich languages , the major sources of available parallel corpora are of - * Yang Liu is the corresponding author : liuyang 2011@ tsinghua.edu.cn.
1
The source code is available at https://github.
com / THUNLP -MT /UCE4BT
Bush hold a talks and Sharon ? ? bushi yu shalong jvxing le huitan y < l a t e x i t s h a 1 _ b a s e 6 4 = " o y l 3 C D d c 4 p K X M b w M X u l N j W Z + g Q Y = " > A A A B 8 X i c b V B N S 8 N A F H y p X 7 V + V T 1 6 W S y C p 5 K o o M e i F 4 8 V b C 2 2 o W y 2 m 3 b p Z h N 2 X 4 Q S + i + 8 e F D E q / / G m / / G T Z u D t g 4 s D D P v s f M m S K Q w 6 L r f T m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 T Z x q x l s s l r H u B N R w K R R v o U D J O 4 n m N A o k f w j G N 7 n / 8 M S 1 E b G 6 x 0 n C / Y g O l Q g F o 2 i l x 1 5 E c R S E 2 W T a r 9 b c u j s D W S Z e Q W p Q o N m v f v U G M U s j r p B J a k z X c x P 0 M 6 p R M M m n l V 5 q e E L Z m A 5 5 1 1 J F I 2 7 8 b J Z 4 S k 6 s M i B h r O 1 T S G b q 7 4 2 M R s Z M o s B O 5 g n N o p e L / 3 n d F M M r P x M q S Z E r N v 8 o T C X B m O T n k 4 H Q n K G c W E K Z F j Y r Y S O q K U N b U s W W 4 C 2 e v E z a Z 3 X v v O 7 e X d Q a 1 0 U d Z T i C Y z g F D y 6 h A b f Q h B Y w U P A M r / D m G O f F e X c + 5 q M l p 9 g 5 h D 9 w P n 8 A / 2 i R H w = = < / l a t e x i t > x < l a t e x i t s h a 1 _ b a s e 6 4 = "
7 t b 5 7 3 A A n u x E h C s A M H c B V c K q + P s = " > A A A B + X i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w V R I V d F l 0 4 7 K C f U A T y m Q 6 a Y d O J m H m p l h C / s S N C 0 X c + i f u / B s n b R b a e m D g c M 6 9 3 D M n S A T X 4 D j f V m V t f W N z q 7 p d 2 9 n d 2 z + w D 4 8 6 O k 4 V Z W 0 a i 1 j 1 A q K Z 4 J K 1 g Y N g v U Q x E g W C d Y P J X e F 3 p 0 x p H s t H m C X M j 8 h I 8 p B T A k Y a 2 L Y 3 J p B 5 E Y F x E G Z P e T 6 w 6 0 7 D m Q O v E r c k d V S i N b C / v G F M 0 4 h J o I J o 3 X e d B P y M K O B U s L z m p Z o l h E 7 I i P U N l S R i 2 s / m y X N 8 Z p Q h D m N l n g Q 8 V 3 9 v Z C T S e h Y F Z r K I q J e 9 Q v z P 6 6 c Q 3 v g Z l 0 k K T N L F o T A V G G J c 1 I C H X D E K Y m Y I o Y q b r J i O i S I U T F k 1 U 4 K 7 / O V V 0 r l o u J c N 5 + G q 3 r w t 6 6 i i E 3 S K z p G L r l E T 3 a M W a i O K p u g Z v a I 3 K 7 N e r H f r Y z F a s c q d Y / Q H 1 u c P V q + U H A = = < / l a t e x i t > ?y!x
< l a t e x i t s h a 1 _ b a s e 6 4 = "
8 n r Q v 4 P T g w ten restricted to government documents or news articles .
Z p E T G Q R G N P p n J 4 w W A = " > A A A C H H i c b V D L S s N A F J 3 4 t r 6 q L t 0 M F s F V S V T Q Z d G N S w X b C k 0 p N 9 N J M 3 Q m C T M 3 a g n 5 A H / C X 3 C r e 3 f i V n D r l z i t W a j 1 w M D h n H O 5 d 0 6 Q S m H Q d T + c m d m 5 + Y X F p e X K y u r a + k Z 1 c 6 t l k k w z 3 m S J T P R 1 A I Z L E f M m C p T 8 O t U c V C B 5 O x i e j f 3 2 D d d G J P E V j l L e V T C I R S g Y o J V 6 1 Z o f A e Z + o H I f I 4 5 Q F L 1 8 R H 0 t B h G C 1 s k t v S t s y q 2 7 E 9 B p 4 p W k R k p c 9 K q f f j 9 h m e I x M g n G d D w 3 x W 4 O G g W T v K j 4 m e E p s C E M e M f S G B Q 3 3 X z y m Y L u W a V P w 0 T b F y O d q D 8 n c l D G j F R g k w o w M n + 9 s f i f 1 8 k w P O n m I k 4 z 5 D H 7 X h R m k m J C x 8 3 Q v t C c o R x Z A k w L e y t l E W h g a P v 7 t S V Q R c W W 4 v 2 t Y J q 0 D u r e Y d 2 9 P K o 1 T s t 6 l s g O 2 S X 7 x C P H p E H O y Q V p E k b u y S N 5 I s / O g / P i v D p v 3 9 E Z p 5 z Z J r / g v H 8 B U c y j B A = = < / l a t e x i t > confidence
Therefore , improving NMT under small - data training conditions has attracted extensive attention in recent years ( Sennrich et al. , 2016a ; Cheng et al. , 2016 ; Zoph et al. , 2016 ; Chen et al. , 2017 ; Fadaee et al. , 2017 ; Ren et al. , 2018 ; Lample et al. , 2018 ) .
Among them , back - translation ( Sennrich et al. , 2016a ) is an important direction .
Its basic idea is to use an NMT model trained on limited authentic bilingual corpora to generate synthetic bilingual corpora using abundant monolingual data .
The authentic and synthetic bilingual corpora are then combined to re-train NMT models .
Due to its simplicity and effectiveness , backtranslation has been widely used in low-resource language translation .
However , as the synthetic corpora generated by the NMT model are inevitably noisy , translation errors can be propagated to subsequent steps and prone to hinder the performance ( Fadaee and Monz , 2018 ; Poncelas et al. , 2018 ) .
In this work , we propose a method to quantify the confidence of NMT model predictions to enable back -translation to better cope with translation errors .
The central idea is to use model uncertainty ( Buntine and Weigend , 1991 ; Gal and Ghahramani , 2016 ; Dong et al. , 2018 ; Xiao and Wang , 2019 ) to measure whether the model parameters can best describe the data distribution .
Based on the expectation and variance of wordand sentence - level translation probabilities calculated by Monte Carlo Dropout ( Gal and Ghahramani , 2016 ) , we introduce various confidence measures .
Different from most previous quality estimation studies that require feature extraction ( Blatz et al. , 2004 ; Specia et al. , 2009 ; Salehi et al. , 2014 ) or post-edited data ( Kim et al. , 2017 ; Wang et al. , 2018 ; Ive et al. , 2018 ) to train external confidence estimators , all our approach needs is the NMT model itself .
Hence , it is easy to apply our approach to arbitrary NMT models trained for arbitrary language pairs .
Experiments on Chinese-English and English - German translation tasks show that our approach significantly improves the performance of back - translation .
Background Let x = x 1 . . . x I be a source- language sentence and y = y 1 . . . y J be a target - language sentence .
We use P ( y|x , ? x?y ) to denote a source- to- target NMT model ( Sutskever et al. , 2014 ; Bahdanau et al. , 2015 ; Vaswani et al. , 2017 ) parameterized by ? x?y .
Similarly , the target- to- source NMT model is denoted by P ( x|y , ? y?x ) .
Let D b = { x ( m ) , y ( m ) } M m=1 be an authentic bilingual corpus that contains M sentence pairs and D m = {y ( n ) } N n=1 be a monolingual corpus that contains N target sentences .
The first step of back - translation ( Sennrich et al. , 2016a ) is to train a target - to -source model on the authentic bilingual corpus D b using maximum likelihood estimation : ?y?x = argmax ?y?x
L( D b , ? y?x ) , ( 1 ) where the log-likelihood is defined as L( D b , ? y?x ) = M m=1 log P ( x ( m ) |y ( m ) , ? y?x ) . ( 2 ) The second step is to use the trained model ?y?x to translate the monolingual corpus D m : x( n ) = argmax x P ( x|y ( n ) , ?y?x ) , ( 3 ) where x( n ) = x( n ) 1 . . . x( n ) I .
The word- level decision rule is given by x( n ) i = argmax x P ( x|y ( n ) , x( n ) < i , ?y?x ) . ( 4 ) The resulting translations { x ( n ) } N n=1 can be combined with D m to generate a synthetic bilingual corpus Db = { x( n ) , y ( n ) } N n=1 .
The third step is to train a source - to- target model P ( y|x , ? x?y ) on the combination of authentic and synthetic bilingual corpora : ?x?y = argmax ?x?y L( D b ? Db , ? x?y ) . ( 5 ) This three -step process can iterate until convergence ( Hoang et al. , 2018 ; Cotterell and Kreutzer , 2018 ) .
A problem with back - translation is that model predictions are inevitably erroneous .
Translation errors can be propagated to subsequent steps and impair the performance of back - translation , especially when Db is much larger than D b ( Pinnis et al. , 2017 ; Fadaee and Monz , 2018 ; Poncelas et al. , 2018 ) .
Therefore , it is crucial to develop principled solutions to enable back -translation to better deal with the error propagation problem .
Approach
This work aims to find solutions to the two following problems : 1 . How to quantify the confidence of model predictions at both word and sentence levels ?
2 . How to leverage confidence to improve backtranslation ?
Section 3.1 introduces how to calculate model uncertainty , which lays a foundation for designing uncertainty - based word - and sentence - level confidence measures in Section 3.2 .
Section 3.3 describes confidence - aware training for NMT models on noisy bilingual corpora .
? ? y < l a t e x i t s h a 1 _ b a s e 6 4 = " o y l 3 C D d c 4 p K X M b w M X u l N j W Z + g Q Y = " > A A A B 8 X i c b V B N S 8 N A F H y p X 7 V + V T 1 6 W S y C p 5 K o o M e i F 4 8 V b C 2 2 o W y 2 m 3 b p Z h N 2 X 4 Q S + i + 8 e F D E q / / G m / / G T Z u D t g 4 s D D P v s f M m S K Q w 6 L r f T m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 T Z x q x l s s l r H u B N R w K R R v o U D J O 4 n m N A o k f w j G N 7 n / 8 M S 1 E b G 6 x 0 n C / Y g O l Q g F o 2 i l x 1 5 E c R S E 2 W T a r 9 b c u j s D W S Z e Q W p Q o N m v f v U G M U s j r p B J a k z X c x P 0 M 6 p R M M m n l V 5 q e E L Z m A 5 5 1 1 J F I 2 7 8 b J Z 4 S k 6 s M i B h r O 1 T S G b q 7 4 2 M R s Z M o s B O 5 g n N o p e L / 3 n d F M M r P x M q S Z E r N v 8 o T C X B m O T n k 4 H Q n K G c W E K Z F j Y r Y S O q K U N b U s W W 4 C 2 e v E z a Z 3 X v v O 7 e X d Q a 1 0 U d Z T i C Y z g F D y 6 h A b f Q h B Y w U P A M r / D m G O f F e X c + 5 q M l p 9 g 5 h D 9 w P n 8 A / 2 i R H w = = < / l a t e x i t >
Bush hold a talks and Sharon x < l a t e x i t s h a 1 _ b a s e 6 4 = "
7 t b 5 7 3 A A n u x E h C s A M H c B V c K q + P s = " > A A A B + X i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w V R I V d F l 0 4 7 K C f U A T y m Q 6 a Y d O J m H m p l h C / s S N C 0 X c + i f u / B s n b R b a e m D g c M 6 9 3 D M n S A T X 4 D j f V m V t f W N z q 7 p d 2 9 n d 2 z + w D 4 8 6 O k 4 V Z W 0 a i 1 j 1 A q K Z 4 J K 1 g Y N g v U Q x E g W C d Y P J X e F 3 p 0 x p H s t H m C X M j 8 h I 8 p B T A k Y a 2 L Y 3 J p B 5 E Y F x E G Z P e T 6 w 6 0 7 D m Q O v E r c k d V S i N b C / v G F M 0 4 h J o I J o 3 X e d B P y M K O B U s L z m p Z o l h E 7 I i P U N l S R i 2 s / m y X N 8 Z p Q h D m N l n g Q 8 V 3 9 v Z C T S e h Y F Z r K I q J e 9 Q v z P 6 6 c Q 3 v g Z l 0 k K T N L F o T A V G G J c 1 I C H X D E K Y m Y I o Y q b r J i O i S I U T F k 1 U 4 K 7 / O V V 0 r l o u J c N 5 + G q 3 r w t 6 6 i i E 3 S K z p G L r l E T 3 a M W a i O K p u g Z v a I 3 K 7 N e r H f r Y z F a s c q d Y / Q H 1 u c P V q + U H A = = < / l a t e x i t > ? ? ? ? ?( 1 ) y!x < l a t e x i t s h a 1 _ b a s e 6 4 = " U s F U 8 k E C G 4 k b 1 B L z i n e 7 E + P w y G U = " > A A A C I n i c b V D L S g N B E J z 1 G e M r 6 t H L Y B D M J e y q o M e g F 4 8 R T C J k Y + i d T L J D Z n a X m V 4 1 L P s N / o S / 4 F X v 3 s S T 4 M k v c R J z 8 F X Q U F R 1 0 9 0 V J F I Y d N 0 3 Z 2 Z 2 b n 5 h s b B U X F 5 Z X V s v b W w 2 T Z x q x h s s l r G + D M B w K S L e Q I G S X y a a g w o k b w X D 0 7 H f u u b a i D i 6 w F H C O w o G k e g L B m i l b q n i h 4 C Z H 6 j M x 5 A j 5 P l V t u d V 8 m 4 2 o r 4 W g x B B 6 / i G 3 u b d U t m t u h P Q v 8 S b k j K Z o t 4 t f f i 9 m K W K R 8 g k G N P 2 3 A Q 7 G W g U T P K 8 6 K e G J 8 C G M O B t S y N Q 3 H S y y U s 5 3 b V K j / Z j b S t C O l G / T 2 S g j B m p w H Y q w N D 8 9 s b i f 1 4 7 x f 5 x J x N R k i K P 2 N e i f i o p x n S c D + 0 J z R n K k S X A t L C 3 U h a C B o Y 2 x R 9 b A p U X b S j e 7 w j + k u Z + 1 T u o u u e H 5 d r J N J 4 C 2 S Y 7 Z I 9 4 5 I j U y B m p k w Z h 5 I 4 8 k E f y 5 N w 7 z 8 6 L 8 / r V O u N M Z 7 b I D z j v n 2 v p p R g = < / l a t e x i t > ?( K ) y!x < l a t e x i t s h a 1 _ b a s e 6 4 = " p 0 1 m I O p n Y Y + p v s v Q v M l 6 / m 3 O 3 z I = " > A A A C I n i c b V A 9 S w N B E N 3 z M 8 a v q K X N Y h C 0 C X c q a B m 0 E W w i m C j k Y p j b b H K L u 3 f H 7 p w a j v s N / g n / g q 3 2 d m I l W P l L 3 M Q U x v h g 4 P H e D D P z g k Q K g 6 7 7 4 U x N z 8 z O z R c W i o t L y y u r p b X 1 h o l T z X i d x T L W V w E Y L k X E 6 y h Q 8 q t E c 1 C B 5 J f B z c n A v 7 z l 2 o g 4 u s B + w l s K e p H o C g Z o p X Z p 1 w 8 B M z 9 Q m Y 8 h R 8 j z 6 2 z n b D d v Z 3 3 q a 9 E L E b S O 7 + h 9 3 i 6 V 3 Y o 7 B J 0 k 3 o i U y Q i 1 d u n L 7 8 Q s V T x C J s G Y p u c m 2 M p A o 2 C S 5 0 U / N T w B d g M 9 3 r Q 0 A s V N K x u + l N N t q 3 R o N 9 a 2 I q R D 9 f d E B s q Y v g p s p w I M z V 9 v I P 7 n N V P s H r U y E S U p 8 o j 9 L O q m k m J M B / n Q j t C c o e x b A k w L e y t l I W h g a F M c 2 x K o v G h D 8 f 5 G M E k a e x V v v + K e H 5 S r x 6 N 4 C m S T b J E d 4 p F D U i W n p E b q h J E H 8 k S e y Y v z 6 L w 6 b 8 7 7 T + u U M 5 r Z I G N w P r 8 B l v m l M g = = < / l a t e x i t > ?( k ) y!x < l a t e x i t s h a 1 _ b a s e 6 4 = "
J f o s C 9 8 e h 4 E 7 O g 9 w H T n 8 0 A K 6 o r s = " > A A A C I n i c b V D L S g N B E J z 1 b X x F P X o Z D I J e w q 4 K e h S 9 e I x g E i E b Q + 9 k k h 0 y s 7 v M 9 K p h 2 W / w J / w F r 3 r 3 J p 4 E T 3 6 J k 8 d B E w s a i q p u u r u C R A q D r v v p z M z O z S 8 s L i 0 X V l b X 1 j e K m 1 s 1 E 6 e a 8 S q L Z a x v A j B c i o h X U a D k N 4 n m o A L J 6 0 H v Y u D X 7 7 g 2 I o 6 u s Z / w p o J u J D q C A V q p V T z w Q 8 D M D 1 T m Y 8 g R 8 v w 2 2 + 8 d 5 K 2 s T 3 0 t u i G C 1 v E 9 f c h b x Z J b d o e g 0 8 Q b k x I Z o 9 I q f v v t m K W K R 8 g k G N P w 3 A S b G W g U T P K 8 4 K e G J 8 B 6 0 O U N S y N Q 3 D S z 4 U s 5 3 b N K m 3 Z i b S t C O l R / T 2 S g j O m r w H Y q w N B M e g P x P 6 + R Y u e 0 m Y k o S Z F H b L S o k 0 q K M R 3 k Q 9 t C c 4 a y b w k w L e y t l I W g g a F N 8 c + W Q O U F G 4 o 3 G c E 0 q R 2 W v a O y e 3 V c O j s f x 7 N E d s g u 2 S c e O S F n 5 J J U S J U w 8 k i e y Q t 5 d Z 6 c N + f d + R i 1 z j j j m W 3 y B 8 7 X D 8 v 5 p V I = < / l a t e x i t > ? ? sentence - level confidence word- level confidence n P ( x|y , ?( k ) y!x ) o K k=1 n P ( x i |y , x<i , ?( k ) y!x ) o K k=1 bushi yu shalong jvxing le huitan Figure 2 : Illustration of uncertainty calculation .
Given a target sentence y and the model prediction x , our approach treats word - and sentence - level translation probabilities as random variables and uses Monte Carlo Dropout to draw samples .
These samples are used to calculate the expectations and variances of translation probabilities .
Calculating Uncertainty Uncertainty quantification , which quantifies how confident a certain mapping is with respect to different inputs , has made significant progress due to the recent advances in Bayesian deep learning ( Kendall et al. , 2015 ; Gal and Ghahramani , 2016 ; Kendall and Gal , 2017 ; Xiao and Wang , 2019 ; Oh et al. , 2019 ; Geifman et al. , 2019 ; Lee et al. , 2019 ) .
In this work , we aim to calculate model uncertainty ( Kendall and Gal , 2017 ; Dong et al. , 2018 ; Xiao and Wang , 2019 ) , which measures whether a model can best describe the data distribution , for NMT using approximate inference methods widely used in Bayesian neural networks .
Given the authentic bilingual corpus D b , Bayesian neural networks aim at finding the posterior distribution over model parameters P ( ? y?x | D b ) .
With a target sentence y in the monolingual corpus D m and its translation x , the translation probability is given by P ( x|y , D b ) = P ( x|y , ? y?x ) P ( ? y?x | D b ) d ? y?x . ( 6 ) In particular , we are interested in calculating the variance of the distribution P ( x|y , ? y?x ) that reflects our ignorance over model parameters , which is referred to as model uncertainty .
As exact inference is intractable , a number of variational inference methods ( Graves , 2011 ; Blundell et al. , 2015 ; Gal and Ghahramani , 2016 ) have been pro-posed to find an approximation to P ( ? y?x | D b ) .
In this work , we leverage the widely used Monte Carlo Dropout ( Gal and Ghahramani , 2016 ) to obtain samples of word - and sentence - level translation probabilities .
Figure 2 illustrates the key idea of our approach .
Given an authentic target sentence y , an NMT model made its prediction x via a standard decoding process ( see Eq. ( 3 ) and Eq. ( 4 ) ) .
To quantify how confident the model was when making the prediction , our approach treats word - and sentence - level translation probabilities as random variables .
2 Drawing samples can be done by randomly deactivating part of neurons of the NMT model and re-calculating translation probabilities while keeping y and x fixed .
This stochastic feedforward is repeated K times and generates K samples for both word - and sentence - level translation probabilities , respectively .
We use ?( k ) y?x to denote the model parameters derived from ?y?x by deactivation in the k-th pass .
Intuitively , if the variance of translation probability is low , it is highly likely that the model was confident in making the prediction .
Given K samples { P ( x|y , ?( k ) y?x ) }
K k=1 , the expectation of sentence -level translation probability can be approximated by E P ( x|y , ?y?x ) ? 1 K K k=1 P ( x|y , ?( k ) y?x ) . ( 7 )
The variance of sentence - level translation probability can be approximated by Var P ( x|y , ?y?x ) ? 1 K K k=1 P ( x|y , ?( k ) y?x ) 2 ? E P ( x|y , ?y?x ) 2 , ( 8 ) which is also referred to as model uncertainty .
The expectation and variance of word-level translation probabilities can also be calculated similarly using K samples .
Confidence Measures
We use C(y , x< i , xi , ?y?x ) to denote the wordlevel confidence for the model to generate xi and C(y , x , ?y?x ) to the denote the sentence - level confidence for the model to generate x.
Intuitively , when making predictions , the more confident an NMT model is , the higher expectation and lower variance of translation probability are .
For comparison reasons , we used the following four types of confidence measures at the sentence level in our experiments : where ? and ? are hyper-parameters to control the gap between confidence values of sentences of different quality .
Larger values of ? and ? lead to bigger gaps .
3 In Eq. ( 12 ) , our approach tries to combine the merits of expectation and variance by using variance divided by expectation because smaller variance and bigger expectation are expected to result in higher confidence .
There may exist more sophisticated ways to estimate prediction confidence using model uncertainty ( Dong et al. , 2018 ) .
As we find that the measures mentioned above are easy - to- implement and prove to be effective in our experiments , we leave the investigation of more complex confidence measures for future work .
The word- level confidence measures can be defined similarly .
Confidence - aware Training for NMT
We propose confidence - aware training for NMT to enable NMT to make better use of noisy data .
Word - and sentence - level confidence measures are complementary : while word- level confidence can provide more fine- grained information than the sentence - level counterpart , it is unable to cope with word omission errors that can only be captured at the sentence level .
As a result , our approach incorporates both word - and sentence - level confidence measures into the training process .
4
Using Sentence-level Confidence
It is easy to integrate sentence - level confidence into back -translation by modifying the likelihood function in Eq. ( 5 ) : L( D b ? Db , ? x?y ) = M m=1 log P ( y ( m ) |x ( m ) , ? x?y ) + N n=1 C(y ( n ) , x( n ) , ?y?x ) ? log P ( y ( n ) | x ( n ) , ? x?y ) . ( 13 ) original attention weights word-level confidence modified attention weights Bush hold a talks and Sharon Bush hold a talks and Sharon Bush hold a talks and Sharon Serving as a weight assigned to each synthetic sentence pair , sentence - level confidence is expected to help to minimize the negative effect of estimating parameters on sentences with lower confidence .
Note that the confidence of an authentic sentence pair in D b is 1 .
Using Word-level Confidence
As the source side instead of the target side of the synthetic bilingual corpus is noisy , wordlevel confidence cannot be integrated into backtranslation in a similar way to sentence - level confidence .
This is because the word-level confidence associated with each source word does not get involved in backpropagation during training .
Alternatively , we build a real-valued word- level confidence vector : c = C y ( n ) , x( n ) < i , xi , ?y?x
I i=1 . ( 14 ) Due to the wide use of attention ( Bahdanau et al. , 2015 ; Vaswani et al. , 2017 ) in NMT , we use the confidence vector c ?
R 1 ?
I to modify attention weights and enable the model to focus more on words with high confidence .
Figure 3 shows an example .
Figure 3 ( a ) gives a source sentence in the synthetic bilingual corpus , in which erroneous words " hold " , " talks " , and " and " receive high attention weights , deteriorating the parameter estimation on this sentence pair .
By multiplying with word-level confidence ( Figure 3 ( b ) ) , the weights are modified to pay less attention to erroneous words ( Figure 3 ( c ) ) .
More formally , the modified attention function is given by Attention ( Q , K , V , c ) = softmax QK ? D c V , ( 15 ) where Q ? R I?D , K ? R I?D , and V ? R I?D are query , key , and value matrices and D is the hidden size .
is a broadcast product .
Since the integration of sentence - and wordlevel confidence measures are independent of each other , it is easy to use both of them in backtranslation .
Experiments
Setup
We evaluated our approach on Chinese-English and English - German translation tasks .
The evaluation metric is BLEU ( Papineni et al. , 2001 ) as calculated by the multi-bleu. perl script .
We use the paired bootstrap resampling ( Koehn , 2004 ) for significance testing .
For the Chinese- English task , the training set contains 1.25 M sentence pairs from LDC 5 with 27.8 M Chinese words and 34.5 M English words .
To build the monolingual corpus for backtranslation , we extracted the English side of the training set of the WMT 2017 Chinese - English news translation task .
After removing sentences longer than 256 words , we randomly selected 10M English sentences as the monolingual corpus .
NIST06 is used as the development set and NIST02 , 03 , 04 , 05 , and 08 datasets as test sets .
For the English - German task , we used the dataset of the WMT 2014 English - German translation task .
The training set consists of 4.47 M sentence pairs with 116M English words and 110M German words .
We randomly selected 4.5 M German sentences from the 2012 News Crawl corpus of WMT 2014 to construct the monolingual corpus for back - translation .
We use newstest 2013 as Chinese sentences were segmented by an opensource toolkit THULAC 6 . German and English sentences were tokenized by the tokenizer in Moses ( Koehn et al. , 2007 ) .
We used byte pair encoding ( Sennrich et al. , 2016 b ) to perform subword segmentation with 32 k merge operations for Chinese -English and 35 k merge operations for English - German .
Sentence pairs are batched together by approximate length and each batch has roughly 25,000 source and target tokens .
We distinguish between three kinds of translations of the monolingual corpus :
1 . NONE : there is no translation and only the authentic bilingual corpus is used ; 2 . SEARCH : the translations are generated by beam search ( Sennrich et al. , 2016 a ) ; 3 . SAMPLE : the translations are generated by sampling ( Edunov et al. , 2018 ) .
As neural quality estimation ( Kim et al. , 2017 ; Wang et al. , 2018 ) can also give word - and sentence - level confidences for the output of NMT models when labeled data is available , we distinguish between two kinds of confidence estimation methods :
1 . NEURALQE : the confidences are given by an external neural quality estimator ; 2 . UNCERTAINTY : the proposed uncertaintybased confidence estimation method .
For NEURALQE , we used the Predictor-Estimator architecture ( Kim et al. , 2017 ) which is an open source software officially recommended by the QE shared task of WMT .
Following the guide of OpenKiwi , we used a German-English parallel corpus containing 2.09 M sentence pairs to train the predictor and a post-edited corpus containing 25 k sentence triples to train the estimator .
All the data used to train QE models are provided by WMT .
As there are no post-edited corpora for the Chinese - English task , NEURALQE can only be used in the English - German task in our experiments .
For NEURALQE , both word - and sentence - level quality scores were considered .
We implemented our method on the top of THUMT ( Zhang et al. , 2017 ) .
The NMT model we use is Transformer ( Vaswani et al. , 2017 ) .
We used the base model for the Chinese - English task and the big model for the English - German task .
We used the Adam optimizer ( Kingma and Ba , 2015 ) with ?
1 = 0.9 , ? 2 = 0.98 and = 10 ?9 to optimize model parameters .
We used the same warmup strategy for learning rate as Vaswani et al . ( 2017 ) with warmup steps = 4 , 000 .
During training , the hyper-parameter of label smoothing was set as ls = 0.1 ( Szegedy et al. , 2016 ; Pereyra et al. , 2017 ) .
During training and the Monte Carlo Dropout process , the hyper-parameter of dropout was set to 0.1 and 0.3 for Transformer base and big models , respectively .
K was set to 20 .
Through experiments , we find our method works best when the ? and ? are set to 2 .
All experiments were conducted on 8 NVIDIA GTX 1080 Ti GPUs .
Comparison of Confidence Measures
Table 1 shows the comparison of confidence measures on the Chinese-English development set .
We find that using either the translation probabilities outputted by the model ( i.e. , " PTP " ) or the expectation of translation probabilities ( i.e. , " EXP " ) deteriorates the translation quality , which suggests that translation probabilities themselves can not help NMT models better cope with synthetic data .
Table 3 : BLEU scores on the NIST Chinese-English translation task .
The ratio of authentic data to synthetic data is 1:1 .
NONE : only the authentic bilingual corpus is used .
SEARCH : the translations of the monolingual corpus are generated by beam search ( Sennrich et al. , 2016a ) . SAMPLE : the translations of the monolingual corpus are generated by sampling ( Edunov et al. , 2018 ) . " CE " : confidence estimation method . " U " : the proposed uncertaintybased confidence estimation .
" All " : the combination of all test sets . " + " : significantly better than SEARCH without CE ( p < 0.05 ) . " + + " : significantly better than SEARCH without CE ( p < 0.01 ) . " ? ? " : significantly better than SAMPLE without CE ( p < 0.01 ) .
Data
In contrast , using the variance or model uncertainty ( i.e. , " VAR " ) increases translation quality .
Combining variance and expectation ( i.e. , " CEV " ) leads to a further improvement .
In the following experiments , we use CEV as the default setting .
Comparison between Word- and Sentence-level Confidence Measures
Table 2 shows the comparison between wordand sentence - level CEV ( i.e. , combination of expectation and variance ) confidence measures on the Chinese - English development set .
It is clear that using either sentence - level or word- level confidence measures improves the translation performance .
Thanks to more fine- grained quantification of uncertainty , using word - level confidence achieves a higher BLEU score than using sentence - level confidence .
Combining the sentence - and word-level of confidences leads to a further improvement , suggesting that they are complementary to each other .
In the following experiments , we use the combination of word - and sentence - level confidences as the default setting .
Main Results
The Chinese-English Task Table 3 shows the results of the Chinese-English task .
Back - translation , either generating translations using beam search ( i.e. , SEARCH ) or using sampling ( i.e. , SAMPLE ) , does lead to significant improvements over using only the authentic bilingual corpus ( i.e. , NONE ) .
We find that SAM - PLE is more effective than SEARCH , which confirms the finding of Edunov et al . ( 2018 ) .
Using uncertainty - based confidence ( i.e. , " U " ) signifi-cantly improves over both SEARCH and SAMPLE on the combination of all test sets ( p < 0.01 ) .
As there is no Chinese - English labeled data to train neural quality estimation models , we did not report the result of NEURALQE in this experiment .
The English - German Task Table 4 shows the results of the English - German task .
We find that using quality estimation , either NEURALQE ( i.e. , " N " ) or UNCERTAINTY ( i.e. , " U " ) , improves over SEARCH and SAMPLE .
UNCERTAINTY even achieves better performance than NEURALQE , although NEURALQE uses additional labeled training data .
As NEURALQE heavily relies on post-edited corpora and labeled data to train QE models , it can only be used in a handful of language pairs .
In contrast , it is easier to apply our approach to arbitrary language pairs since it does not need any labeled data to estimate confidence .
Effect of Training Corpus Size Figure 4 shows the effect of training corpus size .
The X-axis is the size of the total training data ( i.e. , D b ? Db in Eq. ( 5 ) ) .
The BLEU scores were calculated on the Chinese-English development set .
We find that the translation performance of SEARCH rises with the increase of monolingual corpus size in the beginning .
However , further enlarging the monolingual corpus hurts the translation performance .
In contrast , our approach can still obtain further improvements when adding more synthetic bilingual sentence pairs .
Similar findings are also observed for SAMPLE .
Effect of Data Selection Instead of randomly selecting monolingual sentences to generate synthetic data , we also used the method proposed by ( Fadaee and Monz , 2018 ) to select monolingual data by targeting difficult words .
In this series of experiments , we used the same amount of monolingual data that was derived from a larger monolingual corpus using different data selection methods .
Results on NIST06 show that targeting difficult words improves over randomly selecting monolingual data ( 46.23 ? 46.60 BLEU ) , confirming the finding of Fadaee and Monz ( 2018 ) .
Using uncertainty - based confidence can further im - prove the translation performance ( 46.60 ? 47.18 BLEU ) , indicating that our approach can be combined with advanced data selection methods .
Case Study Figure 5 shows an example of model prediction and its corresponding word - and sentence - level confidence measures for the English - German task .
We observe that the PTP and EXP measures are unable to give low confidence to erroneous words .
In contrast , variance - based measures such as VAR and CEV can better quantify how confident the model is to make its prediction .
Related work
Our work is closely related to three lines of research : ( 1 ) back - translation , ( 2 ) confidence estimation , and ( 3 ) uncertainty quantification .
Back-translation Back-translation is a simple and effective approach to leveraging monolingual data for NMT ( Sennrich et al. , 2016 a ) .
There has been a growing body of literature that analyzes and extends back -translation recently .
Currey et al. ( 2017 ) show that low-resource NMT can benefit from the synthetic data generated by simply copying target monolingual data to the source side .
Imamura et al. ( 2018 ) and Edunov et al . ( 2018 ) demonstrate that it is more effective to generate source sentences via sampling rather than beam search .
Cotterell and Kreutzer ( 2018 ) and Hoang et al .
reference
A person who is dying will accept being helped to drink brandy or Pepsi , whatever is their tipple . prediction
The dying person is given oral care with brandy or Pepsi as desired . ( 2018 ) find that iterative back -translation can further improve the performance of NMT .
Fadaee and Monz ( 2018 ) show that words with high predicted loss during training benefit most .
Our work differs from existing methods in that we propose to use confidence estimation to enable back -translation to better cope with noisy synthetic data , which can be easily combined with previous works .
Our experiments show that both neural and uncertainty - based confidence estimation methods benefit back - translation .
Confidence Estimation Estimating the confidence or quality of the output of MT systems ( Ueffing and Ney , 2007 ; Specia et al. , 2009 ; Bach et al. , 2011 ; Salehi et al. , 2014 ; Rikters and Fishel , 2017 ; Kepler et al. , 2019 ) is important for enabling downstream applications such as post-editing and interactive MT to better cope with translation mistakes .
While existing methods rely on external models to estimate confidence , our approach leverages model uncertainty to derive confidence measures .
The major benefit is that our approach does not need labeled data .
Uncertainty Quantification Reliable uncertainty quantification is key to building a robust artificial intelligent system .
It has been successfully applied to many fields , including computer vision ( Kendall et al. , 2015 ; Kendall and Gal , 2017 ) , time series prediction ( Zhu and Laptev , 2017 ) , and natural language processing ( Dong et al. , 2018 ; Xiao and Wang , 2019 ) .
Our work differs from previous work in that we are in-terested in calculating uncertainty after the model has made the prediction rather during inference .
also analyze the inherent uncertainty of machine translation .
The difference is that they focus on the existence of multiple correct translations for a single sentence while we aim to quantify the uncertainty of NMT models .
Conclusions
We have presented a method for qualifying model uncertainty for neural machine translation and use uncertainty - based confidence measures to improve back - translation .
The key idea is to use Monte Carlo Dropout to sample translation probabilities to calculate model uncertainty , without the need for manually labeled data .
As our approach is transparent to model architectures , we plan to further verify the effectiveness of our approach on other downstream applications of NMT such as post-editing and interactive MT in the future .
Figure 1 : 1 Figure 1 : Confidence estimation for back - translation .
Back - translation generates a source ( e.g. , English ) sentence for a ground - truth target ( e.g. , Chinese ) sentence .
Such synthetic sentence pairs are used to train NMT models .
As the model prediction ( i.e. , x ) is often noisy , our work aims to quantify the prediction confidence using model uncertainty to alleviate error propagation .
1 . Predicted translation probability ( PTP ) .
The translation probability of model prediction during standard decoding ( Eq. ( 3 ) ) : C PTP (y , x , ?y?x ) = P ( x|y , ?y?x ) . ( 9 ) 2 . Expected translation probability ( EXP ) .
The expectation of translation probability : C EXP (y , x , ?y?x ) = E P ( x|y , ?y?x ) . ( 10 ) 3 . Variance of translation probability ( VAR ) .
The variance of translation probability : C VAR (y , x , ?y?x ) = 1 ? Var P ( x|y , ?y?x ) Combination of expectation and variance ( CEV ) .
The combination of expectation and variance : C CEV (y , x , ?y?x ) = 1 ? Var P ( x|y , ?y?x ) E P ( x|y , ?y?x ) ? .
Figure 3 : 3 Figure 3 : Using word - level confidence in confidence - aware training .
The basic idea is to use confidence to modify attention weights to pay less attention to erroneous words highlighted in underline .
( a) The original attention weights of the NMT model ; ( b ) the word - level confidence of the noisy source sentence ; ( c ) the attention weights modified by the word- level confidence , which focus more on words with high confidence .
is a broadcast product .
See Eq. ( 15 ) for details .
Figure 4 : 4 Figure 4 : Effect of training corpus size .
Sterbenden je nach Wunsch eine Mundpflege mit Brandy oder Pepsi .
Figure 5 : 5 Figure 5 : Example of confidence measures .
Table 1 : 1 Comparison of confidence measures .
Measure BLEU ? - 46.23 - PTP 45.41 -0.82 EXP 45.22 -1.01 VAR 46.77 +0.54 CEV 47.05 + 0.82 the development set and newstest 2012 , 2014 , and 2015 as test sets .
Table 2 : 2 implemented by OpenKiwi ( Kepler et al. , 2019 ) , Comparison between word - and sentencelevel CEV confidence measures .
6 https://github.com/thunlp/ THULAC - Python
++ 48.06 ++ 46.44 ++ 47.59 ++ 47.03 ++ 38.02 + 45.72 ++ CE MT06 MT02 MT03 MT04 MT05 MT08 All NONE - 45.05 45.09 44.79 46.07 44.34 35.52 43.50 --U 47.05 SAMPLE 46.23 SEARCH 46.69 U 46.78 45.85 46.98 46.75 45.37 45.62 46.53 ? ? 46.77 46.97 47.70 ? ? 46.28 46.29 47.48 ? ? 37.69 37.28 36.99 44.76 44.96 45.37 ? ?
Table 4 : 4 BLEU scores on the WMT14 English - German translation task .
The ratio of authentic data to synthetic data is 1:1 .
NONE : only the authentic bilingual corpus is used .
SEARCH : the translations of the monolingual corpus are generated by beam search ( Sennrich et al. , 2016a ) . SAMPLE : the translations of the monolingual corpus are generated by sampling ( Edunov et al. , 2018 ) . " CE " : confidence estimation method .
" U " : uncertainty - based confidence estimation .
" N " : NEURALQE .
" All " : the combination of all test sets . " + + " : significantly better than SEARCH without CE ( p < 0.01 ) . " * " : significantly better than " SEARCH + N " ( p < 0.05 ) . " ? " : significantly better than SAMPLE without CE ( p < 0.05 ) . " ? ? " : significantly better than SAMPLE without CE ( p < 0.01 ) . " ? ? " : significantly better than " SAMPLE + N " ( p < 0.01 ) .
48 47 BLEU Training Corpus Size 1.25 M 2.50M 3.75 M 6.25 M 11.25 M 45 46 Search + U Sample +U Sample Search
Unlike prior studies that calculate model uncertainty during inference ( Xiao and Wang , 2019 ) , our approach computes uncertainty after the NMT model has made the prediction for two reasons .
First , our goal is to quantify the confidence of model prediction rather than using uncertainty to improve model prediction .
Second , using Monte Carlo Dropout during decoding is very slow because of the autoregressive property of standard NMT models .
Note that all confidence measures are between 0 and 1 .
Clearly , both the expectation and variance of a probability are between 0 and 1 .
It can be proved that the variance of a probability is no greater than the corresponding expectation .
As a result , CCEV ( ? ) is also between 0 and 1.4 Instead of applying confidence estimation to the second pass of decoding ( Luong et al. , 2017 ) , we directly integrate confidence scores into the training process .
These two kinds of methods are complementary .
The training set includes LDC2002E18 , LDC2003E07 , LDC2003E14 , part of LDC2004T07 , LDC2004T08 and LDC2005T06 .
