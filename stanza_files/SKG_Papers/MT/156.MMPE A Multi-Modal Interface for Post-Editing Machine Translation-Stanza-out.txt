title
MMPE : A Multi-Modal Interface for Post-Editing Machine Translation
abstract
Current advances in machine translation ( MT ) increase the need for translators to switch from traditional translation to post-editing ( PE ) of machine - translated text , a process that saves time and reduces errors .
This affects the design of translation interfaces , as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals .
Since this paradigm shift offers potential for modalities other than mouse and keyboard , we present MMPE , the first prototype to combine traditional input modes with pen , touch , and speech modalities for PE of MT .
The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks , while they are of limited use for longer insertions .
On the other hand , speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions but offer less potential for deletion and reordering .
Overall , participants were enthusiastic about the new modalities and saw them as good extensions to mouse & keyboard , but not as a complete substitute .
Introduction
As machine translation ( MT ) has been making substantial improvements in recent years 1 , more and more professional translators are integrating this technology into their translation workflows ( Zaretskaya et al. , 2016 ; Zaretskaya and Seghiri , 2018 ) .
The process of using a pre-translated text as a basis and improving it to create the final translation is called post-editing ( PE ) .
Older research showed a strong dislike of translators towards PE ( Lagoudaki , 2009 ; Wallis , 2006 ) , and more recent studies agree that translators are still cautious about PE and question its benefits ( Gaspari et al. , 2014 ; Koponen , 2012 ) , partly because they see it as a threat to their profession ( Moorkens , 2018 ) .
Experienced translators in particular exhibit rather negative attitudes ( Moorkens and O'Brien , 2015 ) .
Conversely , novice translators have been shown to have more positive views on PE ( Yamada , 2015 ) .
Green et al. ( 2013 ) demonstrated that some translators actually strongly prefer PE and argue that " users might have dated perceptions of MT quality " .
Apart from translators ' preference , productivity gains of 36 % when using modern neural MT for PE ( Toral et al. , 2018 ) already result in substantial changes in translation workflows ( Zaretskaya and Seghiri , 2018 ) and will probably continue to do so the better MT becomes .
Thus , PE requires thorough investigation in terms of interface design , since the task changes from mostly text production to comparing and adapting MT and translation memory ( TM ) proposals , or put differently , from control to supervision .
Previous elicitation - based research ( Herbig et al. , 2019a ) investigated how translation environments could better support the PE process and found that translators envision PE interfaces relying on touch , pen , and speech input combined with mouse and keyboard as particularly useful .
A small number of prototypes exploring some of these modalities also showed promising results ( Teixeira et al. , 2019 ) .
This paper presents MMPE , the first translation environment combining standard mouse & keyboard input with touch , pen , and speech interactions for PE of MT .
The results of a study with 11 professional translators show that participants are enthusiastic about having these alternatives , even though time measurements and subjective ratings do not always agree .
Overall , pen and touch modalities are well suited for deletion and reordering operations , while speech and multi-modal interaction are suitable for insertions and replacements .
Related Work
In this section , we present related research on translation environments and particularly focus on existing multi-modal approaches to PE .
CAT and Post-Editing Most professional translators nowadays use so-called CAT ( computer-aided translation ) tools ( van den Bergh et al. , 2015 ) .
These provide features like MT and TM together with quality estimation and concordance functionality ( Federico et al. , 2014 ) , alignments between source and MT ( Schwartz et al. , 2015 ) , interactive MT offering assistance like auto-completion ( Green et al. , 2014 b , a ) , or intelligibility assessments ( Coppers et al. , 2018 ; Vandeghinste et al. , 2016 Vandeghinste et al. , , 2019 .
While TM is still often valued higher than MT , a recent study by Vela et al . ( 2019 ) shows that professional translators who were given a choice between translation from scratch , TM , and MT , chose MT in 80 % of the cases , highlighting the importance of PE of MT .
Regarding the time savings achieved through PE , Zampieri and Vela ( 2014 ) find that PE was on average 28 % faster for technical translations , Aranberri et al . ( 2014 ) show that PE increases translation throughput for both professionals and lay users , and L?ubli et al . ( 2013 ) find that PE also increases productivity in realistic environments .
Furthermore , it has been shown that PE not only leads to reduced time but also reduces errors ( Green et al. , 2013 ) .
Furthermore , PE changes the interaction pattern ( Carl et al. , 2010 ) , leading to a significantly reduced amount of mouse and keyboard events ( Green et al. , 2013 ) .
Therefore , we believe that other modalities or combinations thereof might be more useful for PE .
Multi-Modal Approaches
Dictating translations dates back to the time when secretaries transcribed dictaphone content on a typewriter ( Theologitis , 1998 ) ; however , the use of automatic speech recognition also has a long history for translation ( Dymetman et al. , 1994 ; Brousseau et al. , 1995 ) .
A more recent approach , called SEECAT ( Martinez et al. , 2014 ) , investigates the use of automatic speech recognition ( ASR ) in PE and argues that its combination with typing could boost productivity .
A survey regarding speech usage with PE trainees ( Mesa - Lao , 2014 ) finds that they have a positive attitude towards speech input and would consider adopting it , but only as a complement to other modalities .
In a small- scale study , Zapata et al . ( 2017 ) found that ASR for PE was faster than ASR for translation from scratch .
Due to these benefits , commercial CAT tools like memoQ and MateCat are also beginning to integrate ASR .
The CASMACAT tool ( Alabau et al. , 2013 ) allows the user to input text by writing with e-pens in a special area .
A vision paper ( Alabau and Casacuberta , 2012 ) proposes to instead use e-pens for PE sentences with few errors in place and showcases symbols that could be used for this .
Studies on mobile PE via touch and speech ( O' Brien et al. , 2014 ; Torres - Hostench et al. , 2017 ) show that participants especially liked reordering words through touch drag and drop , and preferred voice when translating from scratch , but used the iPhone keyboard for small changes .
Zapata ( 2016 ) also explores the use of voice - and touch - enabled devices ; however , the study did not focus on PE , and used Microsoft Word instead of a proper CAT environment .
Teixeira et al. ( 2019 ) explore a combination of touch and speech for translation from scratch , translation using TM , and translation using MT .
In their studies , touch input received poor feedback since ( a ) their tile view ( where each word is a tile that can be dragged around ) made reading more complicated , and ( b ) touch insertions were rather complex to achieve within their implementation .
In contrast , integrating dictation functionality using speech was shown to be quite useful and even preferred to mouse and keyboard by half of the participants .
The results of an elicitation study by Herbig et al . ( 2019a ) indicate that pen , touch , and speech interaction should be combined with mouse and keyboard to improve PE of MT .
In contrast , other modalities like eye tracking or gestures were seen as less promising .
In summary , previous research suggests that professional translators should switch to PE to increase productivity and reduce errors ; however , translators themselves are not always eager to do so .
It has been argued that the PE process might be better supported by using different modalities in addition to the common mouse and keyboard approaches , and an elicitation study suggests concrete modalities that should be well suited for various editing tasks .
A few of these modalities have already been explored in practice , showing promising results .
However , the elicited combination of pen , touch , and speech , together with mouse and keyboard , has not yet been implemented and evaluated .
The MMPE Prototype
We present the MMPE prototype ( see Figure 1 ) which combines these modalities for PE of MT .
A more detailed description of the prototype can be found in Herbig et al . ( 2020 ) , and a video demonstration is available at https://youtu.be/ H2YM2R8Wfd8 .
Apparatus & Overall Layout
On the software side , we decided to use Angular for the frontend , and node .
js for the backend .
As requested in Herbig et al . ( 2019a ) , we use a large tiltable touch & pen screen for the study ( see Figure 1 b ) : the Wacom Cintiq Pro 32 inch display with the Flex Arm that allows the screen to be tilted and moved flat on the table , or to be moved up to work in a standing position .
We further use the Sennheiser PC 8 Headset for speech input .
The goal of this hardware setup was to limit induced bias as much as possible , in order to get results on the modalities and not on a flawed apparatus .
We implemented a horizontal source-target layout ( see Figure 1a ) , where each segment 's status ( unedited , edited , confirmed ) is visualized between source and target .
On the far right , support tools are offered as requested in Herbig et al . ( 2019a ) : ( 1 ) the unedited MT output , to which the users can revert their editing using a button , and ( 2 ) a corpus combined with a dictionary .
The current segment is enlarged , thereby offering space for handwritten input and allowing the user to view a lot of context while still seeing the current segment in a comfortable manner ( Herbig et al . ( 2019a ) ; see Figure 1a ) .
The view for the current segment is further divided into the source segment ( left ) and two editing planes for the target , one for handwriting and drawing gestures ( middle ) , and one for touch deletion & reordering , as well as standard mouse and keyboard input ( right ) .
Both initially show the MT proposal and synchronize on changes to either one .
The reason for having two editing fields instead of only one is that some interactions are overloaded , e.g. , a touch drag can be interpreted as both handwriting ( middle ) and reordering ( right ) .
Undo and redo functionality , as well as confirming segments , are also implemented through buttons between the source and target texts , and can further be triggered through hotkeys .
The target text is spell-checked , as a lack of this feature was criticized in Teixeira et al . ( 2019 ) .
Left Target View : Handwriting
For handwriting recognition ( see Figure 1 c ) , we use the MyScript Interactive Ink SDK .
Apart from merely recognizing the written input , it offers gestures 2 like strike - through or scribble for deletions .
For inserting words , one can directly write into an empty space , or create such a space first by breaking the line ( draw a long line from top to bottom ) , and then handwriting the word .
All changes are immediately interpreted , i.e. , striking through a word deletes it immediately , instead of showing it in a struck - through visualization .
The editor further shows the recognized text immediately at the very top of the drawing view in a small gray font , where alternatives for the current recognition are offered .
Apart from using the pen , the user can also use his / her finger or the mouse on the left - hand editing view for handwriting .
Right Target View : Touch Reordering , Mouse & Keyboard
On the right - hand editing view , the user can delete words by simply double - tapping them with pen / finger touch , or reorder them through a simple drag and drop procedure ( see Figure 1d ) , which visualizes the picked - up word as well as the current drop position , and automatically fixes spaces between words and punctuation marks .
This reordering functionality is strongly related to Teixeira et al . ( 2019 ) ; however , only the currently dragged word is temporarily visualized as a tile to offer better readability .
Naturally , the user can also edit using mouse and keyboard , where all common navigation inputs work as expected from other software .
Speech Input
For speech recognition , we stream the audio recorded by the headset to IBM Watson servers to receive a transcription , which is then analyzed in a command - based fashion .
Thus , our speech module not only handles dictations as in Teixeira et al . ( 2019 ) , but can correct mistakes in place .
As commands , the user has the option to " insert " , " delete " , " replace " , and " reorder " words or subphrases .
To specify the position , if it is ambiguous , one can define anchors as in " after " / " before " / " between " , or define the occurrence of the entity ( " first " / " second " / " last " ) .
A full example is " insert A after second B " , where A and B can be words or subphrases .
Character - level commands are not supported , so instead of e.g. deleting a suffix , one should replace the word .
Multi-Modal Combinations
Last , the user can use a multi-modal combination , i.e. , pen / touch / mouse combined with speech .
For this , the cursor first needs to be positioned on or next to a word , or the word needs to be long-pressed with pen / touch , resulting in a pickup visualization .
Afterwards , the user can then use a simplified voice command like " delete " , " insert A " , " move after / before A / between A and B " , or " replace by A " without needing to specify the position / word .
Logging
In a log file , we store all concrete keypresses , touched pixel coordinates , etc .
Much more importantly , we directly log all UI interactions ( like seg-mentChange ) , as well as all text manipulations ( like replaceWord ) together with the concrete changes ( e.g. with the oldWord , newWord , and complete segmentText ) .
Evaluation Method
The prototype was evaluated by professional translators 3 . We used EN - DE text , as our participants were German natives and we wanted to avoid ASR recognition errors as reported in Dragsted et al . ( 2011 ) .
In the following , " modalities " refers to Touch ( T ) , Pen ( P ) , Speech ( S ) , Mouse & Keyboard ( MK ) , and Multi-Modal combinations ( MM , see Section 3.5 ) , while " operations " refers to Insertions , Deletions , Replacements , and Reorderings .
The experiment consisted of the following phases and took approximately 2 hours per participant : 4.1 Introduction & Independent PE First , participants filled in a questionnaire capturing demographics as well as information on CAT usage .
Then the experimenter introduced all of the prototype 's features in a prepared order to ensure a similar presentation for all participants .
After that , participants were given 10 - 15 minutes to explore the prototype on their own .
We specifically told them that we are more interested in them exploring the presented features than in receiving high-quality translations .
This phase had two main purposes : ( 1 ) to let the participants become familiar with the interface ( e.g. , how best to hold the pen ) and to resolve questions early on ; ( 2 ) to see how participants intuitively work with the prototype .
Two experimenters carefully observed the participants and took notes on interesting behavior and questions asked .
Feature -Wise & General Feedback
The central part of the study was a structured test of each modality for each of our four operations .
For this , we used text from the WMT news test set 2018 .
Instead of actually running an MT system , we manually introduced errors into the reference set to ensure that there was only a single error per segment .
Overall , four sentences had to be corrected per operation using each modality , which results in 4 ? 4 ? 5 = 80 segments per participant .
Within the four sentences per operation , we tried to capture slightly different cases , like deleting single words or a group of words .
For this , we adapted the prototype , such that a pop-up occurs when changing the segment , which shows ( 1 ) the operation to perform and which modality to use , ( 2 ) the source and the " MT " , which is the reference with the introduced error , as well as ( 3 ) the correction to apply , which uses color , bold font , and strike - through to easily show the required change to perform .
The reason why we provided the correction to apply was to ensure a consistent editing behavior across all participants , thereby making subjective ratings and feedback as well as time measurements comparable .
The logging functionality was extended , such that times between clicking " Start " and confirming the segment were also logged .
To avoid ordering effects , the participants went through the operations in counter - balanced order , and through the modalities in random order .
After every operation ( i.e. , after 4 ? 5 = 20 segments ) and similar to Herbig et al . ( 2019a ) , participants rated each modality for that operation on three 7 point Likert scales ranging from " strongly disagree " to " strongly agree " , namely as to whether the interaction " is a good match for its intended purpose " , whether it " is easy to perform " , and whether it " is a good alternative to the current mouse and keyboard approach " .
Furthermore , we asked the translators to give us their thoughts on advantages and disad-vantages of the modalities , and how they could be improved .
Afterward , participants further had to order the 5 modalities from best to worst .
In the end , after completing all 80 segments , we performed a final unstructured interview to capture high - level feedback on the interface as well as things we missed in our implementation .
Remarks Regarding Methodology
While a direct comparison to state- of- the - art CAT tools would be interesting , the results would be highly questionable as the participants would be expert users of their day - to - day tool and novice users of our tool .
Furthermore , the focus of our prototype was on the implemented modalities , while widely used features like a TM or consistency checker are currently missing .
Since our main question was whether the newly implemented features have potential for PE of MT or not , we focus on qualitative feedback , ratings , and timing information , which is more relevant to this research question .
Evaluation Results and Discussion
In this section , we present and discuss the study 's main findings .
Participants Overall , 11 ( f=10 , m=1 , 2 left-handed ) professional EN - DE translators participated in the experiment , 3 freelance and 8 in- house translators .
Their ages ranged from 30 to 64 ( avg = 41.6 , ?=9.3 ) 4 , with 3 to 30 years of professional experience ( avg =13.3 , ?=7.4 ) and a total of 27 language pairs ( avg =2.6 ) .
All translators translate from EN to DE , and all describe their German Language skills as native and their English skills as C1 to native level .
For most participants , the self- rated CAT knowledge was good ( 6 times ) or very good ( 4 times , 1 neutral ) .
However , participants were less confident about their PE skills ( 4 neutral , 4 good , 3 very good ) , thereby matching well with the CAT usage surveys .
Years of experience with CAT tools ranged from 3 to 20 ( avg = 11.5 , ?=5.1 ) , where participants had used between 1 and 10 distinct CAT tools ( avg =4.9 , ?=2.7 ) .
Subjective Ratings
Figure 2 shows the subjective ratings provided for each modality and operation on the three scales " Goodness " , " Ease of use " , and " Good alternative to mouse & keyboard " after having tested each feature ( see Section 4.2 ) .
As can be seen , participants tended to give similar ratings on all three scales .
For insertions and replacements , which required the most text input , the classical mouse & keyboard approach was rated highest ; however , the multi-modal combination and speech were also perceived as good , while pen and especially touch received lower scores .
For deletions and reorderings , pen , touch , and mouse & keyboard were all perceived as very good , where P and T were ranked even slightly higher than MK for reorderings .
Speech and multi-modal were considered worse here .
Orderings
After each operation , participants ordered the modalities from best to worst , with ties being allowed .
As an example , for " MM & S best , then P , then MK , and last T " we assigned 0.5 times the 1 st and 0.5 times the 2 nd position to both MM and S , while P got 3 rd , MK 4 th , and T the 5 th position .
To get an overall ordering across participants , we then multiplied the total amount of times a modality was rated 1 st /2 nd /3 rd / 4 th / 5 th by 1/2/3/4/5 ( similar to Zenner and Kr?ger ( 2017 ) ) .
Consequently , a lower score indicates that this modality is better suited for the operation .
The scores for each modality and operation are : ? Insertions : 1 st : MK ( 20.5 ) , 2 nd : MM ( 26.5 ) , 3 rd : S ( 31.5 ) , 4 th : P ( 38.5 ) , 5 th : T ( 48 ) ? Deletions : 1 st : P ( 21.5 ) , 2 nd : MK ( 29 ) , 3 rd : T ( 31.5 ) , 4 th : MM ( 41 ) , 5 th : S ( 42 ) ?
Replacements : 1 st : MK ( 21 ) , 2 nd : MM ( 29 ) , 3 rd : S ( 30 ) , 4 th : P ( 35 ) , 5 th : T ( 50 ) ?
Reorderings : 1 st : P ( 21.5 ) , 2 nd : T ( 31 ) , 3 rd : S ( 35.5 ) , 4 th : MK ( 36 ) , 5 th : MM ( 41 )
Timings
We analyzed the logged duration of each modalityoperation pair .
Note that this is the time from clicking " Start " until confirming the segment ; thus , it includes recognition times ( for speech and handwriting ) and really measures how long it takes until a participant is satisfied with the edit .
Even though participants were instructed to provide feedback or ask questions only while the popup is shown , i.e. , while the time is not measured , participants infrequently did so during editing .
We filtered out such outliers and averaged the 4 sentences of each modality -operation pair per participant to get a single value , thereby making the samples independent for the remaining analyses .
Figure 3 shows boxplots of the dataset for the 20 modality -operation pairs .
For statistical analysis , we first conducted Friedman tests per operation , showing us that significant differences exist for each operation ( all p < 0.001 ) .
Afterward , posthoc analyses using Wilcoxon tests with Bonferroni- Holm correction showed which pairs of modalities are significant and how large the effect r is .
For insertions , MK was by far the fastest modality , followed by MM and S. All differences except for MM vs .
S and T vs .
P are statistically significant with large effect sizes ( all p < 0.01 , all r > 0.83 ) .
As expected , deletions were faster than insertions .
Here , MK , T , and P were the fastest , followed by S ; MM was slowest by far .
Regarding significance , all modalities were significantly faster than MM , and MK was significantly faster than S ( all p < 0.01 , all r > 0.88 ) .
For reordering , P and T were the fastest , followed by MK and S .
The statistical analysis revealed that T is significantly faster than all modalities except P , both P and MK are significantly faster than S , and S is significantly faster than MM ( all p < 0.05 , all r > 0.83 ) .
Replacements with MK were the fastest , followed by P , T , S , and MM .
MK was significantly faster than all other modalities , and P significantly faster than S and MM ( all p < 0.05 , all r > 0.83 ) , while no significant differences exist between the other three .
Qualitative Analysis
Apart from the ratings and timings , we present the main qualitative feedback from the interviews .
Pen & Touch Especially for short insertions and replacements , handwriting was seen as a suitable input mode ; for more extended changes , one should instead fall back on typing or dictation .
Both touch / pen deletion mechanisms ( strike - through and doubletap ) and touch / pen reordering were highlighted as very useful or even " perfect " as they " nicely resemble a standard correction task " .
Most participants seemed to prefer the pen to finger handwriting for insertions and replacements due to its precision , although it was considered less direct .
? ? ? ? ? ? ? ? ? ? ? ? P?Good P?Ease P?Alt T?Good T?Ease T?Alt S?Good S?Ease S?Alt MK ?
Good MK ?
Ease MM?
Good MM ?
Ease MM?Alt P?Good P?Ease P?Alt T?Good T?Ease T?Alt S?Good S?Ease S?Alt MK ?
Good MK ?
Ease MM ?
Good MM ?
Ease MM ?
Alt
A major concern was thinking about and creating sufficient space to handwrite into .
A suggested improvement was to make the available space configurable to one 's own handwriting .
Furthermore , placing the palm of the hand on the screen should not be interpreted as input .
Six participants also noted that the text jumps around when reordering a word from the end of a line , as the picked - up word is removed from the text , resulting in all remaining words being moved to the front , which could be prevented by adapting the text only on drop .
Speech & Multi-Modal Combinations
Perceptions regarding speech recognition were somewhat mixed , with some thinking it worked " super " while two participants found it exhausting to formulate commands while mentally working with text .
Furthermore , speech was considered impractical for translators working in shared offices .
Both insertions and replacements using speech received lots of positive feedback ( from 8 and 7 participants , respectively ) , interesting findings being that " the longer the insertion , the more interesting speech becomes " .
Speech deletion was considered to " work fine " and to be simpler than insertion as there is usually no need to specify the position .
However , it would be unsatisfactory to have to read 10 words to delete them .
The main advantage of the multi-modal ap- proach was that " one has to speak / think less " .
However , it was also argued that " when you talk , you can also just say everything " , meaning that the simplified MM command was not seen as an advantage for this participant .
An interesting statement was that " if there are no ambiguities , speech is better , but if there are , multi-modal is cool " .
Ideas on how to improve speech ranged from better highlighting the changes in the target view , to adding the possibility to restate the whole segment .
While the ASR tool used ( IBM Watson ) is one of the state - of- the- art APIs , it might still have negatively impacted the results for S and MM , as a few times a word was wrongly recognized ( e.g. , when replacing an ending , the ASR did not always correctly recognize the word form ) .
To improve this aspect , participants discussed the idea of passing the text to the speech recognition ( Dymetman et al. , 1994 ) or training the ASR towards the user .
Mouse & Keyboard
Due to daily usage , participants stated they were strongly biased regarding mouse and keyboard , where " the muscle memory " helps .
However , many actually considered MK as very unintuitive if they imagined never having used it before , especially compared to pen and touch , or as one participant stated for reordering : " why do I have to do all of this , why is it not as simple as the pen " .
General Feedback
In general , we received lots of positive feedback in the final discussion about the prototype , where participants made statements such as " I am going to buy this once you are ready " or expressed " respect for the prototype " .
Multiple participants reported that it would be nice to have multiple options to vary between the modalities .
It was frequently suggested to combine the two editing views , e.g. by having a switch to enable / disable the drawing mode .
Participants also commented positively on the large typeface for the current segment ( " you really see what you are working on " ) .
Suggestions for further improvements included adaptation possibilities for the size of the editing fields and a switch between vertical and horizontal source - target layout .
Discussion
This section discusses the main takeaways regarding each modality .
Pen According to ordering scores , subjective ratings , and comments , we see that the pen is among the best modalities for deletions and reordering .
However , other modalities are superior for insertions and replacements , where it was seen as suitable for short modifications , but to be avoided for more extended changes .
In terms of timings , P was also among the fastest for deletions and reorderings , and among the slowest for insertions .
What is interest-ing , however , is that P was significantly faster than S and MM for replacements , even though it was rated lower .
The main concern for handwriting was the need to think about space and to create space before actually writing .
Touch Results for touch were similar , but it was considered worse for insertions and replacements .
Furthermore , and as we expected due to its precision , pen was preferred to finger touch by most participants .
However , in terms of timings , the two did not differ significantly apart from replace operations , and even for replacements , where it was clearly rated as the worst modality , it actually turned out to be ( non-significantly ) faster than S and MM .
Speech & Multi-modal Combinations Speech and multi-modal PE were considered the worst and were also the slowest modalities for reordering and deletions .
For insertions and replacements , however , these two modalities were rated and ordered 2 nd ( after MK ) and in particular much better than P and T. Timing analysis agrees for insertions , being 2 nd after MK .
For replacements , however , S and MM were the slowest even though the ratings put them before P and T .
An explanation of why MM was slower than S for deletion is that our implementation did not support MM deletions of multiple words in a single command .
Still , we would have expected a comparable speed of MM and S for reordering .
Insertions are the only oper-ation where the multi-modal approach was ( nonsignificantly ) faster than S since the position did not have to be verbally specified .
Furthermore , the participants ' comments highlighted their concern regarding formulating commands while already mentally processing text .
Still , S and MM received a lot of positive feedback for insertions and replacements , where they would be more interesting the more text was to be added .
The main advantage of the MM approach , as argued by the participants , was that one has to speak less , albeit at the cost of doing two things at once .
Mouse & Keyboard Mouse & keyboard received the best scores for insertions and replacements , where it was the fastest modality .
Furthermore , it got good ratings for deletions and reorderings , where it was also fast ( but not the fastest ) for reordering .
However , some participants commented negatively , stating that it only works well because of " years of expertise " .
General Interestingly , our findings are not entirely in line with translators ' intuitions reported in our previous elicitation study ( Herbig et al. , 2019a ) : while touch worked much better than expected , handwriting of whole subphrases did not work as well as they thought .
Additionally , it is interesting to note that some newly introduced modalities could compete with mouse & keyboard even though participants are biased by years of training with the latter .
Overall , many participants provided very positive feedback on this first prototype combining pen , touch , speech , and multi-modal combinations for PE MT , encouraging us to continue .
Furthermore , several promising ideas for improving and extending the prototype have been proposed .
The focus of our study was to explore the implemented interactions in detail , i.e. , each modality for each operation irrespective of frequency .
The chosen methodology guaranteed that we receive comparable feedback on all interactions from professional translators by having them correct the same mistakes using different modalities .
Nevertheless , a more realistic " natural " workflow follow - up study should be conducted in the future , which will also show if participants swap modalities within sentences depending on the error type , or if they stick to single modalities to avoid frequent modality switches .
Conclusion
While more and more professional translators are switching to the use of PE to increase productivity and reduce errors , current CAT interfaces still heavily focus on traditional mouse and keyboard input , even though the literature suggests that other modalities could support PE operations well .
This paper therefore presents MMPE , a CAT prototype combining pen , touch , speech , and multi-modal interaction together with common mouse and keyboard input possibilities , and explores the use of these modalities by professional translators .
The study shows a high level of interest and enthusiasm for using these new modalities .
For deletions and reorderings , pen and touch both received high subjective ratings , with pen being even better than mouse & keyboard .
In terms of timings , they were also among the fastest for these two operations .
For insertions and replacements , speech and multimodal interaction were seen as suitable interaction modes ; however , mouse & keyboard were still favored and faster here .
As a next step , we will integrate the participants ' valuable feedback to improve the prototype .
While the presented study provided interesting first insights regarding participants ' use of and preferences for the implemented modalities , it did not allow us to see how they would use the modalities over a longer time period in day - to - day work , which we also want to investigate in the future .
Furthermore , participants in Herbig et al . ( 2019a ) were positive regarding the idea of a user interface that adapts to measured cognitive load , especially if it automatically provides additional resources like TM matches or MT proposals .
An exploration of multi-modal measuring approaches ( Herbig et al. , 2019 b ) shows the feasibility of this , so we will try to combine explicit multi-modal input , as done in this work , with implicit multi-modal sensor input to better model and support the user during PE .
( a) Screenshot of the interface .
( b) Apparatus .
( c ) Handwriting on left target view .
( d ) Touch reordering on right target view .
