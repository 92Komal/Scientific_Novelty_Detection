title
Neural Machine Translation System using a Content-equivalently Translated Parallel Corpus for the Newswire Translation Tasks at WAT 2019
abstract
This paper describes NHK and NHK Engineering System ( NHK - ES ) 's submission to the newswire translation tasks of WAT 2019 in both directions of Japanese ?
English and English ?
Japanese .
In addition to the JIJI Corpus that was officially provided by the task organizer , we developed a corpus of 0.22 M sentence pairs by manually , translating Japanese news sentences into English contentequivalently .
The content- equivalent corpus was effective for improving translation quality , and our systems achieved the best human evaluation scores in the newswire translation tasks at WAT 2019 .
Introduction
We participated in the newswire translation tasks with JIJI Corpus , one of the tasks in WAT 2019 ( Nakazawa et al. , 2019 ) .
JIJI Corpus , a Japanese - English news corpus , comes from Jiji Press news , which has various categories including politics , economy , nation , business , markets , and sports .
The newswire official tasks of WAT started in 2017 , and some participants and organizer had already submitted their translation results before WAT 2019 .
Their quality , however , has not been equivalent with that in other tasks , such as scientific paper tasks and patent tasks .
This is because of not only the small size ( 0.20M ) of the JIJI Corpus but also a significant amount of noise for the neural machine translation ( NMT ) system training .
The English news articles , which are generated as news - writing , not as translating , are mainly targeted at native English speakers , so information is often omitted or added .
Figure 1 shows an example from JIJI Corpus .
The omitted and added phrases become noise for the NMT training , and we consider this is one of the reasons for the low translation quality .
To solve this problem and improve the translation quality of an NMT system ,
Japanese sentence Content-equivalent translation of Japanese sentence : English Sentence ? ? ? ANA Sales Co. , a travel agency unit of ANA Holdings , organized the tour to meet requests from customers wanting to travel with their pets in the cabin .
Omitted Added Pets are usually kept in the cargo compartment in a plane .
A travel agency unit of the company organized to meet requests from customers wanting to travel with their pets in the cabin .
we are making a corpus with content-equivalent English translations of Japanese Jiji Press news , i.e. translations that do not omit and add information .
We called the corpus Equivalent - JIJI Corpus 1 .
In this system description paper , we focus on these two styles of news parallel data , called the JIJI Corpus and the Equivalent - JIJI Corpus , and we named their styles the JIJI -style and the Equivalent -style , respectively .
For WAT 2019 , we submitted two translation results using translation systems adapted to the JIJI -style .
In addition , to confirm the effectiveness of the content-equivalent translation , we submitted two more translation results using translation systems adapted to the Equivalent -style .
Results showed that although our NMT systems adapted to the Equivalent -style scored lower than that adapted to the JIJI - style in the automatic evaluation , their scores reversed in the human evaluation .
( Sennrich et al. , 2016 b ) .
This corpus is used for Japanese ?
English translation only .
We named this parallel data BT - JIJI Corpus .
For the back - translation , we used our best English ?
Japanese system adapted to the JIJIstyle .
Finally , we used another newspaper parallel corpus originating from the Yomiuri Shimbun , which we named Aligned - Yomiuri Corpus .
Aligned -Yomiuri Corpus is made with a parallel sentence similarity score , as is the case of JIJI Corpus .
Table 1 summarizes the detail of each corpus .
Domain Adaptation Techniques
In this paper , we used a domain-adaptation technique to train a model adapted to the JIJIand Equivalent -style .
The multi-domain method ( Chu et al. , 2017 ; Sennrich et al. , 2016a ) is one of the most effective approaches to leverage out-ofdomain data .
Chu et al. ( 2017 ) proposed training an NMT system with multi-domain parallel corpora using domain tags such as " < domain-name > " attached to the respective corpora .
We used domain adaptations with the names of the styls as domain tags .
We used a " < JIJI -style > " tag for the JIJI , Aligned - JIJI , and BT - JIJI corpora and a " < Equivalent-style > " tag for Equivalent - JIJI Corpus .
In addition , we used a " < YOMIURI -style > " tag for Aligned - Yomiuri Corpus because it comes from a newspaper other than Jiji Press news .
Experiments
In this study , we verified the effectiveness of the Equivalent -style translation through the following procedures .
Firstly , we trained the multiple NMT models with different combinations of five corpora as shown in Table 1 , and evaluated these NMT models with an official test-set , in which the number of data was 2000 .
Then , we evaluated these NMT models with a further test-set , in which the number of data was 1764 , extracted from Equivalent - JIJI Corpus of Equivalent -style in contrast to the official test-set extracted JIJI Corpus in JIJI -style .
Finally , we evaluated the effectiveness of the Equivalent -style translation .
Data Processing and System Setup All of the datasets were preprocessed as follows .
We used the Moses toolkit 2 to clean and tokenize the English data and used KyTea ( Neubig et al. , 2011 ) to tokenize the Japanese data .
Then , we used a vocabulary of 32 K units based on a joint source and target byte-pair encoding ( BPE ) ( Sennrich et al. , 2016 c ) .
For the translation model , we used the encoder and decoder of the transformer model ( Vaswani et al. , 2017 ) , which is a state of the art NMT model .
The transformer model uses a multi-headed attention mechanism applied as self-attention and a position - wise fully connected feed -forward network .
The encoder converts the received source language sentence into a sequence of continuous representations , and the decoder generates the target language sentence .
We implemented our systems with the Sockeye toolkit ( Hieber et al. , 2018 ) , and trained them on one Nvidia P100 Tesla GPU .
While training our models , we used the stochastic gradient descent ( SGD ) with Adam ( Kingma and Ba , 2015 ) as the optimizer , using a learning rate of 0.0002 , multiplied by 0.7 after every eight checkpoints .
We set the batch size to 5000 tokens and maximum sentence length to 99 BPE units .
For the other hyperparameters of our models , we used the default parameter values of Sockeye .
We used early stopping with a patience of 32 .
Decoding was performed with a beam search with a beam size of 5 , and we did not apply an ensemble decoding with multiple models , although this could possibly improve the translation quality , though we used a beam search with a beam size of 30 and an ensemble of ten models when submitting the official results .
To evaluate translation quality , we used BLEU ( Papineni et al. , 2002 ) . BLEU is calculated using multi-bleu.perl 3 . We report case-sensitive scores .
Results
Tables 2 and 3 show the experimental results .
The Training corpus column shows the corpora used for training .
The Style column shows the tag used for translation , i.e. the JIJI - or Equivalent -style .
The JIJI - style test-set is equal to the official testset in the newswire task of WAT 2019 .
Trained with Different Combinations of Five Corpora
The JIJI - style test-set column of Tables 2 and 3 shows the translation quality of the JIJI - style testsets with the BLEU metric for different combinations of the five corpora .
For the models without domain adaptation , where Domain adaptation column is " No , " the BLEU scores are improved by adding the other domains ' data into the JIJI Corpus .
For the JIJI -style Japanese ?
English testset , the BLEU scores are higher with the use of tags for the domain adaptation .
However , the use of the domain adaptation is not effective for the JIJI - style English ?
Japanese test-set .
This seems to be due to the different origins of the target-side sentences in the Equivalent - JIJI Corpus .
Japanese sentences in the Equivalent - JIJI Corpus come from the Japanese Jiji Press news , the same as for JIJI Corpus .
In contrast , the English sentences in Equivalent - JIJI Corpus does not come from Jiji Press news .
It appears that the use of different domain tags is less effective when using the same-origin data for the target - side as shown in the fourth and fifth columns of Table 1 .
In the case of Japanese ?
English task with JIJI Corpus and Equivalent - JIJI Corpus , the origin of the target- side English sentences differs between the two corpora ( JIji Press news and Contentequivalent translation ) despite the origin of the source -side is being the same ( Jiji Press news ) , so the NMT system cannot decide which style , JIJIor Equivalent -style , should be output .
In contrast , no choice is necessary for the English ?
Japanese task because the target- side Japanese sentences is the same origin ( Jiji Press news ) .
The Equivalent - style test-set column in Tables 2 and 3 shows translation quality of the Equivalent -style test-sets .
For the models without domain adaptation , the BLEU scores are not improved by adding the other domains ' data into the Equivalent - JIJI Corpus in case of the Japanese ?
English task .
The domain adaptation using tags is extremely effective for the Japanese ?
Engish task .
Although the amount of Equivalent - style data is much smaller than that of JIJI - style data , the BLEU scores for the Equivalent - style test -set are higher than those for the JIJI - style test-set .
In particular , the BLEU scores of the Equivalent - style test-set for the English ?
Japanese are over 43 .
It appears that it is more difficult to improve the translation quality for the JIJI - style test-set than for the Equivalentstyle test-set because the JIJI - style test-set includes noise for training the NMT system .
Translation with Different Types of Systems Supposing that JIJI Corpus includes noise , the NMT system adapted to the Equivalent - style seems to be a better system to translate news generally .
However , the BLEU scores for the JIJI - style test-set trained with Equivalent - JIJI Corpus are 9.15 for Japanese ?
English and 17.92 for English ?
Japanese and they are lower than the scores for the test-set trained with JIJI Corpus , as shown in Tables 2 and 3 .
To determine whether or not the translation systems adapted to the Equivalent - style are better for human evaluation than those adapted to the JIJI -style , we submitted the translated results with both of the translation systems adapted to JIJI - and Equivalentstyle .
Official Results
We used the bottom translation systems of Tables 2 and 3 for submitting to WAT 2019 .
These systems can be adapted to each style by attaching domain tags , " < JIJI -style > " for JIJI - style translation and " < Equivalent-style > " for Equivalentstyle translation , at the top of the source sentence .
To improve the translation quality further , we submitted the translation results with an ensemble decode of ten models and a beam search with a beam size of 30 .
Table 4 shows the official results of our submission to WAT 2019 .
Our systems adapted to JIJI - style achieved the best BLEU and RIBES scores .
In contrast , for the pairwise crowdsourcing evaluation and the JPO adequacy evaluation 4 , our systems adapted to the Equivalent -style achieved the best evaluation .
For the AMFM , our system Example sentence BLEU Source ? ? Content-equivalent
After the meeting , Akamatsu emphasized to the press , " We will hear opinions translation of the public in a fair and equitable manner , " and Eda said , " We will accept the results of the objective investigation . "
Reference
After the meeting , Akamatsu told reporters , " We will seek the views of the public ( JIJI Corpus ) in a fair and equitable manner . "
NMT output After the meeting , Akamatsu told reporters that he will listen to public opinions 51.61 adapted to JIJI - style in a fair and equitable manner .
NMT output adapted After the meeting , Akamatsu emphasized to the press , " We will listen to the opinions 22.70 to Equivalent - style of the people in a fair and fair manner , " and Eda said , " We will accept the results of the investigation objectively . "
Source ?
Content-equivalent
It is expected to be passed and enacted at a plenary session of the House of translation Councilors in the afternoon of the same day .
Reference
The House of Councillors , the upper chamber of the Diet , approved the spending ( JIJI Corpus ) program at a plenary meeting on Monday afternoon after the House of Representatives , the lower chamber , passed it earlier in the day .
NMT output
The House of Councillors , the upper chamber , is expected to approve the bill 26.33 adapted to JIJI - style at a plenary meeting later in the day .
NMT output adapted
It is expected to be passed and enacted at the plenary session of the House of 0.00 to Equivalent -style Councilors in the afternoon of the same day .
adapted to the JIJI - style achieved the best evaluation for the Japanese ?
English task , whereas our system adapted to the Equivalent -style achieved the best evaluation for the English ?
Japanese task .
These results show that the NMT systems adapted to the Equivalent - style are generally better systems for translating the news .
The overview paper for WAT 2019 gives the details of our submission including the other WAT participants ' results .
Further Human Evaluation Apart from the official pairwise crowdsourcing evaluation and JPO adequacy evaluation , we also evaluated our official submission independently with a translation company to analyze deeply the official results .
We randomly selected 300 and 50 sentences from the Japanese ?
English and English ?
Japanese official test-sets respectively , and three evaluators counted the number of omitted and added words in the NMT outputs adapted to the JIJI - and Equivalent -styles .
Table 6 shows the average number of words per 100 words of the three evaluators .
These results indicate that the NMT systems adapted to the Equivalent - style can prevent the omission and addition of information .
Table 5 shows the examples of NMT outputs adapted to the JIJI - and Equivalent -styles in the official tasks .
The first example shows omitted information , and the second example shows added information in the NMT output adapted to the JIJI -style .
The references also include omitted and added information .
The NMT output adapted to the Equivalent -style is translated without omitted and added information .
The sentence BLEU scores of outputs adapted to the JIJI - style NMT are higher than those of outputs adapted to the Equivalent - style NMT .
These results indicate that NMT outputs adapted to the JIJI - style often include the omission and addition of information , and these cause the worse human evaluation .
This seems to be a reason that our systems adapted to the Equivalent -style , which prevent the omission and addition of information , achieved the best human evaluation in spite of the lower BLEU scores .
Conclusions
In this description paper , we presented our NMT systems adapted to the JIJI - and the Equivalentstyles .
In addition to the JIJI Corpus in the JIJIstyle that was officially provided by the WAT 2019 organizer , we developed a corpus of 0.22 M sentence pairs in the Equivalent - style by manually , content - equivalently translating Japanese news sentences into English .
We obtained the state- of- the - art results for the newswire tasks of WAT 2019 .
In our four submissions , the translation models adapted to the JIJI - style achieved the best results for the BLEU evaluation .
In contrast , the translation models adapted to the Equivalentstyle achieved the best results for the pairwise crowdsourcing evaluation and JPO adequacy evaluation .
We showed that the content-equivalently translated data is effective for the widespread news translation from the perspective of a human evaluation .
Figure 1 : 1 Figure 1 : Example of a Japanese -English parallel sentence pair in JIJI Corpus .
Contents of the underlined parts are not contained in the other language .
Table 2 : 2 BLEU scores for Japanese ?
English translation tasks .
Num. of Domain Tag JIJI - style Equivalent -
Table 3 : 3 BLEU scores for English ?
Japanese translation tasks .
Table 4 : 4 Official results for the newswire translation tasks of WAT 2019 : For JIJI - EJ task , we show the BLEU , RIBES , and AMFM scores with KyTea tokenizer .
Task Tag ( Style ) BLEU Rank RIBES Rank AMFM Rank Pairwise Rank Adequacy Rank JIJI -JE JIJI-style 26.83 1/4 0.70 1/4 0.55 1/4 72.00 2/4 - - Equivalent-style 14.23 4/4 0.61 4/4 0.53 3/4 89.00 1/4 4.55 1/2 JIJI -EJ JIJI-style 29.76 1/4 0.74 1/4 0.65 2/4 81.25 2/4 - - Equivalent-style 28.75 2/4 0.73 2/4 0.66 1/4 87.75 1/4 4.11 1/2
Table 5 : 5 Example results of JIJI - JE tasks translated with JIJI - and Equivalent - style NMT Omitted - Added - Task Tag ( Style ) words words JIJI -JE JIJI -style 18.40 9.39 Equivalent-style 4.27 1.44 JIJI -EJ JIJI-style 28.19 13.16 Equivalent-style 8.22 2.55
Table 6 : 6 Further human evaluation results , which is the average number of words per 100 words .
Equivalent - JIJI Corpus is still under construction and will be completed at the end of March 2021 .
https://github.com/moses-smt/ mosesdecoder
https://github.com/moses-smt/mosesdecoder/blob/ master/scripts/generic/multi-bleu-detok.perl
WAT 2019 organizer selected submissions for JPO adequacy evaluation , and only one submission for each task was evaluated .
