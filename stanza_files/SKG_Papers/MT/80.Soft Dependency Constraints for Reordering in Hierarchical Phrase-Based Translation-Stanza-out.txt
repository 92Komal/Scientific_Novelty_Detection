title
Soft Dependency Constraints for Reordering in Hierarchical Phrase -Based Translation
abstract
Long-distance reordering remains one of the biggest challenges facing machine translation .
We derive soft constraints from the source dependency parsing to directly address the reordering problem for the hierarchical phrasebased model .
Our approach significantly improves Chinese-English machine translation on a large-scale task by 0.84 BLEU points on average .
Moreover , when we switch the tuning function from BLEU to the LRscore which promotes reordering , we observe total improvements of 1.21 BLEU , 1.30 LRscore and 3.36 TER over the baseline .
On average our approach improves reordering precision and recall by 6.9 and 0.3 absolute points , respectively , and is found to be especially effective for long-distance reodering .
Introduction Reordering , especially movement over longer distances , continues to be a hard problem in statistical machine translation .
It motivates much of the recent work on tree- based translation models , such as the hierarchical phrase - based model ( Chiang , 2007 ) which extends the phrase - based model ( Koehn et al. , 2003 ) by allowing the so-called hierarchical phrases containing subphrases .
The hierarchical phrase - based model captures the recursiveness of language without relying on syntactic annotation , and promises better reordering than the phrase - based model .
However , Birch et al. ( 2009 ) find that although the hierarchical phrasebased model outperforms the phrase - based model in terms of medium - range reordering , it does equally poorly in long-distance reordering due to constraints to guarantee efficiency .
Syntax - based models that use phrase structure constituent labels as non-terminals in their transfer rules , exemplified by that of Galley et al . ( 2004 ) , produce smarter and syntactically motivated reordering .
However , when working with off - the-shelf tools for parsing and alignment , this approach may impose harsh limits on rule extraction and requires serious efforts of optimization ( Wang et al. , 2010 ) .
An alternative approach is to augment the general hierarchical phrase - based model with soft syntactic constraints .
Here , we derive three word- based , complementary constraints from the source dependency parsing , including : ?
A dependency orientation feature , trained with maximum entropy on the word-aligned parallel data , which directly models the headdependent orientation for source words ; ?
An integer-valued cohesion penalty that complements the dependency orientation feature , and fires when a word is not translated with its head .
It measures derivation well - formedness and is used to indirectly help reordering ; ?
An auxiliary unaligned penalty feature that mitigates search error given the other two features .
We achieve significant improvements in terms of the overall translation quality and reordering behavior .
To our knowledge we are the first to use the source dependency parsing to target the reordering problem for hierarchical phrase - based MT .
( Chiang , 2007 ) .
Three Soft Dependency Constraints
Our features are based on the source dependency parsing , as shown in Figure 1 .
The basic unit of dependency parsing is a triple consisting of the dependent word , the head word and the dependency relation that connects them .
For example , in Figure 1 , an arrow labelled prep goes from the word yu ( English with ) to the word you ( English have ) , showing that yu is a prepositional modifier of you .
We use the Stanford Parser 1 to generate dependency parsing , which automatically extracts dependency relations from phrase structure parsing ( de Marneffe et al. , 2006 ) .
Dependency Orientation Based on the assumption that constituents generally move as a whole ( Quirk et al. , 2005 ) , we decompose the sentence reordering probability into the reordering probability for each aligned source word with respect to its head , excluding the root word at the top of the dependency hierarchy which does not have a head word .
Similarly , Hayashi et al. ( 2010 ) also take a word- based reordering approach for HPBMT , but they model all possible pairwise orientation from the source side as a general linear ordering problem ( Tromble and Eisner , 2009 ) .
To be more specific , we have a maximum entropy orientation classifier that predicts the probability of a source word being translated in a monotone or reversed manner with respect to its head .
For example , 1 http://nlp.stanford.edu/software/lex-parser.shtml given the alignment in Figure 2 ( a ) , with the alignment points ( i dep , j dep ) for the source dependent word and ( i head , j head ) for the source head word , we define two orientation classes as : ( a ) ( b) S 1 S 2 S 3 S 1 S 2 S 3 T 1 T 1 T 2 T 2 T 3 T 3 T 4 T 4 i head i dep i dep i head c = R if ( j dep ? j head ) ( i dep ?
i head ) < 0 M otherwise ( 1 ) When a source head or dependent word is aligned to multiple target words , as shown in Figure 2 ( b ) , we always take the first target word for orientation classification .
The orientation classifier is trained on the large word-aligned parallel corpus .
Various features can potentially be used , based on the source and target context as well as syntactic and semantic analysis .
The orientation probability is evaluated in the following log-linear equation , where f is the source context , d is the source dependency parsing , e * is the target context produced so far , a * is the alignment produced so far and c is the orientation class : c ?{ M , R} exp ( N n=1 ? n h n ( f , d , e * , a * , c ) ) ( 2 ) Currently , we only use two kinds of features : ( 1 ) the concatenation of the source dependent word with the dependency relation and ( 2 ) the concatenation of the source head word with the dependency relation .
So for the word yu ( English with ) in Figure 1 , we extract these features for orientation classification : prep DEP yu and prep HEAD you .
We define the dependency orientation feature score for a translation hypothesis as the sum of the log orientation probabilities for each source word .
This score is used as one feature in the log-linear formulation of the hierarchical phrase - based model .
Table 1 shows the dependency orientation probabilities for all words in the Figure 1 sentence .
Most interestingly , the orientation probabilities for you ( English have ) strongly support global reordering of one of the few countries with the relative clause that have diplomatic relations with North Korea .
We find that it is a general trend for long-distance reordering to gain stronger support , since it is often correlated with prominent reordering patterns ( such as relative clause and preposition ) as well as lexical evidences ( such as " ... zhiyi " ( English " one of ... " ) ) for which the reversed orientation takes up the majority of the training cases .
Consider the following rules ( both terminals and nonterminals are coindexed ) : X ? ( yu 1 Beihan 2 you 3 bangjiao 4 , have 3 dipl .
4 rels .
4 with 1 North 2 Korea 2 ) ( 3 ) X ? ( yu 1 Beihan 2 you 3 bangjiao 4 , with 1 North 2 Korea 2 have 3 dipl .
4 rels . 4 ) ( 4 ) According to Table 1 , the hypothesis that applies Rule 3 receives a probability of 0.55 for yu getting reversed with its head you , as well as 0.88 and 0.83 for translating Beihan and bangjiao in a monotone manner with respect to their heads .
Rule 4 is associated with probabilities 0.45 , 0.88 and 0.83 for monotone translation of yu , Beihan and bangjiao .
Thus our dependency orientation feature is able to trace the difference in ordering the PP with North Korea ( as underlined ) and the VP have dipl .
rels . down to the orientation of the preposition yu ( English with ) with respect to its head you ( English have ) , and promote Rule 3 which has the right word order .
The word you ( English have ) cannot be scored in Rules 3 or 4 , since its head word zhiyi ( English one of ) is not covered .
In this case , we say that the word you is unresolved .
We carry an unresolved word along in the derivation process until we reach a terminator hypothesis which translates the head word .
Then the resulting dependency orientation score is added to the terminator hypothesis .
This means that the dependency orientation feature is " stateless " , i.e. , hypotheses that cover the same source span with the same orientation information will receive the same feature score , regardless of the derivation history .
Therefore , Derivation 5 in the following will have the same dependency orientation score as Derivation ( Rule ) 3 , and Derivation 6 will score the same as Derivation ( Rule ) 4 . 5.1 X ? ( yu 1 , with 1 ) 5.2 X ? ( Beihan 1 , North 1 Korea 1 ) 5.3 X ? ( X 1 X 2 , X 1 X 2 ) 5.4 X ?
( X 1 you 2 bangjiao 3 , have 2 dipl .
3 rels . 3 X 1 ) ( 5 ) 6.1 X ? ( Beihan 1 you 2 , North 1 Korea 1 has 2 ) 6.2 X ?
( X 1 bangjiao 2 , X 1 dipl .
2 rels . 2 ) 6.3 X ? ( yu 1 X 2 , with 1 X 2 ) ( 6 )
Cohesion Penalty
When the dependency orientation for a word is temporarily unavailable ( " unresolved " ) , a cohesion penalty fires .
Cohesion penalty counts the total occurrences of unresolved words for a translation hypothesis , which involve newly encountered unresolved words as well as old unresolved words carried on from the derivation history .
Therefore , the cohesion penalty is " stateful " , i.e. , an unresolved word is repeatedly penalized until it gets resolved .
Under this definition , the most cohesive derivation translates the entire sentence with one rule , where every word is locally resolved .
The least cohesive derivation translates each word individually and glues word translations together .
Consulting Figure 1 , the cohesion penalty in Derivation 5 is 4 , since the word yu ( English with ) is unresolved twice ( in 5.1 and 5.3 ) , and both Beihan ( English North Korea ) and you ( English have ) are unresolved once ( in 5.2 and 5.4 , respectively ) ; the cohesion penalty in Derivation 6 is 5 : 2 from Beihan ( English North Korea ) ( in 6.1 and 6.2 ) and 3 from you ( English have ) .
As a result , Derivation 5 gets promoted , which echoes with human intuition since Derivation 5 translates syntactic constituents .
To sum up , our cohesion penalty provides an integer-valued measure of derivation well - formedness in the hierarchical phrase - based MT .
Same as dependency orientation , the cohesion penalty is not applicable to the root word of the sentence .
We propose the cohesion penalty in order to further improve reordering , especially in long-distance cases , since a well - formed derivation at an earlier stage makes it more likely to explore hierarchical rules that perform more reliable reordering .
In this respect , the cohesion penalty can be seen as an aid to the glue rule penalty and as an alternative to constituency - based constraints .
Specifically , the glue rule penalty ( Chiang , 2007 ) promotes hierarchical rules .
Hierarchical rules whose lexical evidence helps resolve words locally will also be favored by our cohesion penalty feature .
However , ignorant of the syntactic structure , the glue rule penalty may penalize a reasonably cohesive derivation such as Derivation 5 and at the same time promote a less cohesive hierarchical translation , such as Derivation 6 .
Compared with constituency constraints based on the phrase structure , our cohesion penalty derived from the binary dependency parsing has two different characteristics .
First , our cohesion penalty is by nature more tolerant to some meaningful noncontituent translations .
For example , constituency constraints in ( Chiang , 2005 ; Marton and Resnik , 2008 ; Chiang et al. , 2009 ) would penalize Rule 7 below which is useful for German-English translation ( Koehn et al. , 2003 ) , and Rule 8 which can be applied to the Figure 1 sentence .
Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories ( Chiang , 2010 ) .
Yet our cohesion penalty by nature admits these translations as cohesive ( with no extra cost from es and Aozhou since both are locally resolved ) .
Admittedly , our current implementation of the cohesion penalty is blind to some other meaningful nonconstituent collocations , such as neighbouring siblings of a common uncovered head ( regulated as the " floating structure " in ( Shen et al. , 2008 ) ) .
A concrete example is Rule 9 which is useful for the Figure 1 sentence .
To address this problem , another feature can be defined in the same manner to capture how each head word is translated with its children .
X ? ( es 1 gibt 2 , there 1 is 2 ) ( 7 ) X ? ( Aozhou 1 shi 2 , Australia 1 is 2 ) ( 8 ) X ? ( shaoshu 1 guojia 2 , few 1 countries 2 ) ( 9 ) Second , our cohesion penalty can be by nature more discriminative .
Compared with the constituency constraints , the cohesion penalty is integer-valued , and can be made sensitive to the depth of each word in the dependency hierarchy ( see Section 2.4 ) .
Inspired by ( Marton and Resnik , 2008 ; Chiang et al. , 2009 ) , the cohesion penalty could also be made sensitive to the dependency relation of each word .
However , this drastically increases the number of features and requires a tuning algorithm which scales better to high- dimensional model spaces , such as MIRA ( Watanabe et al. , 2007 ; Chiang et al. , 2008 ) .
Unaligned Penalty
The dependency orientation and cohesion penalty cannot be applied to unaligned source words .
This may lead to search error , such as dropping ( i.e. , unaligning ) key content words that are important for lexical translation and reordering .
The problem is mitigated by an unaligned penalty applicable to all words in the dependency hierarchy .
Grouping Words into Bins Having defined dependency orientation , cohesion penalty and unaligned penalty , we section the source dependency tree uniformly by depth , group words at different depths into bins and only add the feature scores of a word into its respective bin .
In this way one feature is split into several sub-features and each can be trained discriminatively by MERT .
There are two motivations for binning .
The primary motivation is to distinguish long-distance reordering which is still problematic for the hierostyle model , since local reorderings generally operate at low levels of the tree while high tree levels tend to take more care of long-distance reordering .
Parsing accuracy is another concern , yet its impact on feature performance is intricate and our MaxEnt-trained dependency orientation feature also buffers against odd parsing .
Using bins , we simply let the tuning process decide how much to trust feature scores coming from different levels of parsing .
We experiment with 1 , 2 and 3 bins .
An example of binning for the Figure 1 sentence can be found in Figure 3 . With 2 bins ( hereafter " bin - 2 " ) , words at Depth 1 and 2 are grouped into Bin 1 , and words at Depth 3 , 4 , 5 are grouped into Bin 2 .
As a simple approach , binning does not take into account how the tree levels spread out .
Experiments
General Settings
We used a parallel training corpus with 2.1 million Chinese - English sentence pairs , aligned by GIZA ++.
The Chinese side was parsed by the Stanford Parser .
Then we extracted 33.8 million examples from the parsed Chinese side to discriminatively train 1.1 million features ( using the MegaM software 2 ) for dependency orientation classification .
We trained three 5 - gram language models with modified Kneser - Ney smoothing ( Kneser and Ney , 1995 ) : one on the English half of the parallel corpus , one on the Xinhua part of the Gigaword corpus , one on the AFP part , and interpolated them for best fit to the tuning set ( Schwenk and Koehn , 2008 ) .
We used NIST MT06 evaluation data ( 1664 lines ) as our tuning set , and tested on NIST MT02 ( 878 lines ) , MT05 ( 1082 lines ) and MT08 ( 1357 lines ) .
Our baseline system was the Moses implementation of the hierarchical phrase - based model with standard settings ( Hoang et al. , 2009 ) .
When only 1 bin was used , 3 additional features were added to the baseline , one each from the soft dependency constraints .
When we used 2 or 3 bins , the additional feature counts doubled or tripled .
We preserved terminal alignment alongside nonterminal alignment during the rule extraction and output word alignments together with translated strings .
Since the features we currently define are based entirely on the source side , we used preprocessing to speed up decoding of our feature - augmented model .
All experiments were tuned with MERT ( Och , 2003 ) .
Using BLEU as the Tuning Metric
As a standard practice , we first used BLEU ( Papineni et al. , 2002 ) as the objective function for tuning .
Table 2 shows the results of the baseline model as well as our complete feature - augmented model with different bin numbers .
With the " bin - 2 " setting , we get substantial improvement of up to 1.03 BLEU points ( on MT02 data ) , and 0.84 BLEU points on average .
Using more than one bin ( i.e. , differentiating tree depths ) is generally beneficial , although the 4 : Results for the baseline model and the complete feature - augmented model with 2 bins ( " bin - 2 " ) , using BLEU and LRscore ( " - lr " ) as the tuning function .
The BLEU scores of " bin - 2 " and " bin - 2 - lr " are significantly better than baseline ( p < 0.05 ) , computed by paired bootstrap resampling ( Koehn , 2004 ) .
3 : Contributions of the three soft dependency constraints , with the " bin - 2 " setting problem of overfitting sets in when we use 3 bins ( with slightly higher tuning BLEU , not shown here ) .
Setting
We also studied the effect of adding features incrementally onto the baseline with the " bin - 2 " setting , as shown in Table 3 .
On average , all three features seem to have similar contributions .
Using LRscore as the Tuning Metric Since our features are proposed to address the reordering problem and BLEU is not sensitive enough to reordering ( especially in long- distance cases ) , we have also tried tuning with a metric that highlights reordering , i.e. , the LRscore ( Birch and Osborne , 2010 ) .
LRscore is a linear interpolation of a lexical metric and a reordering metric .
We interpolated BLEU ( as the lexical metric ) with the Kendall 's tau permutation distance ( as the reordering metric ) .
The Kendall 's tau permutation distance measures the relative word order difference between the transla-tion output and the reference ( s ) and is particularly sensitive to long-distance reordering .
Testing results in terms of BLEU , LRscore and TER ( Snover et al. , 2006 ) are shown in Table 4 . Tuned with the LRscore , our feature - augmented model achieves further average improvements ( compare " bin - 2 " and " bin - 2 - lr " ) of 0.20 LRscore as well as 0.37 BLEU and 0.90 TER .
Note that while the BLEU increase can largely be seen as a projection of the LRscore increase back into its lexical component , the consistent TER drop confirms that our improvement is not metric-specific 3 . Altogether the final improvement is 1.21 BLEU , 1.30 LRscore and 3.36 TER on average over the baseline .
However , an important question is how our features affect short , medium and long-distance reorderings .
In the next section , we conduct quantitative analysis on reordering precision and recall , as well as qualitative analysis on translation examples .
Analysis
Precision and Recall of Reordering
The key to obtaining precision and recall for reordering is to investigate whether reorderings in the references are reproduced in the translations .
We calculate precision as the number of reproduced reorderings divided by the total number of reorderings in the translation , and recall as the number of reproduced reorderings divided by the number of reorder - ings in the reference .
Then we average the precision and recall over all four reference translations .
Details of measuring reproduced reordering can be found in Birch et al . ( 2008 ) .
An important difference in this work is in handling many - to- one and one- to -many alignments , as we only retain the first word alignment for any source or target word which has multiple alignments .
This is consistent with our treatment in dependency orientation classification , and results in more reorderings being extracted .
From Table 5 we can see that our features improve precision by an average of 4.7 absolute points when BLEU is used for tuning ( " bin - 2 " ) .
Switching from BLEU to the LRscore ( " bin - 2 - lr " ) , we gain 2.2 points more and have a total improvement of 6.9 absolute points on average .
This is a novel and important finding as we directly show that the quality of reordering has been improved .
From Table 6 , we observe a small but consistent increase in recall with the " bin - 2 - lr " setting , averaging 0.3 absolute points .
However , the drop of recall with the " bin - 2 " setting ( by an average 0.8 points from the baseline ) is unexpected .
It seems that when applying our features alone , we are trading a small drop in recall for a large gain in precision .
In Figure 4 we break down the precision and recall statistics in MT08 by the reordering width on the source side .
We find that our features consistently help precision over all word ranges , with more substantial improvement in the medium and long word ranges .
When recall is concerned , our model does not help for short ranges of up to Width 4 , but improves consistently for longer distance re- orderings .
Once again , it seems that the featureaugmented model is able to benefit from tuning with a metric that is more sensitive to reordering , as the performance of " bin - 2 - lr " is the best in all reordering statistics .
Translation Examples
We observe a number of outputs with improved word order and more cohesive derivation , as the one in Figure 5 .
The baseline translation is fragmented and requires more glue rule applications .
Specifically , it fails to translate the boxed area as a whole into " the relations between the palestinian national authority ( pna ) and the european union ( eu ) " .
The key dependency orientation that controls the global reordering is between the prepositional modifier dui ( English to ) and its head word , the verb gandao ( English feel ) .
The baseline system translates dui ( English to ) as " of the " and misorders the sentence .
In contrast , the feature - augmented model " bin - 2 " cap - tures the boxed area as a whole and uses Rule 10 to perform the right global reordering .
X ? ( dui 1 X 2 gandao 3 manyi 4 . 5 , expressed 3 satisfaction 4 with 1 X 2 . 5 ) ( 10 )
Related Work
In recent years , there has been a growing body of research on using dependency for statistical machine translation .
Some directly encodes dependency in the translation model ( Ding and Palmer , 2005 ; Quirk et al. , 2005 ; Xiong et al. , 2007 ; Shen et al. , 2008 ; Mi and Liu , 2010 ) , while others use dependency as a soft constraint ( Cherry , 2008 ; Bach et al. , 2009a , b ; Chang et al. , 2009 ) .
Among them , Shen et al . ( 2008 ) report that just filtering the phrase table by the socalled well - formed target dependency structure does not help , yet adding a target dependency language model improves performance significantly .
Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure : it is based on words and it directly connects head and child .
Therefore , the target dependency language model makes good use of the dependency representation as well as the target side training data .
We follow the second line of research , and derive three word - based soft constraints from the source dependency parsing .
Note that although we reuse the word " cohesion " to name one of the constraints , our work is different from ( Cherry , 2008 ; Bach et al. , 2009 a , b) which have successfully defined another cohesion constraint from the source depen-dency structure , with the aim of improving reordering in phrase - based MT .
To take a glance , Cherry ( 2008 ) and Bach et al . ( 2009 b ) define cohesion as translating a source dependency subtree contiguously into the target side without interruption ( span or subtree overlapping ) , following Fox ( 2002 ) .
This span-based cohesion constraint has a different criterion from our wordbased cohesion penalty and often leads to opposite conclusions .
Bach et al. ( 2009a ) also use cohesion to correlate with the lexicalized reordering model ( Tillman , 2004 ; Koehn et al. , 2005 ) , whereas we define an orthogonal dependency orientation feature to explicitly model head - dependent reordering .
The fundamental difference , however , is rooted in the translation model .
Their span-based cohesion constraint is implemented as an " interruption check " to encourage finishing a subtree before translating something else .
This check is very effective for phrase - based decoding which searches over an entire space within the distortion limit in order to advance a hypothesis .
In fact , it constrains reordering for the phrase - based model , as Cherry finds that the cohesion constraint is used " primarily to prevent distortion " and to provide " an intelligent estimate as to when source order must be respected " ( Cherry , 2008 ) .
However , since the hierarchical phrasebased model already conducts principled reordering search with rules through the more constrained chart- decoding , ill-formed derivations exhibit themselves more often as nonconstituent translation than interrupted translation as defined in ( Cherry , 2008 ; Bach et al. , 2009 a , b) ( They do have a non-empty intersection , but neither subsumes the other ) .
There - fore , our cohesion penalty is better suited for the hierarchical phrase - based model .
To discourage nonconstituent translation , Chiang ( 2005 ) has proposed a constituency feature to examine whether a source rule span matches the source constituent as defined by phrase structure parsing .
Finer-grained constituency constraints significantly improve hierarchical phrase - based MT when applied on the source side ( Marton and Resnik , 2008 ; Chiang et al. , 2009 ) , or on the target side in a more tolerant fashion ( Zollmann and Venugopal , 2006 ) .
Using both source and target syntax , but relaxing on rule extraction and substitution enables HPBMT to produce more well - formed and syntactically richer derivations ( Chiang , 2010 ) .
Softening constituency matching with latent syntactic distributions proves to be helpful ( Huang et al. , 2010 ) .
Compared to constituency - based approaches , our cohesion penalty based on the dependency structure naturally supports constituent translations as well as some nonconstituent translations , if not all of them ( as discussed in Section 2.2 ) .
Our dependency orientation feature is similar to the order model within dependency treelet translation ( Quirk et al. , 2005 ) .
Yet instead of a head-relative position number for each modifier word , we simply predict the head- dependent orientation which is either monotone or reversed .
Our coarser- grained approach is more robust from a machine learning perspective , yet still captures prominent and long-distance reordering patterns observed in Chinese -English ( Wang et al. , 2007 ) , German-English ( Collins et al. , 2005 ) , Japanese -English ( Katz-Brown and Collins , 2008 ) and translation from English to a group of SOV languages ( Xu et al. , 2009 ) .
Not committed to specific language pairs , we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney ( 2006 ) and Chang et al . ( 2009 ) for phrase - based translation and Xiong et al . ( 2006 ) for the BTG model ( Wu , 1996 ) .
While Chang et al. ( 2009 ) also make use of source dependency , their orientation classification concerns two subsequent phrase pairs in the leftto- right phrase - based decoding ( as apposed to each dependent word and its head ) and is therefore less linguistically -motivated .
Conclusion
We have derived three novel features from the source dependency structure for hierarchical phrase - based MT .
They work as a whole to capitalize on two characteristics of the dependency representation : it is directly based on words and it directly connects head and child .
The effectiveness of our approach has been demonstrated by a final average improvement of 1.21 BLEU , 1.30 LRscore and 3.36 TER .
On average we improve reordering precision and recall by 6.9 and 0.3 absolute points , respectively , over the baseline .
Moreover , our approach is found to be especially effective for long-distance reodering .
As mentioned in Section 2.2 , the cohesion penalty can be extended to also account for how a head word is translated with its children so that we are not biased towards one form of cohesive nonconstituent translation .
All our features can be made sensitive to the dependency relations or even words .
This fine- grainedness is especially desirable when we want to reward words for being unaligned or unresolved , such as punctuations and function words in certain context .
Word alignment quality is crucial for the performance of our features as well as the LRscore which uses word alignment to compute the permutation distance .
As an alternative to GIZA + + , we would like to experiment with syntactically informed aligners that better handle function words which often exhibit high alignment ambiguity due to low cross-lingual correspondence .
Finally , since our soft dependency constraints promote reordering without increasing model complexity , further gains can be achieved when combining our approach with orthogonal studies to improve the quantity and quality of hierarchical ( reordering ) rules , such as relaxing hierarchical rule extraction constraints ( Setiawan and Resnik , 2010 ) and selectively lexicalizing rules with function words ( Setiawan et al. , 2009 ) . understand their brilliant work .
Many thanks to the anonymous reviewers for their insightful comments and suggestions .
This work was supported in part by the EuroMatrixPlus project funded by the European Commission ( 7th Framework Programme ) and in part under the GALE program of the Defense Advanced Research Projects Agency , Contract No. HR0011-06-C-0022 .
Figure 2 : 2 Figure 2 : Word alignments to illustrate orientation classification .
In ( a ) , monotone ( M ) ; in ( b ) , reversed ( R ) .
