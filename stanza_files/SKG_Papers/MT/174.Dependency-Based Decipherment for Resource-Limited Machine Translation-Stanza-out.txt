title
Dependency - Based Decipherment for Resource-Limited Machine Translation
abstract
We introduce dependency relations into deciphering foreign languages and show that dependency relations help improve the state- ofthe - art deciphering accuracy by over 500 % .
We learn a translation lexicon from large amounts of genuinely non parallel data with decipherment to improve a phrase - based machine translation system trained with limited parallel data .
In experiments , we observe BLEU gains of 1.2 to 1.8 across three different test sets .
Introduction State- of- the- art machine translation ( MT ) systems apply statistical techniques to learn translation rules from large amounts of parallel data .
However , parallel data is limited for many language pairs and domains .
In general , it is easier to obtain non parallel data .
The ability to build a machine translation system using monolingual data could alleviate problems caused by insufficient parallel data .
Towards building a machine translation system without a parallel corpus , Klementiev et al . ( 2012 ) use non parallel data to estimate parameters for a large scale MT system .
Other work tries to learn full MT systems using only non parallel data through decipherment ( Ravi and Knight , 2011 ; Ravi , 2013 ) .
However , the performance of such systems is poor compared with those trained with parallel data .
Given that we often have some parallel data , it is more practical to improve a translation system trained on parallel corpora with non parallel data .
Dou and Knight ( 2012 ) successfully apply decipherment to learn a domain specific translation lexicon from monolingual data to improve out -ofdomain machine translation .
Although their approach works well for Spanish / French , they do not show whether their approach works for other language pairs .
Moreover , the non parallel data used in their experiments is created from a parallel corpus .
Such highly comparable data is difficult to obtain in reality .
In this work , we improve previous work by Dou and Knight ( 2012 ) using genuinely non parallel data , and propose a framework to improve a machine translation system trained with a small amount of parallel data .
As shown in Figure 1 , we use a lexicon learned from decipherment to improve translations of both observed and out-of-vocabulary ( OOV ) words .
The main contributions of this work are : ?
We extract bigrams based on dependency relations for decipherment , which improves the state - of - the - art deciphering accuracy by over 500 % .
?
We demonstrate how to improve translations of words observed in parallel data by using a translation lexicon obtained from large amounts of non parallel data . ?
We show that decipherment is able to find correct translations for OOV words . ?
We use a translation lexicon learned by deciphering large amounts of non parallel data to improve a phrase - based MT system trained with limited amounts of parallel data .
In experiments , we observe 1.2 to 1.8 BLEU gains across three different test sets .
Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT , a variety of prior research has tried to build a translation lexicon from non parallel or comparable data ( Rapp , 1995 ; Fung and Yee , 1998 ; Koehn and Knight , 2002 ; Haghighi et al. , 2008 ; Garera et al. , 2009 ; Bergsma and Van Durme , 2011 ; Daum ? and Jagarlamudi , 2011 ; Irvine and Callison- Burch , 2013 b ; Irvine and Callison- Burch , 2013a ) .
Although previous work is able to build a translation lexicon without parallel data , little has used the lexicon to improve machine translation .
There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques ( Ravi and Knight , 2011 ; Dou and Knight , 2012 ; Nuhn et al. , 2012 ) .
Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipherment .
In an effort to build a MT system without a parallel corpus , Ravi and Knight ( 2011 ) view Spanish as a cipher for English and apply Bayesian learning to directly decipher Spanish into English .
Unfortunately , their approach can only work on small data with limited vocabulary .
Dou and Knight ( 2012 ) propose two techniques to make Bayesian decipherment scalable .
First , unlike Ravi and Knight ( 2011 ) , who decipher whole sentences , Dou and Knight ( 2012 ) decipher bigrams .
Reducing a ciphertext to a set of bigrams with counts significantly reduces the amount of cipher data .
According to Dou and Knight ( 2012 ) , a ciphertext bigram F is generated through the following generative story : ?
Generate a sequence of two plaintext tokens e 1 e 2 with probability P ( e 1 e 2 ) given by a language model built from large numbers of plaintext bigrams .
?
Substitute e 1 with f 1 and e 2 with f 2 with probability P ( f 1 |e 1 ) ? P ( f 2 |e 2 ) .
The probability of any cipher bigram F is : P ( F ) = e 1 e 2 P ( e 1 e 2 ) 2 i=1 P ( f i |e i )
Given a corpus of N cipher bigrams F 1 ... F
N , the probability of the corpus is : P ( corpus ) = N j=1 P ( F j ) Given a plaintext bigram language model , the goal is to manipulate P ( f |e ) to maximize P ( corpus ) .
Theoretically , one can directly apply EM to solve the problem ( Knight et al. , 2006 ) .
However , EM has time complexity O( N ? V 2 e ) and space complexity O( V f ? V e ) , where V f , V e are the sizes of ciphertext and plaintext vocabularies respectively , and N is the number of cipher bigrams .
Ravi and Knight ( 2011 ) apply Bayesian learning to reduce the space complexity .
Instead of estimating probabilities P ( f |e ) , Bayesian learning tries to draw samples from plaintext sequences given ciphertext bigrams .
During sampling , the probability of any possible plaintext sample e 1 e 2 is given as : P sample ( P bayes ( f i |e i ) = ?P 0 ( f i |e i ) + count ( f i , e i ) ? + count ( e i ) where P 0 is a base distribution , and ? is a parameter that controls how much we trust P 0 . count ( f i , e i ) and count ( e i ) record the number of times f i , e i and e i appear in previously generated samples respectively .
At the end of sampling , P ( f i |e i ) is estimated by : P ( f i |e i ) = count ( f i , e i ) count ( e i )
However , Bayesian decipherment is still very slow with Gibbs sampling ( Geman and Geman , 1987 ) , as each sampling step requires considering V e possibilities .
Dou and Knight ( 2012 ) solve the problem by introducing slice sampling ( Neal , 2000 ) to Bayesian decipherment .
From Adjacent Bigrams to Dependency Bigrams
A major limitation of work by Dou and Knight ( 2012 ) is their monotonic generative story for deciphering adjacent bigrams .
While the generation process works well for deciphering similar languages ( e.g. Spanish and French ) without considering reordering , it does not work well for languages that are more different in grammar and word order ( e.g. Spanish and English ) .
In this section , we first look at why adjacent bigrams are bad for decipherment .
Then we describe how to use syntax to solve the problem .
The left column in Table 1 contains adjacent bigrams extracted from the Spanish phrase " misi ?n de naciones unidas en oriente medio " .
The correct decipherment for the bigram " naciones unidas " should be " united nations " .
Since the deciphering model described by Dou and Knight ( 2012 ) does not consider word reordering , it needs to decipher the bigram into " nations united " in order to get the right word translations " naciones " ? " nations " and " unidas " ? " united " .
However , the English language model used for decipherment is built from English adjacent bigrams , so it strongly disprefers " nations united " and is not likely to produce a sensible decipherment for " naciones unidas " .
The Spanish bigram " oriente medio " poses the same problem .
Thus , without considering word reordering , the model described by Dou and Knight ( 2012 ) is not a good fit for deciphering Spanish into English .
However , if we extract bigrams based on dependency relations for both languages , the model fits better .
To extract such bigrams , we first use dependency parsers to parse both languages , and extract bigrams by putting head word first , followed by the modifier .
1 We call these dependency bigrams .
The right column in Table 1 lists examples of Spanish dependency bigrams extracted from the same Spanish phrase .
With a language model built with English dependency bigrams , the same model used for deciphering adjacent bigrams is able to decipher Spanish dependency bigram " naciones ( head ) unidas ( modifier ) " into " nations ( head ) united ( modifier ) " .
We might instead propose to consider word reordering when deciphering adjacent bigrams ( e.g. add an operation to swap tokens in a bigram ) .
However , using dependency bigrams has the following advantages : ?
First , using dependency bigrams avoids complicating the model , keeping deciphering efficient and scalable .
?
Second , it addresses the problem of long distance reordering , which can not be modeled by swapping tokens in bigrams .
Furthermore , using dependency bigrams allows us to use dependency types to further improve decipherment .
Suppose we have a Spanish dependency bigram " accept ?( verb ) solicitud ( object ) " .
Then all of the following English dependency bigrams are possible decipherments : " accepted ( verb ) UN ( subject ) " , " accepted ( verb ) government ( subject ) " , " accepted ( verb ) request ( object ) " .
However , if we know the type of the Spanish dependency bigram and use a language model built with the same type in English , the only possible decipherment is " accepted ( verb ) request ( object ) " .
If we limit the search space , a system is more likely to find a better decipherment .
Deciphering Spanish Gigaword
In this section , we compare dependency bigrams with adjacent bigrams for deciphering Spanish into English .
Data
We use the Gigaword corpus for our decipherment experiments .
The corpus contains news articles from different news agencies and is available in Spanish and English .
We use only the AFP ( Agence France - Presse ) section of the corpus in decipherment experiments .
We tokenize the corpus using tools that come with the Europarl corpus ( Koehn , 2005 ) .
To shorten the time required for running different systems on large amounts of data , we keep only the top 5000 most frequent word types in both languages and replace all other word types with UNK .
We also throw away lines with more than 40 tokens , as the Spanish parser ( Bohnet , 2010 ) we use is slow when processing long sentences .
After preprocessing , the corpus contains approximately 440 million tokens in Spanish and 350 million tokens in English .
To obtain dependency bigrams , we use the Bohnet parsers ( Bohnet , 2010 ) to parse both the Spanish and English version of the corpus .
Systems
Three systems are evaluated in the experiments .
We implement a baseline system , Adjacent , based on Dou and Knight ( 2012 ) .
The baseline system collects adjacent bigrams and their counts from Spanish and English texts .
It then builds an English bigram language model using the English adjacent bigrams and uses it to decipher the Spanish adjacent bigrams .
Dependency Types Group 1 Verb / Subject Group 2 Preposition / Preposition - Object , Noun/Noun-Modifier Group 3 Verb/ Noun-Object
We build the second system , Dependency , using dependency bigrams for decipherment .
As the two parsers do not output the same set of dependency relations , we cannot extract all types of dependency bigrams .
Instead , we select a subset of dependency bigrams whose dependency relations are shared by the two parser outputs .
The selected dependency relations are : Verb / Subject , Verb / Noun-Object , Preposition / Object , Noun / Modifier .
Decipherment runs the same way as in the baseline system .
The third system , DepType , is built using both dependent bigrams and their dependency types .
We first extract dependency bigrams for both languages , then group them based on their dependency types .
As both parsers treat noun phrases dependent on " del " , " de " , and " of " as prepositional phrases , we choose to divide the dependency bigrams into 3 groups and list them in Table 2 .
A separate language model is built for each group of English dependency bigrams and used to decipher the group of Spanish dependency bigrams with same dependency type .
For all the systems , language models are built using the SRILM toolkit ( Stolcke , 2002 ) .
For the Adjacent system , we use Good- Turing smoothing .
For the other systems , we use a mix of Witten - Bell and Good- Turing smoothing .
Sampling Procedure
In experiments , we find that the iterative sampling method described by Dou and Knight ( 2012 ) helps improve deciphering accuracy .
We also find that combining results from different decipherments helps find more correct translations at each iteration .
Thus , instead of using a single sampling process , we use 10 different sampling processes at each iteration .
The details of the new sampling procedure are provided here : ?
Extract dependency bigrams from parsing outputs and collect their counts .
?
Keep bigrams whose counts are greater than a threshold ?.
Then start 10 different randomly seeded and initialized sampling processes .
Perform sampling . ?
At the end of sampling , extract word translation pairs ( f , e ) from the final sample .
Estimate translation probabilities P ( e|f ) for each pair .
Then construct a translation table by keeping translation pairs ( f , e ) seen in more than one decipherment and use the average P ( e|f ) as the new translation probability .
?
Lower the threshold ? to include more bigrams into the sampling process .
Start 10 different sampling processes again and initialize the first sample using the translation pairs obtained from the previous step ( for each Spanish token f , choose an English token e whose P ( e|f ) is the highest ) .
Perform sampling again .
?
Repeat until ? = 1 .
Deciphering Accuracy
We choose the first 1000 lines of the monolingual Spanish texts as our test data .
The data contains 37,505 tokens and 6556 word types .
We use type accuracy as our evaluation metric : Given a word type f in Spanish , we find a translation pair ( f , e ) with the highest average P ( e|f ) from the translation table learned through decipherment .
If the translation pair ( f , e ) can also be found in a gold translation lexicon T gold , we treat the word type f as correctly deciphered .
Let | C | be the number of word types correctly deciphered , and | V | be the total number of word types evaluated .
We define type accuracy as | C| | V | .
To create T gold , we use GIZA ( Och and Ney , 2003 ) to align a small amount of Spanish - English parallel text ( 1 million tokens for each language ) , and use the lexicon derived from the alignment as our gold translation lexicon .
T gold contains a subset of 4408 types seen in the test data , among which , 2878 are also top 5000 frequent word types .
Results
During decipherment , we gradually increase the size of Spanish texts and compare the learning curves of three deciphering systems in Figure 2 .
With 100k tokens of Spanish text , the performance of the three systems are similar .
However , the learning curve of Adjacent plateaus quickly , while those of the dependency based systems soar up as more data becomes available and still rise sharply when the size of Spanish texts increases to 10 million tokens , where the DepType system improves deciphering accuracy of the Adjacent system from 4.2 % to 24.6 % .
In the end , with 100 million tokens , the accuracy of the DepType system rises to 27.0 % .
The accuracy is even higher ( 41 % ) , when evaluated against the top 5000 frequent word types only .
Improving Machine Translation with Decipherment
In this section , we demonstrate how to use a translation lexicon learned by deciphering large amounts of in- domain ( news ) monolingual data to improve a phrase - based machine translation system trained with limited out - of- domain ( politics ) parallel data .
Data
We use approximately one million tokens of the Europarl corpus ( Koehn , 2005 ) 3 .
Systems
Baseline Machine Translation System
We build a state- of- the - art phrase - based MT system , PBMT , using Moses ( Koehn et al. , 2007 ) . PBMT has 3 models : a translation model , a distortion model , and a language model .
We build a 5 gram language model using the AFP section of the English Gigaword .
We train the other models using the Europarl corpus .
By default , Moses uses the following 8 features to score a candidate translation : ? direct and inverse translation probabilities ? direct and inverse lexical weighting ?
a language model score ?
a distortion score ?
phrase penalty ? word penalty
The 8 features have weights adjusted on the tuning data using minimum error rate training ( MERT ) ( Och , 2003 ) .
PBMT has a phrase table T phrase .
During decoding , Moses copies out - of- vocabulary ( OOV ) words , which can not be found in T phrase , directly to output .
In the following sections , we describe how to use a translation lexicon learned from large amounts of non parallel data to improve translation of OOV words , as well as words observed in T phrase .
Decipherment for Machine Translation
To achieve better decipherment , we : ?
Increase the size of Spanish ciphertext from 100 million tokens to 894 million tokens .
?
Keep top 50 k instead of top 5 k most frequent word types of the ciphertext .
?
Instead of seeding the sampling process randomly , we use a translation lexicon learned from a limited amount of parallel data as seed :
For each Spanish dependency bigram f 1 , f 2 , where both f 1 and f 2 are found in the seed lexicon , we find the English sequence e 1 , e 2 that maximizes P ( e 1 , e 2 ) P ( e 1 |f 1 ) P ( e 2 |f 2 ) .
Otherwise , for any Spanish token f that can be found in the seed lexicon , we choose English word e , where P ( e|f ) is the highest as the initial sample ; for any f that are not seen in the seed lexicon , we do random initialization .
We perform 20 random restarts with 10 k iterations on each and build a word-to - word translation lexicon T decipher by collecting translation pairs seen in at least 3 final decipherments with either P ( f |e ) ? 0.2 or P ( e|f ) ? 0.2 .
Improving Translation of Observed Words with Decipherment
To improve translation of words observed in our parallel corpus , we simply use T decipher as an additional parallel corpus .
First , we filter T decipher by keeping only translation pairs ( f , e ) , where f is observed in the Spanish part and e is observed in the English part of the parallel corpus .
Then we append all the Spanish and English words in the filtered T decipher to the end of Spanish part and English part of the parallel corpus respectively .
The training and tuning process is the same as the baseline machine translation system PBMT .
We denote this system as Decipher - OBSV .
Improving OOV translation with Decipherment
As T decipher is learned from large amounts of indomain monolingual data , we expect that T decipher contains a number of useful translations for words not seen in the limited amount of parallel data ( OOV words ) .
Instead of copying OOV words directly to output , which is what Moses does by default , we try to find translations from T decipher to improve translation .
During decoding , if a source word f is in T phrase , its translation options are collected from T phrase exclusively .
If f is not in T phrase but in T decipher , the decoder will find translations from T decipher .
If f is not in either translation table , the decoder just copies it directly to the output .
We call this system Decipher - OOV .
However , when an OOV 's correct translation is same as its surface form and all its possible translations in T decipher are wrong , it is better to just copy OOV words directly to output .
This scenario happens frequently , as Spanish and English share many common words .
To avoid over trusting T decipher , we add a new translation pair ( f , f ) for each source word f in T decipher if the translation pair ( f , f ) is not originally in T decipher .
For each newly added translation pair , both of its log translation probabilities are set to 0 .
To distinguish the added translation pairs from the others learned through decipherment , we add a binary feature ? to each translation pair in T decipher .
The final version of T decipher has three feature scores : P ( e|f ) , P ( f |e ) , and ?.
Finally , we tune weights of the features in T decipher using MERT ( Och , 2003 ) on the tuning set .
A Combined Approach
In the end , we build a system Decipher - COMB , which uses T decipher to improve translation of both observed and OOV words with methods described in sections 5.2.3 and 5.2.4 .
Results
We tune each system three times with MERT and choose the best weights based on BLEU scores on tuning set .
Table 4 shows that the translation lexicon learned from decipherment helps achieve higher BLEU scores across tuning and testing sets .
Decipher -OBSV improves BLEU scores by as much as 1.2 points .
We analyze the results and find the gain mainly comes from two parts .
First , adding T decipher to small amounts of parallel corpus improves word level translation probabilities , which lead to better lexical weighting ; second , T decipher contains new alternative translations for words observed in the parallel corpus .
Moreover , Decipher - OOV also achieves better BLEU scores compared with PBMT across all tuning and test sets .
We also observe that systems using T decipher learned by deciphering dependency bigrams leads to larger gains in BLEU scores .
When decipherment is used to improve translation of both observed and OOV words , we see improvement in BLEU score as high as 1.8 points on the 2010 news test set .
The consistent improvement on the tuning and different testing data suggests that decipherment is capable of learning good translations for a number of OOV words .
To further demonstrate that our decipherment approach finds useful translations for OOV words , we list the top 10 most frequent OOV words from both the tuning set and testing set as well as their translations ( up to three most likely translations ) in Table 5 . P ( e|f ) and P ( f |e ) are average scores over different decipherment runs .
From the table , we can see that decipherment finds correct translations ( bolded ) for 7 out of the 10 most frequent OOV words .
Moreover , many OOVs and their correct translations are homographs , which makes copying OOVs directly to the output a strong baseline to beat .
Nonetheless , decipherment still finds enough correct translations to improve the baseline .
Conclusion
We introduce syntax for deciphering Spanish into English .
Experiment results show that using dependency bigrams improves decipherment accuracy by over 500 % compared with the state - of - the - art approach .
Moreover , we learn a domain specific translation lexicon by deciphering large amounts of monolingual data and show that the lexicon can improve a baseline machine translation system trained with limited parallel data .
Figure 1 : 1 Figure 1 : Improving machine translation with decipherment ( Grey boxes represent new data and process ) .
Mono : monolingual ; LM : language model ; LEX : translation lexicon ; TM : translation model .
