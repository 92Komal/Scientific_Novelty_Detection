title
WMT 5 - year Retrospective Best Paper Award
abstract
The focus of our workshop was to use parallel corpora for machine translation .
Recent experimentation has shown that the performance of SMT systems varies greatly with the source language .
In this workshop we encouraged researchers to investigate ways to improve the performance of SMT systems for diverse languages , including morphologically more complex languages , languages with partial free word order , and low-resource languages .
Prior to the workshop , in addition to soliciting relevant papers for review and possible presentation , we conducted three shared tasks : a translation task , a quality estimation task , and a task to test automatic evaluation metrics .
The results of the shared tasks were announced at the workshop , and these proceedings also include an overview paper for the shared tasks that summarizes the results , as well as provides information about the data used and any procedures that were followed in conducting or scoring the task .
In addition , there are short papers from each participating team that describe their underlying system in greater detail .
Like in previous years , we have received a far larger number of submission than we could accept for presentation .
This year we have received 45 full paper submissions and 39 shared task submissions .
In total WMT - 2012 featured 20 full paper oral presentations and 39 shared task poster presentations .
The invited talk was given by Salim Roukos ( IBM Research , USA ) , entitled " Deployment of Statistical Machine Translation for the IBM Enterprise " .
We would like to thank the members of the Program Committee for their timely reviews .
We also would like to thank the participants of the shared task and all the other volunteers who helped with the evaluations .
Introduction
The NAACL 2012 Workshop on Statistical Machine Translation ( WMT - 2012 ) took place on Thursday and Friday , June 7 - 8 , 2012 in Montreal , Canada , immediately following the Conference of the North-American Chapter of the Association for Computational Linguistics - Human Language Technologies ( NAACL HLT ) .
The program committee members who selected Lavie and Agarwal 's paper pointed out that METEOR is the only metric that has managed to compete with BLEU for attention in the MT world without a major funder backing the metric .
They pointed out that TER and HTER have also become prominent , but it is not clear whether that would have happened without backing from DARPA .
Furthermore , METEOR has contributed substantially to improving the assessment of the quality of MT systems by showing the importance of word similarity beyond surface form .
In many ways this paper represents the ideals of the WMT workshops .
It introduced a novel approach to the automatic evaluation of machine translation and demonstrated the metric 's value empirically by comparing it to other state - of - the - art metrics on a public data set .
Congratulations to Alon Lavie and Abhaya Agarwal for their excellent work !
Organizers : Chris Callison-Burch ( Johns Hopkins University ) Philipp Koehn ( University of Edinburgh ) Christof Monz ( University of Amsterdam ) Matt Post ( Johns Hopkins University ) Radu Soricut ( SDL Language Weaver ) Lucia Specia ( University of Sheffield ) Table of Contents of Putting Human Assessments of Machine Translation Systems in Order Adam Lopez . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Findings of the 2012 Workshop on Statistical Machine Translation Chris Callison-Burch , Philipp Koehn , Christof Monz , Matt Post , Radu Soricut and Lucia Specia 10 Semantic Textual Similarity for MT evaluation Julio Castillo and Paula Estrella . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Improving AMBER , an MT Evaluation Metric Boxing Chen , Roland Kuhn and George Foster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Linguistic Features for Quality Estimation Mariano Felice and Lucia Specia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . PRHLT Submission to the WMT12 Quality Estimation Task Jes?s Gonz?lez-Rubio , Alberto Sanch ?s and Francisco Casacuberta . . . . . . . . . . . . . . . . . . . . . . . . Tree Kernels for Machine Translation Quality Estimation Christian Hardmeier , Joakim Nivre and J?rg Tiedemann . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . LORIA System for the WMT12 Quality Estimation Shared Task David Langlois , Sylvain Raybaud and Kamel Sma?li . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Quality Estimation : an experimental study using unsupervised similarity measures Erwan Moreau and Carl Vogel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The UPC Submission to the WMT 2012 Shared Task on Quality Estimation Daniele Pighin , Meritxell Gonz?lez and Llu?s M?rquez . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . TerrorCat : a Translation Error Categorization - based MT Quality Metric Mark Fishel , Rico Sennrich , Maja Popovi ? and Ond?ej Bojar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Class error rates for evaluation of machine translation output Maja Popovic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . SPEDE : Probabilistic Edit Distance Metrics for MT Evaluation Mengqiu Wang and Christopher Manning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Quality estimation for Machine Translation output using linguistic analysis and decoding features Eleftherios Avramidis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Black Box Features for the WMT 2012 Quality Estimation Shared Task Christian Buck . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
