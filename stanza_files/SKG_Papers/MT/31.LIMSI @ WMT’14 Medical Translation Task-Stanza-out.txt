title
LIMSI @ WMT '14 Medical Translation Task
abstract
This paper describes LIMSI 's submission to the first medical translation task at WMT '14 .
We report results for English - French on the subtask of sentence translation from summaries of medical articles .
Our main submission uses a combination of NCODE ( n-gram- based ) and MOSES ( phrase - based ) output and continuous - space language models used in a post-processing step for each system .
Other characteristics of our submission include : the use of sampling for building MOSES ' phrase table ; the implementation of the vector space model proposed by Chen et al . ( 2013 ) ; adaptation of the POStagger used by NCODE to the medical domain ; and a report of error analysis based on the typology of Vilar et al . ( 2006 ) .
Introduction
This paper describes LIMSI 's submission to the first medical translation task at WMT '14 .
This task is characterized by high-quality input text and the availability of large amounts of training data from the same domain , yielding unusually high translation performance .
This prompted us to experiment with two systems exploring different translation spaces , the n-gram- based NCODE ( ?2.1 ) and an on- the-fly variant of the phrasebased MOSES ( ?2.2 ) , and to later combine their output .
Further attempts at improving translation quality were made by resorting to continuous language model rescoring ( ?2.4 ) , vector space subcorpus adaptation ( ?2.3 ) , and POS - tagging adaptation to the medical domain ( ?3.3 ) .
We also performed a small-scale error analysis of the outputs of some of our systems ( ?5 ) .
2 System Overview 2.1 NCODE NCODE implements the bilingual n-gram approach to SMT ( Casacuberta and Vidal , 2004 ; that is closely related to the standard phrase - based approach ( Zens et al. , 2002 ) .
In this framework , the translation is divided into two steps .
To translate a source sentence f into a target sentence e , the source sentence is first reordered according to a set of rewriting rules so as to reproduce the target word order .
This generates a word lattice containing the most promising source permutations , which is then translated .
Since the translation step is monotonic , the peculiarity of this approach is to rely on the n-gram assumption to decompose the joint probability of a sentence pair in a sequence of bilingual units called tuples .
The best translation is selected by maximizing a linear combination of feature functions using the following inference rule : e * = argmax e, a K k=1 ? k f k ( f , e , a ) ( 1 ) where K feature functions ( f k ) are weighted by a set of coefficients ( ? k ) and a denotes the set of hidden variables corresponding to the reordering and segmentation of the source sentence .
Along with the n-gram translation models and target ngram language models , 13 conventional features are combined : 4 lexicon models similar to the ones used in standard phrase - based systems ; 6 lexicalized reordering models ( Tillmann , 2004 ; Crego et al. , 2011 ) aimed at predicting the orientation of the next translation unit ; a " weak " distance - based distortion model ; and finally a word-bonus model and a tuple -bonus model which compensate for the system preference for short translations .
Features are estimated during the training phase .
Training source sentences are first reordered so as to match the target word order by unfolding the word alignments .
Tuples are then extracted in such a way that a unique segmentation of the bilingual corpus is achieved and n-gram translation models are then estimated over the training corpus composed of tuple sequences made of surface forms or POS tags .
Reordering rules are automatically learned during the unfolding procedure and are built using partof-speech ( POS ) , rather than surface word forms , to increase their generalization power .
On - the-fly System ( OTF )
We develop an alternative approach implementing an on - the-fly estimation of the parameter of a standard phrase - based model as in ( Le et al. , 2012 b ) , also adding an inverse translation model .
Given an input source file , it is possible to compute only those statistics which are required to translate the phrases it contains .
As in previous works on on - the-fly model estimation for SMT ( Callison - Burch et al. , 2005 ; Lopez , 2008 ) , we first build a suffix array for the source corpus .
Only a limited number of translation examples , selected by deterministic random sampling , are then used by traversing the suffix array appropriately .
A coherent translation probability ( Lopez , 2008 ) ( which also takes into account examples where translation extraction failed ) is then estimated .
As we cannot compute exactly an inverse translation probability ( because sampling is performed independently for each source phrase ) , we resort to the following approximation : p( f | ? ) = min 1.0 , p( ? | f ) ? f req( f ) f req ( ? ) ( 2 ) where the f req ( ? ) is the number of occurrences of the given phrase in the whole corpus , and the numerator p( ? | f ) ? f req( f ) represents the predicted joint count of f and ?.
The other models in this system are the same as in the default configuration of MOSES .
Vector Space Model ( VSM )
We used the vector space model ( VSM ) of Chen et al . ( 2013 ) to perform domain adaptation .
In this approach , each phrase pair ( f , ? ) present in the phrase table is represented by a C-dimensional vector of TF - IDF scores , one for each sub-corpus , where C represents the number of sub-corpora ( see Table 1 ) .
Each component w c ( f , ? ) is a standard TF - IDF weight of each phrase pair for the c th sub-corpus .
TF ( f , ? ) is the raw joint count of ( f , ? ) in the sub-corpus ; the IDF ( f , ? ) is the inverse document frequency across all sub-corpora .
A similar C-dimensional representation of the development set is computed as follows : we first perform word alignment and phrase pairs extraction .
For each extracted phrase pair , we compute its TF - IDF vector and finally combine all vectors to obtain the vector for the develompent set : w dev c = J j=0 K k=0 count dev ( fj , ?k ) w c ( fj , ?k ) ( 3 ) where J and K are the total numbers of source and target phrases extracted from the development data , respectively , and count dev ( fj , ?k ) is the joint count of phrase pairs ( fj , ?k ) found in the development set .
The similarity score between each phrase pair 's vector and the development set vector is added into the phrase table as a VSM feature .
We also replace the joint count with the marginal count of the source / target phrase to compute an alternative average representation for the development set , thus adding two VSM additional features .
SOUL Neural networks , working on top of conventional n-gram back - off language models , have been introduced in ( Bengio et al. , 2003 ; Schwenk et al. , 2006 ) as a potential means to improve discrete language models .
As for our submitted translation systems to WMT '12 and WMT '13 ( Le et al. , 2012 b ; Allauzen et al. , 2013 ) , we take advantage of the recent proposal of .
Using a specific neural network architecture , the Structured OUtput Layer ( SOUL ) , it becomes possible to estimate n-gram models that use large vocabulary , thereby making the training of large neural network language models feasible both for target language models and translation models ( Le et al. , 2012a ) .
Moreover , the peculiar parameterization of continuous models allows us to consider longer dependencies than the one used by conventional n-gram models ( e.g. n = 10 instead of n = 4 ) .
Additionally , continuous models can also be easily and efficiently adapted as in ( Lavergne et al. , 2011 ) needed on a new corpus in order to adapt the parameters to the new domain .
3 Data and Systems Preparation
Corpora
We use all the available ( constrained ) medical data extracted using the scripts provided by the organizers .
This resulted in 7 sub-corpora from the medical domain with distinctive features .
As outof-domain data , we reuse the data processed for WMT '13 ( Allauzen et al. , 2013 ) .
For pre-processing of medical data , we closely followed ( Allauzen et al. , 2013 ) so as to be able to directly integrate existing translation and language models , using in - house text processing tools for tokenization and detokenization steps ( D?chelotte et al. , 2008 ) .
All systems are built using a " true case " scheme , but sentences fully capitalized ( plentiful especially in PATTR - TITLES ) are previously lowercased .
Duplicate sentence pairs are removed , yielding a sentence reduction up to 70 % for EMEA .
Table 1 summarizes the data used along with some statistics after the cleaning and pre-processing steps .
Language Models
A medical- domain 4 - gram language model is built by concatenating the target side of the paral- lel data and all the available monolingual data 1 , with modified Kneser - Ney smoothing ( Kneser and Ney , 1995 ; Chen and Goodman , 1996 ) , using the SRILM ( Stolcke , 2002 ) and KENLM ( Heafield , 2011 ) toolkits .
Although more similar to term-toterm dictionaries , UMLS and WIKIPEDIA proved better to be included in the language model .
The large out - of- domain language model used for WMT '13 ( Allauzen et al. , 2013 ) is additionaly used ( see Table 1 ) .
Part-of-Speech Tagging Medical data exhibit many peculiarities , including different syntactic constructions and a specific vocabulary .
As standard POS - taggers are known not to perform very well for this type of texts , we use a specific model trained on the Penn Treebank and on medical data from the MedPost project ( Smith et al. , 2004 ) .
We use Wapiti ( Lavergne et al. , 2010 ) , a state- of- the - art CRF implementation , with a standard feature set .
Adaptation is performed as in ( Chelba and Acero , 2004 ) using the out-of- domain model as a prior when training the in-domain model on medical data .
On a medical test set , this adaptation leads to a 8 point reduction of the error rate .
A standard model is used for WMT '13 data .
For the French side , due to the lack of annotaded data for the medical domain , corpora are tagged using the TreeTagger ( Schmid , 1994 ) .
Proxy Test Set For this first edition of a Medical Translation Task , only a very small development set was made available ( DEVEL in Table 1 ) .
This made both system design and tuning challenging .
In fact , with such a small development set , conventional tuning methods are known to be very unstable and prone to overfitting , and it would be suboptimal to select a configuration based on results on the development set only .
2
To circumvent this , we artificially created our own internal test set by randomly selecting 3 000 sentences out from the 30 000 sentences from PATTR - ABSTRACTS having the lowest perplexity according to 3 - gram language models trained on both sides of the DEVEL set .
This test set , denoted by LMTEST , is however highly biaised , especially because of the high redundancy in PATTR - ABSTRACTS , and should be used with great care when tuning or comparing systems .
Systems NCODE
We use NCODE with default settings , 3 gram bilingual translation models on words and 4 gram bilingual translation factor models on POS , for each included corpora ( see Table 1 ) and for the concatenation of them all .
OTF
When using our OTF system , all indomain and out - of- domain data are concatenated , respectively .
For both corpora , we use a maximum random sampling size of 1 000 examples and a maximum phrase length of 15 .
However , all sub-corpora but GIGA 3 are used to compute the vectors for VSM features .
Decoding is done with MOSES 4 ( Koehn et al. , 2007 ) . SOUL
Given the computational cost of computing n-gram probabilities with neural network models , we resort to a reranking approach .
In the following experiments , we use 10 - gram SOUL models to rescore 1 000 - best lists .
SOUL models provide five new features : a target language model score and four translation scores ( Le et al. , 2012a ) .
We reused the SOUL models trained for our participation to WMT '12 ( Le et al. , 2012 b ) .
Moreover , target language models are adapted by running 6 more epochs on the new medical data .
System Combination
As NCODE and OTF differ in many aspects and make different errors , we use system combination techniques to take advantage of their complementarity .
This is done by reranking the concatenation of the 1 000 - best lists of both systems .
For each hypothesis within this list , we use two global features , corresponding either to the score computed by the corresponding system or 0 otherwise .
We then learn reranking weights using Minimum Error Rate Training ( MERT ) ( Och , 2003 ) on the development set for this combined list , using only these two features ( SysComb - 2 ) .
In an alternative configuration , we use the two systems without the SOUL rescoring , and add instead the five SOUL scores as features in the system combination reranking ( SysComb - 7 ) .
Evaluation Metrics All BLEU scores ( Papineni et al. , 2002 ) are computed using cased multi-bleu with our internal tokenization .
Reported results correspond to the average and standard deviation across 3 optimization runs to better account for the optimizer variance ( Clark et al. , 2011 ) .
Experiments
Tuning Optimization Method MERT is usually used to optimize Equation 1 .
However , with up to 42 features when using SOUL , this method is known to become very sensitive to local minima .
Table 2 compares MERT , a batch variant of the Margin Infused Relaxation Algorithm ( MIRA ) ( Cherry and Foster , 2012 ) and PRO ( Hopkins and May , 2011 ) when tuning an NCODE system .
MIRA slightly outperforms PRO on DEVEL , but seems prone to overfitting .
However this was not possible to detect before the release of the test set ( TEST ) , and so we use MIRA in all our experiments .
Importance of the Data Sources Table 3 shows that using the out-of- domain data from WMT '13 yields better scores than only using the provided medical data only .
Moreover , combining both data sources drastically boosts performance .
Table 1 displays the weights ( ? k ) given by NCODE to the different sub-corpora bilingual language models .
Three corpora seems particulary useful : EMEA , PATTR -ABSTRACTS and GIGA .
Note that several models are given a negative weight , but removing them from the model surprisingly results in a drop of performance .
Part-of-Speech Tagging Using the specialized POS - tagging models for medical data described in Section 3.3 instead of a standart POS - tagger , a 0.5 BLEU points increase is observed .
4 : BLEU results when using a standard POS tagging ( std ) or our medical adapted specialized method ( spec ) , either for the reordering rule mechanism ( Reordering ) or for the POS - POS bilingual language models features ( Factor model ) .
Development and Proxy Test Sets In Table 5 , we assess the importance of domain adaptation via tuning on the development set used and investigate the benefits of our internal test set .
Best scores are obtained when using the provided development set in the tuning process .
Us - Table 7 : Results for manual error analysis following ( Vilar et al. , 2006 ) for the first 100 test sentences .
NCODE outperforming OTF by 2.8 BLEU points on the TEST set .
VSM does not yield any significant improvement , contrarily to the work of Chen et al . ( 2013 ) ; it may be the case all individual subcorpus are equally good ( or bad ) at approximating the stylistic preferences of the TEST set .
Integrating SOUL
Table 6 shows the substantial impact of adding SOUL models for both baseline systems .
With only the SOUL LM , improvements on the test set range from 0.5 BLEU points for NCODE system to 1.2 points for the OTF system .
The adaptation SOUL LM with the medical data brings an additional improvement of about 0.2 BLEU points .
Adding all SOUL translation models yield an improvement of 1.8 BLEU points for NCODE and of 2.4 BLEU points with the OTF system using VSM models .
However , the SOUL adaptation step has then only a modest impact .
In future work , we plan to also adapt the translation models in order to increase the benefit of using in - domain data .
System Combination
Table 6 shows that performing the system combination allows a gain up to 0.6 BLEU points on the DEVEL set .
However this gain does not transfer to the TEST set , where instead a drop of 0.5 BLEU is observed .
The system combination using SOUL scores showed the best result over all of our other systems on the DEVEL set , so we chose this ( a posteriori sub-obtimal ) configuration as our main system submission .
Our system combination strategy chose for DE - VEL about 50 % hypotheses among those produced by NCODE and 25 % hypotheses from OTF , the remainder been common to both systems .
As expected , the system combination prefers hypotheses coming from the best system .
We can observe nearly the same distribution for TEST .
Error Analysis
The high level of scores for automatic metrics encouraged us to perform a detailed , small - scale analysis of our system output , using the error types proposed by Vilar et al . ( 2006 ) .
A single annotator analyzed the output of our main submission , as well as our OTF variant .
Results are in Table 7 .
Looking at the most important types of errors , assuming the translation hypotheses were to be used for rapid assimilation of the text content , we find a moderate number of unknown terms and incorrectly translated terms .
The most frequent error types include missing fillers , incorrect disambiguation , form and order , which all have some significant impact on automatic metrics .
Comparing more specifically the two systems used in this small - scale study , we find that our combination ( which reused more than 70 % of hypotheses from NCODE ) mostly improves over the OTF variant on the choice of correct word form and word order .
We may attribute this in part to a more efficient reordering strategy that better exploits POS tags .
Conclusion
In this paper , we have demonstrated a successful approach that makes use of two flexible translation systems , an n-gram system and an on - the-fly phrase - based model , in a new medical translation task , through various approaches to perform domain adaptation .
When combined with continuous language models , which yield additional gains of up to 2 BLEU points , moderate to high-quality translations are obtained , as confirmed by a finegrained error analysis .
The most challenging part of the task was undoubtedly the lack on an internal test to guide system development .
Another interesting negative result lies in the absence of success for our configuration of the vector space model of Chen et al . ( 2013 ) for adaptation .
Lastly , a more careful integration of medical terminology , as provided by the UMLS , proved necessary .
Table 1 : 1 . Starting from a previously trained SOUL model , only a few more training epochs are Parallel corpora used in this work , along with the number of sentences and the number of English and French tokens , respectively .
Weights ( ?
Corpus Sentences Tokens ( en- fr ) Description wrd-lm pos-lm COPPA 454 246 10-12M -3 - 15 EMEA 324 189 6- 7 M 26 -1 PATTR -ABSTRACTS 634 616 20-24 M 22 21 in-domain PATTR -CLAIMS 888 725 32-36 M 6 2 PATTR-TITLES 385 829 3- 4 M 4 - 17 UMLS 2 166 612 8-8 M term dictionary - 7 - 22 WIKIPEDIA 8 421 17 - 18 k short titles - 5 - 13 NEWSCOMMENTARY 171 277 4- 5 M 6 16 out-of-domain EUROPARL 1 982 937 54-60M -7 -33 GIGA 9 625 480 260-319 M 27 52 all parallel all 17 M 397-475 M concatenation 33 69 target - lm medical - data wmt13 - data - 146M -2 536 M 69 49 -- DEVEL 500 10 - 12 k khresmoi-summary devel/ test LMTEST NEWSTEST12 3 000 3 003 61-69 k 73 - 82 k see Section 3.4 from WMT'12 TEST 1 000 21 - 26 k khresmoi-summary k ) from our best NCODE configuration are indicated for each sub-corpora 's bilingual word language model ( wrd - lm ) and POS factor language model ( pos - lm ) .
