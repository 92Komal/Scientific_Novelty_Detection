title
A Multi-Task Incremental Learning Framework with Category Name Embedding for Aspect-Category Sentiment Analysis
abstract
T) ACSA tasks , including aspect-category sentiment analysis ( ACSA ) and targeted aspectcategory sentiment analysis ( TACSA ) , aims at identifying sentiment polarity on predefined categories .
Incremental learning on new categories is necessary for ( T) ACSA real applications .
Though current multi-task learning models achieve good performance in ( T) ACSA tasks , they suffer from catastrophic forgetting problems in ( T) ACSA incremental learning tasks .
In this paper , to make multi-task learning feasible for incremental learning , we proposed Category Name Embedding network ( CNE - net ) .
We set both encoder and decoder shared among all categories to weaken the catastrophic forgetting problem .
Besides the origin input sentence , we applied another input feature , i.e. , category name , for task discrimination .
Our model achieved state - of- theart on two ( T) ACSA benchmark datasets .
Furthermore , we proposed a dataset for ( T) ACSA incremental learning and achieved the best performance compared with other strong baselines .
Introduction Sentiment analysis has become an increasingly popular natural language processing ( NLP ) task in academia and industry .
It provides real-time feedback on consumer experience and their needs , which helps producers to offer better services .
To deal with the presence of multiple categories in one document , ( T) ACSA tasks , including aspectcategory sentiment analysis ( ACSA ) and targeted aspect-category sentiment analysis ( TACSA ) , were introduced .
The main purpose for ACSA task is to identify sentiment polarity ( i.e. positive , neutral , negative and none ) of an input sentence upon specific predefined categories ( Mohammad et al. , 2018 ; Wu et al. , 2018 ) .
For example , as shown in Table 1 , giving an input sentence " Food is always fresh and hot-ready to eat , but it is too expensive . " and predefined categories { food , service , price , ambience and anecdotes / miscellaneous} , the sentiment of category food is positive , the polarity regarding to category price is negative , while is none for others .
In this task , the models should capture both explicit expressions and implicit expressions .
For example , the phrase " too expensive " indicates the negative polarity in the price category , without a direct indication of " price " .
In order to deal with ACSA with both multiple categories and multiple targets , TACSA task was introduced ( Saeidi et al. , 2016 ) to analyze sentiment polarity on a set of predefined targetcategory pairs .
An example is shown in Table 1 , given targets " restaurant - 1 " and " restaurant - 2 " , in the case " I like restaurant - 1 because it 's cheap , but restaurant - 2 is too expansive " , the category price for target " restaurant - 1 " is positive , but is negative for target " restaurant - 2 " , while is none for other target - category pairs .
A mathematical definition for ( T) ACSA is given as follows : giving a sentence s as input , a predefined set of targets T and a predefined set of aspect categories A , a model predicts the sentiment polarity y for each target - category pair { ( t , a ) : t ?
T , a ? A}.
For ACSA task , there is only one target t in all ( t , a ) categories .
In this paper , in order to simplify the expression in TACSA , we use predefined categories , which is short for predefined target - category pairs .
Multi-task learning , with shared encoders but individual decoders for each category , is an approach to analyze all the categories in one sample simultaneously for ( T) ACSA ( Akhtar et al. , 2018 ; Schmitt et al. , 2018 ) .
Compared with single - task ways ( Liang et al. , 2019 ) , multi-task approaches utilize category -specific knowledge in training signals from each task and get better performance .
However , current multi-task models still suffer from a
Task Sentence Labels ACSA
Food is always fresh and hot-ready to eat , but it is too expensive ( food , positive ) , ( service , none ) , ( price , negative ) , ( ambience , none ) ( anecdotes / miscellaneous , none ) TACSA I like restaurant - 1 because it 's cheap , but restaurant - 2 is too expansive .
( restaurant - 1 - general , none ) , ( restaurant - 1 - price , positive ) , ( restaurant - 1- location , none ) , ( restaurant - 1- safety , none ) , ( restaurant - 2- general , none ) , ( restaurant - 2 - price , negative ) , ( restaurant -2-location , none ) , ( restaurant - 2 - safety , none ) lack of features such as category name ( Meisheri and Khadilkar , 2018 ) .
Models with category name features encoded in the model may further improve the performance .
On the other hand , the predefined categories in ( T) ACSA task make the application in new categories inflexible , as for ( T) ACSA applications , the number of categories maybe varied over time .
For example , fuel consumption , price level , engine power , space and so on are source categories to be analyzed in the gasoline automotive domain .
For electromotive domain , source categories in the automotive domain will still be used , while new target category such as battery duration should also be analyzed .
Incremental learning is a way to solve this problem .
Therefore , it is necessary to propose an incremental learning task and an incremental learning model concerned with new category for ( T) ACSA tasks .
Unfortunately , in the current multi-task learning ( T) ACSA models , the encoder is shared but the decoders for each category are individual .
This parameter sharing mechanism results in only the shared encoder and target - category - related decoders are finetuned during the finetuning process , while the decoder of source categories remains unchanged .
The finetuned encoder and original decoder of source categories may cause catastrophic forgetting problem in the origin categories .
For real applications , high accuracy is excepted in source categories and target categories .
Based on the previous researches that decoders between different tasks are usually modeled by mean regularization ( Evgeniou and Pontil , 2004 ) , an idea comes up to further make the decoders the same by sharing the decoders in all categories to decrease the catastrophic forgetting problem .
But here raises another question , how to identify each category in the encoder and decoder shared network ?
In our approach , we solve the category discrimination problem by the input category name feature .
In this paper , we proposed a multi-task category name embedding network ( CNE - net ) .
The multi-task learning framework makes full use of training signals from all categories .
To make it feasible for incremental learning , both encoder and decoders for each category are shared .
The category names were applied as another input feature for task discrimination .
We also present a new task for ( T) ACSA incremental learning .
In particular , our contribution is three -folded : ( 1 ) We proposed a multi-task CNE - net framework with both encoder and decoder shared to weaken catastrophic forgetting problem in multitask learning ( T) ACSA model .
( 2 ) We achieved state - of - the - art on the two ( T) ACSA datasets , SemEval14 - Task4 and Sentihood .
( 3 ) We proposed a new task for incremental learning in ( T) ACSA .
By sharing both encoder layers and decoder layers of all the tasks , we achieved better results compared with other baselines both in source categories and in the target category .
2 Related Work 2.1 Aspect-category Sentiment Analysis ( T) ACSA task is to predict sentiment polarity on a set of predefined categories .
It is able to analyze sentiment in an end-to - end way with explicit expressions or implicit expressions ( Mohammad et al. , 2018 ; Wu et al. , 2018 ) .
The earliest works most concerned on feature engineering ( Zirn et al. , 2011 ; Wiebe , 2012 ; Wagner et al. , 2014 ) . Subsequently , Nguyen and Shirai ( 2015 ) ;
Wang et al . ( 2017 ) ; Meisheri and Khadilkar ( 2018 ) applied neural network models to achieve higher accuracy .
Ma et al. ( 2018 ) then involved commonsense knowledge as additional features .
The current approaches consist of multi-task models ( Akhtar et al. , 2018 ; Schmitt et al. , 2018 ) , which analyze all the categories simultaneously in one sample to make full use of all the features and labels in the training sample , and single - task models that treat one category in one sample ( Jiang et al. , 2019 ) .
Multi-Task Learning Multi-task learning ( MTL ) utilizes all the related tasks by sharing the commonalities while learning individual features for each sub-task .
MTL has been proven to be effective in many NLP tasks , such as information retrieval ( Liu et al. , 2015 ) , machine translation ( Dong et al. , 2015 ) , and semantic role labeling ( Collobert and Weston , 2008 ) .
For ACSA task , Schmitt et al . ( 2018 ) applied MTL framework with a shared LSTM encoder and individual decoder classifiers for each category .
The multiple aspects in MTL were handled by constrained attention networks with orthogonal and sparse regularization ( Hu et al. , 2019 ) .
Incremental Learning Incremental learning was inspired by adding new abilities to a model without having to retrain the entire model .
For example , Doan and Kalita ( 2016 ) presented several random forest models to perform sentiment analysis on customers ' reviews .
Many domain adaptation approaches utilizing transfer learning suffer from " catastrophic forgetting " problem ( French and Chater , 2002 ) .
To solve this problem , Rosenfeld and Tsotsos ( 2017 ) proposed an incremental learning Deep-Adaption - Network that constrains newly learned filters to be linear combinations of existing ones .
To the best of our knowledge , for ( T) ACSA task , few researches concerned with incremental learning in new categories .
In this paper , we proposed a ( T) ACSA incremental learning task and the CNEnet model to solve this problem in a multi-task learning approach with a shared encoder and shared decoders .
We also apply category name for task discrimination .
Datasets
This section describes the benchmark datasets we used to evaluate our model , the incremental learning task definition , the methodology to prepare the incremental learning dataset , and the evaluation metric .
Evaluation Benchmark Datasets
We evaluated the performance of the CNE - net model on two benchmark datasets , i.e. , ACSA task on SemEval - 2014 Task4 ( Pontiki et al. , 2014 ) and TACSA task on SentiHood ( Saeidi et al. , 2016 ) .
The ACSA task was evaluated on SemEval - 2014 Task4 , a dataset on restaurant reviews .
Our model provides a joint solution for sub-task 3 ( Aspect Category Detection ) and sub-task 4 ( Aspect Category Sentiment Analysis ) .
The sentiment polarities are y ?
Y = { positive , neutral , negative , conflict and none} , and the categories are a ?
A = { food , service , price , ambience and anecdotes / miscellaneous } .
The conflict label indicates both positive and negative sentiment is expressed in one category ( Pontiki et al. , 2014 ) .
The TACSA task was evaluated on the Sentihood dataset , which describes locations or neighborhoods of London and was collected from question answering platform of Yahoo .
The sentiment polarities are y ?
Y = { positive , negative and none} , the targets are t ?
T = { Location1 , and Location2 } , and the aspect categories are a ?
A = { general , price , transit-location , and safety } .
Evaluation Transfer Learning Datasets
Besides evaluating the model on existing ( T) ACSA tasks , we also proposed incremental learning tasks for ( T) ACSA 1 in new category based on SemEval - 2014 Task4 and Sentihood dataset , respectively .
Firstly , we split the categories into source categories and target categories .
For ACSA task , the source categories are { food , price , ambience and anecdotes / miscellaneous} , while the target category is { service} .
For TACSA task , the source categories are { general , transit-location , and safety } , while the target category is { price} .
This was considered by the amount of data with positive / negative / neutral polarity in this category , as well as the sense of this category for real applications .
origin ACSA sample { " text " : " The only thing more wonderful than the food is the service . " , " sentiment " : { " food " : " Positive " , " service " : " Positive " , " price " : None , " ambience " : None , " anecdotes/ miscellaneous " : None } }
ACSA Sample-Source { " text " : " The only thing more wonderful than the food is the service . " , " sentiment " : { " food " : " Positive " , " price " : None , " ambience " : None , " anecdotes/ miscellaneous " : None } } ACSA Sample-Target { " text " : " The only thing more wonderful than the food is the service . " , " sentiment " : { " service " : " Positive " } } Table 2 : An example for generating ACSA incremental learning task .
Secondly , we prepare training , validation and testing data for incremental learning task by independently splitting the origin training data , validation data and test data into source - category data ( Sample - Source ) containing label only in source categories and target- category data ( Sample - Target ) with target - category label only .
For example , as shown in Table 2 , in ACSA task , the origin labels { food : positive , service : positive , price : none , ambience : none , anecdotes / miscellaneous : none } were transformed to { food : positive , price : none , ambience : none , anecdotes / miscellaneous : none } in Sample -Source and { service : positive } in Sample -Target .
The input sentences were kept the same as origin dataset .
For other researches to investigate the influence of target - category training data amount quantitatively , we also created incremental learning data by combining all the Sample -Source and sampled Sample -Target .
The sampling rate is a range from 0.0 to 1.0 .
In this paper , the ACSA incremental learning dataset is created from SemEval14 - Task ACSA dataset , and it is called SemEval14 - Task-inc .
The TACSA incremental learning dataset is created from Sentihood TACSA dataset , and it is called Sentihood-inc .
Evaluation Metrics
We evaluated the aspect category extraction ( to determine whether the sentiment is none for each category ) and sentiment analysis ( to predict the sentiment polarity ) on the two datasets .
For aspect category extraction evaluation , we applied the probability 1 ? p as the not none probability for each category , where p is the probability of the " none " class in this category .
The evaluation metric is the same as Sun et al . ( 2019 ) .
For the origin SemEval - 14 Task4 dataset , we use Micro - F1 for category extraction evaluation and accuracy for sentiment analysis evaluation .
For the origin Sentihood dataset , we use Macro - F1 , strict accuracy , and area-under- curve ( AUC ) for category extraction evaluation while use AUC , and strict accuracy for sentiment analysis evaluation .
When evaluating the incremental learning task , we use the F1 metric ( Micro - F1 for SemEval - 14 and Macro- F1 for Sentihood ) for category extraction and accuracy for sentiment analysis .
Approach
In this section , we describe the architecture of CNE - net for ( T) ACSA task .
In BERT classification tasks , the typical approach is feeding sentence " [ CLS ] tokens in sentence [ SEP ] " into the model , while the token " [ CLS ] " is used as a feature for classification .
In order to encode category names into BERT model , as well as analyze sentiment polarity of all the categories simultaneously , we made two significant differences from the original BERT , one on the encoder module and another on the decoder module .
Encoder with Category Name Embedding
In order to get a better category name embedding , as well as to make it feasible for incremental learning cross categories , the category names are encoded into the model , along with the origin sentence like " [ CLS ] sentence words input [ SEP ] cate - gory1 input [ SEP ] category2 input [ SEP ] ... [ SEP ] categoryN input [ SEP ] " , as shown in the BERT encoder module in Figure 1 .
In ACSA task , the category names are " { food , service , price , ambiance , and anecdotes / miscellaneous } " , while in TACSA task , the category names are " { location - 1 general , location - 1 price , location - 1 transit-location , location - 1 safety , location - 2 general , location - 2 price , location - 2 transit-location , and location - 2 safety } " .
We mark output states of the BERT encoder as follows : the hidden state of [ CLS ] h [ CLS ] ?
R d , the hidden states of words in origin sentences [ CLS ] Sentence Words Input [ SEP 1 ] Category1 Words Input [ SEP 2 ] [ SEP 3 ] Category2 Words Input ? [ SEP - N ] [ SEP - N+1 ]
Category -N Words Input BERT Encoder [ CLS ] Sentence Words Embedding [ SEP 1 ] Category1 Words Embedding [ SEP 2 ] [ SEP 3 ] Category2 Words Embedding ? [ SEP - N ] [ SEP - N+1 ]
Category -N Words Embedding [ SEP 1 ] [ SEP 2 ] ? [ SEP - N ] BERT Encoder
CNE - net-CLS - att. [ H cat ? i ? R L cat ? i ?d for the i-th cate - gory ( 0 < i ? n cat ) , where L sent is the length of the input sentence , d is the dimension of hidden states , n cat is the number of categories feed into the model , and L cat ? i is the length of the i-th category input words .
Multi-Task Decoders
We proposed three types of decoder for ( T) ACSA task , as shown in Figure 1 1 , 2 and 3 .
These decoders are multi-label classifiers , which apply a softmax classifier for sentiment analysis in each category .
Type 1 , CNE - net- SEP , as shown in Figure 1 1 , the separator token h [ SEP ?i ] is applied as feature representation for sentiment polarity analysis in each category directly .
The probability for each polarity in category i is calculated as follows where h = h [ SEP ?i ] : f i = W i ? h + b i ; p i = sof tmax ( f i ) ( 1 ) where f i ?
R s is the output logits for category i , p i ?
R s is the output probability for category i , W i ?
R d?s and b i ?
R s are randomly initialized parameters to be trained , and s is the number of sentiment classes .
s = 5 for { positive , neutral , negative , conflict and none} in SemEval14 - Task4 , while s = 3 for { positive , negative and none} in Sentihood dataset .
In our approach , W 1 = W 2 = ... = W ncat and b 1 = b 2 = ... = b ncat .
Type 2 , CNE - net-CLS - att. , in order to get content - aware category embedding vector , we applied attention mechanism with h [ CLS ] serves as query vector , and H cat ?
i serves as both key and value matrix , as shown in Figure 1 2 .
The category embedding vector e cat ? i for the i-th category is as follows : e cat i = sof tmax ( h [ CLS ] ?
H cat ? i ) ? H cat ? i
( 2 ) The probability for category i in type 2 is calculated following equation ( 1 ) where h = e cat i .
Type 3 , CNE - net-SEP -sent .- att. applied attention mechanism for both sentence embedding and category name embedding .
As it is shown in Figure 1 3 .
Firstly , sentence vector correlated with the i-th category is calculated by attention with separator embedding h [ SEP ?i ] serving as query , and sentence embedding H sent serving as key and value matrix .
Sentence vector h sent ? i correlated with the i-th category is as follows : h sent ? i = sof tmax ( h [ SEP ?i ] ?
H sent ) ?
H sent ( 3 ) Secondly , similar to that in type 2 , the category embedding vector e cat ? i for the i-th category calculated by attention mechanism is as follows : e cat i = sof tmax ( h sent ? i ? H cat ? i ) ? H cat ? i
( 4 ) The probability for for category i in type 3 is calculated following equation ( 1 ) where h = e cat i .
Model Training
The CNE - net multi-task framework was trained in an end-to - end way by minimizing the sum of cross-entropy loss of all the categories .
We employed L 2 regularization to ease over-fitting .
The loss function is given as follows : L = ? 1 | D| x,y?D
N i=1 y i ? log p i ( x ; ? ) + ? 2 ||?|| 2 ( 5 ) where D is the training dataset , N is the number of categories , Y is the sentiment classes Y = { positive , neutral , negative , conflict , none} ( neutral and conflict is not included in TACSA task ) , y i ?
R |Y | is the one- hot label vector for the i-th category with true label marked as 1 and others marked as 0 , p i ( x ; ? ) is the probability for the i-th category , and ? is the L 2 regularization weight .
Besides L 2 regularization , we also employed dropout and early stopping to ease over-fitting .
During training incremental learning models , we follow the workflow of the incremental learning application .
We firstly train a source-category model with the Sample - Source training data .
Then finetuned the source-category model with Sample - Target training data to get incremental learning model .
Experiments
Experiment Settings
The pretrained uncased BERT - base 2 was used as the encoder in CNE - net .
The number of Transformer blocks is 12 , the number of self-attention heads is 12 , and the hidden layer size in each selfattention head is 64 .
The total amount of parameters in BERT encoder is about 110M .
The dropout ratio is 0.1 during training , the traning epochs is 10 , and the learning rate is 5e - 5 with a warm - up ratio of 0.25 .
Compared Methods
We compare the performance of our model with some state - of - the - art models .
For ACSA task : ? XRCE ( Brun et al. , 2014 ) : a hybrid classifier based on linguistic features .
? NRC - Canada ( Kiritchenko et al. , 2014 ) : several binary one- vs- all SVM classifiers for this multi-class multi-label classification problem .
? AT - LSTM and ATAE -LSTM ( Wang et al. , 2016 ) : a LSTM attention framework with aspect word embeddings concatenated with sentence word embeddings .
? BERT - pair-QA -B ( Sun et al. , 2019 ) : a question answering and natural language inference model based on BERT .
? Multi-task framework ( MTL ) ( Schmitt et al. , 2018 ) : a LSTM multi-task learning framework with an individual attention head for each category .
To better compare our model with this approach , we changed the encoder to BERT - base .
For TACSA task : ? LR ( Saeidi et al. , 2016 ) : a logistic regression classfier with linguistic features .
? LSTM -final ( Saeidi et al. , 2016 ) ( Ye and Li , 2020 ) : a recurrent entity memory network that employs both word-level information and sentence - level hidden memory for entity state tracking .
In TACSA task , besides these models , we also compared our model with the BERT - pair-QA -B model and MTL model mentioned in ACSA comparison methods .
Main Results
The performances of compared methods and three types of CNE - net are shown in Table 3 ( ACSA task ) and Table 4 ( TACSA task ) .
All the models with BERT encoder ( QA -B , MTL and our CNE - net ) achieved better performance compared with models without BERT encoder ( XRCE , NCR - Canada , AT - LSTM , ATAE - LSTM , SenitcLSTM , Dmu entnet , and REN ) .
Our CNE - net performs better compared with QA -B and MTL framework
Model Category Extraction Sentiment Analysis P R F binary 3 - way 4 - way XRCE ( Brun et al. , 2014 ) 83.23 81.37 82.29 --78.1 NRC - Canada ( Kiritchenko et al. , 2014 ) in both ACSA and TACSA tasks .
QA - B is a singletask approach , which each category is trained independently .
Our CNE - net is a multi-task learning framework .
It performs better than QA - B by using shared semantic features and sentiment labels in all the categories .
CNE - net also performs better compared with the MTL model since it encodes the category names as additional features to generate the representation of each category .
Our CNE - net-SEP -sent .- att. model achieves state - of- the - art on all the evaluation metrics in both SemEval14 - Task4 and Sentihood dataset .
The improved extraction F 1 is 0.0080 in the SemEval14 - Task4 ( increased from 0.9147 in QA - B to 0.9227 in CNE - net-SEP-sent.att. ) , while it is 0.010 in the Sentihood dataset ( increased from 0.884 in MTL to 0.894 in CNE - net-SEP -sent.att . ) .
The accuracy metrics for sentiment analysis in the SemEval14 - Task4 are binary , 3 - way and 4way , which refers to accuracy with positive / negative ( binary ) , positive / neutral / negative ( 3 - way ) and positive / neutral / negative / conflict ( 4 - way ) .
The improvement of sentiment classification accuracy is 0.012 in SemEval14 - Task4 ( 4 - way setting , in - creased from 0.859 in QA - B to 0.871 in CNEnet-SEP -sent.att. ) , while is 0.004 in the Sentihood dataset ( increased from 0.971 in MTL to 0.975 in CNE - net-SEP -sent.att . ) .
CNE - net-SEP uses [ SEP ] as a feature representation for sentiment classification .
It performs the poorest among all three types of CNE - net since representation from only [ SEP ] token does not make full use of sentence information and category information .
CNE - net-CLS - att. uses [ CLS ] as sentence representation and applies attention mechanism to build the relationship between sentence representation and the category name hidden states to get sentiment classification feature and achieve better performance .
The CNE-net-SEPsent .- att. uses attention twice .
The first one is to build category - name - aware sentence embeddings for each category with [ SEP ] as query and sentence hidden states matrix as key and value , while the second one is to apply each category - name - aware sentence embedding to generate category representation like what we do in CNE - net- CLS - att . .
This category - name - aware sentence embedding and the sentence - aware category embedding makes it per- form the best in the three types of CNE - net .
Incremental Learning Results
This section describes the performance in the incremental learning task .
We trained the model following incremental learning workflow , as mentioned in section 4.3 .
We compared the results between mixtraining ( short as mix . ) ( mixing Sample - Source and Sample-Target ) and incremental learning ( short as incre . ) , for both extraction F 1 and sentiment accuracy .
Firstly , we compare the performance in target category , i.e. aspect category extraction F 1 ( short as extra . ) and sentiment analysis accuracy ( short as senti . ) from mix-training process and incremental learning .
As the target category performance shown in Table 5 , there is no significant difference between mix-training and incremental learning for both aspect extraction and sentiment analysis .
For example , in SemEval14 - Task-inc , the extraction F 1 and sentiment accuracy of CNE - net-SEP -sent .- att. are 0.936 and 0.930 respectively in mix-training , while they are 0.937 and 0.932 respectively in incremental learning .
In Sentihood-inc , the extraction F 1 and sentiment accuracy of CNE - net-SEPsent .- att. are 0.952 and 0.919 respectively in mix-training , while they are 0.954 and 0.920 respectively in incremental learning .
This indicates incremental learning does not decrease the performance in the target category .
Our CNE - net-SEP -sent .- att. performs the best in all the models .
Secondly , we compare aspect extraction and sentiment analysis performance in source categories after incremental learning , since both source categories and target categories requires high accuracy .
The extraction F 1 and sentiment accuracy of source categories after the incremental learning process as well as in the mix-training process are shown in Table 6 .
There is no significant difference in sentiment accuracy of source categories after training with incremental learning data .
For example , in SemEval14 - Task-inc , sentiment accuracy of CNEnet-SEP -sent .- att. is 0.855 in mix-training , while it is 0.854 in incremental learning .
This is probably because of the similar sentiment features between categories , in which the fine-tuning process does not make a great difference .
However , for category extraction , MTL suffers from catastrophic forgetting after fine-tuning .
In SemEval14 - Task4-inc , extraction F 1 of MTL model of source categories decreases from 0.898 in mix-training to 0.698 after incremental learning ,
Discussion
We have confirmed the effectiveness of CNE -nets for ( T) ACSA tasks and ( T) ACSA incremental learning tasks .
However , there remains a question , why our model suffers less from catastrophic forgetting in incremental learning ?
To answer this question , we compare the incremental learning performance of our CNE - net-SEPsent .- att. with a similar model but the decoders in each category are unshared with W 1 = W 2 = ... = W ncat and b 1 = b 2 = ... = b ncat ( CNE - net-SEPsent .- att.- unshared ) in equation ( 1 ) and the results are shown in Table 7 .
There is no significant difference in target category between the model with shared decoders and the model with unshared decoders , indicating both shared and unshared model is able to get enough feature for category extraction and sentiment analysis in target category .
However , it is more important that , in CNE - net-SEP -sent.att . - unshared , the extraction F 1 suffers from a sudden decrease .
In SemEval14 - Task4-inc , extraction F 1 decreases from 0.913 with shared decoder to 0.842 with unshared decoder , while in Sentihoodinc , extraction F 1 decreases from 0.863 with shared decoder to 0.796 with unshared decoder .
We believe the decreased extraction F 1 in source categories is due to the unshared decoders for each task , which results in only shared encoder and target - category decoders are fine-tuned during the fine-tuning process .
In contrast , the decoder of source categories remains unchanged .
The fine-tuned encoder and original source - category decoder is the reason for the catastrophic forgetting problem in the category extraction evaluation .
In our shared decoder approach , both encoders and decoders are shared and fine-tuned to weaken the catastrophic forgetting problem .
Conclusion
In this paper , in order to make multi-task learning feasible for incremental learning , we proposed CNE - net with different attention mechanisms .
The category name features and the multi-task learning structure help the model achieve state - of- the - art on ACSA and TACSA tasks .
Furthermore , the shared encoder and decoder layers weaken catastrophic forgetting in the incremental learning task .
We proposed a task for ( T) ACSA incremental learning and achieved the best performance with CNE - net compared with other strong baselines .
Further research may be concerned with zero-shot learning on new categories .
Table 1 : 1 Example and gold standard for ( T) ACSA examples .
