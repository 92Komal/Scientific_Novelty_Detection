title
Lifelong Learning for Sentiment Classification
abstract
This paper proposes a novel lifelong learning ( LL ) approach to sentiment classification .
LL mimics the human continuous learning process , i.e. , retaining the knowledge learned from past tasks and use it to help future learning .
In this paper , we first discuss LL in general and then LL for sentiment classification in particular .
The proposed LL approach adopts a Bayesian optimization framework based on stochastic gradient descent .
Our experimental results show that the proposed method outperforms baseline methods significantly , which demonstrates that lifelong learning is a promising research direction .
Introduction Sentiment classification is the task of classifying an opinion document as expressing a positive or negative sentiment .
Liu ( 2012 ) and Pang and Lee ( 2008 ) provided good surveys of the existing research .
In this paper , we tackle sentiment classification from a novel angle , lifelong learning ( LL ) , or lifelong machine learning .
This learning paradigm aims to learn as humans do : retaining the learned knowledge from the past and use the knowledge to help future learning ( Thrun , 1998 , Chen and Liu , 2014 b , Silver et al. , 2013 .
Although many machine learning topics and techniques are related to LL , e.g. , lifelong learning ( Thrun , 1998 , Chen and Liu , 2014 b , Silver et al. , 2013 , transfer learning ( Jiang , 2008 , Pan and Yang , 2010 ) , multi-task learning ( Caruana , 1997 ) , never-ending learning ( Carlson et al. , 2010 ) , selftaught learning ( Raina et al. , 2007 ) , and online learning ( Bottou , 1998 ) , there is still no unified definition for LL .
Based on the prior work and our research , to build an LL system , we believe that we need to answer the following key questions : 1 . What information should be retained from the past learning tasks ?
2 . What forms of knowledge will be used to help future learning ?
3 . How does the system obtain the knowledge ?
4 . How does the system use the knowledge to help future learning ?
Motivated by these questions , we present the following definition of lifelong learning ( LL ) .
Definition ( Lifelong Learning ) :
A learner has performed learning on a sequence of tasks , from 1 to N ? 1 . When faced with the N th task , it uses the knowledge gained in the past N ?
1 tasks to help learning for the N th task .
An LL system thus needs the following four general components :
1 . Past Information Store ( PIS ) :
It stores the information resulted from the past learning .
This may involve sub-stores for information such as ( 1 ) the original data used in each past task , ( 2 ) intermediate results from the learning of each past task , and ( 3 ) the final model or patterns learned from the past task , respectively .
2 . Knowledge Base ( KB ) :
It stores the knowledge mined or consolidated from PIS ( Past Information Store ) .
This requires a knowledge representation scheme suitable for the application .
3 . Knowledge Miner ( KM ) .
It mines knowledge from PIS ( Past Information Store ) .
This mining can be regarded as a meta-learning process because it learns knowledge from information resulted from learning of the past tasks .
The knowledge is stored to KB ( Knowledge Base ) .
4 . Knowledge -Based Learner ( KBL ) : Given the knowledge in KB , this learner is able to leverage the knowledge and / or some information in PIS for the new task .
Based on this , we can define lifelong sentiment classification ( LSC ) :
Definition ( Lifelong Sentiment Classification ) :
A learner has performed a sequence of supervised sentiment classification tasks , from 1 to N ? 1 , where each task consists of a set of training documents with positive and negative polarity labels .
Given the N th task , it uses the knowledge gained in the past N ?
1 tasks to learn a better classifier for the N th task .
It is useful to note that although many researchers have used transfer learning for supervised sentiment classification , LL is different from the classic transfer learning or domain adaptation ( Pan and Yang , 2010 ) .
Transfer learning typically uses labeled training data from one ( or more ) source domain ( s ) to help learning in the target domain that has little or no labeled data ( Aue and Gamon , 2005 , Bollegala et al. , 2011 ) .
It does not use the results of the past learning or knowledge mined from the results of the past learning .
Further , transfer learning is usually inferior to traditional supervised learning when the target domain already has good training data .
In contrast , our target ( or future ) domain / task has good training data and we aim to further improve the learning using both the target domain training data and the knowledge gained in past learning .
To be consistent with prior research , we treat the classification of one domain as one learning task .
One question is why the past learning tasks can contribute to the target domain classification given that the target domain already has labeled training data .
The key reason is that the training data may not be fully representative of the test data due to the sample selection bias ( Heckman , 1979 , Shimodaira , 2000 , Zadrozny , 2004 .
In few real- life applications , the training data are fully representative of the test data .
For example , in a sentiment classification application , the test data may contain some sentiment words that are absent in the training data of the target domain , while these sentiment words have appeared in some past domains .
So the past domain knowledge can provide the prior polarity information in this situation .
Like most existing sentiment classification papers ( Liu , 2012 ) , this paper focuses on binary classification , i.e. , positive ( + ) and negative ( ? ) polarities .
But the proposed method is also applicable to multi-class classification .
To embed and use the knowledge in building the target domain classifier , we propose a novel optimization method based on the Na?ve Bayesian ( NB ) framework and stochastic gradient descent .
The knowledge is incorporated using penalty terms in the optimization for-mulation .
This paper makes three contributions : 1 . It proposes a novel lifelong learning approach to sentiment classification , called lifelong sentiment classification ( LSC ) .
2 . It proposes an optimization method that uses penalty terms to embed the knowledge gained in the past and to deal with domain dependent sentiment words to build a better classifier .
3 . It creates a large corpus containing reviews from 20 diverse product domains for extensive evaluation .
The experimental results demonstrate the superiority of the proposed method .
Related Work
Our work is mainly related to lifelong learning and multi-task learning ( Thrun , 1998 , Caruana , 1997 , Chen and Liu , 2014 b , Silver et al. , 2013 .
Existing lifelong learning approaches focused on exploiting invariances ( Thrun , 1998 ) and other types of knowledge ( Chen and Liu , 2014 b , Chen and Liu , 2014a , Ruvolo and Eaton , 2013 across multiple tasks .
Multi-task learning optimizes the learning of multiple related tasks at the same time ( Caruana , 1997 , Chen et al. , 2011 , Saha et al. , 2011 , Zhang et al. , 2008 .
However , these methods are not for sentiment analysis .
Also , our na?ve Bayesian optimization based LL method is quite different from all these existing techniques .
Our work is also related to transfer learning or domain adaptation ( Pan and Yang , 2010 ) .
In the sentiment classification context , Aue and Gamon ( 2005 ) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews .
Blitzer et al. ( 2007 ) proposed to first find some common or pivot features from the source and the target , and then identify correlated features with the pivot features .
The final classifier is built using the combined features .
Li and Zong ( 2008 ) built a meta-classifier ( called CLF ) using the outputs of each base classifier constructed in each domain .
Other works along similar lines include ( Andreevskaia and Bergler , 2008 , Bollegala et al. , 2011 , He et al. , 2011 , Ku et al. , 2009 , Li et al. , 2012 , Pan and Yang , 2010 , Tan et al. , 2007 , Wu et al. , 2009 , Xia and Zong , 2011 , Yoshida et al. , 2011 . Additional details about these and other related works can be found in ( Liu , 2012 ) .
However , as we discussed in the introduction , these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner .
3 Proposed LSC Technique
Na?ve Bayesian Text Classification
Before presenting the proposed method , we briefly review the Na?ve Bayesian ( NB ) text classification as our method uses it as the foundation .
NB text classification ( McCallum and Nigam , 1998 ) basically computes the conditional probability of each word w given each class c j ( i.e. , P ( w| c j ) ) and the prior probability of each class c j ( i.e. , P ( c j ) ) , which are used to calculate the posterior probability of each class c j given a test document d ( i.e. , P ( c j | d ) ) .
c j is either positive ( + ) or negative ( ? ) in our case .
The key parameter P ( w|c j ) is computed as : P ( w| c j ) = ? + N c j , w ? | V | + | V | v=1 N c j , v ( 1 ) where N c j , w is the frequency of word w in documents of class c j .
| V | is the size of vocabulary V and ?
( 0 ? ? ? 1 ) is used for smoothing .
Components in LSC
This subsection describes our proposed method corresponding to the proposed LL components .
Objective Function
In this subsection , we introduce the objective function used in our method .
The key parameters that affect NB classification results are P ( w|c j ) which are computed using empirical counts of word w with class c j , i.e. , N c j , w ( Eq. 1 ) .
In binary classification , they are N + , w and N ? ,w .
This suggests that we can revise these counts appropriately to improve classification .
In our optimization , we denote the optimized variables X + , w and X ? ,w as the number of times that a word w appears in the positive and negative class .
We called them virtual counts to distinguish them from empirical counts N + , w and N ? , w .
For correct classification , ideally , we should have the posterior probability P ( c j |d i ) = 1 for labeled class c j , and for the other class c f , we should have P ( c f |d i ) = 0 .
Formally , given a new domain training data D t , our objective function is : | D t | i=1 ( P ( c j |d i ) ? P ( c f |d i ) ) ( 2 )
Here c j is the actual labeled class of d i ?
D t .
In this paper , we use stochastic gradient descent ( SGD ) to optimize on the classification of each document d i ?
D t .
Due to the space limit , we only show the optimization process for a positive document ( the process for a negative document is similar ) .
The objective function under SGD for a positive document is : F + , i = P ( + | d i ) ? P ( ?|d i ) ( 3 )
To further save space , we omit the derivation steps and give the final derivatives below ( See the detailed derivation steps in the separate supplementary note ) : where n u ,d i is the term frequency of word u in document d i .
X denotes all the variables consisting of X + , w and X ? , w for each word w .
The partial derivatives for a word u , i.e. , ?g ?X +, u and ?g ?X ? , u , are quite straightforward and thus not shown here .
g ( X ) = ? | V | + | V | v=1 X + , v ? | V | + | V | v=1 X? , v |d i | ( 4 ) ?F + , i ?X + , u = n u, d i ?+ X + , u + P ( ? ) P ( + ) w?d i ?+ X ?,w ?+ X +, w n w, d i ? ?g ?X +, u 1 + P ( ? ) P ( + ) w?d i ?+ X ?,w ?+X +, w n w, d i ?
g ( X ) ? n u, d i ? + X + , u ( 5 ) ?F + , i ?X ? , u = n u , d i ?+ X ? , u ? g ( X ) + ?g ?X ? , u P ( + ) P ( ? ) w?d i ?+ X +, w ?+X ?, w n w, d i + g ( X ) ( X 0 + , w = N t + , w +N KB + , w and X 0 ? , w = N t ? , w +N KB ? ,w are served as a reasonable starting point for SGD , where N t + , w and N t ? ,w are the empirical counts of word w and classes + and ? from domain D t , and N KB + , w and N KB ? ,w are from knowledge KB ( Section 3.2 ) .
The SGD runs iteratively using the following rules for the positive document d i until convergence , i.e. , when the difference of Eq. 2 for two consecutive iterations is less than 1e?3 ( same for the negative document ) , where ? is the learning rate : X l + , u = X l?1 + , u ? ?F + , i ?X + , u , X l ? , u = X l?1 ? , u ? ?F + , i ?X ?,u
Exploiting Knowledge via Penalty Terms
The above optimization is able to update the virtual counts for a better classification in the target domain .
However , it does not deal with the issue of domain dependent sentiment words , i.e. , some words may change the polarity across different domains .
Nor does it utilize the domain-level knowledge in the knowledge base KB ( Section 3.2 ) .
We thus propose to add penalty terms into the optimization to accomplish these .
The intuition here is that if a word w can distinguish classes very well from the target domain training data , we should rely more on the target domain training data in computing counts related to w .
So we define a set of words V T that consists of distinguishable target domain dependent words .
A word w belongs to V T if P ( w| + ) is much larger or much smaller than P ( w| ? ) in the target domain , i.e. , P ( w | + ) P ( w| ? ) ? ? or P ( w| ? ) P ( w| + ) ? ? , where ? is a parameter .
Such words are already effective in classification for the target domain , so the virtual counts in optimization should follow the empirical counts ( N t + , w and N t ? , w ) in the target domain , which are reflected in the L2 regularization penalty term below ( ? is the regularization coefficient ) : 1 2 ? w?V T X+ , w ? N t + , w 2 + X? , w ? N t ? , w 2 ( 7 ) To leverage domain-level knowledge ( the second type of knowledge in KB in Section 3.2 ) , we want to utilize only those reliable parts of knowledge .
The rationale here is that if a word only appears in one or two past domains , the knowledge associated with it is probably not reliable or it is highly specific to those domains .
Based on it , we use domain frequency to define the reliability of the domain-level knowledge .
For w , if M KB + , w ? ? or M KB ? ,w ? ? (? is a parameter ) , we regard it as appearing in a reasonable number of domains , making its knowledge reliable .
We denote the set of such words as V S .
Then we add the second penalty term as follows : 1 2 ? w?V S X +, w ? R w ? X 0 +, w 2 + 1 2 ? w?V S X ? ,w ? ( 1 ? R w ) ? X 0 ? , w 2 ( 8 ) where the ratio R w is defined as M KB + , w /( M KB + , w + M KB ? , w ) .
X 0 + , w and X 0 ? ,w are the starting points for SGD ( Section 3.3 ) .
Finally , we revise the partial derivatives in Eqs. 4 - 6 by adding the corresponding partial derivatives of Eqs. 7 and 8 to them .
Experiments Datasets .
We created a large corpus containing reviews from 20 types of diverse products or domains crawled from Amazon.com ( i.e. , 20 datasets ) .
The names of product domains are listed in Table 1 . Each domain contains 1,000 reviews .
Following the existing work of other researchers ( Blitzer et al. , 2007 , Pang et al. , 2002 , we treat reviews with rating > 3 as positive and reviews with rating < 3 as negative .
The datasets are publically available at the authors websites .
Natural class distribution :
We keep the natural ( or skewed ) distribution of the positive and negative reviews to experiment with the real-life situation .
F1 - score is used due to the imbalance .
Table 3 : Balanced class distribution : Average accuracy over 20 domains for each system .
Balanced class distribution :
We also created a balance dataset with 200 reviews ( 100 positive and 100 negative ) in each domain dataset .
This set is smaller because of the small number of negative reviews in each domain .
Accuracy is used for evaluation in this balanced setting .
We used unigram features with no feature selection in classification .
We followed ( Pang et al. , 2002 ) to deal with negation words .
For evaluation , each domain is treated as the target domain with the rest 19 domains as the past domains .
All the models are evaluated using 5 - fold cross validation .
Baselines .
We compare our proposed LSC model with Na?ve Bayes ( NB ) , SVM 1 , and CLF ( Li and Zong , 2008 ) For LSC , we empirically set ? = 6 and ? = 6 .
The learning rate ? and regularization coefficient ? are set to 0.1 empirically .
? is set to 1 for ( Laplace ) smoothing .
Table 2 shows the average F1 - scores for the negative class in the natural class distribution , and Table 3 shows the average accuracies in the balanced class distribution .
We can clearly see that our proposed model LSC achieves the best performance in both cases .
In general , NB -S ( and SVM -S ) are worse than NB -T ( and SVM -T ) , both of which are worse than NB - ST ( and SVM - ST ) .
This shows that simply merging both past domains and the target domain data is slightly beneficial .
Note that the average F1 - score for the positive class is not shown as all classifiers perform very well because the positive class is the majority class ( while our model performs slightly better than the baselines ) .
The improvements of the proposed LSC model over all baselines in both cases are statistically significant using paired t-test ( p < 0.01 compared to NB - ST and CLF , p < 0.0001 compared to the others ) .
In the balanced class setting ( Table 3 ) , CLF performs better than NB -T and SVM -T , which is consistent with the results in ( Li and Zong , 2008 ) .
However , it is still worse than our LSC model .
Effects of # Past Domains .
Figure 1 shows the effects of our model using different number of past domains .
We clearly see that LSC performs better with more past domains , showing it indeed has the ability to accumulate knowledge and use the knowledge to build better classifiers .
Conclusions
In this paper , we proposed a lifelong learning approach to sentiment classification using optimization , which is based on stochastic gradient descent in the framework of Bayesian probabilities .
Penalty terms are introduced to effectively exploit the knowledge gained from past learning .
Our experimental results using 20 diverse product review domains demonstrate the effectiveness of the method .
We believe that lifelong learning is a promising direction for building better classifiers .
.
Note that NB and SVM can only work on a single domain data .
To have a comprehensive comparison , they are fed with three types of training data : a ) labeled training data from the target domain only , denoted by NB -T and SVM -T ; b ) labeled training data from all past source domains only , denoted by NB -S and SVM -S ; c ) merged ( labeled ) training data from all past domains and the target domain , referred to as NB - ST and SVM - ST .
Figure 1 : 1 Figure 1 : ( Left ) : Negative class F1 - score of LSC with # past domains in natural class distribution .
( Right ) : Accuracy of LSC with # past domains in balanced class distribution .
Table 1 : 1 Names of the 20 product domains and the proportion of negative reviews in each domain .
6 )
Table 2 : 2 Natural class distribution : Average F1 - score of the negative class over 20 domains .
Negative class is the minority class and thus harder to classify .
NB -T NB-S NB -ST SVM -T SVM -S SVM -ST CLF LSC 56.21 57.04 60.61 57.82 57.64 61.05 12.87 67.00 NB -T NB-S NB -ST SVM -T SVM -S SVM -ST CLF LSC 80.15 77.35 80.85 78.45 78.20 79.40 80.49 83.34
