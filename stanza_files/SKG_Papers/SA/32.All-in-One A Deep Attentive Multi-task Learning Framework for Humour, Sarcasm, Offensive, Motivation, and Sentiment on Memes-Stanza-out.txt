title
All-in-One : A Deep Attentive Multi-task Learning Framework for Humour , Sarcasm , Offensive , Motivation , and Sentiment on Memes
abstract
In this paper , we aim at learning the relationships and similarities of a variety of tasks , such as humour detection , sarcasm detection , offensive content detection , motivational content detection and sentiment analysis on a somewhat complicated form of information , i.e. , memes .
We propose a multi-task , multi-modal deep learning framework to solve multiple tasks simultaneously .
For multi-tasking , we propose two attention - like mechanisms viz. , Inter-task Relationship Module ( iTRM ) and Inter-class Relationship Module ( iCRM ) .
The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other .
In contrast , iCRM develops relations between the different classes of tasks .
Finally , representations from both the attentions are concatenated and shared across the five tasks ( i.e. , humour , sarcasm , offensive , motivational , and sentiment ) for multi-tasking .
We use the recently released dataset in the Memotion Analysis task @ SemEval 2020 , which consists of memes annotated for the classes as mentioned above .
Empirical results on Memotion dataset show the efficacy of our proposed approach over the existing state - of- theart systems ( Baseline and SemEval 2020 winner ) .
The evaluation also indicates that the proposed multi-task framework yields better performance over the single - task learning .
Introduction
The content and form of content shared on online social media platforms have changed rapidly over time .
Currently , one of the most popular forms of media shared on such platforms is ' Memes ' .
According to its definition from Oxford Dictionary , a meme is a piece of data , often in the form of images , text or videos that carry cultural information through an imitable phenomenon with a mimicked theme , that is shared ( sometimes with slight modification ) rapidly by internet users .
Every meme can be associated with five affect values , namely humour ( Hu ) , sarcastic ( Sar ) , offensive ( Off ) , motivational ( Mo ) , and sentiment ( Sent ) .
Hence , in a broad sense , memes can be categorized into four intersecting sets viz .
humorous memes , sarcastic memes , offensive memes , and motivational memes .
Humour refers to the quality of being amusing or comic .
Formally , humour is defined as the nature of experiences to induce laughter and provide amusement .
Humourous memes are the most popular and widely used on social media platforms .
An example for humourous memes is shown in Figure 1a .
Sarcasm is often used to convey thinly veiled disapproval humorously .
A sarcastic meme is a meme where an incongruity exists between the intended meaning and the way it is expressed .
These are generally used to express dissatisfaction or to veil insult through humour .
As we can see in Figure 1a , the person on the right is made fun of , without explicitly expressing it , which is a typical example of a sarcastic meme .
Offensive content include a lot of insulting , derogatory terms .
It is contrary to the moral sense or good .
As social media expands , offensive language has become a huge headache to maintain sanity on social media .
As memes are growing to become more and more popular , detecting offensive memes on such platforms is becoming an important and challenging task .
Motivation is derived from the word ' motive ' which means needs or desires within the individuals .
It is the process of stimulating people to actions to achieve their goals .
By its definition , motivational memes are those that benefit a certain group of people to achieve their plans or goals .
Motivation can be both either positive or negative .
However , we usually consider motivation in a positive sense .
Figure 1 b is an excellent example for the positive motivation .
Sentiment analysis refers to the process of computationally identifying and categorizing opinions expressed in a piece of communication , especially to determine whether the writer 's attitude towards a particular topic , product , etc. is positive , negative , or neutral .
This has been a very prominent and important task in Natural Language Processing .
Sentiment analysis on memes refers to the task of systematically extracting its emotional tone in understanding the opinion expressed by the meme .
Figure 1 b is an example for positive sentiment towards the government and Figure 1c for negative sentiment towards Ph.D. in Electrical Engineering .
Generally , specific labels of one task have a strong relation to the other labels of sarcasm , offensive , humour or motivational tasks .
Through proper representation , training , and evaluation , these relations can be modelled to help each other for better classification .
For example , in Figure 1 b , just by seeing text , the meme can be either sarcastic or motivational , but the image in the meme confirms that this has an overall positive sentiment and hence motivational .
Similarly , in Figure 1 c , knowing that the meme is sarcastic and has a negative sentiment makes it highly probable to being offensive .
As seen above , humorous , motivational , offensive , and sarcastic nature of the memes are closely related .
Thus , a multi-task learning framework would be extremely beneficial in such scenarios .
In this paper , we exploit these relationships and similarities in the tasks of humour detection , sarcasm detection , offensive content detection , motivational content detection , and sentiment in a multi-task manner .
The main contributions and / or attributes are as follows : ( a ) .
We propose a multi-task multimodal deep learning framework to leverage the util-ity of each task to help each other in a multi-task framework ; ( b ) .
We propose two attention mechanisms viz .
iTRM and iCRM to better understand the relationship between the tasks and between the classes of tasks , respectively ; and ( c ) .
We present the state- of - the - art results for meme prediction in the multi-modal scenario .
Related Work Sentiment analysis and its related tasks , such as humour detection , sarcasm detection , and offensive content detection , are the topics of interest due to their needs in recent times .
There has been a phenomenal growth in multi-modal information sources in social media , such as audio , video , and text .
Multi-modal information analysis has attracted the attention of researchers and developers due to their complexity , and multi-tasking has been of keen interest in the field of affect analysis .
Humour : Early feature - based models attempt to solve humour include the models based on word overlap with jokes , presence of ambiguity , and word overlap with common idioms ( Sj?bergh and Araki , 2007 ) , human-centeredness , and negative polarity ( Mihalcea and Pulman , 2007 ) .
Some of the recent multi-modal approaches include utilizing information from the various modalities , such as acoustic , visual , and text , using deep learning models ( Bertero and Fung , 2016 ; Yang et al. , 2019 ; Swamy et al. , 2020 ) .
Yang et al. ( 2020 ) employs a paragraph decomposition technique coupled with fine-tuning BERT ( Devlin et al. , 2018 ) model for humour detection on three languages ( Chinese , Spanish and Russian ) .
Sarcasm : Starting from the traditional approaches , such as rule- based methods ( Veale and Hao , 2010 ) , lexical features ( Carvalho et al. , 2009 ) , and incongruity ( Joshi et al. , 2015 ) to all the way up to multi-modal deep learning techniques ( Schi-fanella et al. , 2016 ) , sarcasm detection has been showing its presence .
Castro et al. ( 2019 ) created a multi-modal conversational dataset , MUStARD from the famous TV shows , and provided baseline SVM approaches for sarcasm detection .
Recently , Chauhan et al. ( 2020 ) proposed a multi-task learning framework for multi-modal sarcasm , sentiment and emotion analysis to explore how sentiment and emotion helps sarcasm .
The author used the MUS - tARD dataset and extended the MUStARD dataset with sentiment ( implicit and explicit ) and emotion ( implicit and explicit ) labels .
Offensive 2020 ) proposes a novel chaining method of neural networks for identifying motivational texts where the output from one model is passed on to the second model .
Sentiment :
An important task to leverage multimodality information effectively is to combine them using various strategies .
Mai et al. ( 2019 ) employs a hierarchical feature fusion strategy , Divide , Conquer , and Combine for affective computing .
Chauhan et al. ( 2019 ) uses the Inter-modal Interaction Module ( IIM ) to combine information from a pair of modalities for multi-modal sentiment and emotion analysis .
Some of the other techniques include a contextual inter-modal attention based framework for multi-modal sentiment classification ( Ghosal et al. , 2018 ; . Multi-task :
Some of the early attempts to correlate the tasks like sarcasm , humour , and offensive statements include a features based classification using various syntactic and semantic features , such as frequency of words , the intensity of adverbs and adjectives , the gap between positive and negative terms , the structure of the sentence , synonyms and others ( Barbieri and Saggion , 2014 ) .
More recently , Badlani et al. ( 2019 ) proposed a convolution - based model to extract the embedding by fine-tuning the same for the tasks of sentiment , sarcasm , humour , and hate-speech and then concatenating these representations to be used in a sentiment classifier .
In our current work , we propose a multi-task multi-modal deep learning framework to simultaneously solve the tasks of sarcasm , humour , offensive , and motivational on memes .
Further , to the best of our knowledge , this is the very first attempt at solving the multi-modal affect analysis on memes in a multi-task deep learning framework .
We demonstrate through a detailed empirical evaluation that a multi-task learning framework can improve the performance of individual tasks over a single task learning framework .
Proposed Methodology
We propose an attention - based deep learning model to solve the problem of multi-task affect analysis of memes .
The inputs to the model are the meme itself and the manually corrected text extracted through OCR .
The overall architecture is depicted in Figure 2 .
The source code is available at http://www.
iitp.ac.in / ?ai-nlp-ml/resources.html .
Input Layer :
We now describe the input features for our proposed model .
Text Input Given
N number of samples , where each sample is associated with meme image and the corresponding text .
Let us assume , in each sample , there are n T number of words w 1:n T = w 1 , ... , w n T , where w j ?
R d T , d T = 768 , and w j is obtained using BERT ( Devlin et al. , 2018 ) .
The maximum number of words for i th sample across the dataset is 189 .
Image Input Image is the prime component of any meme and contains the majority of the information .
To leverage this information effectively , feature vectors from average pooling layer ( avgpool ) of the Im-ageNet pre-trained ResNet - 152 ( He et al. , 2016 ) image classification model are extracted .
Each image is first pre-processed by resizing to 224 ? 224 and then normalized .
The extracted feature vector for image of i th sample is represented by V i ?
R dv and d v = 2048 .
Attention Modules
These vectors are concatenated and then passed through a set of four dense layers to obtain the vectors of equal length d represented by where t is a task ?
{ humour , sarcasm , offensive , motivational} .
These vectors are then passed through the Inter-class Relationship Module and Inter-task Relationship module .
The output is then concatenated and passed through another set of four dense layers , and a layer of softmax is applied to obtain the final output .
T V t ?
R d ,
Inter-class Relationship Module
This module is used to learn the relationship between the classes of all the tasks .
This is done by passing T V t through another dense layer and softmax ( confidence score ) .
For each task , we first group all the classes into two classes for the hierarchical classification of the sample .
At this level , the sample is labelled with either positive or negative for all the tasks .
For instance , a sample will be labelled as either sarcastic or not sarcastic for sarcasm tasks .
A loss is back - propagated using these confidence scores for the corresponding tasks .
This is done in order to control each dense layer so that it aligns with the respective tasks .
Meanwhile , a dot-product of the softmax scores of each task is obtained and used to form the Score Matrix .
This is then flattened and passed forward .
Inter-task Relationship Module
While the above module is used to find the correlation between the individual classes , this module is used to find the relationship between the different tasks in the model .
This is done by initially finding the cosine-similarity between T V t vectors .
And a pooling layer is used to collect information between the tasks and then normalized by the corresponding cosine-similarity score .
The output from the pooling layer is then flattened and passed forward .
Output Unit
The flattened vectors from iT RM and iCRM are concatenated and then branched into four dense layers for each task .
This is then forwarded through a softmax layer to obtain the final output for each task , and the loss is back - propagated to learn the parameters .
In this layer , the information from both iCRM and iTRM modules will be leveraged and used to predict the final outcome .
Please note that , there are two sets of loss used in the model , one in the iCRM module and second at the end the of Output Unit .
Dataset
We perform experiments using the dataset released in the Memotion Analysis 1.0 @ SemEval 2020 Task ( Sharma et al. , 2020 ) 1 . This dataset consists of 6992 samples .
Each sample consists of an image , corrected text extracted from the meme , and the five labels associated with the five tasks , viz. , Humour , Sarcasm , Offensive , Motivational , and Overall Sentiment .
The distribution of the classes associated with each of the five tasks with label is shown in Table 1 and Table 2
We address 5 multi-modal affective analysis problems , namely humour classification , sarcasm classification , offensive classification , motivational classification , and sentiment classification .
A. Humour classification :
There are four classes associated with the humour task , namely not funny , funny , very funny , and hilarious , which are labelled as 0 , 1 , 2 , and 3 , respectively .
B. Sarcasm classification :
There are four classes associated with the sarcasm task , namely not sarcastic , general , twisted meaning , and very twisted which are labelled as 0 , 1 , 2 , and 3 respectively .
C. Offensive classification :
There are four classes associated with the offensive task , namely not offensive , slight , very offensive , and hateful offensive which are labelled as 0 , 1 , 2 , and 3 , respectively .
D. Motivational classification :
There are two classes associated with the motivational task , namely not motivational and motivational , which are labelled as 0 and 1 , respectively .
E. Sentiment classification :
There are five classes associated with the sentiment task , namely very negative , negative , neutral , positive , and very positive , which are labelled as 0 , 1 , 2 , 3 , and 4 , respectively .
Experimental setup
In accordance with the SemEval 2020 ( Sharma et al. , 2020 ) , the project is organized into three sets of tasks 2 . ? Task A : Sentiment Classification :
In this task , memes are classified into 3 classes viz. , - 1 ( negative , very negative ) , 0 ( neutral ) and + 1 ( positive , very positive ) .
?
Task B : Binary - class Classification :
In this set of tasks , the memes are classified as follows ( c.f. T-B in Table 2 ) ; 1 . Humour ( funny , very funny , hilarious ) and Non-humour ( not funny ) .
2 . Sarcasm ( general , twisted meaning , very twisted ) and Non-sarcasm ( non sarcastic ) 3 . Offensive ( slight , very offensive , hateful offensive ) and Non-Offensive ( not offensive ) , and 4 . Motivational ( motivational ) and Nonmotivational ( not motivational ) .
?
Task C : Multi-class Classification :
In this set of task , the original labels are used as described in the dataset ( c.f. T-C in Table 2 ) for the tasks of Humour , Sarcasm , Offensive and Motivational .
Please note that , in Task A , as it is not a multitask scenario , iCRM and iTRM are not applicable .
For all the other sets of tasks , the entire network is shown in Figure 2 .
We evaluate our proposed model on the multimodal Memotion dataset .
We perform grid search to find the optimal hyper-parameters ( c.f. Table 3 ) .
Though we aim for a generic hyper-parameter configuration for all the experiments , in some cases , a different choice of the parameter has a significant effect .
Therefore , we choose different parameters for a different set of experiments .
We implement our proposed model on the open source machine learning library PyTorch 3 . Hugging Face 4 library is used for BERT implementation .
As the evaluation metric , we employ precision ( P ) , recall ( R ) , macro - F1 ( M a - F1 ) , and micro- F1 ( M i - F1 ) for all the tasks i.e. , humour , sarcasm , offensive , motivational , and sentiment .
We use Adam as an optimizer , Softmax as a classifier , and the categorical cross-entropy as a loss function for all the tasks .
Results and Analysis
We evaluate our proposed architecture with bimodal inputs ( i.e. , text and visual ) .
We show the obtained results for Task - A ( i.e. , sentiment analysis ) in Table 4 . Task - B has four different tasks , i.e. , humour , sarcasm , offensive , and sentiment with binary - class labels ( c.f. binary - class classification in Section 5 ) .
The results are shown in Table 5 .
L a b e l s Task - B ( Binary Classification )
Task - C has also four different tasks , i.e. , humour , sarcasm , offensive , and sentiment with multi-class labels ( c.f. multi-class classification in Section 5 ) .
The results are shown in Table 6 .
In both the tasks B and C , we outline the comparison between the multi-task ( MTL ) and single - task ( STL ) learning frameworks in Table 5 and Table 6 .
We observe that MTL shows better performance over the STL setups .
STL MTL P R Ma-F1 M i - F1 P R Ma-F1 M i - F1
Hu L a b e l s Task -C ( Multi-class Classification ) STL MTL P R Ma-F1 M i - F1 P R Ma-F1 M i - For the offensive task , we find that STL performs better than MTL .
We hypothesize that this is due to the model getting confused between the offensive and sarcastic ( or humorous ) memes .
From Table 9 , under Sarcasm , we can see that for the class V t , MTL predicts a few samples as sarcastic , whereas in actuality it belongs to the other classes .
However , we can see a decrease in performance for class H o under Offensive .
This is due to the lack of a larger dataset for the complex model to disambiguate the same .
In the example , BRB ... GOT TO TAKE CARE OF SOME SH*T IN UKRAIN ( c.f. Figure 1d ) , the actual set of labels are F n , G n , S g , N m .
The predicted labels in STL are V f , G n , S g , M o and in MTL are V f , T m , V o , M o .
This is supposed to be slightly offensive but got it confused with the sarcastic .
Comparative Analysis
We compare the results obtained in our proposed model against the baseline model and SemEval 2020 winner , which also made use of the same dataset .
The comparative analysis is shown in Table 7 .
Our proposed multi-modal framework achieves the best macro- F1 of 35.8 % ( 0.4 % ? ) and micro- F1 of 50.6 % ( 1.9 % ? ) as compared to macro- F1 of 35.4 % and micro- F1 of 48.7 % of the state - of - the - art system ( i.e. , SemEval 2020 Winner ) for Task - A. Similarly , for Task - B , we obtain the macro- F1 of 53.5 % ( 1.7 % ? ) and micro- F1 of 63.4 % ( 2.0 % ? ) as compared to the macro- F1 of 51.8 % and micro- F1 of 61.4 % of the state- ofthe - art system , whereas for Task - C , we obtain the macro - F1 of 33.3 % ( 1.1 % ? ) and micro- F1 of 41.9 % ( 4.1 % ? ) as compared to the macro- F1 of 32.2 % and micro- F1 of 37.8 % of the state - of- theart system .
It is evident from inter-dependence between all the tasks in improving the overall performance in comparison to the single - task learning .
We also show the confusion matrices corresponding to each set of tasks in Table 8a , Table 8 b , and Table 9 , respectively .
f F n V f H r N s G r T m V t N o S g V o H o N m M o STL N f 122
Error Analysis
We perform error analysis ( i.e. for Task - C ) on the predictions of our proposed model .
We take some utterances ( c.f. Table 10 ) with corresponding image ( c.f. Figure 3 ) , where we show that MTL is predicting correct while STL is not able to predict the right labels .
We also present the attention heatmaps for iCRM and iTRM of the multi-task learning framework in Figure 4 and Figure 5 , respectively .
We take the fifth utterance from Table 10 ( c.f. Figure 3e ) to illustrate the heatmap .
For iCRM ( c.f. Figure 4 ) , there are six matrices which show the interdependency between humour and sarcasm ( Hu - Sar ) , humour and offensive ( Hu - Off ) , humour and motivational ( Hu - Mo ) , sarcasm and offensive ( saroff ) , sarcasm and motivational ( Sar - Mo ) , and offensive and motivational ( Off - Mo ) , respectively , where 10 . the light shade to dark shade shows the amount of contributions in ascending sequence .
The main objective of iCRM is to develop the relationship between the classes of tasks .
Figure 4 shows the established relationship between the tasks .
We see the established relationship between the classes of tasks in Figure 4 .
For predicting the fifth utterance correctly in Table 10 , humour and Similarly , the main objective of iTRM is to develop the relationship between the tasks .
Figure 5 shows the established relationship between the tasks , and we see that attention put more weight on sarcasm and offensive pair while less weight on humour and sarcasm .
It is clear from the definition of sarcasm and humour ( c.f. Section 1 ) that both of them have a very different meaning when used in a sentence while the actual sentence looks similar .
Hence sarcasm and humour is found not be helping each other .
In this paper , we have successfully established the concept of obtaining effective relationships between inter-tasks and between inter-classes for multi-modal affect analysis .
We have proposed a deep attentive multi-task learning framework which helps to obtain very effective inter-tasks and interclasses relationship .
To capture the interdependence , we have proposed two attention - like mechanisms viz. , Inter-task Relationship Module ( iTRM ) and Inter-class Relationship Module ( iCRM ) .
The main motivation of iTRM is to learn the relationship between the tasks , i.e. which task helps the other tasks .
In contrast , iCRM develops the relations between the classes of tasks .
We have evaluated our proposed approach on a recently published Memotion dataset .
Experimental results suggest the efficacy of the proposed model over the existing state - of - the - art systems ( Baseline and SemEval 2020 winner ) .
The evaluation shows that the proposed multi-task framework yields better performance over single - task learning .
The dataset used for the experiments is relatively small for training an effective deep learning model and is heavily biased .
Therefore , assembling a large , and more balance dataset with quality annotations is an important job .
Moreover , the memes are a complicated form of data which includes both text and image that repeat over numerous memes ( meme templates ) .
Hence quality representation of memes for affect analysis is challenging future work .
Figure 1a , Figure 1c and Figure 1d are the instances of Offensive memes .
( a) Humour , sarcasm , offensive .
( b) Motivational , positive .
( c ) Sarcasm , offensive , Negative .
( d ) Sarcasm , offensive , Funny .
Figure 1 : 1 Figure 1 : Few examples from the Memotion dataset to show the inter-dependency between different tasks .
: Razavi et al. ( 2010 ) used a threelevel classification model taking advantage of various features from statistical models and rulebased patterns and various dictionary - based features .
Chen et al . ( 2012 ) proposed a feature - based Lexical Syntactic Feature ( LSF ) architecture to detect the offensive contents .
Gomez et al. ( 2020 ) created a multi-modal hate-speech dataset from Twitter ( MMHS150K ) to introduce a deep-learningbased multi-modal Textual Kernels Model ( TKM ) and compare it with various existing deep learning architectures on the proposed MMHS150 K dataset .
Motivation : Swieczkowska et al . (
Figure 2 : 2 Figure 2 : Overall architecture of the proposed multi-modal multi-task affect analysis framework for Memes .
Here V refers to the Meme Image and T refers to the text extracted from the Meme .
Figure 3 : 3 Figure 3 : Few examples for Human Error Analysis corresponding to Table10 .
Figure 4 : 4 Figure 4 : iCRM attention for Figure 3e under Task C
Figure 5 : 5 Figure 5 : iTRM attention for Figure 3e under Task C
Table 1 : 1 . Dataset Distribution of Task -A , where RC and T-A denotes the relative count and abbreviation for labels of Task -A , respectively .
Task Classes Count RC ( % ) T-A very negative 1033 negative 3127 17.34 52.48 N g Sent neutral 2201 36.94
N u positive very positive 480 151 8.06 2.53 P s Task Classes Count RC ( % ) T-C T-B not funny 1651 30.91 N f N h Hu funny very funny 2452 2238 45.91 41.90
F n V f H m hilarious 651 12.19
H r not sarcastic 1544 22.08 N s N s Sar general twisted meaning 1547 3507 50.16 22.13
G r T m S r very twisted 394 5.64 V t not offensive 2713 38.80 N o N o Off slight very offensive 2592 1466 37.07 20.97
S g V o O f hateful offensive 221 3.16 H o Mo not motivational 4525 motivational 2467 64.72 35.28 N m N m M o M o Table 2 : Dataset Distribution of Task -B and Task -C , where RC , T-B and T-C denotes the relative count , abbreviation for labels of Task -B , and abbreviation for labels of Task - C respectively .
Table 3 : 3 Model configurations Parameters Task -A Task -B Task -C Activations ReLu Optimizer Adam ( lr=0.001 )
Output Softmax Loss Categorical cross-entropy Batch 16 Epochs 30 Dropout -p 0.3 0.5 0.7 # neurons ( Dense ) 50 200 200
Table 4 : 4 Memes : Sentiment Classification ( Task A )
Table 5 : 5 Memes : Single-task vs Multi-task ( Task B )
Table 6 : 6 Memes : Single-task vs Multi-task ( Task C ) F1
Table 7 : 7 Table 5 and Table 6 that multitask learning framework successfully leverages the - F1 Mi - F1 M a - F1 M i - F1 M a - F1 M i - F1 Comparative Analysis of the proposed approach with recent state - of - the - art systems .
Here , SE '20 denotes the SemEval 2020 winner , and ' Proposed ' refers to the models described in the paper for the respective tasks .
Task A 21.76 M a Baseline S y s t e m s 30.77 Task B 50.02 56.86 Task C 30.08 33.28 SE ' 20 Winner 35.46 48.72 51.83 61.44 32.24 37.79 Proposed 35.81 50.58 53.46 63.44 33.27 41.92 Sentiment N g N u P s N g 17 19 127 N u 25 170 399 P s 58 290 763 ( a ) Task -A Setups STL MTL Humour N h H m 91 354 H m 185 1248 S a 196 1261 O f 366 805 M o 417 273 Sarcasm Offensive Motivational N s S r N o O f N m M o N h N s 68 353 N o 252 455 N m 801 387 N h 92 353 N s 90 331 N o 285 422 N m 801 387 H m 186 1247 S a 239 1218 O f 440 731 M o 431 259 ( b ) Task-B
Table 8 : 8 Confusion Matrix for Task -A and Task - B ( Refer Table 1 and Table 2 for Label definitions ) .
Setups Humour Sarcasm Offensive Motivational N
Table 9 : 9 Confusion Matrix for Task C ( Refer Table 2 for Label definitions ) .
https://competitions.codalab.org/com petitions/20629
https://competitions.codalab.org/com petitions /20629#learn the details - task - la bels- format
https://pytorch.org/ 4 https://github.com/huggingface/trans formers
