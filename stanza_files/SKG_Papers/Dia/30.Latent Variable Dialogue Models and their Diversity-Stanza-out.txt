title
Latent Variable Dialogue Models and their Diversity
abstract
We present a dialogue generation model that directly captures the variability in possible responses to a given input , which reduces the ' boring output ' issue of deterministic dialogue models .
Experiments show that our model generates more diverse outputs than baseline models , and also generates more consistently acceptable output than sampling from a deterministic encoder-decoder model .
Introduction
The task of open-domain dialogue generation is an area of active development , with neural sequenceto-sequence models dominating the recently published literature ( Shang et al. , 2015 ; Vinyals and Le , 2015 ; Li et al. , 2016 b , a ; Serban et al. , 2016 ) .
Most previously published models train to minimise the negative log-likelihood of the training data , and then at generation time either perform beam search to find the output Y which maximises P ( Y | input ) ( Shang et al. , 2015 ; Vinyals and Le , 2015 ; Serban et al. , 2016 ) ( ML decoding ) , or sample from the resulting distribution ( Serban et al. , 2016 ) .
A notorious issue with ML decoding is that this tends to generate short , boring responses to a wide range of inputs , such as " I do n't know " .
These responses are common in the training data , and can be replies to a wide range of inputs ( Li et al. , 2016a ; Serban et al. , 2016 ) .
In addition , shorter responses typically have higher likelihoods , and so wide beam sizes often result in very short responses ( Tu et al. , 2017 ; Belz , 2007 ) .
To resolve this problem , Li et al . ( 2016a ) propose instead using maximum mutual information with a length boost as a decoding objective , and report more interesting generated responses .
Further , natural dialogue is not deterministic ; for example , the replies to " What 's your name and where do you come from ? " will vary from person to person .
Li et al. ( 2016 b ) have proposed learning representations of personas to account for interperson variation , but there can be variation even among a single person 's responses to certain questions .
Recently , Serban et al. ( 2017 ) have introduced latent variables to the dialogue modelling framework , to model the underlying distribution over possible responses directly .
These models have the benefit that , at generation time , we can sample a response from the distribution by first sampling an assignment of the latent variables , and then decoding deterministically .
In this way , we introduce stochasticity without resorting to sampling from the decoder , which can lead to incoherent output - see Table 1 for examples .
In this paper , we present a latent variable model for one - shot dialogue response , and investigate what kinds of diversity the latent variables capture .
Our experiments show that our model has higher lexical as well as sentential diversity than baseline models .
We also show that our model generates more acceptable diverse output than sampling from a deterministic decoder .
We end by noting that all three methods proposed above to combat the ' maximum likelihood response ' are ways of decreasing the probability of the generated output , and report some preliminary results for how response probability interacts with grammaticality and interestingness .
A Latent Variable Dialogue Model
Model Description
Our task is to model the true probability of a response Y given an input X .
We denote our model distribution by P ( Y | X ) .
We introduce a latent because i'm hotel .
Table 1 : 3 random outputs for 3 random prompts from the dataset from our proposed model ( DIAL - LV ) and naively sampling from the decoder of a deterministic encoder-decoder .
variable z with a standard Gaussian prior - i.e. P ( z ) = N ( 0 , I n ) - and factor P ( Y | X ) as : P ( Y | X ) = z P ( Y |z , X ) P ( z ) dz ( 1 )
To motivate this model , we point out that existing encoder-decoder models encode an input X as a single fixed representation .
Hence , all of the possible replies to X must be stored within the decoder 's probability distribution P ( Y | X ) , and during decoding it is hard to disentangle these possible replies .
However , our model contains a stochastic component z in the decoder P ( Y |z , X ) , and so by sampling different z and then performing ML decoding on P ( Y |z , X ) , we hope to tease apart the replies stored in the probability distribution P ( Y | X ) , without resorting to sampling from the decoder .
This has the benefit that we use the decoder at generation time in a similar way to how we train it , making it more likely that the output of our model is grammatical and coherent .
Further , as we do not marginalize out z when decoding , we no longer perform exact maximum likelihood search for a reply Y , and so we hope to avoid the boring reply problem .
At training time , we follow the variational autoencoder framework Sohn et al. , 2015 ; Miao et al. , 2016 ) , and approximate the posterior P ( z|X , Y ) with a proposal distribution Q( z|X , Y ) , which in our case is a diagonal Gaussian whose parameters depend on X and Y .
We thus have the following evidence lower bound ( ELBO ) for the loglikelihood of the data : log P ( Y | X ) ? ?KL ( Q( z|X , Y ) | | P ( z ) ) + E z?Q log P ( Y |z , X ) ( 2 ) Note that this loss decomposes into two parts : the KL divergence between the approximate pos- terior and the prior , and the cross-entropy loss between the model distribution and the data distribution .
If the model can encode useful information into z , then the KL divergence term will be non-zero ( Bowman et al. , 2016 ) .
As our model decoder is given a deterministic representation of X already , z will then encode information about the variation in replies to X .
Model Implementation Given an input sentence X and a response Y , we run two separate bidirectional RNNs over their word embeddings x i and y i .
We concatenate the final states of each and pass them through a single nonlinear layer to obtain our representations h x and h y of X and Y .
We use GRUs ( Cho et al. , 2014 ) as our RNN cell as a compromise between expressive power and computational cost .
We calculate the mean and variance of Q as : ? = W ? [ h x h y ] + b ? log ( ? ) = diag ( W ? [ h x h y ] + b ? ) ( 3 ) where [ a b] denotes the concatenation of a and b , and diag denotes inserting along the diagonal of a matrix .
We take a single sample z from Q using the reparametrization trick ( Kingma and Welling , 2014 ) , concatenate h x and z , and initialize the hidden state of the decoder GRU with [ h x z ] .
We then train the decoder GRU to minimize the negative log-likelihood of the response Y .
While training this model , we noted the same difficulties as Bowman et al . ( 2016 ) - as RNNs are powerful density estimators , the model will prefer to ignore the latent variables and instead optimize the data reconstruction term of the ELBO , while forcing the KL term to 0 .
We overcome this using similar techniques by gradually annealing the KL term weight over the course of model training and using word dropout in the decoder with a drop rate of 0.5 .
Experiments
We compare our model , DIAL - LV , to three baselines .
The first is an encoder-decoder dialogue model with ML decoding ( DIAL - MLE ) .
The second baseline model implements the anti-LM decoder of Li et al . ( 2016 a ) ( DIAL - MMI ) on top of the encoder-decoder , with no length normalization .
For these models , we use beam search with a width of 2 to find the sentence Y which maximises the decoding objective ( either ML or MMI ) .
The final baseline uses the encoder-decoder model , but instead samples from the decoder to find Y ( DIAL - SAMP ) .
We found that naively sampling from the decoder resulted in meaningless jumbles of words .
To solve this , we introduced a temperature parameter ? ? ( 0 , 1 ] , which scales the probability of each word of the decoder as p w ? p 1 / ? w .
This parameter serves to sharpen the word distribution of the decoder .
We found ? = 0.35 to be a reasonable balance between preserving stochasticity while also improving the coherence of the generated output .
We used the OpenSubtitles dataset of movie subtitles to train our models ( Tiedemann , 2012 ) .
We took a random sample of 100K files from the full dataset to train our models on , and then pruned this of repeated files to leave roughly 95 K files and capped sentence length to 50 .
The total size of the resulting corpus was around 731 M tokens .
Please see the supplementary material for model hyperparameters and training details .
Table 2 : Some statistics pertaining to the responses generated by the models .
As seeds for our replies , we used list of 50 prompts : 150 lines from the OpenSubtitles dataset outside of our training set which we judged to make sense as independent sentences and 50 questions chosen from a list of suggested conversation starters 1 .
Reply statistics Previous work ( e.g. Li et al. ( 2016 a ) ) used typetoken ratio ( TTR ) to measure the diversity of the generated output .
However , as language follows a Zipf distribution , TTR is affected by the length of the generated replies ( Mitchell , 2015 ) .
Hence , we use the estimated parameter of a Zipf distribution fitted to our replies as a proxy for the lexical diversity of generated output , with more diverse output having smaller scores .
As ML decoding is known to give the same few replies repeatedly , we also report the percentage of unique replies , as a coarser measure of sentential diversity compared to lexical diversity .
Further , we give the negative loglikelihood ( NLL ) as predicted by the deterministic encoder-decoder model , to see what regions of the probability space the replies occupy .
We present these statistics in Table 2 .
We note that DIAL - LV generates more diverse replies than the other deterministic models , measured in terms of percentage of unique responses .
Interestingly , the lexical diversity of DIAL -LV is almost identical to DIAL - MLE , suggesting that the latent variables help DIAL - LV avoid the boring output problem and generate more diverse outputs .
We note that DIAL -LV even rivals DIAL - SAMP in terms of sentential diversity , and beats DIAL - SAMP in terms of lexical diversity .
This could be because DIAL - SAMP chooses words greedily , and so is biased towards choosing highprobability words at each timestep .
This suggests that maintaining a beam of hypotheses while sampling could help sampling - based methods escape the trap of having to make near-greedy local decisions .
Human acceptability judgments
We also tested whether DIAL - LV could generate a greater number of acceptable replies to a prompt than DIAL - SAMP .
We randomly selected 50 prompts from our list of 200 , and generated 5 replies at random to each one using both models .
We then asked human annotators 2 to judge how many replies were appropriate replies , taking into account grammaticality , coherence and relevance .
The results are shown in Table 3 .
Interestingly , even though DIAL - LV has a lower NLL score , both models generate roughly the same number of acceptable replies .
DIAL -LV also has less variance in the number of acceptable replies , suggesting that the outputs it generates are more consistent than responses from DIAL - SAMP .
Finally , we note that DIAL - LV generates more diverse output than DIAL - SAMP in this scenario , even thought its replies are judged equally acceptable , suggesting that it is managing to produce a wide range of coherent , fluent and appropriate output .
Sampling from the latent variable space
We next explored the effect of sampling from different regions of the latent space .
For each prompt in the test set , we took 5 uniform samples from shells of radius 0 ( which collapses to determinis - 2
We used 50 in total , 25 for each model tic decoding ) , 4 , 8 , 12 and 16 in the latent space 3 by sampling from P ( z ) = N ( 0 , I ) and then scaling the sample z by the appropriate amount .
We then generated a response to the prompt using each value of z , and measured some statistics of the replies .
The results are shown in Table 4 .
As expected , samples with small radius show less diversity in terms of unique outputs .
Further , we see a consistent trend that samples with greater radius have a higher NLL score , showing the influence of the prior in Eqn .
1 .
However , at the highest radius , we observe the highest NLLs , but also the lowest lexical diversities , suggesting that it manages to combine the words it produces in many different ways .
Discussion
Taken together , our experiments show that ML decoding does not seem to be the best objective for generating diverse dialogue , and so corroborates the inadequacy of perplexity as an evaluation metric for dialogue models ( Liu et al. , 2016 ) .
Indeed , all three models which show a diversity gain over the vanilla encoder-decoder with MLE decoding try to instead sample responses from a lowerprobability region of the response space .
However , if the response probability is too low , it runs the risk of being nonsensical .
Hence , there appears to be a ' Goldilocks ' region of the probability space , where the responses are interesting and coherent .
Finding ways of concentrating model samples to this region is thus a potentially promising area of research for open-domain dialogue agents .
We also note that our proposed model can be combined with MMI decoding or temperaturebased sampling to get the benefits of both worlds .
While we did not do this in our experiments in order to isolate the impact of our model , doing so improves the diversity of our generated output even more .
Conclusion
In this paper , we present a latent variable model to generate responses to input utterances .
We investigate the diversity of output generated from this model , and show that it improces both lexical and sentential diversity .
It also generates more consistently acceptable output as judged by humans compared to sampling from a decoder .
Figure 1 : 1 Figure 1 : A schematic of how our model is implemented .
Please see the text for full details .
