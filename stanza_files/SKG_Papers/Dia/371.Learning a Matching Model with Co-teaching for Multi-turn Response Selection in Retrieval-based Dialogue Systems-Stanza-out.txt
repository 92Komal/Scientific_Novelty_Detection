title
Learning a Matching Model with Co-teaching for Multi-turn Response Selection in Retrieval - based Dialogue Systems
abstract
We study learning of a matching model for response selection in retrieval - based dialogue systems .
The problem is equally important with designing the architecture of a model , but is less explored in existing literature .
To learn a robust matching model from noisy training data , we propose a general co-teaching framework with three specific teaching strategies that cover both teaching with loss functions and teaching with data curriculum .
Under the framework , we simultaneously learn two matching models with independent training sets .
In each iteration , one model transfers the knowledge learned from its training set to the other model , and at the same time receives the guide from the other model on how to overcome noise in training .
Through being both a teacher and a student , the two models learn from each other and get improved together .
Evaluation results on two public data sets indicate that the proposed learning approach can generally and significantly improve the performance of existing matching models .
Introduction Human-machine conversation is a long-standing goal of artificial intelligence .
Recently , building a dialogue system for open domain human-machine conversation is attracting more and more attention due to both availability of large-scale human conversation data and powerful models learned with neural networks .
Existing methods are either retrieval - based or generation - based .
Retrievalbased methods reply to a human input by selecting a proper response from a pre-built index ( Ji et al. , 2014 ; , while generation - based methods synthesize a response with a natural language model ( Shang et al. , 2015 ; Serban et al. , 2017 ) .
In this work , we study the problem of response selection for retrieval - based dialogue systems , since retrieval - based systems are often superior to their generation - based counterparts on response fluency and diversity , are easy to evaluate , and have powered some real products such as the social bot Xi-aoIce from Microsoft ( Shum et al. , 2018 ) , and the E-commerce assistant AliMe Assist from Alibaba Group .
A key problem in response selection is how to measure the matching degree between a conversation context ( a message with several turns of conversation history ) and a response candidate .
Existing studies have paid tremendous effort to build a matching model with neural architectures ( Lowe et al. , 2015 ; Zhou et al. , 2016 ; , and advanced models such as the deep attention matching network ( DAM ) have achieved impressive performance on benchmarks .
In contrary to the progress on model architectures , there is little exploration on learning approaches of the models .
On the one hand , neural matching models are becoming more and more complicated ; on the other hand , all models are simply learned by distinguishing human responses from some automatically constructed negative response candidates ( e.g. , by random sampling ) .
Although this heuristic approach can avoid expensive and exhausting human labeling , it suffers from noise in training data , as many negative examples are actually false negatives 1 . As a result , when evaluating a well - trained model using human judgment , one can often observe a significant gap between training and test , as will be seen in our experiments .
In this paper , instead of configuring new architectures , we investigate how to effectively learn existing matching models from noisy training data , given that human labeling is infeasible in practice .
We propose learning a matching model under a general co-teaching framework .
The framework maintains two peer models on two i.i.d. training sets , and lets the two models teach each other during learning .
One model transfers knowledge learned from its training set to its peer model to help it combat with noise in training , and at the same time gets updated under the guide of its peer model .
Through playing both a role of a teacher and a role of a student , the two peer models evolve together .
Under the framework , we consider three teaching strategies including teaching with dynamic margins , teaching with dynamic instance weighting , and teaching with dynamic data curriculum .
The first two strategies let the two peer models mutually " label " their training examples , and transfer the soft labels from one model to the other through loss functions ; while in the last strategy , the two peer models directly select training examples for each other .
To examine if the proposed learning approach can generally bridge the gap between training and test , we select sequential matching network ( SMN ) and DAM as representative matching models , and conduct experiments on two public data sets with human judged test examples .
The first data set is the Douban Conversation benchmark published in , and the second one is the E-commerce Dialogue Corpus published in Zhang et al . ( 2018 b ) where we recruit human annotators to judge the appropriateness of response candidates regarding to their contexts on the entire test set 2 . Evaluation results indicate that co-teaching with the three strategies can consistently improve the performance of both matching models over all metrics on both data sets with significant margins .
On the Douban data , the most effective strategy is teaching with dynamic margins that brings 2.8 % absolute improvement to SMN and 2.5 % absolute improvement to DAM on P@1 ; while on the E-commerce data , the best strategy is teaching with dynamic data curriculum that brings 2.4 % absolute improvement to SMN and 3.2 % absolute improvement to DAM on P@1 .
Through further analysis , we also unveil how the peer models get evolved together in learning and how the choice of peer models affects the performance of learning .
Our contributions in the paper are four-folds : ( 1 ) proposal of learning matching models for response selection with a general co-teaching framework ; ( 2 ) proposal of two new teaching strategies as special cases of the framework ; and ( 3 ) empirical verification of the effectiveness of the proposed learning approach on two public data sets .
Problem Formalization Given a data set D = {( y i , c i , r i ) }
N i=1 where c i represents a conversation context , r i is a response candidate , and y i ? { 0 , 1 } denotes a label with y i = 1 indicating r i a proper response for c i and otherwise y i = 0 , the goal of the task of response selection is to learn a matching model s( ? , ? ) from D. For any context- response pair ( c , r ) , s( c , r ) gives a score that reflects the matching degree between c and r , and thus allows one to rank a set of response candidates according to the scores for response selection .
To obtain a matching model s( ? , ? ) , one needs to deal with two problems : ( 1 ) how to define s( ? , ? ) ; and ( 2 ) how to learn s( ? , ? ) .
Existing studies concentrate on Problem ( 1 ) by defining s( ? , ? ) with sophisticated neural architectures , and leave Problem ( 2 ) in a simple default setting where s( ? , ? ) is optimized with D using a loss function L usually defined by cross entropy .
Ideally , when D is large enough and has good enough quality , a carefully designed s( ? , ? ) learned using the existing paradigm should be able to well capture the semantics in dialogues .
The fact is that since large-scale human labeling is infeasible , D is established under simple heuristics where negative response candidates are automatically constructed ( e.g. , by random sampling ) with a lot of noise .
As a result , advanced matching models only have sub-optimal performance in practice .
The gap between ideal and reality motivates us to pursue a better learning approach , as will be presented in the next section .
Learning a Matching Model through Co-teaching
In this section , we present co-teaching , a new framework for learning a matching model .
We first give a general description of the framework , and then elaborate three teaching strategies as special cases of the framework .
( " # $ , & $ ) ( " # ( , & ( ) ( " # $ , & $ ) " ) $ " ) ( ( " # ( , & ( ) " ) Figure 1 : Co-teaching framework .
Co-teaching Framework
The idea of co-teaching is to maintain two peer models and let them learn from each other by simultaneously acting as a teacher and a student .
Figure 1 gives an overview of the co-teaching framework .
The learning program starts from two pre-trained peer models A and B .
In each iteration , a batch of training data is equally divided into two sub-batches without overlap as DA and DB for B and A respectively .
A and B then examine their sub-batches and output learning protocols ( DB , J B ) and ( DA , J A ) for their peers , where DB and DA are training data and J B and J A are loss functions .
After that , A and B get updated according to ( DA , J A ) and ( DB , J B ) respectively , and the learning program moves to the next iteration .
Algorithm 1 describes the pseudo code of co-teaching .
The rationale behind the co-teaching framework is that the peer models can gradually obtain different abilities from the different training data as the learning process goes on , even when the two models share the same architecture and the same initial configuration , and thus , they can acquire different knowledge from their training data and transfer the knowledge to their peers to make them robust over the noise in the data .
This resembles two peer students who learn from different but related materials .
Through knowledge exchange , one can inspire the other to get new insights from his or her material , and thus the two students get im - proved together .
Advantages of the framework reside in various aspects : first , the peer models have their own " judgment " regarding to the quality of the same training example .
Thus , one model may guide the other how to pick high quality training examples and circumvent noise ; second , since the peer models are optimized with different training sub-batches , knowledge from one sub-batch could be supplementary to the other through exchange of learning protocols ; third , the two peer models may have different decision boundaries , and thus are good at recognizing different patterns in data .
This may allow one model to help the other rectify errors in learning .
To instantiate the co-teaching framework , one needs to specify initialization of the peer models and teaching strategies that can form the learning protocols .
In this work , to simplify the learning program of co-teaching , we assume that model A and model B are initialized by the same matching model pre-trained with the entire training data .
We focus on design of teaching strategies , as will be elaborated in the next section .
Teaching Strategies
We consider the following three strategies that cover teaching with dynamic loss functions and teaching with data curriculum .
Teaching with Dynamic Margins :
The strategy fixes DA and DB as DA and DB respectively , and dynamically creates loss functions as the learning protocols .
Without loss of generality , the training data D can be re-organized in a form of {( c i , r + i , r ? i ) }
N i=1 , where r + i and r ?
i refer to a positive response candidate and a negative response candidate regarding to c i respectively .
Suppose that DA = {( c A , i , r + A , i , r ? A , i ) } N A i=1 and DB = {( c B , i , r + B , i , r ? B , i ) } N B i=1 , then model A evaluates each ( c B , i , r + B , i , r ? B , i ) ? DB with match - ing scores s A ( c B , i , r + B , i ) and s A ( c B , i , r ? B , i ) , and form a margin for model B as ?
B , i = max 0 , ? s A ( c B , i , r + B , i ) ? s A ( c B , i , r ?
B , i ) , ( 1 ) where ? is a hyper-parameter .
Similarly , ?( c
A , i , r + A , i , r ? A , i ) ? DA , the margin provided by model B for model A can be formulated as ?
A , i = max 0 , ? s B ( c A , i , r + A , i ) ? s B ( c A , i , r ? A , i ) , ( 2 ) where s B ( c A , i , r J A and J B are then defined as J A = N A i=1 max{0 , ? A , i ? s A ( c A , i , r + A , i ) + s A ( c A , i , r ? A , i ) } , ( 3 ) J B = N B i=1 max{0 , ? B , i ? s B ( c B , i , r + B , i ) + s B ( c B , i , r ? B , i ) }.
( 4 ) Intuitively , one model may assign a small margin to a negative example if it identifies the example as a false negative .
Then , its peer model will pay less attention to such an example in its optimization .
This is how the two peer models help each other combat with noise under the strategy of teaching with dynamic margins .
Teaching with Dynamic Instance Weighting : Similar to the first strategy , this strategy also defines the learning protocols with dynamic loss functions .
The difference is that this strategy penalizes low-quality negative training examples with weights .
Formally , let us represent DB as {( y B , i , c B , i , r B , i ) }
N B i=1 , then ?(y B , i , c B , i , r B , i ) ? DB , its weight from model A is defined as w B , i = 1 y B , i = 1 1 ? s A ( c B , i , r B , i ) y B , i = 0 ( 5 ) Similarly , ?(y A , i , c A , i , r A , i ) ? DA , model B assign a weight as w A , i = 1 y A , i = 1 1 ? s B ( c A , i , r A , i ) y A , i = 0 ( 6 )
Then , loss functions J A and J B can be formulated as J A = N A i=1 w A , i L(y A , i , s A ( c A , i , r A , i ) ) , ( 7 ) J B = N B i=1 w B , i L(y B , i , s B ( c B , i , r B , i ) ) , ( 8 ) where L ( ? , ? ) is defined by cross entropy : ?y log ( s ( c , r ) ) + ( 1 ? y ) log ( 1 ? s( c , r ) ) .
( 9 ) In this strategy , negative examples that are identified as false negatives by one model will obtain small weights from the model , and thus be less important than other examples in the learning process of the other model .
Teaching with Dynamic Data Curriculum :
In the first two strategies , knowledge is transferred mutually through " soft labels " defined by the peer matching models .
In this strategy , we directly transfer data to each model .
During learning , J A and J B are fixed as cross entropy , and the learning protocols vary by DA and DB . Inspired by Han et al . ( 2018 ) , we construct DA and DB with small - loss instances .
These instances are far from decision boundaries of the two models , and thus are more likely to be true positives and true negatives .
Formally , DA and DB are defined as DB = argmin | DB |=? | DB | , DB ? DB J A ( DB ) , DA = argmin | DA | =?| DA | , DA ? DA J B ( DA ) , ( 10 ) where | ?
| measures the size of a set , J A ( DB ) and J B ( DA ) stand for accumulation of loss on the corresponding data sets , and ? is a hyper-parameter .
Note that we do not shrink ? as in Han et al . ( 2018 ) , since fixing ? as a constant yields a simple yet effective learning program , as will be seen in our experiments .
Experiments
We test our learning schemes on two public data sets with human annotated test examples .
Experimental Setup
The first data set we use is Douban Conversation Corpus ( Douban ) 2017 ) , we employ R 10 @1 , R 10 @2 , R 10 @5 , mean average precision ( MAP ) , mean reciprocal rank ( MRR ) , and precision at position 1 ( P@1 ) as evaluation metrics .
In addition to the Douban data , we also choose E-commerce Dialogue Corpus ( ECD ) ( Zhang et al. , 2018 b ) as an experimental data set .
The data consists of real-world conversations between customers and customer service staff in Taobao 4 , which is the largest e-commerce platform in China .
There are 1 million context-response pairs in the training set , and 10 thousand pairs in both the validation set and the test set .
Each context in the training set and the validation set corresponds to one positive response candidate and one negative response candidate , while in the test set , the number of response candidates per context is 10 with only one of them positive .
In the released data , human responses are treated as positive responses , and negative ones are automatically collected by ranking the response corpus based on conversation history augmented messages using Apache Lucene 5 .
Thus , we recruit 3 active users of Taobao as human annotators , and ask them to judge each context- response pair in the test data ( i.e. , in total 10 thousand pairs are judged ) .
If a response can naturally reply to a message given the conversation history before it , then the contextresponse pair is labeled as 1 , otherwise , it is labeled as 0 .
Each pair receives three labels and the majority is taken as the final decision .
On average , each context has 2.5 response candidates labeled as positive .
There are only 33 contexts with all responses labeled as positive or negative , and we remove them from test .
Fleiss ' kappa ( Fleiss , 1971 ) of the labeling is 0.64 , indicating substantial agreement among the annotators .
We employ the same metrics as in Douban for evaluation .
Note that we do not choose the Ubuntu Dialogue Corpus ( Lowe et al. , 2015 ) for experiments , because ( 1 ) the test set of the Ubuntu data is constructed by randomly sampling ; and ( 2 ) conversations in the Ubuntu data are in a casual style and too technical , and thus it is very difficult for us to find qualified human annotators to label the data .
Matching Models
We select the following two models that achieve superior performance on benchmarks to test our learning approach .
SMN : first lets each utterance in a context interact with a response , and forms a matching vector for the pair through CNNs .
Matching vectors of all the pairs are then aggregated with an RNN as a matching score .
DAM : ) performs matching under a representation - matching -aggregation framework , and represents a context and a response with stacked self-attention and crossattention .
Both models are implemented with TensorFlow according to the details in and .
To implement co-teaching , we pre-train the two models using the training sets of Douban and ECD , and tune the models with the validation sets of the two data .
Each pre-trained model is used to initialize both model A and model B. After co-teaching , the one in A and B that performs better on the validation sets is picked for comparison .
We denote models learned with the teaching strategies in Section 3.2 Douban ECD MAP MRR P@1 R 10 @1 R 10 @2 R 10 @5 MAP MRR P@1 R 10 @1 R 10 @2 R 10 @5 SMN 0
Implementation Details
We limit the maximum number of utterances in each context as 10 and the maximum number of words in each utterance and response as 50 for computational efficiency .
Truncation or zeropadding are applied when necessary .
Word embedding is pre-trained with Word2Vec ( Mikolov et al. , 2013 ) on the training sets of Douban and ECD , and the dimension of word vectors is 200 .
The co-teaching framework is implemented with TensorFlow .
In co-teaching , learning rates ( i.e. , ? in Algorithm 1 ) in dynamic margins , dynamic instance weighting , and dynamic data curriculum are set as 0.001 , 0.0001 , and 0.0001 respectively .
We choose 200 in co-teaching with SMN and 50 in co-teaching with DAM as the size of mini-batches .
Optimization is conducted using stochastic gradient descent with Adam algorithm ( Kingma and Ba , 2015 ) .
In teaching with dynamic margins , we vary ? in { 1 , 1 2 , 1 3 , 1 5 , 1 10 , 1 15 , 1 20 } , and choose 1 10 for SMN on Douban , 1 2 for SMN on ECD , 1 3 for DAM on Douban , and 1 2 for DAM on ECD .
In teaching with dynamic data curriculum , we select ? in { 0.1 , 0.2 , ... , 0.9 , 1.0} , and find that 0.9 is the best choice for both models on both data sets .
Evaluation Results
Table 1 reports evaluation results of co-teaching with the three teaching strategies on the two data sets .
We can see that all teaching strategies can improve the original models on both data sets , and improvement from the best strategy is statistically significant ( t- test with p-value < 0.05 ) on most metrics .
On Douban , the best strategy for SMN is teaching with dynamic margins , and it is comparable with teaching with dynamic instance weighting for DAM , while on ECD , for both SMN and DAM , the best strategy is teaching with dynamic data curriculum .
The difference may stem from the nature of training sets of the two data .
The training set of Douban is built from random sampling , while the training set of ECD is constructed through response retrieval that may contain more false negatives .
Thus , in training , Douban could be cleaner than ECD , making " hard data filtering " more effective than " soft labeling " on ECD .
It is worth noting that on ECD , there are significant gaps between the results of SMN ( pre-trained ) reported in Table 1 and those reported in Zhang et al . ( 2018 b ) , since SMN in this paper is evaluated on the human-judged test set while SMN in Zhang et al . ( 2018 b ) is evaluated on the automatically constructed test set that is homogeneous with the training set .
This somehow indicates the gap between training and test in real applications for the existing research on response selection , and thus demonstrates the merits of this work .
Discussions
In addition to efficacy of co-teaching as a learning approach , we are also curious about Q1 : if model A and model B can " co- evolve " when they are initialized with one network ; Q2 : if co-teaching is still effective when model A and model B are initialized with different networks ; and Q3 : if the teaching strategies are sensitive to the hyperparameters ( i.e. , ? in Equations ( 1 ) -( 2 ) and ? in Equation ( 10 ) ) .
Douban ( Margin ) ECD ( Curriculum ) MAP MRR P@1 R 10 @1 R 10 @2 R 10 @5 MAP MRR P@1 R 10 @1 R 10 @2 R 10 @5 SMN - Pre-training 0.527 0.570 0 . Answer to Q1 : Figure 2 shows P@1 of DAM vs. number of iterations on the test set of ECD under the three teaching strategies .
Co-teaching with any of the three strategies can improve both the performance of model A and the performance of model B after pre-training , and the peer models move with almost the same pace .
The results verified our claim that " by learning from each other , the peer models can get improved together " .
Curves of dynamic margins oscillate more fiercely than others , indicating that optimization with dynamic margins is more difficult than optimization with the other two strategies .
Answer to Q2 : as a case study of co-teaching with two networks in different capabilities , we initialize model A and model B with DAM and SMN respectively , and select teaching with dynamic margins for Douban and teaching with dynamic data curriculum for ECD ( i.e. , the best strategies for the two data sets when co-teaching is initialized with one network ) .
Table 2 shows comparison between models before / after co-teaching .
We find that co-teaching is still effective when starting from two networks , as both SMN and DAM get improved on the two data sets .
Despite the improvement , it is still better to learn the two networks one by one , as co-teaching with two networks cannot bring more improvement than coteaching with one network , and the performance of the stronger one between the two networks could also drop ( e.g. , DAM on Douban ) .
We guess this is because the stronger model cannot be well taught by the weaker model , especially in teaching via soft labels , and as a result , it is not able to transfer more knowledge to the weaker one as well .
Answer to Q3 : finally , we check the effect of hyper-parameters to co-teaching .
Figure 3 ( a ) illustrates how the performance of DAM varies under different ?s in teaching with dynamic margins on Douban .
We can see that both small ?s and large ?s will cause performance drop .
This is because small ?s will reduce the effect of margins , making clean examples and noisy examples indifferent in learning , while with large ?s , some errors from the " soft labels " might be magnified , and thus hurt the performance of the learning approach .
Figure 3 ( b ) shows the performance of DAM under different ?s in teaching with dynamic data curriculum on ECD .
Similarly , DAM gets worse when ?
becomes small or large , since a smaller ?
means fewer data will be involved in training , while a larger ?
brings more risks to introducing noise into training .
Thus , we conclude that the teaching strategies are sensitive to the choice of hyperparameters .
Related Work
So far , methods used to build an open domain dialogue system can be divided into two categories .
The first category utilize an encoderdecoder framework to learn response generation models .
Since the basic sequence-to-sequence models ( Vinyals and Le , 2015 ; Shang et al. , 2015 ; tend to generate generic responses , extensions have been made to incorporate external knowledge into generation ( Mou et al. , 2016 ; , and to generate responses with specific personas or emotions ( Li et al. , 2016 ; Zhou et al. , 2018a ) .
The second category design a discriminative model to measure the matching degree between a human input and a response candidate for response selection .
At the beginning , research along this line assumes that the human input is a single message Wang et al. , 2013 ; Hu et al. , 2014 ; Wang et al. , 2015 ) .
Recently , researchers begin to make use of conversation history in matching .
Representative methods include the dual LSTM model ( Lowe et al. , 2015 ) , the deep learning to respond architecture , the multi-view matching model ( Zhou et al. , 2016 ) , the sequential matching network ( Wu et al. , , 2018 c , the deep attention matching network , and the multi-representation fusion network ( Tao et al. , 2019 ) .
Our work belongs to the second group .
Rather than crafting a new model , we are interested in how to learn the existing models with a better approach .
Probably the most related work is the weakly supervised learning approach proposed in .
However , there is stark difference between our approach and the weak supervision approach : ( 1 ) weak supervision employs a static generative model to teach a discriminative model , while co-teaching dynamically lets two discriminative models teach each other and evolve together ; ( 2 ) weak supervision needs pretraining a generative model with extra resources and pre-building an index for training data construction , while co-teaching does not have such request ; and ( 3 ) in terms of multi-turn response selection , weak supervision is only tested on the Douban data with SMN and the multi-view matching model , while co-teaching is proven effective on both the Douban data and the E-commerce data with SMN and DAM which achieves state - of - theart performance on benchmarks .
Moreover , improvement to SMN on the Douban data from coteaching is bigger than that from weak supervision , when the ratio of the positive and the negative is 1:1 in training 7 .
Our work , in a broad sense , belongs to the effort on learning with noisy data .
Previous studies including curriculum learning ( CL ) ( Bengio et al. , 2009 ) and self-paced learning ( SPL ) ( Jiang et al. , 2014 ( Jiang et al. , , 2015 tackle the problem with heuristics , such as ordering data from easy instances to hard ones ( Spitkovsky et al. , 2010 ; Tsvetkov et al. , 2016 ) and retaining training instances whose losses are smaller than a threshold ( Jiang et al. , 2015 ) .
Recently , Fan et al. ( 2018 ) propose a deep reinforcement learning framework in which a simple deep neural network is used to adaptively select and filter important data instances from the training data .
Jiang et al. ( 2017 ) propose a Men-torNet which learns a data-driven curriculum with a Student - Net to mitigate overfitting on corrupted labels .
In parallel to curriculum learning , several studies explore sample weighting schemes where training samples are re-weighted according to their label- quality Dehghani et al. , 2018 ; . Instead of considering data quality , Wu et al . ( 2018a ) employ a parametric model to dynamically create appropriate loss functions .
The learning approach in this work is mainly inspired by the work of Han et al . ( 2018 ) for handling extremely noisy labels .
However , with substantial extensions , our work is far beyond that work .
First , we generalize the concept of " coteaching " to a framework , and now the method in Han et al . ( 2018 ) becomes a special case of the framework .
Second , Han et al. ( 2018 ) only exploits data curriculum , while in addition to data curriculum , we also propose two new strategies for teaching with dynamic loss functions as special cases of the framework .
Third , unlike Han et al . ( 2018 ) who only use one network to initialize the peer models in co-teaching , we studied coteaching with both one network and two different networks .
Finally , Han et al. ( 2018 ) verified that the special co-teaching method is effective in some computer vision tasks , while we demonstrate that the co-teaching framework is generally useful for building retrieval - based dialogue systems .
Conclusions
We propose learning a matching model for response selection under a general co-teaching framework with three specific teaching strategies .
The learning approach lets two matching models teach each other and evolve together .
Empirical studies on two public data sets show that the proposed approach can generally improve the performance of existing matching models .
Figure 2 : 2 Figure2 : Test P@1 of DAM with the three teaching strategies on ECD .
All curves are smoothed by exponential moving average 6 for beauty .
Figure 3 : 3 Figure 3 : Effects of ? and ? to co-teaching .
Experiments are conducted with DAM on the two data sets .
The proposed co-teaching framework Input : model parameters ?
A , ?
B , learning rate ? , number of epochs n T , number of iterations n K ; 1 for T = 1 , 2 , ... , T n T do Update model B by ( DB , J B ) .
2 Shuffle training set D ; 3 4 for K = 1 , 2 , ... , K n K do Fetch a batch of training data D ; 5 Distributes D equally to two sub-batches of training data DA , DB ; DA , DB ?
D 10 end 11 end Output : ? + A , i ) and s B ( c A , i , r ?
A , i ) are matching scores calculated with model B. Loss functions Algorithm 1 : 6 Obtain learning protocol ( DB , J B ) from model A and DB ; 7 Obtain learning protocol ( DA , J A ) from model B and DA ; 8 Update ?
A = ? A ? ?J A ( DA ) ; Update model A by ( DA , J A ) .
9 Update ? B = ? B ? ?J B ( DB ) ; A , ? B .
which is a multi-turn Chinese conversation data set crawled from Douban group 3 .
The data set consists of 1 million context- response pairs for training , 50 thousand pairs for validation , and 6 , 670 pairs for test .
In the training set and the validation set , the last turn of each conversation is regarded as a positive response and negative responses are randomly sampled .
The ratio of the positive and the negative is 1:1 in training and validation .
In the test set , each context has 10 response candidates retrieved from an index whose appropriateness regarding to the context is judged by human annotators .
The average number of positive responses per context is 1.18 .
FollowingWu et al . (
Table 1 : 1 0.678 0.762 * 0.622 * 0.323 * 0.487 * 0.778 * Evaluation results on the two data sets .
Numbers marked with * mean that the improvement is statistically significant compared with the best baseline ( t- test with p-value < 0.05 ) .
Numbers in bold indicate the best strategies for the corresponding models on specific metrics .
.529 0.569 0.397 0.233 0.396 0.724 - - - - - - SMN - Pre-training 0.527 0.570 0.396 0.236 0.392 0.734 0.662 0.742 0.598 0.302 0.464 0.757 SMN - Margin 0.559 * 0.601 * 0.424 * 0.260 * 0.426 * 0.764 * 0.674 0.750 0.615 0.318 0.481 0.765 SMN - Weighting 0.550 * 0.593 * 0.414 0.253 0.413 0.762 * 0.666 0.745 0.601 0.311 0.475 0.775 SMN - Curriculum 0.763 DAM
( Zhou et al. , 2018 b ) 0.550 0.548 0.594 * 0.418 * 0.254 * 0.411 0.601 0.427 0.254 0.410 0.757 - - - - - - DAM - Pre-training 0.552 0.605 0.426 0.258 0.408 0.766 0.685 0.756 0.621 0.325 0.491 0.772 DAM - Margin 0.583 * 0.628 * 0.451 * 0.276 * 0.454 * 0.806 * 0.692 0.777 * 0.652 * 0.337 0.506 0.778 DAM - Weighting 0.579 * 0.629 * 0.453 * 0.272 0.454 * 0.809 * 0.695 0.775 0.651 * 0.343 0.497 0.789 DAM -Curriculum 0.580 * 0.623 * 0.442 0.269 0.459 * 0.804 * 0.696 0.777 * 0.653 * 0.345 * 0.506 0.781 as Model-Margin , Model-Weighting , and Model- Curriculum respectively , where " Model " refers to either SMN or DAM .
These models are compared with the pre-trained model denoted as Model - Pre - training , and those reported in Wu et al . ( 2017 ) ;
Zhou et al . ( 2018 b ) ;
Zhang et al . ( 2018 b ) . *
Table 2 : 2 Evaluation results of co-teaching initialized with different networks .
396 0.236 0.392 0.734 0.662 0.742 0.598 0.302 0.464 0.757 SMN -Co-teaching 0.558 0.602 0.420 0.255 0.431 0.787 0.674 0.765 0.626 0.322 0.485 0.779 DAM -Pre-training 0.552 0.605 0.426 0.258 0.408 0.766 0.685 0.756 0.621 0.325 0.491 0.772 DAM -Co-teaching 0.570 0.617 0.438 0.270 0.455 0.781 0.696 0.775 0.652 0.341 0.499 0.784
Responses sampled from other contexts may also be proper candidates for a given context .
We have released labeled test data of E-commerce Dialogue Corpus at https://drive.google.
com/open?id=1HMDHRU8 kbbWTsPVr6lKU_
- Z2Jt -n-dys .
https://www.douban.com/group 4 https://www.taobao.com
http://lucene.apache.org/
https://en.wikipedia.org/wiki/Moving_ average# Exponential _moving_average
Our results are 0.559 ( MAP ) , 0.601 ( MRR ) , and 0.424 ( P@1 ) , while results reported in are 0.542 ( MAP ) , 0.588 ( MRR ) , and 0.408 ( P@1 ) .
