title
Aiming to Know You Better Perhaps Makes Me a More Engaging Dialogue Partner
abstract
There have been several attempts to define a plausible motivation for a chit-chat dialogue agent that can lead to engaging conversations .
In this work , we explore a new direction where the agent specifically focuses on discovering information about its interlocutor .
We formalize this approach by defining a quantitative metric .
We propose an algorithm for the agent to maximize it .
We validate the idea with human evaluation where our system outperforms various baselines .
We demonstrate that the metric indeed correlates with the human judgments of engagingness .
Introduction
There has been a significant progress in creating end-to - end data-driven dialogue systems ( Ritter et al. , 2011 ; Vinyals and Le , 2015 ; Shang et al. , 2015 ; Sordoni et al. , 2015 ) .
The general scheme is to view dialogues as a sequence transduction process .
This process is then modeled with the sequence-to-sequence ( SEQ2SEQ ) neural network ( Sutskever et al. , 2014 ) whose parameters are fit on large dialogue corpora such as OpenSubtitles ( Tiedemann , 2009 ) .
What is especially appealing about these systems is that they do not require hand -crafted rules to generate reasonable responses in the open-domain dialogue ( i.e. , chit-chat ) setting .
An important goal of such systems is to be able to have a meaningful and engaging conversation with a real person .
Despite the progress , however , this goal remains elusive - current systems often generate generic and universally applicable responses ( to any questions ) such as " I do not know " .
While such responses are reasonable in isolation , collectively too many of them are per - *
On leave from U. of Southern California ( feisha@usc.edu ) ceived as dull and repetitive ( Sordoni et al. , 2015 ; Li et al. , 2016 a , b) .
It remains open what metrics to use to optimize a data-driven model to produce highly engaging dialogues ( Liu et al. , 2016 ) .
Li et al. ( 2016 b , a ) propose to use several heuristic criteria : how easy to answer the utterance with non-generic response , how grammatical the response is , etc .
Zhang et al. ( 2018 ) suggests to use pre-defined facts about the conversation agents as the context for the dialogue .
Specifically , conditioning on those facts ( called " memories " in their approach ) , the dialogue becomes " personalized " , purposefully coherent and is perceived being more engaging .
In this paper , we investigate a different approach which leverages the following intuition : an engaging dialogue between two agents is a conversation that is focused and intends to discover information with the goal of increased understanding of each other .
In other words , discovering implies asking engaging and inquisitive questions that are not meant to be answered with dull responses .
How do we use these intuitions to build engaging dialogue chatbots ?
Imagine a dialogue between a chatbot and a human .
The human has facts about herself and is willing to share with the chatbot .
The chatbot has only a vague idea what those facts might be - for instance , it knows out of 100 possible ones , 3 of them are true .
The chatbot 's initial utterance could be random as it has no knowledge of what the 3 are .
However , the chatbot wants to be engaging so it constantly selects utterances so that it can use them to identify those 3 facts .
This is in spirit analogous to a ( job ) interview : the HR representative ( i.e. , our interviewer " chatbot " ) is trying to figure out the personality characteristics ( i.e. , " facts " ) of the applicant ( i.e. , the " human " interviewee ) .
A successful interview implies that the HR representative was able to get as much information about the applicant as possi-ble within a limited amount of time , while dull and repetitive questions are avoided at all cost .
In other words , the amount of gathered information can be seen as a proxy measure to the engagingness of the dialogue .
We have implemented such an " interview " setting to validate our intuitions .
First , we have developed a metric called DISCOVERYSCORE that can measure how much information has been gathered by the chit- chat bot after a dialogue .
During a dialogue , we show how this metric can be used to guide the chatbot 's generation of responses at its turns - these responses are selected so that they lead to the highest expected DISCOVERYSCORE .
To identify such responses , the chit-chat chatbot needs to simulate how its human counterpart would react .
To this end , we have proposed an improved version of the personalized chatbot ( Zhang et al. , 2018 ) and use it as the chit- chat bot 's model of the human .
Finally , we perform human studies on the Amazon Mechanical Turk platform and demonstrate the positive correlation between DIS - COVERYSCORE and the engagingness scores assessed by human evaluators on our chit- chat bot .
The rest of the paper is organized as the follows .
We discuss briefly the related work in Section 2 .
In Section 3 , we then describe various components in our approach : the metric DISCOVERYSCORE for assessing how engaging an dialogue is , a chatbot model that is used in our study , and a response selection procedure for our chatbot to yield engaging conversations .
We report empirical studies in Section 4 and conclude in Section 5 .
Related Work
One of the biggest challenges for chit- chat bots is the lack of the exact objective for models to optimize .
This stands in stark contrast to taskoriented dialogue systems ( Wen et al. , 2016 ; . Several heuristic criteria are proposed in ( Li et al. , 2016 a , b) as objectives to optimize .
Asghar et al. ( 2017 ) proposes humans - in- the - loop to select the best response out of a few generated candidates .
Cheng et al. ( 2018 ) uses an additional input signal - the specificity level of a response , which is estimated by certain heuristics at training time and can be varied during evaluation .
Another way to address the lack of the explicit objective function is to predict many possible responses at once .
Zhou et al . ( 2017 ) maps the input message to the distribution over intermediate factors , each of which produces a different response .
Similarly , ( Zhao et al. , 2017 ; Shen et al. , 2018 ; Gu et al. , 2018 ) use variants of variational autoencoder .
These approaches are complementary to defining the objective for dialogue models , as an external reward can further guide the response generation and simplify learning such oneto-many mappings .
Liu et al. ( 2016 ) hypothesizes that creating a perfect metric for automatic evaluation ( so it can be used to optimize a dialogue model to be more engaging , at least in principle ) is as hard as creating human- like dialogue system itself .
The authors also note that some of the common automatic evaluation metrics ( of generated texts ) like BLEU , METEOR or ROGUE correlate poorly with human judgments of engagingness .
suggests a metric ADEM , which is trained to mimic human evaluators .
While it 's shown to have better correlation with the scores assigned by humans , it also gives preference to safer and generic responses .
In our work , we propose to measure how much information the chit- chat bot has gathered about its human counterpart as a proxy to the engagingness of the dialogue .
To the best of our knowledge , this metric has not been explored actively in the design of chit- chat bots .
To apply the metric to generate engaging utterances , the chit- chat bot needs to have a model of how the human partner will respond to its utterances .
To this end , we have used the chit- chat bot developed in ( Zhang et al. , 2018 ) as a base model and improved upon it .
That bot , called PROFILE -MEMORY , has a set of memories ( basically , factual sentences ) defining its persona and can output personalized utterances using those memories .
Note that in ( Zhang et al. , 2018 ) PROFILEMEM -ORY is used as a chit-chat bot to generate contextualized dialogue ( so as to be engaging ) .
In our work , however , we use it and its improved version as a model of how humans might chat .
Our chit - chat bots can be any existing ones ( such as a vanilla SEQ2SEQ model without persona ) or another PROFILEMEMORY with its own persona that is different from what humans might have .
The key difference is that our chit- chat bot generates utterances to elicit human counterparts to reveal about themselves while PROFILEMEMORY in its original work generates utterances to tell stories about itself .
Similar ideas have been explored in cognitive research .
Rothe et al. ( 2016 ) analyzed how people ask questions to elicit information about the world within a Battleship game ( Gureckis and Markant , 2009 ) .
In particular , they proposed to evaluate questions based on Expected Information Gain ( Oaksford and Chater , 1994 ) , which is built on the similar principles as DISCOVERYSCORE .
Method
In the following section , we describe in details our approach for designing engaging chit- chat bots .
We start by describing the main idea , followed by discussing each component in our approach .
Main Idea
The main idea behind our approach is that the chitchat bot stays in " discovery " mode .
Its main goal is to identify key aspects of its human counterpart .
Algorithmically , it chooses utterances to elicit responses from the human so that the responses increase its understanding of the human .
More formally , imagine each human is characterized by a collection of K facts F = {z 1 , z 2 , . . . , z K } , where z 1 is I was born in Russia , z 2 is My favorite vegetable is carrot , and z K is I like to swim .
The chit- chat bot has access to a universal set of all candidate facts U , and F is just a subset of U .
However , the bot does not know the precise composition of F at the beginning of the conversation .
Its goal is to identify the subset ( or to reduce the uncertainty about it ) .
With a bit abuse of terminology , we call F the personality of the human or the persona .
We denote a dialogue as a sequence of sentences h N = [ s 1 , t 1 , ... , s N , t N ] where s n denotes the sentences by the chit- chat bot and t n denotes the ones by the human .
A Metric for Measuring Engagingness
The chit- chat bot assumes that the human 's response t is generated probabilistically when it is the human 's turn to respond to the chit- chat bot 's utterance s P ( t | s , F ) = z?F P ( t | s , z ) P ( z | s , F ) ( 1 ) Intuitively , the human first decides on which fact z she plans to use ( ie , which information she wants to reveal ) and based on the fact and the chit- chat bot 's question , she provides an answer .
The goal of the discovery oriented chit-chat is to maximize the mutual information between the dialogue and the revealed personality I ( F ; h N ) = H [ P ( F ) ] ? H [ P ( F | h N ) ] ( 2 ) where H [ ? ] stands for the entropy of the distribution .
Maximizing the mutual information is equivalent to minimizing the uncertainty about F after a dialogue .
Intuitively , the chit- chat bot aims to discover the maximum amount of knowledge about the human .
We thus term this quantity as the DIS- COVERYSCORE .
For simplicity , we assume a uniform prior on which F is .
Thus , the key quantity to compute is the entropy of the posterior probability .
We proceed in two steps .
Calculating the posterior probability
We assume that every human 's response t n is independent from the previous dialogue history , conditioned on the immediately previous message , and chatbot 's question s n is independent unconditionally .
Thus , the posterior can be computed recursively : P ( F | h N ) ? P ( F | h N ?1 ) f ?F P ( z N = f | s N , t N ) ( 3 ) where z N is the fact used in the N th turn .
The " single-turn " posterior for the specific fact f is computed as ( we have dropped the subscript N to be cleaner ) P ( z = f | s , t ) = P ( t | s , z = f ) P ( z = f | s ) f ?U P ( t | s , z = f ) P ( z = f | s ) ( 4 )
We will make a further simplifying assumption that P ( z = f | s ) is uniform 1 and compute the 1 This is only an approximation : the human will respond to " what kind of food do you like ? " with any facts that relate to food but definitely not to geographical locations , sports , etc .
However , this assumption is not as damaging as long as P ( t | s , z = f ) is almost zero for the z that P ( z = f | s ) should be ignored - the multiplication would result in zero anyway .
Since z refers to the fact , P ( t|s , z = f ) being almost zero reduces to suggest that for a response t , there are just only a very limited number of s ( questions ) and facts that can be used to generate that response .
For example , a response " I lived in Russia as a child " can only be elicited from " Where did you spend your childhood ? " ( as question ) and " I was born in Russia " ( as a fact ) .
For any other question and fact pair ( such as " Where did you spend your childhood ? " , posterior approximately P ( z = f | s , t ) ?
P ( t | s , z = f ) f ?U P ( t | s , z = f ) ( 5 ) Substituting this into the expression for P ( F | h N ) , we obtain P ( F | h N ) ? P ( F | h N ?1 ) f ?F P ( t N | s N , z N = f ) f ?U P ( t N | s N , z N = f ) ( 6 ) Acute readers might have identified this as a form of Bayesian belief update , incorporating new evidence at time N .
The likelihood P ( t N | s N , z N = f ) depends on how to model how the human generates responses .
It is sufficient to note that this probability can be computed conveniently by personalized chatbot models .
We postpone the details to the next section .
Calculating the entropy
We make an assumption that the number of facts K assigned to the human is known in advance .
Therefore , we can consider only probabilities P ( F | h N ) , where F is of a particular known size .
P ( F | h N , | F | = K ) = P ( F | h N ) F ?U ,|F |=K P ( F | h N ) ( 7 )
The entropy of distribution P ( F | h N , | F | = K ) can be computed directly by enumerating all possible combinations of K facts .
ChatBot Models
In our work , there are two types of chatbot models .
The first one is the chit- chat bot who will respond to messages from the human conversation partner .
While we can use any existing chatbot models , the key ingredient to our approach is to respond so that the expected gain of knowledge on the human is increased .
However , since the chit- chat bot cannot inquire the human with " if I answer you this , would I gain knowledge ? " , it has to estimate the gain in knowledge from its model of the human .
The second type of model addresses the aspect of modeling the human .
In particular , among the 3 and " I like apples " ) , the response would be unlikely .
We believe this is largely due to the experimental / data design that has ensured facts are being largely non-overlapping for each personality and the dialogues are in general centered around the facts .
We leave to future work on how to refine this approximation .
models described below , all 3 can be used as the chit- chat bot models and only PROFILEMEMORY and PROFILEMEMORY + can be used as the model of humans 2 . SEQ2SEQ dialogue model
This basic model maps an input message t to a vector representation using the encoder LSTM layer and uses it as an initial state h d 0 for the decoder LSTM layer .
The decoder predicts a response s sequentially , word by word via softmax .
Both the encoder and the decoder share the same input embeddings table .
PROFILEMEMORY model PROFILEMEM -ORY
( Zhang et al. , 2018 ) is built on top of SEQ2SEQ and uses exactly the same architecture for the encoder .
Additionally , it has a list of memory slots ( called profile memory ) and each slot stores a fact , represented by a sentence .
Each fact is encoded into a single vector representation using the weighted average of its word embeddings where the embeddings table is shared with the encoder and the decoder .
In this work , we call the profile memory as the personality .
The decoder is an LSTM layer with attention over the encoded memories .
In essence , the attention mechanism computes a weight for each fact and a weighted sum of the facts form a context vector .
The context vector and the hidden states are combined as inputs to a softmax layer to generate words sequentially .
For details , please consult ( Zhang et al. , 2018 ) PROFILEMEMORY + model
The PROFILE -MEMORY has a weakness that is especially critical to our intent of using it as a model of the human .
It has to apply attention at every step , even when responding to messages which are not relevant to any of the facts .
Thus it always reveals something about the personality ( unless the attention is uniform , generally hard to achieve in practice ) .
To address this issue , we enhance the model with a DefaultFact , which does not correspond to any real sentence .
It does have a vector representation ( as other facts do ) except the representation is learned during the training .
An advantage is that the DefaultFact allows to efficiently train on the dialogue datasets without profile memories , such as OpenSubtitles - intuitively it is the bucket for " all other facts " that the dialogue does not explicitly refer to .
Dialoguing with Intent to Discover
As a metric , DISCOVERYSCORE can only be computed over and assess a finished dialogue .
How can we leverage it to encourage the chit- chat bot to be more engaging ?
In what follows , we describe one of the most important components in our approach .
Instead of using the standard maximum a posterior inference for the typical SEQ2SEQ ( and its variants ) to generate a sentence , we proceed in two steps to identify the best utterance that has the potential to yield high DISCOVERYSCORE .
The first step is to generate a large set of candidate utterances ( for example , using beam search ) .
The second step is to re-rank these utterances .
We describe the second step in details as the first step is fairly standard .
At the N th turn of the dialogue , the chit- chat bot has access to the dialogue history h N ?1 and an estimate of the human's personality P ( F | h N ?1 ) .
Let s be a sentence from the chatbot 's candidate set .
Since the bot has a model of the human , it can predict the human 's response t as t ? P (? | h N ?1 , s , F ) = P ( ? | s , F ) ( 8 ) where F is used to instantiate the model 's memory / facts / personality - in other words , we query the model to see what kind of utterances the human might respond with .
The value of a possible response s , i.e , the expected DISCOVERYSCORE assuming s and t completes the dialogue with h N = [ h N ?1 , s , t ] , is then given by V ( s ) = E F ?P (?|h N ?1 ) E t?P ( ?|s, F ) I ( F ; h N ) ( 9 ) Note that the first expectation is needed as the bot has uncertainty of what personality the human is .
In practice , we compute this for each s from the candidate set by sampling F and t .
We then select the optimal utterance that maximize the value s N = arg max s V ( s ) ( 10 )
Experiments
We evaluate empirically the proposed approach in several aspects .
First , we investigate the effectiveness of the proposed PROFILEMEMORY + model .
This model is especially used to model human interlocutors so that it can be used by the chit- chat bot to estimate how an utterance could elicit the human partner to reveal key facts about her ( cf. Section 3.4 ) .
Secondly , we investigate whether the proposed metric DISCOVERYSCORE correlates with the engagingness score of a dialogue assessed by human evaluators .
Evaluating PROFILEMEMORY + We contrast PROFILEMEMORY + to SEQ2SEQ and PROFILEMEMORY .
We show that not only PRO-FILEMEMORY + is a stronger model for personalized chit-chat but also PROFILEMEMORY + does not reveal its personality easily .
Being discreet is a highly desirable property when the model is used to simulate the human participating in the dialogue ; when the facts are easily revealed , then the chit- chat bot can use generic or irrelevant questions to identify the personality thus the dialogue does not become engaging .
As a stronger personalized chatbot Datasets
We train all three models on the original Persona Chat dataset ( Zhang et al. , 2018 ) and the Year 2009 version of the OpenSubtitles corpus ( Tiedemann , 2009 ) .
The PersonaChat data set , which consists of crowdsourced 9000 dialogues ( 123,000 message - response pairs in total ) between two people with randomly assigned personas / personalities .
There are total 1155 personalities and each personality is defined by 3 to 5 memories ( facts such as " I was born in Russia " or " I like to swim " ) .
968 dialogues are set aside for validation and 1000 for testing .
We report the perplexity of our models on this test data set .
The OpenSubtitles corpus has 322,000 dialogues ( 1.2 million message - response pairs ) .
During training , we augment samples from OpenSubtitles with random personas , which forces PROFILEMEMORY + to actively prioritize DefaultFact over these fake facts .
Implementation Details Similarly to ( Zhang et al. , 2018 ) , we use a single layer LSTM for both the encoder and the decoder with hidden size of 1024 for all models .
The word embeddings are of size 300 and are initialized with GloVe word vectors ( Pennington et al. , 2014 ) .
All models are trained for 20 epochs to maximize the likelihood of the data by using SGD with momentum with batch size 128 .
Learning rate is reduced by a factor of 4 if the validation perplexity has increased compared to the previous epoch .
We found that general post-attention ( Luong et al. , 2015 ) ( Zhang et al. , 2018 ) .
The rests are from our implementation .
encoded memories gives better performance than pre-attention .
Weights for encoding memories are being learned during training and are initialized with 0.01 for the top 100 frequent words , and with 1 for others .
We found that this simple initialization procedure outperforms the one suggested in ( Zhang et al. , 2018 ) .
Results
The perplexity on the test dialogues by all of the models is contrasted in Table 1 .
The first two rows are previously reported in ( Zhang et al. , 2018 ) .
The rest results are from models implemented by us .
Our re-implementation of SEQ2SEQ and PRO-FILEMEMORY show better performance than what are reported in ( Zhang et al. , 2018 ) , likely due to the difference in the amount of data used for training 3 , as well as model architecture ( post-instead of pre-attention ) and optimization procedure ( e.g. , SGD vs. ADAM ) .
Including additional data such as OpenSubtitles , in general , improves performance .
Our PRO-FILEMEMORY + performs better than PROFILE -MEMORY .
This is the benefit of having Default - Fact ( cf. Section 3.3 ) which re-directs the attention by the messages and responses that are not related to the real personality away it .
On the other end , in PROFILEMEMORY , the attention has to select a real personality no matter what the messages or responses are .
As a discreet chatbot Since we intend to use a personalized chatbot such as PROFILEMEMORY and PROFILEMEMORY + as a model of the human interlocutor , we would want the model to behave intelligently : when given an 3 Zhang et al . ( 2018 ) only modeled the second person in dialogues , which reduces the training data by half .
Hence the fact that she survived .
P R O F I L E M E M O R Y P R O F I L E M E M O R Y + * P R O F I L E M E M O R Y * P R O F I L E M E M O R Y + Maybe she just needs a friend ?
Table 2 : Examples of sentences from PersonaChat dataset with the highest and the worst accuracies in revealing a personality of PROFILEMEMORY + model ( trained jointly on PersonaChat and OpenSubtitles ) .
We expect human to reply to such utterances with something which will more likely ( correspondingly , less likely ) reveal her personality .
Note , that we do n't predict human 's personality from the presented utterances alone .
Rather , these are considered good ( correspondingly , bad ) questions to get to know your interlocutor better .
irrelevant message , the model should not reveal its personality .
When given a relevant message , the model reveals its personality .
We can expect a similar behavior from a real human , which might reply with " I do n't know " or " I do n't understand " , when the question is irrelevant to them .
In other words , we want to avoid simulating dialogues like this - Chatbot : " Hmm ...
Thank you . " , Human ( Simulation ) : " I was born in Russia " .
With this adversity , the chit- chat bot has to ask meaningful and relevant questions if its goal is to discover the personality of the human interlocutor .
Experiment setup
We randomly sample 100 memories / facts ( out of total 5709 ) from the Per-sona Chat dataset .
For simplicity , we assume the model of the human interlocutor has a simple personality , denoted by one of the 100 facts .
We assign this single personality to each of the PRO-FILEMEMORY and PROFILEMEMORY + models trained on either the Personal Chat dataset or jointly with the OpenSubtitles dataset .
So there are 4 variants in total .
We then construct a simple 2 - turn dialogue , where the model is given a probing message and the model responses with a sampled utterance .
We use the DISCOVERYSCORE ( cf. Section 3.2 ) to measure how much the dialogue reveals a personality .
We then select the personality that maximizes the revealing .
If the selected personality is the true personality , we consider the lead message is able to accurately predict the personality .
We then average all probing messages to compute the averaged accuracy .
For probing messages , we use sentences from 4 different datasets - PersonaChat , OpenSubtitles , CornellMovieDialogCorpus ( Danescu-Niculescu-Mizil and Lee , 2011 ) and DailyDialog .
Our expectation is that an ideal model wo n't reveal its personality when asked a random question from OpenSubtitles or CornellMovieDi-alogCorpus , since most of the time it 's completely irrelevant lines from a movie script .
DailyDialog contains more casual conversations , so some of them we expect to be useful .
Of course , the accuracy of random sentences from Persona Chat should be the highest on average , since the corpus was collected with the intent to get to know each other better .
Results
The averaged accuracies from the different corpora are shown in Figure 1 . For PROFILEMEMORY + trained only on Per-sona Chat data , all types of sentences have similar effectiveness in predicting personality .
However , after joint learning with OpenSubtitles , only sentences from PersonaChat ( which are most relevant to personalities ) are able to predict noticeably accurate than other sentences .
As an illustration , examples of the sentences from PersonaChat with the best and the worst accuracy are presented in the Table 2 , for the PRO-FILEMEMORY + trained both on PersonaChat and OpenSubtitles .
These findings , together with the superior modeling ability ( cf. Section 4.1.1 and Table 1 ) , have validated the usage of PROFILEMEMORY + trained additionally on OpenSubtitles as a proper model for human interlocutors .
Human Evaluation
We report human evaluations to show that ( 1 ) DIS - COVERYSCORE can be used to measure how engaging the conversation is .
( 2 ) the dialogue 's quality can be increased by choosing a response with the highest expected future DISCOVERYSCORE ( cf. Section 3.4 ) .
Setup
We use " The Conversational Intelligence Challenge 2 " 4 evaluation procedure provided in ParlAI framework ( Miller et al. , 2017 ) .
We use around 200 Amazon Mechanical Turkers for human evaluation .
The same procedure is also used in ( Zhang et al. , 2018 ) .
During an evaluation round , a Turker is assigned a random persona ( with 3 - 5 profile facts ) from the Persona Chat dataset .
Each Turker is paired with a chatbot - we experiment with several models including SEQ2SEQ and PROFILEMEM - ORY trained on PersonaChat and PROFILEMEM - ORY + model trained on both PersonaChat and OpenSubtitles .
The chatbot can also adopt personal facts , but only PROFILEMEMORY and PRO-FILEMEMORY + are able to utilize it .
Every evaluation dialogue has at least 6 turns per participant .
After the dialogue the Turker is asked to evaluate its interlocutor ( i.e. , the chatbot ) by how fluent , engaging and consistent it is on a 1 to 5 scale ( 5 being the best ) .
Our primary focus is engagingness score and we will show in below that it correlates well with the DISCOVERYSCORE we proposed .
The Turker is also asked to guess the chatbot 's persona out of two given persona candidates ( each with 3 - 5 profile facts ) .
This metric is called " Persona Detection " and demonstrates how well the model is utilizing the assigned persona .
Naturally , we expect SEQ2SEQ - based chatbots to have Persona Detection rate around 50 % since they are not using provided persona at all .
Each chatbot model is evaluated on at least 100 dialogues .
Response generation
We experimented with both the greedy decoding ( which is default ) and the beam search ( with 100 beam size ) for text generation .
DISCOVERYSCORE -based re-ranking
As described in Section 3.4 , we use DISCOV -ERYSCORE - based re-ranking to select the response with the intent to discover the personality of the human participant .
Concretely , the chatbot is given a set of 30 facts from Persona Chat data set , which does include the true facts .
The chatbot is also told that the human has only 3 facts in her personality .
This is mainly for computational efficiency .
The re-ranking takes place in two steps .
First , the chatbot generates 100 response candidates .
For every candidate , it performs 10 simulated di-alogues with the PROFILEMEMORY + model as a proxy for the human interlocutor .
Finally , it selects the response with the highest expected DIS - COVERYSCORE .
Results
The evaluation results are presented in the Table 3 .
The results clearly demonstrate that the DISCOVERYSCORE - oriented re-ranking makes conversations more engaging for all type of the chatbot models .
When re-ranking is used , many human evaluators provided a feedback stating that the model was acting " genuinely interested " and asked a lot of questions .
In contrast , modeling without reranking had a lower engagingness score precisely because of the lack of questions .
Persona Detection score indicates that PRO-FILEMEMORY + is doing a better job in modeling a persona .
We also see a decrease in this metric when we combine PROFILEMEMORY + with the re-ranking procedure , which is likely caused by the chatbot asking more questions than revealing itself personality .
Example dialogues between human and two PROFILEMEMORY + models with and without DISCOVERYSCORE - based re-ranking are given in the Table 5 .
DISCOVERYSCORE as a proxy for Engagingness
We group all the dialogues between chatbots and humans by the assigned engagingness score and compute the average DISCOV - ERYSCORE , average length of utterances and average percentage of generated questions - see Table 4 .
Interestingly enough , there is no obvious correlation between how engaging the dialogue has been perceived and simple metrics like the length of the response or the number of asked questions .
On the other hand , it is strongly correlated with DISCOVERYSCORE , indicating that it indeed can be used as one of the automatic metrics for dialogues quality .
Conclusion & Future Work
We introduce a new metric DISCOVERYSCORE to assess the engagingness of a dialogue based on the intuition that the more interested the chatbot is in its interlocutor the more engaging the dialog becomes .
We propose an improved PROFILEMEM - ORY + model , which achieves state - of- the - art perplexity results on the Persona Chat dataset .
One appealing property of the model is that it does n't reveal assigned personality upon irrelevant ques-tions .
We demonstrate how it can be used to estimate the expected DISCOVERYSCORE by running simulations with the model as a human substitute .
A re-ranking method that uses such estimates allows us to significantly improve the dialogue engagingness score over several baselines , which we demonstrate with human evaluations .
We hope to continue exploring DISCOV -ERYSCORE in more general settings with richer , more complicated personalization or when profile information is not explicitly defined .
Figure 1 : Average accuracies of utterances sampled from different corpora ( PersonaChat , OpenSubtitles , Cor-nellMovieDialog , DailyDialog ) in revealing the personality of the human interlocutor modeled by personalized chatbots ( cf. Section 4.1.2 ) .
PROFILEMEMORY and PROFILE -MEMORY + have been trained on PersonaChat data set , while * PROFILEMEMORY and * PROFILEMEMORY + have been trained on both PersonaChat and OpenSubtitles .
