title
Effective Inference for Generative Neural Parsing
abstract
Generative neural models have recently achieved state - of - the - art results for constituency parsing .
However , without a feasible search procedure , their use has so far been limited to reranking the output of external parsers in which decoding is more tractable .
We describe an alternative to the conventional action- level beam search used for discriminative neural models that enables us to decode directly in these generative models .
We then show that by improving our basic candidate selection strategy and using a coarse pruning function , we can improve accuracy while exploring significantly less of the search space .
Applied to the model of Choe and Charniak ( 2016 ) , our inference procedure obtains 92.56 F1 on section 23 of the Penn Treebank , surpassing prior state - of - the - art results for single -model systems .
Introduction
A recent line of work has demonstrated the success of generative neural models for constituency parsing ( Dyer et al. , 2016 ; Choe and Charniak , 2016 ) .
As with discriminative neural parsers , these models lack a dynamic program for exact inference due to their modeling of unbounded dependencies .
However , while discriminative neural parsers are able to obtain strong results using greedy search ( Dyer et al. , 2016 ) or beam search with a small beam ( Vinyals et al. , 2015 ) , we find that a simple action - level approach fails outright in the generative setting .
Perhaps because of this , the application of generative neural models has so far been restricted to reranking the output of external parsers .
Intuitively , because a generative parser defines a joint distribution over sentences and parse trees , probability mass will be allocated unevenly between a small number of common structural actions and a large vocabulary of lexical items .
This imbalance is a primary cause of failure for search procedures in which these two types of actions compete directly .
A notion of equal competition among hypotheses is then desirable , an idea that has previously been explored in generative models for constituency parsing ( Henderson , 2003 ) and dependency parsing ( Titov and Henderson , 2010 ; Buys and Blunsom , 2015 ) , among other tasks .
We describe a related state- augmented beam search for neural generative constituency parsers in which lexical actions compete only with each other rather than with structural actions .
Applying this inference procedure to the generative model of Choe and Charniak ( 2016 ) , we find that it yields a self-contained generative parser that achieves high performance .
Beyond this , we propose an enhanced candidate selection strategy that yields significant improvements for all beam sizes .
Additionally , motivated by the look - ahead heuristic used in the top-down parsers of Roark ( 2001 ) and Charniak ( 2010 ) , we also experiment with a simple coarse pruning function that allows us to reduce the number of states expanded per candidate by several times without compromising accuracy .
Using our final search procedure , we surpass prior state- ofthe - art results among single-model parsers on the Penn Treebank , obtaining an F1 score of 92.56 .
Common Framework
The generative neural parsers of Dyer et al . ( 2016 ) and Choe and Charniak ( 2016 ) can be unified under a common shift-reduce framework .
Both systems build parse trees in left-to- right depth-first order by executing a sequence of actions , as illustrated in Figure 1 .
These actions can be grouped Figure 1 : A parse tree and the action sequence that produced it , corresponding to the sentence " He had an idea . "
The tree is constructed in left-toright depth-first order .
The tree contains only nonterminals and words ; part- of-speech tags are not included . OPEN ( X ) and CLOSE ( X ) are rendered as " ( X " and " X ) " for brevity .
into three major types : OPEN ( X ) and CLOSE ( X ) , which open and close a constituent with nonterminal X , 1 respectively , and SHIFT ( x ) , which adds the word x to the current constituent .
The probability of an action sequence ( a 1 , . . . , a T ) is P ( a 1 , . . . , a T ) = T t=1 P ( a t | a 1 , . . . , a t?1 ) = T t=1 [ softmax ( Wu t + b ) ] at , where u t is a continuous representation of the parser 's state at time t , and [ v ] j denotes the jth component of a vector v .
We refer readers to the respective authors ' papers for the parameterization of u t in each model .
In both cases , the decoding process reduces to a search for the most probable action sequence that represents a valid tree over the input sentence .
For a given hypothesis , this requirement implies several constraints on the successor set ( Dyer et al. , 2016 ) ; e.g. , SHIFT ( x ) can only be executed if the next word in the sentence is x , and CLOSE ( X ) cannot be executed directly after OPEN ( X ) .
Model and Training Setup
We reimplemented the generative model described in Choe and Charniak ( 2016 ) and trained it on the Penn Treebank ( Marcus et al. , 1993 )
Action - Level Search Given that ordinary action- level search has been applied successfully to discriminative neural parsers ( Vinyals et al. , 2015 ; Dyer et al. , 2016 ) , it offers a sensible starting point for decoding in generative models .
However , even for large beam sizes , the following pathological behavior is encountered for generative decoding , preventing reasonable parses from being found .
Regardless of the sequence of actions taken so far , the generative model tends to assign much higher probabilities to structural OPEN and CLOSE actions than it does lexical SHIFT actions , as shown in Figure 2 .
The model therefore prefers to continually open new constituents until a hard limit is reached , as the alternative at each step is to take the low-probability action of shifting the next word .
The resulting sequence typically has much lower overall probability than a plausible parse , but the model 's myopic comparison between structural and lexical actions prevents reasonable candidates from staying on the beam .
Action - level beam search with beam size 1000 obtains an F1 score of just 52.97 on the development set .
Word -Level Search
The imbalance between the probabilities of structural and lexical actions suggests that the two kinds of actions should not compete against each other within a beam .
This leads us to consider an augmented state space in which they are kept separate by design , as was done by Fried et al . ( 2017 ) .
In conventional action- level beam search , hypotheses are grouped by the length of their action history | A| .
Letting
A i denote the set of actions taken since the ith shift action , we instead group hypotheses by the pair ( i , | A i | ) , where i ranges between 0 and the length of the sentence .
Let k denote the target beam size .
The search process begins with the empty hypothesis in the ( 0 , 0 ) bucket .
Word - level steps are then taken according to the following procedure for i = 0 , 1 , . . . , up to the length of the sentence ( inclusive ) .
Beginning with the ( i , 0 ) bucket , the successors of each hypothesis are pooled together , sorted by score , and filtered down to the top k .
Of those that remain , successors obtained by taking an OPEN or CLOSE action advance to the ( i , 1 ) bucket , whereas successors obtained from a SHIFT action are placed in the ( i + 1 , 0 ) bucket if i is less than the sentence length , or the completed list if i is equal to the sentence length .
This process is repeated for the ( i , 1 ) bucket , the ( i , 2 ) bucket , and so forth , until the ( i + 1 , 0 ) bucket contains at least k hypotheses .
If desired , a separate word beam size k w < k can be used at word boundaries , in which case each word - level step terminates when the ( i + 1 , 0 ) bucket has k w candidates instead of k .
This introduces a bottleneck that can help to promote beam diversity .
Development set results for word- level search with a variety of beam sizes and with k w = k or k w = k/10 are given in Table 1 .
We observe that performance in both cases increases steadily with beam size .
Word - level search with k w = k/10 consistently outperforms search without a bottleneck at all beam sizes , indicating the utility of this simple diversity - inducing modification .
The top result of 92.93 F1 is already quite strong compared to other single -model systems .
Fast - Track Candidate Selection
The word- level beam search described in Section 5 goes one step toward ameliorating the issue that causes action - level beam search to fail , namely the direct competition between common structural actions with high probabilities and low-frequency shift actions with low probabilities .
However , the issue is still present to some extent , in that successors of both types from a given bucket are pooled 1 , together with the fast - track selection strategy from Section 6 with k s = k/100 .
together and filtered down as a single collection before being routed to their respective destinations .
We therefore propose a more direct solution to the problem , in which a small number k s k of SHIFT successors are fast-tracked to the next word - level bucket before any filtering takes place .
These fast-tracked candidates completely bypass competition with potentially high-scoring OPEN or CLOSE successors , allowing for higher -quality results in practice with minimal overhead .
See Figure 3 for an illustration .
We repeat the experiments from Section 5 with k s = k/100 and report the results in Table 2 .
Note that the use of fast-tracked candidates offers significant gains under all settings .
The top result improves from 92.93 to 93.18 with the use of fasttracked candidates , surpassing prior single -model systems on the development set .
OPEN Action Pruning
At any point during the trajectory of a hypothesis , either 0 or all 26 of the OPEN actions will be available , compared with at most 1 CLOSE action and at most 1 SHIFT action .
Hence , when available , OPEN actions comprise most or all of a candidate 's successor actions .
To help cut down on this portion of the search space , it is natural to consider whether some of these actions could be ruled out using a coarse model for pruning .
Coarse Model
We consider a class of simple pruning models that condition on the c ?
0 most recent actions and the next word in the sentence , and predict a probability distribution over the next action .
In the interest of efficiency , we collapse all SHIFT actions into a single unlexicalized SHIFT action , significantly reducing the size of the output vocabulary .
The input v t to the pruning model at time t is the concatenation of a vector embedding for each action in the context ( a t?c , a t?c+ 1 , . . . , a t?1 ) and a vector embedding for the next word w : v t = [ e a t?c ; e a t?c + 1 ; . . . ; e a t?1 ; e w ] , where each e j is a learned vector embedding .
The pruning model itself is implemented by feeding the input vector through a one- layer feedforward network with a ReLU non-linearity , then applying a softmax layer on top : P ( a t = a | a 1 , . . . , a t?1 , next- word = w ) = P ( a t = a | a t?c , . . . , a t?1 , next- word = w ) = [ softmax ( W 2 max ( W 1 v t + b 1 , 0 ) + b 2 ) ] a .
The pruning model is trained separately from the main parsing model on gold action sequences derived from the training corpus , with log-likelihood as the objective function and a cross entropy loss .
Strategy and Empirical Lower Bound Once equipped with a coarse model , we use it for search reduction in the following manner .
As mentioned above , when a hypothesis is eligible to open a new constituent , most of its successors will be obtained through OPEN actions .
Accordingly , we use the coarse model to restrict the set of OPEN actions to be explored .
When evaluating the pool of successors for a given collection of hypotheses during beam search , we run the coarse model on each hypothesis to obtain a distribution over its next possible actions , and gather together all the coarse scores of the would - be OPEN successors .
We then discard the OPEN successors whose coarse scores lie below the top 1 ? p quantile for a fixed 0 < p < 1 , guaranteeing that no more than a p-fraction of OPEN successors are considered for evaluation .
Taking p = 1 corresponds to the unpruned setting .
This strategy gives us a tunable hyperparameter p that allows us to trade off between the amount of search we perform and the quality of our results .
Before testing our procedure , however , we would first like to investigate whether there is a principled bound on how low we can expect to set p without a large drop in performance .
A simple estimate arises from noting that the pruning fraction p should be set to a value for which most or all of the outputs encountered in the training set are retained .
Otherwise , the pruning model would prevent the main model from even recreating the training data , let alone producing good parses for new sentences .
To this end , we collect training corpus statistics on the occurrences of inputs to the pruning function and their corresponding outputs .
We then c 1 2 3 4 5 6 7 8 9 10 0 20.0 58.4 82.4 91.0 94.9 96.8 97.9 98.6 98.9 99.2 1 54.9 80.5 91.1 95.9 97.7 98.8 99.5 99.8 99.9 100.0 2 61.2 85.0 93.8 97.4 98.6 99.5 99.8 99.9 100.0 100.0 compute the number of unique OPEN actions associated with inputs occurring at least 20 times , and restrict our attention to inputs with at least one OPEN output .
The resulting cumulative distributions for context sizes c = 0 , 1 , 2 are given in Table 3 .
If we require that our pruning fraction p be large enough to recreate at least 99 % of the training data , then since there are 26 total nonterminals , approximate 2 lower bounds for p are 10 / 26 ? 0.385 for c = 0 , 7/26 ? 0.269 for c = 1 , and 6/26 ? 0.231 for c = 2 .
Pruning Results
We reran our best experiment from Section 6 with an order - 2 pruning function and pruning fractions p = 6/26 , . . . , 11/ 26 .
The results are given in Table 4 .
We observe that performance is on par with the unpruned setup ( at most 0.1 absolute difference in F1 score ) for p as low as 8/26 ? 0.308 .
Setting p to 7/26 ? 0.269 results in a drop of 0.18 , and setting p to 6/26 ? 0.231 results in a drop of 0.40 .
Hence , degradation begins to occur right around the empirically - motivated threshold of 6 /26 given above , but we can prune 1 ? 8/26 ? 69.2 % of OPEN successors with minimal changes in performance .
Final Results and Conclusion
We find that the best overall settings are a beam size of k = 2000 , a word beam size of k w = 200 , and k s = 20 fast - track candidates per step , as this 2
These thresholds are not exact due to the fact that our pruning procedure operates on collections of multiple hypotheses ' successors at inference time rather than the successors of an individual hypothesis .
and Charniak ( 2016 ) works well as an accurate , self-contained system .
The fact that we match the performance of their reranking parser using the same generative model confirms the efficacy of our approach .
We believe that further refinements of our search procedure can continue to push the bar higher , such as the use of a learned heuristic function for forward score estimation , or a more sophisticated approximate decoding scheme making use of specific properties of the model .
We look forward to exploring these directions in future work .
NP He NP ) ( VP had ( NP an idea NP ) VP ) . S )
Figure 3 : 3 Figure 3 : One step of word- level search with fasttrack candidate selection ( Sections 5 and 6 ) for the example in Figure 1 .
Grouping candidates by the current word i ensures that low-probability lexical actions are kept separate from high - probability structural actions at the beam level .
Fast - track selection mitigates competition between the two types of actions within a single pool of successors .
Table 1 : 1 Development F1 scores using word- level search with various beam sizes k and two choices of word beam size k w .
Beam Size k 200 400 600 800 1000 2000 k w = k 87.47 89.86 90.98 91.62 91.97 92.74 k w = k/10 89.25 91.16 91.83 92.12 92.38 92.93
Table 2 : 2 Development F1 scores using the settings from Table Beam Size k 200 400 600 800 1000 2000 k w = k 91.33 92.17 92.51 92.73 92.89 93.05 k w = k/10 91.41 92.34 92.70 92.94 93.09 93.18
Table 3 : 3 Cumulative distributions of the number of unique OPEN outputs per input for an orderc pruning function , computed over pruning inputs with at least one OPEN output .
p 6/26 7/26 8/26 9/26 10/26 11/26 1 Dev F1 92.78 93.00 93.08 93.13 93.19 93.19 93.18
Table 4 : 4 Results when the best setting from Section 6 is rerun with OPEN action pruning with context size c = 2 and various pruning fractions p.
Lower values of p indicate more aggressive pruning , while p = 1 means no pruning is performed .
Table 5 : 5 Comparison of F1 scores on section 23 of the Penn Treebank .
Here we only include models trained without external silver training data .
Results in the first two sections are for single-model systems .
setup achieves both the highest probabilities under the model and the highest development F1 .
We report our test results on section 23 of the Penn Treebank under these settings in Table5both with and without pruning , as well as a number of other recent results .
We achieve F1 scores of 92.56 on the test set without pruning and 92.53 when 1 ? 8/26 ? 69.2 % of OPEN successors are pruned , obtaining performance well above the previous state - of - the - art scores for single -model parsers .
This demonstrates that the model of Choe Parser LR LP F1 Vinyals et al . ( 2015 ) - - 88.3 Shindo et al. ( 2012 ) - - 91.1 Cross and Huang ( 2016 ) 90.5 92.1 91.3
Dyer et al . ( 2016 ) - - 91.7 Liu and Zhang ( 2017 ) 91.3 92.1 91.7 Stern et al . ( 2017 ) 90.63 92.98 91.79 Our Best Result 92.57 92.56 92.56
Our Best Result ( with pruning ) 92.52 92.54 92.53
Vinyals et al. ( 2015 ) ( ensemble ) - - 90.5 Shindo et al. ( 2012 ) ( ensemble ) - - 92.4 Choe and Charniak ( 2016 ) ( rerank ) - - 92.6 Dyer et al. ( 2016 ) ( rerank ) - - 93.3 Fried et al. ( 2017 ) ( ensemble , rerank ) - - 94.25
The model described in Dyer et al . ( 2016 ) has only a single CLOSE action , whereas the model described in Choe and Charniak ( 2016 ) annotates CLOSE ( X ) actions with their nonterminals .
We present the more general version here .
