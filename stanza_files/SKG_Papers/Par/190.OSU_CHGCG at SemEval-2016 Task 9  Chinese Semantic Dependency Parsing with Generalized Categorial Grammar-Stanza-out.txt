title
OSU CHGCG at SemEval - 2016 Task 9 : Chinese Semantic Dependency Parsing with Generalized Categorial Grammar
abstract
This paper introduces our Chinese semantic dependency parsing system for Task 9 of Se-mEval 2016 .
Our system has two components : a parser trained using the Berkeley Grammar Trainer on the Penn Chinese Treebank reannotated in a Generalized Categorial Grammar , and a multinomial logistic regression classifier .
We first parse the data with the automatic parser to obtain predicate - argument dependencies and then we use the classifier to predict the semantic dependency labels for the predicate - argument dependency relations extracted .
Although our parser is not trained directly on the task training data , our system yields the best performance for the non-local dependency recovery for the news data and comparable overall results .
Introduction Semantic dependency parsing is an important language processing task which is useful in information extraction and question answering .
In this paper , we introduce a Chinese semantic dependency parsing system which is built upon a categorial analysis of the Chinese language .
Categorial grammar annotations are attractive because they have a transparent syntactic -semantic interface and provide a natural account of longdistance dependencies in a language .
For this system , we adopt a Generalized Categorial Grammar framework , GCG , ( Bach , 1981 ) , for our language analysis .
GCG annotations , compared with other Categorial Grammars , have a larger set of languagespecific rules and a smaller set of lexical categories , which on the one hand retains the desirable features of a categorial grammar , such as straightforward compositionality of its syntactic derivations and elegant analysis of filler - gap phenomenon , and on the other hand , mitigates the sparse data problem faced by any heavily lexicalized annotations .
Parsers trained with English GCG annotations have been shown to have state - of - the - art parsing performance and better long-distance dependency recovery ( Rimell et al. , 2009 ; Nguyen et al. , 2012 ) .
Parsers trained with Chinese GCG annotations have been shown to achieve better parsing accuracy than the parser trained with Chinese Combinatory Categorial Grammar , CCG , ( Steedman , 2000 ; Steedman , 2012 ) annotations ( Tse and Curran , 2010 ; Tse and Curran , 2012 ) for those trees which both grammar annotations assign the same tree structures ( Duan and Schuler , 2015 ) .
The current experiment is our first experiment with dependency relations generated from the Chinese GCG annotations .
We evaluate them against the manually annotated semantic dependencies in the current SemEval task .
Since the purpose of the system is to verify the semantic dependencies generated by the Chinese GCG parser are reasonable , we adopt a minimalist machine learning scheme for this system to accomplish the evaluation .
We first train the Berkeley parser ( Petrov and Klein , 2007 ) with GCG annotations converted from the currently reannotated protion of around 71 % of the Chinese Treebank ( Xue et al. , 2005 ) sentences .
With this parser , we parse the sentences from training sets of the SemEval task and extract dependencies from the parses .
Since the dependency labels are more finegrained in the SemEval task , we train a multinomial logistic regression classifier to predict the dependency labels for the extracted dependencies , using lexical , POS and other position features .
Even though the parser is not directly trained on the gold GCG annotations of the training sentences , this system still yields respectable results compared with other more task dependent systems .
Also the official evaluation of the task shows that the current system yields the best non-local dependency parsing accuracy for the newspaper corpus , which supports the findings in English that GCG annotations yield superior performance in long-distance dependency recovery ( Nguyen et al. , 2012 ) .
Chinese GCG Parser
This experiment used the Berkeley parser trained on Chinese GCG reannotated trees .
Chinese GCG framework A generalized categorial grammar ( Bach , 1981 ; Nguyen et al. , 2012 ) 1 is a tuple P , O , R , W , M ( Oehrle , 1994 ) consisting of a set P of primitive category types , a set O of type- constructing operators , a set R of inference rules , a set W of vocabulary items , and a mapping M from vocabulary items to syntactic categories .
A set of complex syntactic categories C may then be defined as : P ? C ; C ? O ? C ? C ; nothing else is in C .
The reannotation of Chinese Treebank into GCG annotations is still an on-going project .
So far , we have identified the following set of primitive syntactic categories P for Mandarin Chinese : 1 Nguyen et al ( 2012 ) notate the ' / / ' and ' \\ ' operators of Bach ( 1981 ) as -g and -h , mnemonic for ' gap ' and ' heavy shift ' .
V : verb-headed clause N : noun-headed phrase or clause D : de-clause headed by ?
C : cardinal number Q : quantificational phrase A : adjectival phrase or nominal modifier R : adverbial phrase or verbal modifier B : verbal complement of in ba-construction E : verbal complement of in passive voice
The set of type-constructing operators O for Mandarin Chinese includes - a and -b operators for unsatisfied requirements of preceding or succeeding arguments , -c and -d operators for unsatisfied requirements of preceding or succeeding conjuncts , and a -g operator for unsatisfied requirements of gap categories .
2 A GCG category consists of a primitive category followed by one or more unsatisfied dependencies , each consisting of an operator followed by another category .
For example the category for a transitive verb is ' V - aN - bN ' , since it is headed by a verb and has unsatisfied dependencies for noun phrases preceding and following it , i.e. , the subject and direct object respectively .
As in other categorial grammars , inference rules for local argument attachment apply functors of category ?
1...n- 1 - ac or p? 1..n- 1 - bc to initial or final arguments of category c , where c ?
C , p ?
P and each ? ? {- a , - b} ? C : c:g p? 1..n- 1 - ac:h ? p? 1..n- 1 :? x g ( f n x ) ? ( h x ) ( Aa ) p? 1..n- 1 - bc:g c:h ? p? 1..n- 1 :? x ( g x ) ? h ( f n x ) ( Ab )
These two inference rules stipulate the argument of category c is the n-th argument of the head .
Inference rules for modifier composition apply preceding or succeeding modifiers of category p-bd to modificands of category c , where p ? { A , R} , d ? { N , V} : p-bd: g c:h ? c :?
x ? y ( g y ) ? ( h x ) ? ( f 1 y ) =x ( Ma ) c:g p-bd:h ? c :?
x ? y ( g x ) ? ( h y ) ?
( f 1 y ) =x ( Mb ) Separate modifier composition rules makes it possible to assign the same syntactic category to the modifier regardless of its occurring position .
The modifier composition rules Ma and Mb establish a ' 1 ' labeled dependency from the modifier to the modificand .
For example , for the sentence ' ? ?
The little cat ate the fish ' , we have the derivation and the dependencies extracted from the derivation as follows .
? little A- bN ? cat N Ma N ? ate V-aN- bN ? ASP R- bV Ma V-aN- bN ? fish N Ab V-aN Aa V ?'little ' 1 ?'cat ' ?' ate ' 1 2 ?ASP 1 ?' fish '
Inference rules for gap composition are : p? 1..n- 1 oc ? p? 1..n- 1 - gc :? vx ( g x ) ? ( f n x ) =v ( Ga ) c:g ? c-gd : ? vx ( g x ) ? ( f 1 v ) =x ( Gb ) N:g ? N -gN : ? vx ( g x ) ? ? e ( de-asso e x v ) ( Gc ) where p ?
P , o ? {- a , - b} , c ? C , d ? { A- bN , R- bV } and ? ? {- a , - b} ? C. Rule Ga hypothesizes a gap as a preceding or succeeding argument , rule Gb hypothesizes an adjectival or adverbial modifier gap and rule Gc hypothesizes a gap which is associated with the subject in the topicalization construction which does not involve movement .
Non-local arguments , each consisting of a nonlocal operator and argument category ? ? {- g} ? C , are then propagated to consequents from all possible combinations of antecedents .
For d:g e:h ? c:( f g h ) ? { Aa -b , Ma-b} : d? 1 ..m :g e? m+1..n :h ? c? 1..n :? v1..n f ( g v 1 ..m ) ( h v m+1..n ) ( Ac - d , Mc -d ) Rules Ac -d and Mc-d stipulate non-local propagation through argument and modifier composition .
Inference rules for filler attachment apply gapped clauses to topicalized phrases as fillers .
For c ? C , and p ? P : p:g c-gp:h ? c :?
x ? y ( g y ) ? ( h y x ) ( Fa ) For example , for a topicalized sentence such as " ?
? ? ? ? ?
? The fish , the little cat ate . " , we can extract the dependencies as follows .
?' fish ' ?' little ' 1 ?'cat ' ?' ate ' 1 2 ?ASP 1 In Mandarin relative clauses , the particle ? ' de ' takes a preceding clause containing a gap to form a relative clause modifying a succeeding noun .
The modified noun is the filler of the gap in the relative clause .
The inference rules for relative clauses apply the gapped de-clause to the modificand as a filler .
For c ? C : D-gc:g N:h ? N :? x ( h x ) ? ? y ( g x y ) ( R ) For a noun phrase such as " ?
the fish that the little cat ate " , we can extract the following dependencies .
?' little ' 1 ?' cat ' ?' ate '
1 2 ? DE 1 ?' fish ' Ba constructions in Mandarin Chinese require the affected patients of certain verbs to occur before the verb .
In our analysis , we propose that the particle ba takes a ba-verb as its complement .
Ba-verbs can be derived from transitive verbs with the type conversion rule , or some verbs , such as some resultative verbs , have Ba-verb categories .
The particle ? ba is assigned the category V-aNb ( B - aN ) , with coindexation between the referent of its subject ( f 1 x ) and the referent of the subject of its complement ( f 1 ( f 2 x ) ) .
? ' ba ' ?V- aN -b( B - aN ) : ? x ( f 0 x ) =ba ? ( f 1 x ) =( f 1 ( f 2 x ) )
The lexical entry of ba gives the following dependencies for the sentence ' ?
The cat ate the fish .
?' cat ' ? BA 1 2 ?' fish ' ?' ate ' 2 1 O O ?ASP 1 Mandarin Chinese uses the particle ? bei to construct passive sentences .
In bei constructions , the patient argument of a verb , usually the second argument of a transitive verb or a ba-verb , is moved to the subject position of the clause .
We propose the particle ?
bei takes a bei-verb as its complement , which is converted from a transitive verb with a missing object .
Here is the lexical entry we propose for the bei particle .
? ' bei ' ?V-aN -b( E-aN - gN ) - bN : ? x ( f 0 x ) =bei ? ( f 3 x ) =( f 1 ( f 2 x ) )
For example , the sentence ' ?
The fish was eaten by the cat gives us the following dependencies .
?' fish ' ? BEI 1 2 ?'cat ' ?' ate ' 1 2 O O ?ASP 1 2 .
Training Chinese GCG Parser
The syntactic parser we used for the current semantic dependency parsing is trained by the latent variable PCFG trainer ( Petrov and Klein , 2007 ) on Chinese GCG annotations .
Converting Penn Chinese Treebank 5 and 6 into GCG annotations is still an on-going project .
We use a set of reannotation rules similar to those described by Nguyen et al . ( 2012 ) to reannotate the Penn Chinese Treebank into GCG trees .
We currently have fully annotated 71 % of sentences ( 18,505 out of 26,062 sentences ) from the Penn Chinese Treebank 5 and 6 .
3 With these 18,505 , we have trained the Chinese GCG parser which is used for the current semantic dependency parsing task .
From the parses , we extracted the raw dependences as the input for the multinomial classifier in the next stage .
Multinomial Dependency Label Classifier
As shown in the examples above , the predicateargument dependencies extracted from GCG derivations do not have fine - grained labels as those dependencies annotated for the task .
Also the dependencies identified by the parser sometimes have different directions than those annotated in the task .
Therefore , in order to increase the coverage , for each dependency identified by the parser , we also add a dependency which has the reverse direction .
For example , if the parser predicts that a dependency such as 1 ( eat , cat ) , in which the head is eat , the dependent is cat , the dependency label is ' 1 ' , we would add another dependency with inversed direction : 1 - inv( cat , eat ) .
By doing so , we can increase the coverage of the annotated dependencies to around 83 % .
However , it also doubles the dependencies predicted by the parser and potentially hurts the recall of the accuracy later on .
There are totally 157 semantic dependency labels used in the task .
Since the classifier also needs to decide whether a dependency relation exists between each pair of words , we add a " NoRel " label for those pairs of words which , according to the gold annotation , do not hold any dependency relation between them .
We train a one- vs- all multiclass classifier from the Vowpal Wabbit machine learning package .
4
We use the following features to predict the dependency labels : Lexical features : the 300 - dimensional word embeddings of the head and dependent words trained with word2vec ( Mikolov et al. , 2013 ) on the full Chinese Wikipedia , the Chinese Gigaword as well as the training and test datasets in this task ; POS features : the 50 - dimensional vector representations of the POS tags of the head and dependent trained with the POS tag sequences from training and test datasets in this task ; Linear distance : the linear distance of the head and the dependent in the sentence ;
Path distance : the distance of the nodes of the head and the dependent in the syntactic tree ; Syntactic categories : the GCG syntactic categories of the head and the dependent ; Pred-arg dependency labels : the dependency labels predicted by the parser , such as ' 1 ' or ' 2 ' ;
Repetition penalty : the reciprocal of the number of heads that the dependent word has , to penalize proposing too many heads for one word ; Joint features : two - way combinational features between GCG syntactic categories of the two words where GCG is the current system and TOP is the system with the best labeled F1 score .
and the dependency label , such " V - aN 1 " or " N 1 " ;
Results and Discussion
This Chinese semantic dependency parsing task comes in two domains , the newspaper articles ( News ) and texts selected from Chinese textbooks ( Text ) .
In our experiment , we found the combining the two training sets yields better accuracy for the textbook corpus and a slightly worse performance for the newspaper corpus .
Therefore the News results reported in Table 1 and 2 are obtained by a classifier only trained on the newspaper corpus , and the Text results are obtained by a classifier trained on the combined training set of the newspaper corpus and the textbook corpus .
The results in Table 1 show that newspaper text is more difficult to parse , even though the GCG parser is trained on a newspaper corpus .
However , it also shows that the parser trained on the newspaper corpus can generalize nicely to another domain such as the textbook corpus , where more diverse syntactic constructions are found .
Table 2 shows the results on the test set compared with the system yielding the highest labeled F1 score .
We can see that the current system is around 3 percentage lower than the top system in terms of the labeled F1 score .
Considering the fact that the parser is not directly trained on the task -specific dependency annotations and gold POS tags , these results look reasonably good with the rather simplistic machine learning architecture .
Table 2 also shows that the current system achieves the best performance on non-local dependencies according to the official evaluation , which supports the corresponding findings in English where parsers trained on GCG English annotations achieve the state- ofthe - art performance in long distance dependency recovery ( Nguyen et al. , 2012 ) .
Error Analysis
We randomly inspected around 20 sentences from each domain where the predictions of the current system are different from the gold annotations to examine the reason , and we identified the following sources of errors .
Parsing errors :
Parsing errors caused around half of the wrong predictions we inspected .
One type of mistake that we notice the parser often makes is wrong predictions about the internal structure of complex noun phrases .
For example , for the noun phrase '?
? ? ? ? ? ? ? International Monetary Fund Organization ' , the parser proposes all first three nouns to be modifiers of the head noun '? organization ' , while '?
monetary ' actually modifies '? fund ' in gold annotations .
The parser also often makes mistakes when parsing questions , since there are not many questions in the Treebank .
Uncovered linguistic phenomena : the gold dependency annotations issued by the task contain dependencies involving co-reference .
( In ( 1 ) , '?
I ' is annotated to have a eEqu relation with ' ?
myself '. In ( 2 ) , '? Lusu ' has a eEqu relation with ' ?
me '.
Dependencies like these , especially the one in ( 2 ) , cannot be resolved easily by a syntactic parser , which means we might need an extra layer of post-processing to do co-reference inference based on discourse information .
Ambiguous constructions :
In some cases , a sentence can be analyzed in more than one way .
All of them are reasonable analyses but each gives different dependencies .
The current parser parses both ( 3 ) and ( 4 ) as object control sentences .
In ( 3 ) '?
he ' is the object of ' ?
love ' and the subject of ' ?
have aspiration ' .
In the gold annotation of ( 3 ) , '? love ' takes a sentential complement 'he has aspiration ' .
Therefore , for ( 3 ) , our system proposes a dependency between '? love ' and '?
he ' , while in the gold annotations , the dependency is between '? love ' and '?
have '.
In ( 4 ) , our parser parses '? person ' as the object of ' ?
have ' and the subject of ' ?
came '. '? have '? therefore , is the root of the sentence .
In gold annotations , '? come ' is the root of the sentence .
Inconsistent annotations :
There are some cases where our predictions are systematically different from the gold annotations .
For example , the current system is consistently different from the gold annotations on the identification of root where some adverbial clauses are involved .
( We think both ( 5 ) and ( 6 ) contain a conditional subordinate clause , and the root of the sentence should be ' ? postpone ' in ( 5 ) and ' ? buy ' in ( 6 ) .
In gold annotations , '? rain ' is annotated to be the root of ( 5 ) and ' ?
dislike ' the root of ( 6 ) .
Our assumption is that those clauses are handled as conjunctions in gold annotations .
Our predictions also do not agree with the gold annotations in some relative clauses .
For ( 7 ) , we think there is a dependency between ' ? do ' and ' ?
thing ' , rather than ' ?
like ' and '?
thing ' .
Conclusion
This paper introduces the Chinese semantic dependency parsing system based on the predicateargument dependencies predicted by a Berkeley parser trained on Chinese GCG trees reannotated from the Penn Chinese Treebank .
This system achieves comparable performance for the overall labeled dependency prediction and superior performance for the non-local dependency recovery .
Our error analysis shows that many dependency parsing errors can be attributed to the syntactic parsing errors .
In the future , we will expand the training set of the parser to cover more diverse syntactic constructions such as questions .
We will also consider including corpora from different domains to make the parser more adaptable to data from new domains .
have come here before '
