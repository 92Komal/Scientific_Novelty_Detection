title
Joint Inference for Heterogeneous Dependency Parsing
abstract
This paper is concerned with the problem of heterogeneous dependency parsing .
In this paper , we present a novel joint inference scheme , which is able to leverage the consensus information between heterogeneous treebanks in the parsing phase .
Different from stacked learning methods ( Nivre and McDonald , 2008 ; Martins et al. , 2008 ) , which process the dependency parsing in a pipelined way ( e.g. , a second level uses the first level outputs ) , in our method , multiple dependency parsing models are coordinated to exchange consensus information .
We conduct experiments on Chinese Dependency Treebank ( CDT ) and Penn Chinese Treebank ( CTB ) , experimental results show that joint inference can bring significant improvements to all state - of - the - art dependency parsers .
Introduction
Dependency parsing is the task of building dependency links between words in a sentence , which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation ( Ding and Palmer , 2004 ) to question answering ( Zhou et al. , 2011a ) .
Over the past few years , supervised learning methods have obtained state - of - the - art performance for dependency parsing ( Yamada and Matsumoto , 2003 ; McDonald et al. , 2005 ; McDonald and Pereira , 2006 ; Hall et al. , 2006 ; Zhou et al. , 2011 b ; Zhou et al. , 2011 c ) .
These methods usually rely heavily on the manually annotated treebanks for training the dependency models .
However , annotating syntac - ( below ) . CTB is converted into dependency grammar based on the head rules of ( Zhang and Clark , 2008 ) . tic structure , either phrase - based or dependencybased , is both time consuming and labor intensive .
Making full use of the existing manually annotated treebanks would yield substantial savings in dataannotation costs .
In this paper , we present a joint inference scheme for heterogenous dependency parsing .
This scheme is able to leverage consensus information between heterogenous treebanks during the inference phase instead of using individual output in a pipelined way , such as stacked learning methods ( Nivre and McDonald , 2008 ; Martins et al. , 2008 ) .
The basic idea is very simple : although heterogenous treebanks have different grammar formalisms , they share some consensus information in dependency structures for the same sentence .
For example in Figure 1 , the dependency structures actually share some partial agreements for the same sentence , the two words " eyes " and " Hongkong " depend on " cast " in both Chinese Dependency Treebank ( CDT ) ( Liu et al. , 2006 ) and Penn Chinese Treebank ( CTB ) ( Xue et al. , 2005 ) .
Therefore , we would like to train the dependency parsers on individual heterogenous treebank and jointly parse the same sentences with consensus information exchanged between them .
The remainder of this paper is divided as fol- lows .
Section 2 gives a formal description of the joint inference for heterogeneous dependency parsing .
In section 3 , we present the experimental results .
Finally , we conclude with ideas for future research .
Our Approach
The general joint inference scheme of heterogeneous dependency parsing is shown in Figure 2 .
Here , heterogeneous treebanks refer to two Chinese treebanks : CTB and CDT , therefore we have only two parsers , but the framework is generic enough to integrate more parsers .
For easy explanation of the joint inference scheme , we regard a parser without consensus information as a baseline parser , a parser incorporates consensus information called a joint parser .
Joint inference provides a framework that accommodates and coordinates multiple dependency parsing models .
Similar to Li et al. ( 2009 ) and Zhu et al . ( 2010 ) , the joint inference for heterogeneous dependency parsing consists of four components : ( 1 ) Joint Inference Model ; ( 2 ) Parser Coordination ; ( 3 ) Joint Inference Features ; ( 4 ) Parameter Estimation .
Joint Inference Model
For a given sentence x , a joint dependency parsing model finds the best dependency parsing tree y * among the set of possible candidate parses Y( x ) based on a scoring function F s : y * = arg max y?Y ( x ) Fs(x , y ) ( 1 ) Following ( Li et al. , 2009 ) , we will use d k to denote the kth joint parser , and also use the notation H k ( x ) for a list of parse candidates of sentence x determined by d k .
The sth joint parser can be written as : Fs( x , y ) = Ps( x , y ) + ? k , k? =s ? k ( y , H k ( x ) ) ( 2 ) where P s ( x , y ) is the score function of the sth baseline model , and each ? k (y , H k ( x ) ) is a partial consensus score function with respect to d k and is defined over y and H k ( x ) : ? k ( y , H k ( x ) ) = ?
l ? k, l f k ,l ( y , H k ( x ) ) ( 3 ) where each f k ,l ( y , H k ( x ) ) is a feature function based on a consensus measure between y and H k ( x ) , and ?
k ,l is the corresponding weight parameter .
Feature index l ranges over all consensusbased features in equation ( 3 ) .
Parser Coordination
Note that in equation ( 2 ) , though the baseline score function P s ( x , y ) can be computed individually , the case of ? k ( y , H k ( x ) ) is more complicated .
It is not feasible to enumerate all parse candidates for dependency parsing .
In this paper , we use a bootstrapping method to solve this problem .
The basic idea is that we can use baseline models ' nbest output as seeds , and iteratively refine joint models ' n-best output with joint inference .
The joint inference process is shown in Algorithm 1 .
Algorithm 1 Joint inference for multiple parsers Step1 : For each joint parser d k , perform inference with a baseline model , and memorize all dependency parsing candidates generated during inference in H k ( x ) ; Step2 : For each candidate in H k ( x ) , we extract subtrees and store them in H ? k ( x ) .
First , we extract bigram-subtrees that contain two words .
If two words have a dependency relation , we add these two words as a subtree into H ? k ( x ) .
Similarly , we can extract trigram-subtrees .
Note that the dependency direction is kept .
Besides , we also store the " ROOT " word of each candidate in H ? k ( x ) ; Step3 : Use joint parsers to re-parse the sentence x with the baseline features and joint inference features ( see subsection 2.3 ) .
For joint parser d k , consensus - based features of any dependency parsing candidate are computed based on current setting of H ? s ( x ) for all s but k .
New dependency parsing candidates generated by d k in re-parsing are cached in H ? k ( x ) ; Step4 : Update all H k ( x ) with H ? k ( x ) ; Step5 : Iterate from Step2 to Step4 until a preset iteration limit is reached .
In Algorithm 1 , dependency parsing candidates of different parsers can be mutually improved .
For example , given two parsers d 1 and d 2 with candidates H 1 and H 2 , improvements on H 1 enable d 2 to improve H 2 , and H 1 benefits from improved H 2 , and so on .
We can see that a joint parser does not enlarge the search space of its baseline model , the only change is parse scoring .
By running a complete inference process , joint model can be applied to re-parsing all candidates explored by a parser .
Thus Step3 can be viewed as full-scale candidates reranking because the reranking scope is beyond the limited n-best output currently cached in H k .
Joint Inference Features
In this section we introduce the consensus- based feature functions f k ,l ( y , H k ( x ) ) introduced in equation ( 3 ) .
The formulation can be written as : f k ,l ( y , H k ( x ) ) = ? y ? ?H k ( x ) P (y ? |d k ) I l ( y , y ? ) ( 4 ) where y is a dependency parse of x by using parser 2006 ) ) .
The consensus- based score functions I l (y , y ? ) include the following parts : d s ( s ? = k ) , ( 1 ) head -modifier dependencies .
Each headmodifier dependency ( denoted as " edge " ) is a tuple t =< h , m , h ? m > , so I edge ( y , y ? ) = ? t?y ?( t , y ? ) . ( 2 ) sibling dependencies :
Each sibling dependency ( denoted as " sib " ) is a tuple t =< i , h , m , h ? i ? m > , so I sib ( y , y ? ) = ? t?y ?( t , y ? ) . ( 3 ) grandparent dependencies :
Each grandparent dependency ( denoted as " gp " ) is a tuple t =< h , i , m , h ? i ? m > , so I gp ( y , y ? ) = ? <h, i, m,h?i?m>?y ?( t , y ? ) . ( 4 ) root feature :
This feature ( denoted as " root " ) indicates whether the multiple dependency parsing trees share the same " ROOT " , so I root ( y , y ? ) = ? < ROOT >?y ?(< ROOT > , y ? ) . ?(? , ? ) is a indicator function -?( t , y ? ) is 1 if t ? y ? and 0 otherwise , feature index l ?
{edge , sib , gp , root } in equation ( 4 ) .
Note that < h , m , h ? m > and < m , h , m ? h > are two different edges .
In our joint model , we extend the baseline features of ( McDonald et al. , 2005 ; McDonald and Pereira , 2006 ; Carreras , 2007 ) by conjoining with the consensus- based features , so that we can learn in which kind of contexts the different parsers agree / disagree .
For the third - order features ( e.g. , grand-siblings and tri-siblings ) described in ( Koo et al. , 2010 ) , we will discuss it in future work .
Parameter Estimation
The parameters are tuned to maximize the dependency parsing performance on the development set , using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training ( Koo et al. , 2008 ) .
Due to limited space , we do not present the details .
For more information , please refer to ( Koo et al. , 2008 ) .
Experiments
In this section , we describe the experiments to evaluate our proposed approach by using CTB4 ( Xue et al. , 2005 ) and CDT ( Liu et al. , 2006 ) .
For the former , we adopt a set of headselection rules ( Zhang and Clark , 2008 ) to convert the phrase structure syntax of treebank into a dependency tree representation .
The standard data split of CTB4 from Wang et al . ( 2007 ) is used .
For the latter , we randomly select 2,000 sentences for test set , another 2,000 sentences for development set , and others for training set .
We use two baseline parsers , one trained on CTB4 , and another trained on CDT in the experiments .
We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give the best performance .
CTB4 and CDT use two different POS tag sets and transforming from one tag set to another is difficult ( Niu et al. , 2009 ) .
To overcome this problem , we use Stanford POS Tagger 1 to train a universal POS tagger on the People 's Daily corpus , 2 a large-scale Chinese corpus ( approximately 300 thousand sentences and 7 million words ) annotated with word segmentation and POS tags .
Then the POS tagger produces a universal layer of POS tags for both the CTB4 and CDT .
Note that the word segmentation standards of these corpora ( CTB4 , CDT and People 's Daily ) slightly differs ; however , we do not consider this problem and leave it for future research .
The performance of the parsers is evaluated using the following metrics : UAS , DA , and CM , which are defined by ( Hall et al. , 2006 ) .
All the metrics except CM are calculated as mean scores per word , and punctuation tokens are consistently excluded .
We conduct experiments incrementally to evaluate the joint features used in our first-order and second-order parsers .
The first-order parser ald ( 2008 ) .
Type D = discriminative dependency parsers without using any external resources ; C = combined parsers ( stacked and ensemble parsers ) ;
H = discriminative dependency parsers using external resources derived from heterogeneous treebanks , S = discriminative dependency parsers using external unlabeled data . ?
The results on CTB4 were not directly reported in these papers , we implemented the experiments in this paper .
( dep1 ) only incorporates head-modifier dependency part ( McDonald et al. , 2005 ) .
The secondorder parser ( dep2 ) uses the head-modifier and sibling dependency parts ( McDonald and Pereira , 2006 ) , as well as the grandparent dependency part ( Carreras , 2007 ; Koo et al. , 2008 ) .
Table 1 shows the experimental results .
As shown in Table 1 , we note that adding more joint inference features incrementally , the dependency parsing performance is improved consis-tently , for both treebanks ( CTB4 or CDT ) .
As a final note , all comparisons between joint models and baseline models in Table 1 are statistically significant .
3 Furthermore , we also present a baseline method called " CTB4 + CDT " for comparison .
This method first tags both CTB4 and CDT with the universal POS tagger trained on the People 's Daily corpus , then simply concatenates the two corpora and trains a dependency parser , and finally tests on CTB4 and CDT using this single model .
The comparisons in Table 1 tell us that very limited information is obtained without consensus features by simply taking a union of the dependencies and their contexts from the two treebanks .
To put our results in perspective , we also compare our second-order joint parser with other bestperforming systems . " ? 40 " refers to the sentence with the length up to 40 and " Full " refers to all the sentences in test set .
The results are shown in Table 2 , our approach significantly outperforms many systems evaluated on this data set .
Chen et al. ( 2009 ) and Chen et al . ( 2012 ) reported a very high accuracy using subtree - based features and dependency language model based features derived from large-scale data .
Our systems did not use such knowledge .
Moreover , their technique is orthogonal to ours , and we suspect that combining their subtree - based features into our systems might get an even better performance .
We do not present the comparison of our proposed approach with the state - of - the - art methods on CDT because there is little work conducted on this treebank .
Some researchers conducted experiments on CTB5 with a different data split : files 1 - 815 and files 1,001 - 1,136 for training , files 886-931 and 1,148 - 1,151 for development , files 816- 885 and files 1,137 - 1,147 for testing .
The development and testing sets were also performed using goldstandard assigned POS tags .
We report the experimental results on CTB5 test set in Table 4 .
Our results are better than most systems on this data split , except Zhang and Nivre ( 2011 ) , and Chen et al . ( 2009 ) .
Additional Results
To obtain further information about how dependency parsers benefit from the joint inference , we conduct an initial experiment on CTB4 and CDT .
From Table 4 , we find that out of 355 sentences the development set of CTB4 , 74 sentences benefit from the joint inference , while 26 sentences suffer from it .
For CDT , we also find that out of 2,000 sentences on the development set , 341 sentences benefit from the joint inference , while 97 sentences suffer from it .
Although the overall dependency parsing results is improved , joint inference worsens dependency parsing result for some sentences .
In order to obtain further information about the error sources , it is necessary to investigate why joint inference gives negative results , we will leave it for future work .
Conclusion and Future Work
We proposed a novel framework of joint inference , in which multiple dependency parsing mod-els were coordinated to search for better dependency parses by leveraging the consensus information between heterogeneous treebanks .
Experimental results showed that joint inference significantly outperformed the state - of - the - art baseline models .
There are some ways in which this research could be continued .
First , recall that the joint inference scheme involves an iterative algorithm by using bootstrapping .
Intuitively , there is a lack of formal guarantee .
A natural avenue for further research would be the use of more powerful algorithms that provide certificates of optimality ; e.g. , dual decomposition that aims to develop decoding algorithms with formal guarantees .
Second , we would like to combine our heterogeneous treebank annotations into a unified representation in order to make dependency parsing results comparable across different annotation guidelines ( e.g. , Tsarfaty et al . ( 2011 ) ) .
Figure 2 : 2 Figure 2 : General joint inference scheme of heterogeneous dependency parsing .
