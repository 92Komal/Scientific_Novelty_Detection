title
Grounded Adaptation for Zero-shot Executable Semantic Parsing
abstract
We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing ( GAZP ) to adapt an existing semantic parser to new environments ( e.g. new database schemas ) .
GAZP combines a forward semantic parser with a backward utterance generator to synthesize data ( e.g. utterances and SQL queries ) in the new environment , then selects cycleconsistent examples to adapt the parser .
Unlike data-augmentation , which typically synthesizes unverified examples in the training environment , GAZP synthesizes examples in the new environment whose inputoutput consistency are verified .
On the Spider , Sparc , and CoSQL zero-shot semantic parsing tasks , GAZP improves logical form and execution accuracy of the baseline parser .
Our analyses show that GAZP outperforms dataaugmentation in the training environment , performance increases with the amount of GAZPsynthesized data , and cycle-consistency is central to successful adaptation .
Introduction Semantic parsers ( Zelle and Mooney , 1996 ; Zettlemoyer and Collins , 2005 ; Liang et al. , 2011 ) build executable meaning representations for a range of tasks such as question - answering ( Yih et al. , 2014 ) , robotic control ( Matuszek et al. , 2013 ) , and intelligent tutoring systems ( Graesser et al. , 2005 ) .
However , they are usually engineered for each application environment .
For example , a languageto - SQL parser trained on an university management database struggles when deployed to a sales database .
How do we adapt a semantic parser to new environments where no training data exists ?
We propose Grounded Adaptation for Zero-shot Executable Semantic Parsing , which adapts existing semantic parsers to new environments by synthesizing new , cycle-consistent data .
In the previous example , GAZP synthesizes high-quality sales questions and SQL queries using the new sales database , then adapts the parser using the synthesized data .
This procedure is shown in Figure 1 . GAZP is complementary to prior modeling work in that it can be applied to any model architecture , in any domain where one can enforce cycleconsistency by evaluating equivalence between logical forms .
Compared to data-augmentation , which typically synthesizes unverified data in the training environment , GAZP instead synthesizes consistency - verified data in the new environment .
GAZP synthesizes data for consistency - verified adaptation using a forward semantic parser and a backward utterance generator .
Given a new environment ( e.g. new database ) , we first sample logical forms with respect to a grammar ( e.g. SQL grammar conditioned on new database schema ) .
Next , we generate utterances corresponding to these logical forms using the generator .
Then , we parse the generated utterances using the parser , keeping those whose parses are equivalent to the original sampled logical form ( more in Section 2.4 ) .
Finally , we adapt the parser to the new environment by training on the combination of the original data and the synthesized cycle-consistent data .
We evaluate GAZP on the Spider , Sparc , and CoSQL ( Yu et al. , 2018 b
( Yu et al. , , 2019a language - to - SQL zero-shot semantic parsing tasks which test on unseen databases .
GAZP improves logical form and execution accuracy of the baseline parser on all tasks , successfully adapting the existing parser to new environments .
In further analyses , we show that GAZP outperforms data augmentation in the training environment .
Moreover , adaptation performance increases with the amount of GAZPsynthesized data .
Finally , we show that cycleconsistency is critical to synthesizing high-quality examples in the new environment , which in turn allows for successful adaptation and performance Output is shown in red .
First , we train a parser and a utterance generator using training data .
We then sample logical forms in the inference environment and generate corresponding utterances .
We parse the generated utterances and check for cycle-consistency between the parse and the sampled logical form ( see Section 2.4 ) .
Consistent pairs of utterance and logical form are used to adapt the parser to the inference environment .
improvement .
1 2 Grounded Adaptation for Zero-shot Executable Semantic Parsing Semantic parsing involves producing a logical form q that corresponds to an input utterance u , such that executing q in the environment e produces the desired denotation EXE ( q , e ) .
In the context of language - to - SQL parsing , q and e correspond to SQL queries and databases .
We propose GAZP for zero-shot semantic parsing , where inference environments have not been observed during training ( e.g. producing SQL queries in new databases ) .
GAZP consists of a forward semantic parser F ( u , e ) ! q , which produces a logical form q given an utterance u in environment e , and a backward utterance generator G( q , e ) ! u.
The models F and G condition on the environment by reading an environment description w , which consists of a set of documents d .
In the context of SQL parsing , the description is the database schema , which consists of a set of table schemas ( i.e. documents ) .
We assume that the logical form consists of three types of tokens : syntax candidates c s from a fixed syntax vocabulary ( e.g. SQL syntax ) , environment candidates c e from the environment description ( e.g. table names from database schema ) , and 1 We will open-source our code .
utterance candidates c u from the utterance ( e.g. values in SQL query ) .
Finally , c e tokens have corresponding spans in the description d .
For example , a SQL query q consists of columns c e that directly map to related column schema ( e.g. table , name , type ) in the database schema w .
In GAZP , we first train the forward semantic parser F and a backward utterance generator G in the training environment e. Given a new inference environment e 0 , we sample logical forms q from e 0 using a grammar .
For each q , we generate a corresponding utterance u 0 = G( q , e 0 ) .
We then parse the generated utterance into a logical form q 0 = F ( u 0 , e 0 ) .
We combine cycle-consistent examples from the new environment , for which q 0 is equivalent to q , with the original labeled data to retrain and adapt the parser .
Figure 1 illustrates the components of GAZP .
We now detail the sampling procedure , forward parser , backward generator , and cycle-consistency .
Query sampling
To synthesize data for adaptation , we first sample logical forms q with respect to a grammar .
We begin by building an empirical distribution over q using the training data .
For language - to - SQL parsing , we preprocess queries similar to and further replace mentions of columns and values with typed slots to form coarse Algorithm 1 Query sampling procedure .
that we remove JOINs which are later filled back deterministically after sampling the columns .
Next , we build an empirical distribution P Z over these coarse templates by counting occurrences in the training data .
The sampling procedure is shown in Algorithm 1 for the language - to - SQL example .
Invalid queries and those that execute to the empty set are discarded .
Given some coarse template z = SELECT key1 , text1 WHERE text2 = val , the function d.CANFILL ( z ) returns whether the database d contains sufficient numbers of columns .
In this case , at the minimum , d should have a key column and two text columns .
The function d.RANDASSIGNCOLSTOSLOTS ( ) returns a database copy d 0 such that each of its columns is mapped to some identifier text1 , key1 etc .
Appendix A.1 quantifies query coverage of the sampling procedure on the Spider task , and shows how to extend Algorithm 1 to multi-turn queries .
Forward semantic parser
The forward semantic parser F produces a logical form q = F ( u , e ) for an utterance u in the environment e.
We begin by cross-encoding u with the environment description w to model coreferences .
Since w may be very long ( e.g. entire database schema ) , we instead cross-encode u with each document d i in the description ( e.g. each table schema ) similar to .
We then combine each environment candidate c e, i across documents ( e.g. table columns ) using RNNs , such that the final representations capture dependencies between c e from different documents .
To produce the logical form q , we first generate a logical form template q whose utterance candidates c u ( e.g. SQL values ) are replaced by slots .
We generate q with a pointerdecoder that selects among syntax candidates c s ( e.g. SQL keywords ) and environment candidate c e ( e.g. table columns ) .
Then , we fill in slots in q with a separate decoder that selects among c u in the utterance to form q.
Note that logical form template q is distinct from coarse templates z described in sampling ( Section 2.1 ) .
Figure 2 describes the forward semantic parser .
Let u denote words in the utterance , and d i denote words in the ith document in the environment description .
Let [ a ; b] denote the concatenation of a and b.
First , we cross-encode the utterance and the document using BERT ( Devlin et al. , 2019 ) , which has led to improvements on a number of NLP tasks .
!
B i = BERT ! ( [ u ; d i ] ) ( 1 ) Next , we extract environment candidates in document i using self-attention .
Let s , e denote the start and end positions of the jth environment candidate in the ith document .
We compute an intermediate representation x ij for each environment candidate : a = softmax ( W [ !
B is ; ... ! B ie ] + b ) ( 2 ) x ij = e X k=s a k !
B ik ( 3 ) For ease of exposition , we abbreviate the above self-attention function as x ij = selfattn ( ! B i [ s : e ] )
Because x ij do not model dependencies between different documents , we further process x with bidirectional LSTMs ( Hochreiter and Schmidhuber , 1997 ) .
We use one LSTM followed by selfattention to summarize each ith document : ! h enc , i = selfattn ( BiLSTM ( [ x i 1 ; x i2 ; ... ] ) ) ( 4 ) We use another LSTM to build representations for each environment candidate c e , i c e = BiLSTM ( [ x 11 ; x 12 ; ...x 21 ; x 22 ... ] ) ( 5 ) We do not share weights between different LSTMs and between different self-attentions .
Next , we use a pointer-decoder ( Vinyals et al. , 2015 ) to produce the output logical form template User utterance u < l a t e x i t s h a 1 _ b a s e 6 4 = "
A d v w c f P B g Z Q s W p O 1 z A c a C v + K G P o = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c I c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j i D w 0 f / 1 9 F V 5 U X C 6 6 0 b X 9 Z m Y X F p e W V 7 G p u b X 1 j c y u / v V N T U S I Z V l k k I t n w q E L B Q 6 x q r g U 2 Y o k 0 8 A T W v f 7 l K K / f o V Q 8 C m / 0 I E Y 3 o N 2 Q + 5 x R b a x K 0 s 4 X 7 K I 9 F p k H Z w q F i 4 / 7 7 6 v 3 v b T c z n + 2 O h F L A g w 1 E 1 S p p m P H 2 k 2 p 1 J w J H O Z a i c K Y s j 7 t Y t N g S A N U b j o e d E g O j d M h f i T N C z U Z u 7 8 7 U h o o N Q g 8 U x l Q 3 V O z 2 c j 8 L 2 s m 2 j 9 3 U x 7 G i c a Q T T 7 y E 0 F 0 R E Z b k w 6 X y L Q Y G K B M c j M r Y T 0 q K d P m N j l z B G d 2 5 X m o H R e d k + J p x S 6 U b J g o C / t w A E f g w B m U 4 B r K U A U G C A / w B M / W r f V o v V i v k 9 K M N e 3 Z h T + y 3 n 4 A A s u Q v Q = = < / l a t e x i t > u < l a t e x i t s h a 1 _ b a s e 6 4 = "
A d v w c f P B g Z Q s W p O 1 z A c a C v + K G P o = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c I c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j i D w 0 f / 1 9 F V 5 U X C 6 6 0 b X 9 Z m Y X F p e W V 7 G p u b X 1 j c y u / v V N T U S I Z V l k k I t n w q E L B Q 6 x q r g U 2 Y o k 0 8 A T W v f 7 l K K / f o V Q 8 C m / 0 I E Y 3 o N 2 Q + 5 x R b a x K 0 s 4 X 7 K I 9 F p k H Z w q F i 4 / 7 7 6 v 3 v b T c z n + 2 O h F L A g w 1 E 1 S p p m P H 2 k 2 p 1 J w J H O Z a i c K Y s j 7 t Y t N g S A N U b j o e d E g O j d M h f i T N C z U Z u 7 8 7 U h o o N Q g 8 U x l Q 3 V O z 2 c j 8 L 2 s m 2 j 9 3 U x 7 G i c a Q T T 7 y E 0 F 0 R E Z b k w 6 X y L Q Y G K B M c j M r Y T 0 q K d P m N j l z B G d 2 5 X m o H R e d k + J p x S 6 U b J g o C / t w A E f g w B m U 4 B r K U A U G C A / w B M / W r f V o v V i v k 9 K M N e 3 Z h T + y 3 n 4 A A s u Q v Q = = < / l a t i b + p Q O F g W + 4 R o v 2 r L A E I m o l t P v U = " > A A A C I n i c b V B N S w M x F M z 6 W e t X 1 a O X Y B E 8 S N m V F v V W 8 O K x g l W h W 0 o 2 + 9 o G s 5 s l e a s t y / 4 W L / 4 V L x 4 U 9 S T 4 Y 0 x r D 9 o 6 E B h m 3 m P y J k i k M O i 6 n 8 7 c / M L i 0 n J h p b i 6 t r 6 x W d r a v j I q 1 R y a X E m l b w J m Q I o Y m i h Q w k 2 i g U W B h O v g 9 m z k X 9 + B N k L F l z h M o B 2 x X i y 6 g j O 0 U q d 0 6 i M M E D E z m I Y Q o 6 m I M P f 7 J m E c s l o y y H 1 l 1 7 X o 9 Z F p r e 6 z Q d 7 J v E P q 5 Z 1 S 2 a 2 4 Y 9 B Z 4 k 1 I m U z Q 6 J T e / V D x N L I p X D J j W p 6 b Y D t j G g W X k B f 9 1 I C N v W U 9 a F k a s w h M O x u f m N N 9 q 4 S 0 q 7 R 9 M d K x + n s j Y 5 E x w y i w k x H D v p n 2 R u J / X i v F 7 k k 7 E 3 G S I s T 8 J 6 i b S o q K j v q i o d D A U Q 4 t Y V w L + 1 f K + 0 w z j r b V o i 3 B m z 5 5 l l w d V b x q p X Z R L d f d S R 0 F s k v 2 y A H x y D G p k 3 P S I E 3 C y Q N 5 I i / k 1 X l 0 n p 0 3 5 + N n d M 6 Z 7 O y Q P 3 C + v g G O d a Y M < / l a t e x i t > students .
id ! x 1,1 < l a t e x i t s h a 1 _ b a s e 6 4 = " i b + p Q O F g W + 4 R o v 2 r L A E I m o l t P v U = " > A A A C I n i c b V B N S w M x F M z 6 W e t X 1 a O X Y B E 8 S N m V F v V W 8 O K x g l W h W 0 o 2 + 9 o G s 5 s l e a s t y / 4 W L / 4 V L x 4 U 9 S T 4 Y 0 x r D 9 o 6 E B h m 3 m P y J k i k M O i 6 n 8 7 c / M L i 0 n J h p b i 6 t r 6 x W d r a v j I q 1 R y a X E m l b w J m Q I o Y m i h Q w k 2 i g U W B h O v g 9 m z k X 9 + B N k L F l z h M o B 2 x X i y 6 g j O 0 U q d 0 6 i M M E D E z m I Y Q o 6 m I M P f 7 J m E c s l o y y H 1 l 1 7 X o 9 Z F p r e 6 z Q d 7 J v E P q 5 Z 1 S 2 a 2 4 Y 9 B Z 4 k 1 I m U z Q 6 J T e / V D x N L I p X D J j W p 6 b Y D t j G g W X k B f 9 1 I C N v W U 9 a F k a s w h M O x u f m N N 9 q 4 S 0 q 7 R 9 M d K x + n s j Y 5 E x w y i w k x H D v p n 2 R u J / X i v F 7 k k 7 E 3 G S I s T 8 J 6 i b S o q K j v q i o d D A U Q 4 t Y V w L + 1 f K + 0 w z j r b V o i 3 B m z 5 5 l l w d V b x q p X Z R L d f d S R 0 F s k v 2 y A H x y D G p k 3 P S I E 3 C y Q N 5 I i / k 1 X l 0 n p 0 3 5 + N n d M 6 Z 7 O y Q P 3 C + v g G O d a Y M < / l a t e x i t > students .school ! x 1,2 < l a t e x i t s h a 1 _ b a s e 6 4 = "
W a m n h u j n W 8 7 a + T s k w 5 D w 7 / 7 I 1 h E = " > A A A C J n i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J I U R S 9 C w Y v H C l a F p p T N d t o s 3 W T D 7 k R b Q n 6 N F / + K F w 8 V E W / + F L e 1 B 7 8 G F h 7 v z c z b e W E q h U H P e 3 f m 5 h c W l 5 Z L K + X V t f W N T X d r + 9 q o T H N o c i W V v g 2 Z A S k S a K J A C b e p B h a H E m 7 C w f l E v 7 k D b Y R K r n C U Q j t m / U T 0 B G d o q Y 5 7 F i A M E T E 3 m H U h Q V M 1 P F J K F k F k U s Y h P 0 6 H R a D s C i 3 6 E T K t 1 X 0 + L D q 5 f 0 h r R c e t e F V v W v Q v 8 G e g Q m b V 6 L j j o K t 4 F l s n L p k x L d 9 L s Z 0 z j Y J L K M p B Z s D a D l g f W h Y m L A b T z q d n F n T f M l 3 a U 9 q + B O m U / T 6 R s 9 i Y U R z a z p h h Z H 5 r E / I / r Z V h 7 7 S d i y T N E B L + Z d T L J E V F J 5 n R r t D A U Y 4 s Y F w L + 1 f K I 6 Y Z R 5 t s 2 Y b g / z 7 5 L 7 i u V f 2 j 6 v H l U a X u z e I o k V 2 y R w 6 I T 0 5 I n V y Q B m k S T h 7 I E x m T F + f R e X Z e n b e v 1 j l n N r N D f p T z 8 Q k p 0 6 f w < / l a t e x i t > students .school ! x 1,2 < l a t e x i t s h a 1 _ b a s e 6 4 = "
W a m n h u j n W 8 7 a + T s k w 5 D w 7 / 7 I 1 h E = " > A A A C J n i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J I U R S 9 C w Y v H C l a F p p T N d t o s 3 W T D 7 k R b Q n 6 N F / + K F w 8 V E W / + F L e 1 B 7 8 G F h 7 v z c z b e W E q h U H P e 3 f m 5 h c W l 5 Z L K + X V t f W N T X d r + 9 q o T H N o c i W V v g 2 Z A S k S a K J A C b e p B h a H E m 7 C w f l E v 7 k D b Y R K r n C U Q j t m / U T 0 B G d o q Y 5 7 F i A M E T E 3 m H U h Q V M 1 P F J K F k F k U s Y h P 0 6 H R a D s C i 3 6 E T K t 1 X 0 + L D q 5 f 0 h r R c e t e F V v W v Q v 8 G e g Q m b V 6 L j j o K t 4 F l s n L p k x L d 9 L s Z 0 z j Y J L K M p B Z s D a D l g f W h Y m L A b T z q d n F n T f M l 3 a U 9 q + B O m U / T 6 R s 9 i Y U R z a z p h h Z H 5 r E / I / r Z V h 7 7 S d i y T N E B L + Z d T L J E V F J 5 n R r t D A U Y 4 s Y F w L + 1 f K I 6 Y Z R 5 t s 2 Y b g / z 7 5 L 7 i u V f 2 j 6 v H l U a X u z e I o k V 2 y R w 6 I T 0 5 I n V y Q B m k S T h 7 I E x m T F + f R e X Z e n b e v 1 j l n N r N D f p T z 8 Q k p 0 6 f w < / l a t e x i t > ? schools .
id ! x 2,1 < l a t e x i t s h a 1 _ b a s e 6 4 = " U V i Y e r 9 k Y s K + u P H s W p H 9 I v x y 2 L o = " > A A A C I X i c b V D L S s N A F J 3 4 r P U V d e l m s A g u p C S l o s u C G 5 c V r A p N K Z P p b T N 0 k g k z N 9 o S 8 i t u / B U 3 L h T p T v w Z p 7 U L X w c G D u f c w 5 1 7 w l Q K g 5 7 3 7 i w s L i 2 v r J b W y u s b m 1 v b 7 s 7 u t V G Z 5 t D i S i p 9 G z I D U i T Q Q o E S b l M N L A 4 l 3 I T D 8 6 l / c w f a C J V c 4 T i F T s w G i e g L z t B K X f c s Q B g h Y m 5 4 p J Q 0 V d E r g s i k j E N + k o 6 K Q N m 0 F o M I m d b q P h 8 V 3 b x 2 T P 2 i 6 1 a 8 q j c D / U v 8 O a m Q O Z p d d x L 0 F M 9 i S J B L Z k z b 9 1 L s 5 E y j 4 B K K c p A Z s G u H b A B t S x M W g + n k s w s L e m i V H u 0 r b V + C d K Z + T + Q s N m Y c h 3 Y y Z h i Z 3 9 5 U / M 9 r Z 9 g / 6 + Q i S T O E h H 8 t 6 m e S o q L T u m h P a O A o x 5 Y w r o X 9 K + U R 0 4 y j L b V s S / B / n / y X X N e q f r 1 6 c l m v N L x 5 H S W y T w 7 I E f H J K W m Q C 9 I k L c L J A 3 k i L + T V e X S e n T d n 8 j W 6 4 M w z e + Q H n I 9 P j s m l h A = = < / l a t e x i t > schools .
id ! x 2,1 < l a t e x i t s h a 1 _ b a s e 6 4 = " U V i Y e r 9 k Y s K + u P H s W p H 9 I v x y 2 L o = " > A A A C I X i c b V D L S s N A F J 3 4 r P U V d e l m s A g u p C S l o s u C G 5 c V r A p N K Z P p b T N 0 k g k z N 9 o S 8 i t u / B U 3 L h T p T v w Z p 7 U L X w c G D u f c w 5 1 7 w l Q K g 5 7 3 7 i w s L i 2 v r J b W y u s b m 1 v b 7 s 7 u t V G Z 5 t D i S i p 9 G z I D U i T Q Q o E S b l M N L A 4 l 3 I T D 8 6 l / c w f a C J V c 4 T i F T s w G i e g L z t B K X f c s Q B g h Y m 5 4 p J Q 0 V d E r g s i k j E N + k o 6 K Q N m 0 F o M I m d b q P h 8 V 3 b x 2 T P 2 i 6 1 a 8 q j c D / U v 8 O a m Q O Z p d d x L 0 F M 9 i S J B L Z k z b 9 1 L s 5 E y j 4 B K K c p A Z s G u H b A B t S x M W g + n k s w s L e m i V H u 0 r b V + C d K Z + T + Q s N m Y c h 3 Y y Z h i Z 3 9 5 U / M 9 r Z 9 g / 6 + Q i S T O E h H 8 t 6 m e S o q L T u m h P a O A o x 5 Y w r o X 9 K + U R 0 4 y j L b V s S / B / n / y X X N e q f r 1 6 c l m v N L x 5 H S W y T w 7 I E f H J K W m Q C 9 I k L c L J A 3 k i L + T V e X S e n T d n 8 j W 6 4 M w z e + Q H n I 9 P j s m l h A = = < / l a t e x i t > schools .name ! x 2,2 < l a t e x i t s h a 1 _ b a s e 6 4 = " n c o u b k P Y X u p Y 0 R 0 + q 9 x k S E P K X A o = " > A A A C I 3 i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J K U i u J J 8 O K x g t V C U 8 p m O 2 0 W N 9 m w O 9 G W k P / i x b / i x Y M i X j z 4 X 9 z W H t T 6 Y O D x 3 g w z 8 8 J U C o O e 9 + H M z S 8 s L i 2 X V s q r a + s b m + 7 W 9 r V R m e b Q 5 E o q 3 Q q Z A S k S a K J A C a 1 U A 4 t D C T f h 7 f n Y v 7 k D b Y R K r n C U Q i d m g 0 T 0 B W d o p a 5 7 G i A M E T E 3 P F J K m m r C Y i i C y K S M Q 3 6 U D o t A 2 X k t B h E y r d V 9 P i y 6 e e 2 Q 1 o q u W / G q 3 g R 0 l v h T U i F T N L r u W 9 B T P I s h Q S 6 Z M W 3 f S 7 G T M 4 2 C S y j K Q W b A r r 1 l A 2 h b O r 7 E d P L J j w X d t 0 q P 9 p W 2 l S C d q D 8 n c h Y b M 4 p D 2 x k z j M x f b y z + 5 7 U z 7 J 9 0 c p G k G U L C v x f 1 M 0 l R 0 X F g t C c 0 c J Q j S x j X w t 5 K e c Q 0 4 2 h j L d s Q / L 8 v z 5 L r W t W v V 4 8 u 6 5 U z b x p H i e y S P X J A f H J M z s g F a Z A m 4 e S B P J E X 8 u o 8 O s / O m / P + 3 T r n T G d 2 y C 8 4 n 1 9 L g q Z t < / l a t e x i t > schools .name ! x 2,2 < l a t e x i t s h a 1 _ b a s e 6 4 = " n c o u b k P Y X u p Y 0 R 0 + q 9 x k S E P K X A o = " > A A A C I 3 i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J K U i u J J 8 O K x g t V C U 8 p m O 2 0 W N 9 m w O 9 G W k P / i x b / i x Y M i X j z 4 X 9 z W H t T 6 Y O D x 3 g w z 8 8 J U C o O e 9 + H M z S 8 s L i 2 X V s q r a + s b m + 7 W 9 r V R m e b Q 5 E o q 3 Q q Z A S k S a K J A C a 1 U A 4 t D C T f h 7 f n Y v 7 k D b Y R K r n C U Q i d m g 0 T 0 B W d o p a 5 7 G i A M E T E 3 P F J K m m r C Y i i C y K S M Q 3 6 U D o t A 2 X k t B h E y r d V 9 P i y 6 e e 2 Q 1 o q u W / G q 3 g R 0 l v h T U i F T N L r u W 9 B T P I s h Q S 6 Z M W 3 f S 7 G T M 4 2 C S y j K Q W b A r r 1 l A 2 h b O r 7 E d P L J j w X d t 0 q P 9 p W 2 l S C d q D 8 n c h Y b M 4 p D 2 x k z j M x f b y z + 5 7 U z 7 J 9 0 c p G k G U L C v x f 1 M 0 l R 0 X F g t C c 0 c J Q j S x j X w t 5 K e c Q 0 4 2 h j L d s Q / L 8 v z 5 L r W t W v V 4 8 u 6 5 U z b x p H i e y S P X J A f H J M z s g F a Z A m 4 e S B P J E X 8 u o 8 O s / O m / P + 3 T r n T G d 2 y C 8 4 n 1 9 L g q Z t < / l a t e x i t > ? ?
Env desc BiLSTM + SelfAttn
Template pointer decoder
Candidate phrase BiLSTM Fixed syntax vocabulary SELECT , FROM , WHERE , > , < ?
Output logical form Environment description w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > ?
Table : students id school year ?
Document d 1 < l a t e x i t s h a 1 _ b a s e 6 4 = "
W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t > d 1 < l a t e x i t s h a 1 _ b a s e 6 4 = "
W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t >
Table : schools id name city ?
Document d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t > d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t >
Value pointer decoder Value BERT c e < l a t e x i t s h a 1 _ b a s e 6 4 = " 1 C 6 L y d S t v n S S 7 V m R C p a h 6 Q Z A 8 O g = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 N B 8 B R 2 R d F j w I v H i O Y B y R J m J 7 3 J k N n Z Z W Z W C C G f 4 M W D I l 7 9 E X / B g + D J T 9 H J 4 6 C J B Q 1 F V T f d X U E i u D a u + + l k s k v L K 6 u 5 t f z 6 x u b W d m F n t 6 b j V D G s s l j E q h F Q j Y J L r B p u B D Y S h T Q K B N a D / u X Y r 9 + h 0 j y W t 2 a Q o B / R r u Q h Z 9 R Y 6 Y a 1 s V 0 o u i V 3 A r J I v B k p l r M f 3 2 / 7 X 1 h p F 9 5 b n Z i l E U r D B N W 6 6 b m J 8 Y d U G c 4 E j v K t V G N C W Z 9 2 s W m p p B F q f z g 5 d U S O r N I h Y a x s S U M m 6 u + J I Y 2 0 H k S B 7 Y y o 6 e l 5 b y z + 5 z V T E 1 7 4 Q y 6 T 1 K B k 0 0 V h K o i J y f h v 0 u E K m R E D S y h T 3 N 5 K W I 8 q y o x N J 2 9 D 8 O Z f X i S 1 k 5 J 3 W j q 7 t m m 4 M E U O D u A Q j s G D c y j D F V S g C g y 6 c A + P 8 O Q I 5 8 F 5 d l 6 m r R l n N r M H f + C 8 / g D a n Z H j < / l a t e x i t > !
h enc < l a t e x i t s h a 1 _ b a s e 6 4 = " 2 g h C i z P h 3 G 9 U 3 g e a C x X F m z V e 5 / 4 = " > A A A C B X i c b V D L S s N A F J 1 Y H 7 W + o u J K F 4 N F c F U S U X R Z c O O y g n 1 A E 8 J k O m m G T j J h Z q K U 0 I 0 b f 8 W N C 0 X c i r / g Q n D l p + g k 7 U J b D w w c z r m X O + f 4 C a N S W d a n M V e a X 1 h c K i 9 X V l b X 1 j f M z a 2 W 5 K n A p I k 5 4 6 L j I 0 k Y j U l T U c V I J x E E R T 4 j b X 9 w n v v t a y I k 5 f G V G i b E j V A / p g H F S G n J M / c c r m 1 B + 6 F C Q v C b L B x 5 m S M i S G I 8 8 s y q V b M K w F l i T 0 i 1 X v r 4 f t v 5 I g 3 P f H d 6 H K c R i R V m S M q u b S X K z Z B Q F D M y q j i p J A n C A 9 Q n X U 1 j F B H p Z k W K E T z Q S g 8 G X O g X K 1 i o v z c y F E k 5 j H w 9 G S E V y m k v F / / z u q k K z t y M x k m q 8 l T F o S B l U H G Y V w J 7 V B C s 2 F A T h A X V f 4 U 4 R A J h p Y u r 6 B L s 6 c i z p H V U s 4 9 r J 5 e 6 D Q u M U Q a 7 Y B 8 c A h u c g j q 4 A A 3 Q B B j c g n v w C J 6 M O + P B e D Z e x q N z x m R n G / y B 8 f o D f X a d k A = = < / l a t e x i t > c u < l a t e x i t s h a 1 _ b a s e 6 4 = " 4 3 t M W i v O v W x 3 C 8 X c c r + E i O c N H r Y = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 N B 8 B R 2 R d F j w I v H i O Y B y R J m J 7 3 J k N n Z Z W Z W C C G f 4 M W D I l 7 9 E X / B g + D J T 9 H J 4 6 C J B Q 1 F V T f d X U E i u D a u + + l k s k v L K 6 u 5 t f z 6 x u b W d m F n t 6 b j V D G s s l j E q h F Q j Y J L r B p u B D Y S h T Q K B N a D / u X Y r 9 + h 0 j y W t 2 a Q o B / R r u Q h Z 9 R Y 6 Y a 1 0 3 a h 6 J b c C c g i 8 W a k W M 5 + f L / t f 2 G l X X h v d W K W R i g N E 1 T r p u c m x h 9 S Z T g T O M q 3 U o 0 J Z X 3 a x a a l k k a o / e H k 1 B E 5 s k q H h L G y J Q 2 Z q L 8 n h j T S e h A F t j O i p q f n v b H 4 n 9 d M T X j h D 7 l M U o O S T R e F q S A m J u O / S Y c r Z E Y M L K F M c X s r Y T 2 q K D M 2 n b w N w Z t / e Z H U T k r e a e n s 2 q b h w h Q 5 O I B D O A Y P z q E M V 1 C B K j D o w j 0 8 w p M j n A f n 2 X m Z t m a c 2 c w e / I H z + g P y 3 Z H z < / l a t e x i t > c s < l a t e x i t s h a 1 _ b a s e 6 4 = " i b t E V 4 v O N 5 u x l Y X G S U 7 H 9 x B 5 + m Y = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 N B 8 B R 2 R d F j w I v H i O Y B y R J m J 7 3 J k N n Z Z W Z W C C G f 4 M W D I l 7 9 E X / B g + D J T 9 H J 4 6 C J B Q 1 F V T f d X U E i u D a u + + l k s k v L K 6 u 5 t f z 6 x u b W d m F n t 6 b j V D G s s l j E q h F Q j Y J L r B p u B D Y S h T Q K B N a D / u X Y r 9 + h 0 j y W t 2 a Q o B / R r u Q h Z 9 R Y 6 Y a 1 d b t Q d E v u B G S R e D N S L G c / v t / 2 v 7 D S L r y 3 O j F L I 5 S G C a p 1 0 3 M T 4 w + p M p w J H O V b q c a E s j 7 t Y t N S S S P U / n B y 6 o g c W a V D w l j Z k o Z M 1 N 8 T Q x p p P Y g C 2 x l R 0 9 P z 3 l j 8 z 2 u m J r z w h 1 w m q U H J p o v C V B A T k / H f p M M V M i M G l l C m u L 2 V s B 5 V l B m b T t 6 G 4 M 2 / v E h q J y X v t H R 2 b d N w Y Y o c H M A h H I M H 5 1 C G K 6 h A F R h 0 4 R 4 e 4 c k R z o P z 7 L x M W z P O b G Y P / s B 5 / Q H v 1 Z H x < / l a t e x i t > !
B 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " y H I q u Y i G + c 9 K s l k J 0 Q P e b Q u B 5 i 8 = " > A A A B / X i c b V C 7 S g N B F J 1 N f M T 4 W l + V z W A Q r M K u K F o G b S w j m A c k y z I 7 u U m G z O 4 s M 7 N K X I K / Y m O h i K 2 1 v 2 A h W P k p O n k U m n j g w u G c e 7 n 3 n i D m T G n H + b Q y 2 b n 5 h c X c U n 5 5 Z X V t 3 d 7 Y r C q R S A o V K r i Q 9 Y A o 4 C y C i m a a Q z 2 W Q M K A Q y 3 o n Q / 9 2 j V I x U R 0 p f s x e C H p R K z N K N F G 8 u 3 t p j C 2 Z J 2 u J l K K m / R s 4 L u + X X C K z g h 4 l r g T U i h l P 7 7 f d r 6 g 7 N v v z Z a g S Q i R p p w o 1 X C d W H s p k Z p R D o N 8 M 1 E Q E 9 o j H W g Y G p E Q l J e O r h / g f a O 0 c F t I U 5 H G I / X 3 R E p C p f p h Y D p D o r t q 2 h u K / 3 m N R L d P v Z R F c a I h o u N F 7 Y R j L f A w C t x i E q j m f U M I l c z c i m m X S E K 1 C S x v Q n C n X 5 4 l 1 c O i e 1 Q 8 v j R p O G i M H N p F e + g A u e g E l d A F K q M K o u g W 3 a N H 9 G T d W Q / W s / U y b s 1 Y k 5 k t 9 A f W 6 w + 5 D J n C < / l a t e x i t > !
B 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " O I N Y n f e L 4 I r 5 7 y k n 9 Y 8 5 Y i / k o V E = " > A A A B / X i c b V C 7 S g N B F J 0 1 P m J 8 r a / K Z j E I V m E 3 K F o G b S w j m A c k y z I 7 u U m G z M 4 s M 7 N K X I K / Y m O h i K 2 1 v 2 A h W P k p O n k U m n j g w u G c e 7 n 3 n j B m V G n X / b T m M v M L i 0 v Z 5 d z K 6 t r 6 h r 2 5 V V U i k Q Q q R D A h 6 y F W w C i H i q a a Q T 2 W g K O Q Q S 3 s n Q / 9 2 j V I R Q W / 0 v 0 Y / A h 3 O G 1 T g r W R A n u n K Y w t a a e r s Z T i J j 0 b B M X A z r s F d w R n l n g T k i 9 l P r 7 f d r + g H N j v z Z Y g S Q R c E 4 a V a n h u r P 0 U S 0 0 J g 0 G u m S i I M e n h D j Q M 5 T g C 5 a e j 6 w f O g V F a T l t I U 1 w 7 I / X 3 R I o j p f p R a D o j r L t q 2 h u K / 3 m N R L d P / Z T y O N H A y X h R O 2 G O F s 4 w C q d F J R D N + o Z g I q m 5 1 S F d L D H R J r C c C c G b f n m W V I s F 7 6 h w f G n S c N E Y W b S H 9 t E h 8 t A J K q E L V E Y V R N A t u k e P 6 M m 6 s x 6 s Z + t l 3 D p n T W a 2 0 R 9 Y r z + 6 k J n D < / l a t e x i t >
Figure 2 : Forward semantic parser .
Model components are shown in purple , inputs in blue , and outputs in red .
First , we cross-encode each environment description text and the utterance using BERT .
We then extract document- level phrase representations for candidate phrases in each text , which we subsequently encode using LSTMs to form input and environment - level candidate phrase representations .
A pointer- decoder attends over the input and selects among candidates to produce the output logical form .
q by selecting among a set of candidates that corresponds to the union of environment candidates c e and syntax candidates c s .
Here , we represent a syntax token using its BERT word embedding .
The representation for all candidate representations !
c is then obtained as ! c = [ c e,1 ; c e,2 ; ...c s,1 ; c s,2 ; ...]
At each step t of the decoder , we first update the states of the decoder LSTM : h dec , t = LSTM ( ! c qt 1 , h dec , t 1 ) ( 7 ) Finally , we attend over the document representations given the current decoder state using dotproduct attention ( Bahdanau et al. , 2015 ) : ?t = softmax ( h dec , t ! h | enc ) ( 8 ) v t = X i ?t , i ! h enc , i ( 9 ) The score for the ith candidate !
c i is o t = ? [ h dec , t ; v t ] + b ( 10 ) s t, i = o t ! c | i ( 11 ) qt = argmax ( s t ) ( 12 ) Value-generation .
The pervious template decoder produces logical form template q , which is not executable because it does not include utterance candidates c u .
To generate full-specified executable logical forms q , we use a separate value pointer - decoder that selects among utterance tokens .
The attention input for this decoder is identical to that of the template decoder .
The pointer candidates c u are obtained by running a separate BERT encoder on the utterance u .
The produced values are inserted into each slot in q to form q.
Both template and value decoders are trained using cross-entropy loss with respect to the groundtruth sequence of candidates .
Backward utterance generator
The utterance generator G produces an utterance u = G( q , e ) for the logical form q in the environment e.
The alignment problem between q and the environment description w is simpler than that between u and w because environment candidates c e ( e.g. column names ) in q are described by corresponding spans in w ( e.g. column schemas in database schema ) .
To leverage this deterministic alignment , we augment c e in q with relevant spans from w , and encode this augmented logical form q .
The pointer - decoder selects among words c v from a fixed vocabulary ( e.g. when , where , who ) and words c q from q .
Figure 3 illustrates the backward utterance generator .
Logical form q < l a t e x i t s h a 1 _ b a s e 6 4 = " e x x z + < l a t e x i t s h a 1 _ b a s e 6 4 = " p Z o w U P w i 5 z S r E i k K / e h g Q s J N h H o 3 D G L q V n M 1 c D Q v s z J s = " > A A A B 6 H i c b V A 9 S w N B E J 2 L X 0 n 8 i l r a H A b B Q s K d K F o G b C w T M B + Q h L C 3 N 5 e s 2 d s 7 d / e E c K S x s b C x U M T W 3 j 9 j 5 6 / R z U e h i Q 8 G H u / N M D P P i z l T 2 n G + r M z S 8 s r q W j a X X 9 / Y 3 N o u 7 O z W V Z R I i j U a 8 U g 2 P a K Q M 4 E 1 z T T H Z i y R h B 7 H h j e 4 H P u N O 5 S K R e J a D 2 P s h K Q n W M A o 0 U a q 3 n Y L R a f k T G A v E n d G i u X c g / / x f X 9 c 6 R Y + 2 3 5 E k x C F p p w o 1 X K d W H d S I j W j H E f 5 d q I w J n R A e t g y V J A Q V S e d H D q y D 4 3 i 2 0 E k T Q l t T 9 T f E y k J l R q G n u k M i e 6 r e W 8 s / u e 1 E h 1 c d F I m 4 k S j o N N F Q c J t H d n j r 2 2 f S a S a D w 0 h V D J z q 0 3 7 R B K q T T Z 5 E 4 I 7 / / I i q Z + U 3 N P S W d W k 4 c A U W d i H A z g C F 8 6 h D F d Q g R p Q Q H i E Z 3 i x b q w n 6 9 V 6 m 7 Z m r N n M H v y B 9 f 4 D n q y Q d Q = = < / l a t e x i t > q < l a t e x i t s h a 1 _ b a s e 6 4 = " e x x z + J N h H o 3 D G L q V n M 1 c D Q v s z J s = " > A A A B 6 H i c b V A 9 S w N B E J 2 L X 0 n 8 i l r a H A b B Q s K d K F o G b C w T M B + Q h L C 3 N 5 e s 2 d s 7 d / e E c K S x s b C x U M T W 3 j 9 j 5 6 / R z U e h i Q 8 G H u / N M D P P i z l T 2 n G + r M z S 8 s r q W j a X X 9 / Y 3 N o u 7 O z W V Z R I i j U a 8 U g 2 P a K Q M 4 E 1 z T T H Z i y R h B 7 H h j e 4 H P u N O 5 S K R e J a D 2 P s h K Q n W M A o 0 U a q 3 n Y L R a f k T G A v E n d G i u X c g / / x f X 9 c 6 R Y + 2 3 5 E k x C F p p w o 1 X K d W H d S I j W j H E f 5 d q I w J n R A e t g y V J A Q V S e d H D q y D 4 3 i 2 0 E k T Q l t T 9 T f E y k J l R q G n u k M i e 6 r e W 8 s / u e 1 E h 1 c d F I m 4 k S j o N N F Q c J t H d n j r 2 2 f S a S a D w 0 h V D J z q 0 3 7 R B K q T T Z 5 E 4 I 7 / / I i q Z + U 3 N P S W d W k 4 c A U W d i H A z g C F 8 6 h D F d Q g R p Q Q H i E Z 3 i x b q w n 6 9 V 6 m 7 Z m r N n M H v y B 9 f 4 D n q y Q d Q = = < / l a t h P B X g = " > A A A B 9 H i c b V A 9 S w N B E N 3 z M 8 a v G L G y W Q y C V b g T g 5 Y B G 8 s I 5 g O S I + z t 7 S V L 9 v Y u u 3 O B c F x r Z a + F h U F s / T F 2 / h s 3 H 4 U m P h h 4 v D f D z D w v F l y D b X 9 b a + s b m 1 v b u Z 3 8 7 t 7 + w W H h q N j Q U a I o q 9 N I R K r l E c 0 E l 6 w O H A R r x Y q R 0 B O s 6 Q 1 u p 3 5 z x J T m k X y A c c z c k P Q k D z g l Y C S X d t M O c O G z d J h l 3 U L J L t s z 4 F X i L E i p W p w 8 v l R O n m r d w l f H j 2 g S M g l U E K 3 b j h 2 D m x I F n A q W 5 T u J Z j G h A 9 J j b U M l C Z l 2 0 9 n R G T 4 3 i o + D S J m S g G f q 7 4 m U h F q P Q 8 9 0 h g T 6 e t m b i v 9 5 7 Q S C G z f l M k 6 A S T p f F C Q C Q 4 S n C W C f K 0 Z B j A 0 h V H F z K 6 Z 9 o g g F k 1 P e h O A s v 7 x K G p d l 5 6 p c u T d p 2 G i O H D p F Z + g C O e g a V d E d q q E 6 o m i I n t E b m l g j 6 9 V 6 t z 7 m r W v W Y u Y Y / Y H 1 + Q N f l p V m < / l a t e x i t > c v < l a t e x i t s h a 1 _ b a s e 6 4 = " Z / A 7 4 Z s C k x q l 5 4 E F h p S z r j J v O A I = " > A A A B 7 H i c b V B N S 8 N A E J 2 0 f t T 6 V R V P X o J F 8 F Q S U f R Y 8 O K x g m k L b S i b 7 a R d u t m E 3 U 2 h h P 4 G L x 4 U 8 e r / 8 C 9 4 E D z 5 U 3 T 7 c d D W B w O P 9 2 a Y m R c k n C n t O J 9 W L r + y u r Z e 2 C h u b m 3 v 7 J b 2 9 u s q T i V F j 8 Y 8 l s 2 A K O R M o K e Z 5 t h M J J I o 4 N g I B t c T v z F E q V g s 7 v Q o Q T 8 i P c F C R o k 2 k k c 7 2 X D c K Z W d i j O F v U z c O S l X 8 x / f b 4 d f W O u U 3 t v d m K Y R C k 0 5 U a r l O o n 2 M y I 1 o x z H x X a q M C F 0 Q H r Y M l S Q C J W f T Y 8 d 2 y d G 6 d p h L E 0 J b U / V 3 x M Z i Z Q a R Y H p j I j u q 0 V v I v 7 n t V I d X v k Z E 0 m q U d D Z o j D l t o 7 t y e d 2 l 0 m k m o 8 M I V Q y c 6 t N + 0 Q S q k 0 + R R O C u / j y M q m f V d z z y s W t S c O B G Q p w B M d w C i 5 c Q h V u o A Y e U G B w D 4 / w Z A n r w X q 2 X m a t O W s + c w B / Y L 3 + A L k h k w A = < / l a t e x i t > h enc < l a t e x i t s h a 1 _ b a s e 6 4 = " V w U g i Y e S E q 3 T H P W r X B 4 r C F X y r y s = " > A A A C B H i c b V C 7 S g N B F J 0 1 P m J 8 R c U q z W A Q r M K u K F o G b C w j m A c k S 5 i d 3 E 2 G z O 4 s M 7 N K W F L Y + C s 2 F o r Y C v 6 C h W D l p + j s J o U m H h g 4 n H M v d 8 7 x I s 6 U t u 1 P a y G 3 u L S 8 k l 8 t r K 1 v b G 4 V t 3 c a S s S S Q p 0 K L m T L I w o 4 C 6 G u m e b Q i i S Q w O P Q 9 I b n q d + 8 B q m Y C K / 0 K A I 3 I P 2 Q + Y w S b a R u s d Q R x u b g a y K l u E k G 4 2 7 S k Q G G k I 6 7 x b J d s T P g e e J M S b m a + / h + 2 / u C W r f 4 3 u k J G g c Q a s q J U m 3 H j r S b E K k Z 5 T A u d G I F E a F D 0 o e 2 o S E J Q L l J F m K M D 4 z S w 7 6 Q 5 o U a Z + r v j Y Q E S o 0 C z 0 w G R A / U r J e K / 3 n t W P t n b s L C K N Z p q u y Q H 3 O s B U 4 b w T 0 m g W o + M o R Q y c x f M R 0 Q S a g 2 v R V M C c 5 s 5 H n S O K o 4 x 5 W T S 9 O G j S b I o x L a R 4 f I Q a e o i i 5 Q D d U R R b f o H j 2 i J + v O e r C e r Z f J 6 I I 1 3 d l F f 2 C 9 / g C d 8 Z 0 T < / l a t e x i t >
Environment description w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W First , we encode the input logical form along with environment description for each of its symbols .
we subsequently encode using LSTMs to form the input and environment - level candidate token representations .
A pointer- decoder attends over the input and selects among candidate representations to produce the output utterance .
x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > ?
Table : students id school year ?
Document d < l a t e x i t s h a 1 _ b a s e 6 4 = "
W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t > d < l a t e x i t s h a 1 _ b a s e 6 4 = "
W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t >
Table : schools id name city ?
Document d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t > d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t >
B < l a t e x i t s h a 1 _ b a s e 6 4 = " V A k b 0 5 7 q l / c k 6 4 x w + B A 2 1 f I W r 4 A = " > A A A B + n i c b V D L S g N B E O z 1 G e N r o 9 6 8 D A b B U 9 g V R W 8 G P e g x g n l A s o T Z y W w y Z H Z n m Z k 1 x D W f 4 s W D I o K n f I k 3 j / 6 J k 8 d B E w s a i q p u u r v 8 m D O l H e f L W l h c W l 5 Z z a x l 1 z c 2 t 7 b t 3 E 5 F i U Q S W i a C C 1 n z s a K c R b S s m e a 0 F k u K Q 5 / T q t + 9 G v n V e y o V E 9 G d 7 s f U C 3 E 7 Y g E j W B u p a e c a w t i c B h p L K X r p 5 a B p 5 5 2 C M w a a J + 6 U 5 C + G D 9 / X H 3 t p q W l / N l q C J C G N N O F Y q b r r x N p L s d S M c D r I N h J F Y 0 y 6 u E 3 r h k Y 4 p M p L x 6 c P 0 K F R W i g Q 0 l S k 0 V j 9 P Z H i U K l + 6 J v O E O u O m v V G 4 n 9 e P d H B u Z e y K E 4 0 j c h k U Z B w p A U a 5 Y B a T F K i e d 8 Q T C Q z t y L S w R I T b d L K m h D c 2 Z f n S e W 4 4 J 4 U T m + d f N G B C T K w D w d w B C 6 c Q R F u o A R l I N C D J 3 i B V + v R e First , we encode the logical form using BERT .
B = BERT ( q ) ( 13 ) Next , we apply a bidirectional LSTM to obtain the input encoding h enc and another bidirectional LSTM to obtain representations of tokens in the augmented logical form c q. h enc = BiLSTM ( B ) ( 14 ) c q = BiLSTM ( B ) ( 15 )
To represent c v , we use word embeddings from BERT .
Finally , we apply a pointer - decoder that attends over h enc and selects among candidates c = [ c q ; c v ] to obtain the predicted utterance .
Synthesizing cycle-consistent examples
Having trained a forward semantic parser F and a backward utterance generator G in environment e , we can synthesize new examples with which to adapt the parser in the new environment e 0 . First , we sample a logical form q using a grammar ( Algorithm 1 in Section 2.1 ) .
Next , we predict an utterance u 0 = G( q , e ) .
Because G was trained only on e , many of its outputs are low-quality or do not correspond to its input q .
On their own , these examples ( u 0 , q ) do not facilitate parser adaptation ( see Section 3.1 for analyses ) .
To filter out low-quality examples , we additionally predict a logical form q 0 = F ( u 0 , e 0 ) , and keep only examples that are cycle consistent - the synthesized logical form q 0 is equivalent to the originally sampled logical form q in e 0 .
In the case of SQL parsing , the example is cycle-consistent if executing the synthesized query EXE (q 0 , e 0 ) results in the same denotation ( i.e. same set of database records ) as executing the original sampled query EXE (q , e 0 ) .
Finally , we combine cycle-consistent examples synthesized in e 0 with the original training data in e to retrain and adapt the parser .
Experiments
We evaluate performance on the Spider ( Yu et al. , 2018 b ) , Sparc ( Yu et al. , 2019 b ) , and CoSQL ( Yu et al. , 2019a ) zero-shot semantic parsing tasks .
Table 1 shows dataset statistics .
Figure 4 shows examples from each dataset .
For all three datasets , we use preprocessing steps from to preprocess SQL logical forms .
Evaluation consists of exact match over logical form templates ( EM ) in which values are stripped out , as well as execution accuracy ( EX ) .
Official evaluations also recently incorporated fuzz-test accuracy ( FX ) as tighter variant of execution accuracy .
In fuzztesting , the query is executed over randomized database content numerous times .
Compared to an execution match , a fuzz-test execution match is less likely to be spurious ( e.g. the predicted query coincidentally executes to the correct result ) .
FX implementation is not public as of writing , hence we only report test FX.
Spider .
Spider is a collection of databaseutterance - SQL query triplets .
The task involves producing the SQL query given the utterance and the database .
Figure 2 and 3 show preprocessed input for the parser and generator .
Sparc .
In Sparc , the user repeatedly asks questions that must be converted to SQL queries
We do not show Sparc because its data format is similar to CoSQL , but without user dialogue act prediction and without response generation .
For our experiments , we produce the output logical form given the data , utterance , and the previous logical form if applicable .
During evaluation , the previous logical form is the output of the model during the previous turn ( i.e. no teacher forcing on ground - truth previous output ) .
by the system .
Compared to Spider , Sparc additionally contains prior interactions from the same user session ( e.g. database -utterance -queryprevious query quadruplets ) .
For Sparc evaluation , we concatenate the previous system -produced query ( if present ) to each utterance .
For example , suppose the system was previously asked " where is Tesla born ? " and is now asked " how many people are born there ? " , we produce the utterance CoSQL .
CoSQL is combines task -oriented dialogue and semantic parsing .
It consists of a number of tasks , such as response generation , user act prediction , and state-tracking .
We focus on statetracking , in which the user intent is mapped to a SQL query .
Similar to , we restrict the context to be the previous query and the current utterance .
Hence , the input utterance and environment description are obtained in the same way as that used for Sparc .
Spider
Results
We primarily compare GAZP with the baseline forward semantic parser , because prior systems produce queries without values which are not executable .
We include one such non-executable model , EditSQL , one of the top parsers on Spider at the time of writing , for reference .
However , EditSQL EM is not directly comparable because of different outputs .
Due to high variance from small datasets , we tune the forward parser and backward generator using cross-validation .
We then retrain the model with early stopping on the development set using hyperparameters found via cross-validation .
For each task , we synthesize 100k examples , of which ?40 k are kept after checking for cycle-consistency .
The adapted parser is trained using the same hyperparameters as the baseline .
Please see appendix A.2 for hyperparameter settings .
Table 2 shows that adaptation by GAZP results in consistent performance improvement across Spider , Sparc , and CoSQL in terms of EM , EX , and FX .
We also examine the performance breakdown across query classes and turns ( details in appendix A.4 ) .
First , we divide queries into difficulty classes based on the number of SQL components , selections , and conditions ( Yu et al. , 2018 b ) .
For example , queries that contain more components such as nested subqueries , column selections , and aggregators , etc are considered to be harder .
Second , we divide multi-turn queries into how many turns into the interaction they occur for Sparc and CoSQL ( Yu et al. , 2019 b , a ) .
We observe that the gains in GAZP are generally more pronounced in more difficult queries and in turns later in the interaction .
Finally , we answer the following questions regarding the effectiveness of cycle-consistency and grounded adaptation .
Does adaptation on inference environment outperform data-augmentation on training environment ?
For this experiment , we synthesize data on training environments instead of inference environments .
The resulting data is similar to data augmentation with verification .
As shown in the " syntrain " row of Table 3 , retraining the model on the combination of this data and the supervised data leads to overfitting in the training environments .
A method related to data-augmentation is jointly supervising the model using the training data in the reverse direction , for example by generating utterance from query ( Fried et al. , 2018 ; Cao et al. , 2019 ) . For Spider , we find that this dual objective ( 57.2 EM ) underperforms GAZP adaptation ( 59.1 EM ) .
Our results indicate that adaptation to the new environment significantly outperforms augmentation in the training environment .
How important is cycle-consistency ?
For this experiment , we do not check for cycle-consistency and instead keep all synthesized queries in the inference environments .
As shown in the " nocycle " row of Table 3 , the inclusion of cycle-consistency effectively prunes ? 60 % of synthesized examples , which otherwise significantly degrade performance .
This shows that enforcing cycle-consistency is crucial to successful adaptation .
In another experiment , we keep examples that have consistent logical forms , as deemed by string match ( e.g. q == q 0 ) , instead of consistent denotation from execution .
The " EM consistency " row of Table 3 shows that this variant of cycleconsistency also improves performance .
In particular , EM consistency performs similarly to execution consistency , albeit typically with lower execution accuracy .
How much GAZP synthesized data should one use for grounded adaptation ?
For this experiment , we vary the amount of cycle-consistent syn- thesized data used for adaptation .
Figure 5 shows that that adaptation performance generally increases with the amount of synthesized data in the inference environment , with diminishing return after 30 - 40 k examples .
Related work Semantic parsing .
Semantic parsers parse natural language utterances into executable logical forms with respect to an environment ( Zelle and Mooney , 1996 ; Zettlemoyer and Collins , 2005 ; Liang et al. , 2011 ) .
In zero-shot semantic parsing , the model is required to generalize to environments ( e.g. new domains , new database schemas ) not seen during training ( Pasupat and Liang , 2015 ; Zhong et al. , 2017 ; Yu et al. , 2018 b ) .
For languageto -SQL zero-shot semantic parsing , a variety of methods have been proposed to generalize to new databases by selecting from table schemas in the new database Guo et al. , 2019 ) .
Our method is complementary to these work - the synthesis , cycle-consistency , and adaptation steps in GAZP can be applied to any parser , so long as we can learn a backward utterance generator and evaluate logical - form equivalence .
Data augmentation .
Data augmentation transforms original training data to synthesize artificial training data .
Krizhevsky et al. ( 2017 ) crop and rotate input images to improve object recognition .
Dong et al. ( 2017 ) and Yu et al . ( 2018a ) respectively paraphrase and back - translate ( Sennrich et al. , 2016 ; Edunov et al. , 2018 ) questions and documents to improve question - answering .
Jia and Liang ( 2016 ) perform data-recombination in the training domain to improve semantic parsing .
Hannun et al. ( 2014 ) superimpose noisy background tracks with input tracks to improve speech recognition .
Our method is distinct from dataaugmentation in the following ways .
First , we synthesize data on logical forms sampled from the new environment instead of the original environment , which allows for adaptation to the new environments .
Second , we propose cycle-consistency to prune low-quality data and keep high-quality data for adaptation .
Our analyses show that these core differences from data-augmentation are central to improving parsing performance .
Cycle-consistent generative adversarial models ( cycle - GANs ) .
In cycle-GAN ( Zhu et al. , 2017 ; Hoffman et al. , 2018 ) , a generator forms images that fools a discriminator while the discriminator tries distinguish generated images from naturally occurring images .
The the adversarial objectives of the generator and the discriminator are optimized jointly .
Our method is different from cycle - GANs in that we do not use adversarial objectives and instead rely on matching denotations from executing synthesized queries .
This provides an exact signal compared to potentially incorrect outputs by the discriminator .
Morevoer , cycle - GANs only synthesize the input and verify whether the input is synthesized ( e.g. the utterance looks like a user request ) .
In contrast , GAZP synthesizes both the input and the output , and verifies consistency between the input and the output ( e.g. the utterance matches the query ) .
Conclusion and Future work
We proposed GAZP to adapt an existing semantic parser to new environments by synthesizing cycle-consistent data .
GAZP improved parsing performance on three zero-shot parsing tasks .
Our analyses showed that GAZP outperforms data augmentation , performance improvement scales with the amount of GAZP - synthesized data , and cycleconsistency is central to successful adaptation .
In principle , GAZP applies to any problems that lack annotated data and differ between training and inference environments .
One such area is robotics , where one trains in simulation because it is prohibitively expensive to collect annotated trajectories in the real world .
In future work , we will consider how to interpret environment specifications to facilitate grounded adaptation in these other areas .
