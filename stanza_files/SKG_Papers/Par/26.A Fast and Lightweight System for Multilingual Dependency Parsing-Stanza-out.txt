title
A Fast and Lightweight System for Multilingual Dependency Parsing
abstract
Following Kiperwasser and Goldberg ( 2016 ) , we present a multilingual dependency parser with a bidirectional - LSTM ( BiLSTM ) feature extractor and a multi-layer perceptron ( MLP ) classifier .
We trained our transition - based projective parser in UD version 2.0 datasets without any additional data .
The parser is fast , lightweight and effective on big treebanks .
In the CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies , the official results show that the macro- averaged LAS F1 score of our system Mengest is 61.33 % .
Introduction
Developing tools that can process multiple languages has always been an important goal in NLP .
Ten years ago , CoNLL 2006 ( Buchholz and Marsi , 2006 ) and CoNLL 2007 ( Nivre et al. , 2007 )
Shared
Task were a major milestone for multilingual dependency parsing .
The CoNLL 2017 UD Shared Task ( Zeman et al. , 2017 ) is an extension of the tasks addressed in previous years .
Unlike CoNLL 2006 and CoNLL 2007 , the focus of the CoNLL 2017 UD Shared Task is learning syntactic dependency parsers on a universal syntactic annotation standard .
This shared task requires participants to parse raw texts from different languages , which vary both in typology and training set size .
The CoNLL 2017 UD Shared Task provided universal dependencies description from LREC 2016 ( Nivre et al. , 2016 ) , two datasets , which are UD version 2.0 datasets ( Nivre et al. , 2017 b ) and this task test datasets ( Nivre et al. , 2017a ) , two baseline models , which are UDPipe ( Straka et al. , 2016 ) and SyntaxNet ( Weiss et al. , 2015 ) , and the evaluation platform TIRA ( Potthast et al. , 2014 ) .
In this paper , We present our multilingual dependency parsing system Mengest for CoNLL 2017 UD Shared Task .
The system contains a BiLSTM feature extractor for feature representation and a MLP classifier for the transition system .
The inputs of our system are word form ( lemma or stem , which depending on the particular treebank ) and part of speech ( POS ) tags ( coarse- grained and fine- grained ) for each token .
Based on this input , the system finds a governor for each token , and assigns a universal dependency relation label to each syntactic dependency .
Our official submission obtains 61.33 % macro-averaged LAS F1 score on all treebanks .
The rest of this paper is organized as follows .
Section 2 discusses the transition - based model ( Kiperwasser and Goldberg , 2016 ) and our implementation .
Section 3 explains how our system deals with parallel sets and surprise languages .
Finally , we present experimental and official results in Section 4 .
System Description
We implement a transition - based projective parser following Kiperwasser and Goldberg ( 2016 ) .
The system consists of a BiLSTM feature extractor and an MLP classifier .
We describe their model and our implementation in the following sections in detail .
Arc-Hybrid System
In this work , we use the arc-hybrid transition system ( Kuhlmann et al. , 2011 ) .
In the arc-hybrid system , a configuration c = ( ? , ? , A ) consists of a stack ? , a buffer ? , and a set of dependency arcs A. Given n words sentence s = w 1 , ? ? ? , w n , the initial configuration c = ( ? , { 1 , 2 , ? ? ? , n , root} , ? ) with an empty stack , an empty arc set , and a full buffer ? = 1 , 2 , ? ? ? , n , root , where root is the special root index .
The terminal configuration set contains configurations with an empty stack , an arc set and a buffer containing only root .
For each configuration c = ( ?|s 1 |s 0 , b 0 |? , A ) , the arc-hybrid system has 3 kinds of transitions , T = { SHIFT , LEFT l , RIGHT l } : SHIFT ( c ) = (?|s1|s0 | b0 , ? , A ) s.t. |?| > 0 LEFT l ( c ) = ( ?| s1 , b0 | ? , A ? { ( b0 , s0 , l ) } ) s.t. |?| > 0 , |?| > 0 RIGHT l ( c ) = ( ?| s1 , b0 | ? , A ? { ( s1 , s0 , l ) } ) s.t. |?| > 0 , s0 ? = root
The SHIFT transition moves the first item of the buffer ( b 0 ) to the stack .
The LEFT l transition removes the first item on top of the stack ( s 0 ) and attaches it as a modifier to b 0 with label l , adding the arc ( b 0 , s 0 , l ) to arc set A .
The RIGHT l transition removes s 0 from the stack and attaches it as a modifier to the next item on the stack ( s 1 ) , adding the arc ( s 1 , s 0 , l ) to arc set A .
We apply a classifier to determine the best action for a configuration .
Following Chen and Manning ( 2014 ) , we use a MLP with one hidden layer .
The score of the transition t ?
T is defined as : M LP ? ( ?( c ) ) = W 2 ? tanh ( W 1 ? ?( c ) + b 1 ) + b 2 SCORE ? ( ?( c ) , t ) = M LP ? ( ?( c ) ) [ t ] where ? = { W 1 , W 2 , b 1 , b 2 } are the model pa- rameters , ?( c ) is the feature representation of the configuration c. M LP ? ( ?( c ) ) [ t ] denotes an indexing operation taking the output element which is the class of transition t.
The Feature Representation
We consider two types of feature repersentations ?( c ) of a configuration : simple and extended .
Simple : For an input sequence s = w 1 , ? ? ? , w n , we associate each word w i with a vector x i : x i = e( w i ) ? e( p i ) ? e( q i ) where e( w i ) is the embedding vector of word w i , e( p i ) is the embedding vector of POS tag p i , e( q i ) is the embedding vector of coarsegrained POS ( CPOS ) tag q i .
The embeddings e( w i ) , e( p i ) , e( q i ) are randomly initialized ( without pre-training ) and jointly trained with the parsing model .
Then , in order to encode context features , we use a 2 - layer sentence level BiLSTM on top of x 1:n : ? h t = LST M ( ? h t?1 , x i , ? ? ) ? h t = LST M ( ? h t+1 , x i , ? ? ) v i = ? h i ? ? h i ? ? are the model parameters of the forward hidden sequence ?
h. ? ? are the model parameters of the backward hidden sequence ? h.
The vector v i is our final vector representation of ith token in s , which has took into account both the entire history ?
h i and the entire future ?
h i by concatenating the matching Long Short - Term Memory Network ( LSTM ) .
For ?( c ) , our simple feature function is the concatenated BiLSTM vectors of the top 3 items on the stack and the first item on the buffer .
A configuration c is represented by : ?( c ) = v s 2 ? v s 1 ? v s 0 ? v b 0 Extended :
We add the feature vectors corresponding to the right-most and left-most modifiers of s 0 , s 1 and s 2 , as well as the left-most modifier of b 0 , reaching a total of 11 BiLSTM vectors as extended feature representation .
As we will see in experimental sections , using the extended set does indeed improves parsing accuracies .
Training Details
The training objective is to make the score of correct transitions always above the scores of incorrect transitions .
We use a margin-based criteria .
Assume T gold is the set of gold transitions at the current configuration c.
At each time stamp , the objective function tries to maximize the margin between T gold and T ? T gold .
The hinge loss of a configuration c is defined as : Loss ? ( c ) = ( 1 ? max to ?
T gold SCORE ? ( ? ( c ) , to ) + max tp ?( T ?T gold ) SCORE ? ( ?( c ) , tp ) ) +
Our system use the backpropagation algorithm to calculate the gradients of the entire network ( including the MLP and the BiLSTM ) .
Since our parser can only deal with projective dependency trees , we exclude all training examples with non-projective dependencies .
This approach undoubtedly downgrades the performance of our system , we plan to use pseudo- projective approach to improve it in the future work .
Multilingual Dependency Parsing
There are 81 treebanks in the CoNLL 2017 UD Shared Task , including 55 big treebanks , 14 PUD treebanks ( additional parallel test sets ) , 8 small treebanks and 4 surprise language treebanks .
For each language treebank of UD version 2.0 training sets , we train a parser only using its monolingual training set ( no cross-lingual features ) .
In total , we trained 61 models , 55 on big treebanks and 6 on small treebanks 1 . Our system reads the CoNLL -U files predicted by UDPipe , and uses morphology ( lemmas , UPOS , XPOS ) predicted by UDPipe .
Dealing with Parallel Test Sets
There are 14 additional parallel test sets .
Our system simply selects one trained model when we encounter a parallel test set where multiple training treebanks exist .
For example , although we do n't have English - PUD training set but we have English , English -LinES and English - ParTUT training set .
So we only use the model trained on English training set to predict English - PUD test set .
Dealing with Surprise Languages
There are 4 surprise languages in the CoNLL 2017 UD Shared Task .
Our system simply use the model trained on English to predict 4 surprise languages , without looking at the input words .
Results
We trained our system based on a MacBook Air with a Intel Core i5 1.6 GHz CPU and 4G memory .
We used the official TIRA ( Potthast et al. , 2014 ) to evaluate the system .
We used Dynet neural network library to build our system ( Neubig et al. , 2017 ) .
The hyper-parameters of the final system used for all the reported experiments are detailed in Table 1 .
Token Representation
We compare two constructions of x i : ? lemma and POS tag ( w i ? p i ) . ? lemma , POS tag and CPOS tag ( w i ? p i ? q i ) .
The performance of different token representations on 4 example languages are given in Table 2 .
The results show that the CPOS tag improves the LAS measure between 0.5 % and 0.72 % .
BiLSTM Feature Representation Performances of simple feature representation and extended feature representation are given in Table 3 .
The results show that the extended feature representation slightly increases the performance of our system .
while the simple feature representation can significantly speed up the system .
Overall Performances
In our final submitted system to the shared task , we used lemmas , POS tags and CPOS tags in token representation and selected extended feature representation .
The LAS F1 score of our system and best system on the 4 surprise language treebanks : bxr , hsb , kmr , sme .
shown in Table 4 .
The macro- average LAS of the 8 small treebanks is 33.88 % and the results for each language are shown in Table 5 .
The macroaverage LAS of the 14 PUD treebanks is 63.68 % and the results for each language are shown in Table 6 .
The macro- average LAS of the 4 surprise language treebanks is 11.31 % and the results for each language are shown in Table 7 .
The macroaveraged LAS F1 score of our system on all treebanks is 61.33 % .
Computational Efficiencies
The parser is fast .
Offline training time is about 300 words / sec .
Prediction time on the official TIRA is about 400 words / sec without asking for more resources .
Memory requirements are lower than 512 M for each language .
Conclusions
In this paper , we present a fast and lightweight multilingual dependency parsing system for the CoNLL 2017 UD Shared Task , which composed of a BiLSTMs feature extractor and a MLP classifier .
Our system only uses UD version 2.0 datasets ( without any additional data ) .
The parser makes a good ranking at some of the big treebanks .
The results suggests that the simple BiLSTM extractor is a reasonable baseline for multilingual dependency parsing .
We will continue to improve our system and add cross-lingual techniques in our future work .
Table 1 : 1 Hyper-parameter values used in shared task .
Language w i ?
p i w i ? p i ? q i Word embedding dimension 100 POS tag embedding dimension 25 CPOS tag embedding dimension 10 Label embedding dimension 25 Hidden units in MLP 100 BiLSTM layers 2 BiLSTM hidden layer dimensions 125 BiLSTM output layer dimensions 125 ? ( for word dropout ) 0.25 Learning rate 0.1 Optimization algorithm Adam Bulgarian ( bg ) 83.78 84.28 Catalan ( ca ) 85.67 86.26 German ( de ) 70.77 71.49 English ( en ) 75.91 76.42
Table 2 : 2 The LAS score of two different token representations on the 4 treebanks : Bulgarian ( bg ) , Catalan ( ca ) , German ( de ) , English ( en ) .
Table 3 : 3 Comparison of Simple and Extended feature representations , we report LAS score , offline training time , and TIRA testing time .
Simple Feature Extended Feature LAS train( sec ) test ( sec ) LAS train ( sec ) test ( sec ) bg 84.24 205.6 22.4 84.28 287.9 29.1 ca 85.74 663.5 37.2 86.26 878.5 48.8 de 71.15 416.8 29.8 71.49 733.2 37.4 en 76.18 375.6 24.5 76.42 524.8 31.1
The macro- average LAS of the 55 big treebanks is 68.37 % and the results for each language are Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) ar 65.65( 72.90 ) bg 84.28( 89.81 ) ca 86.26(90.70 ) cs 83.85( 90.17 ) cs cac 83.22( 90.43 ) cs cltt 68.42( 85.82 ) cu 48.95 ( 76.84 ) da 72.78( 82.97 ) de 71.49 ( 80.71 ) el 78.72( 87.38 ) en 76.42( 82.23 ) en lines 72.66( 82.09 ) en partut 73.74 ( 84.46 ) es 75.41 ( 87.29 ) es ancora 78.64( 89.99 ) et 55.40 ( 71.65 ) eu 62.89 ( 81.44 ) fa 61.43( 86.31 ) fi 69.86( 85.64 ) fi ftb 75.13( 86.81 ) fr 80.07 ( 85.51 ) fr sequoia 79.00 ( 87.31 ) gl 79.28( 83.23 ) got 57.02( 71.36 ) grc 49.30 ( 73.19 ) grc proiel 60.61( 75.28 ) he 58.10 ( 68.16 ) hi 86.76( 91.59 ) hr 76.59 ( 85.25 ) hu 57.85 ( 77.56 ) id 74.40 ( 79.19 ) it 86.14( 90.68 ) ja 73.00 ( 91.13 ) ko 63.21 ( 82.49 ) la ittb 74.37 ( 87.02 ) la proiel 54.07 ( 71.55 ) lv 59.50 ( 74.01 ) nl 68.84 ( 80.48 ) nl lassysmall 71.53 ( 87.71 ) no bokmaal 75.96( 89.88 ) no nynorsk 70.97 ( 88.81 ) pl 67.63( 90.32 ) pt 62.85 ( 87.65 ) pt br 79.71( 91.36 ) ro 64.38( 85.92 ) ru 56.56 ( 83.65 ) ru syntagrus 82.42( 92.60 ) sk 60.48( 86.04 ) sl 61.28( 91.51 ) sv 61.43 ( 85.87 ) sv lines 61.09 ( 82.89 ) tr 49.11( 62.79 ) ur 61.77( 82.28 ) vi 31.67( 47.51 ) zh 58.03( 68.56 )
Table 4 : 4
The LAS F1 score of our system and best system on the 55 big treebanks : ar , bg , ca , cs , cs cac , cs cltt , cu , da , de , el , en , en lines , en partut , es , es ancora , et , eu , fa , fi , fi ftb , fr , fr sequoia , gl , got , grc , grcproiel , he , hi , hr , hu , id , it , ja , ko , la ittb , la proiel , lv , nl , nl lassysmall , no bokmaal , no nynorsk , pl , pt , pt br , ro , ru , ru syntagrus , sk , sl , sv , sv lines , tr , ur , vi , zh. Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) fr partut 72.40 ( 88.13 ) ga 55.07( 70.06 ) gl treegal 61.17 ( 74.34 ) kk ( 29.22 ) la 38.00 ( 63.37 ) sl sst 23.77( 59.07 ) ug ( 43.51 ) uk 20.61( 75.33 )
Table 5 : 5
The LAS F1 score of our system and best system on the 8 small treebanks : fr partut , ga , gl treegal , kk , la , sl sst , ug , uk .
Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) ar pud 43.70 ( 49.94 ) cs pud 80.44 ( 84.42 ) de pud 69.13 ( 74.86 ) en pud 79.02 ( 85.51 ) es pud 72.61( 81.05 ) fi pud 71.77 ( 88.47 ) fr pud 73.92 ( 78.81 ) hi pud 51.07 ( 54.49 ) it pud 83.79 ( 88.14 ) ja pud 76.66( 83.75 ) pt pud 59.32 ( 78.48 ) ru pud 52.73 ( 75.71 ) sv pud 54.83 ( 78.49 ) tr pud 22.52( 38.22 )
Table 6 : 6 The LAS F1 score of our system and best system on the 14 PUD treebanks ( additional parallel test sets ) : ar pud , cs pud , de pud , en pud , es pud , fi pud , fr pud , hi pud , it pud , ja pud , pt pud , ru pud , sv pud , tr pud .
Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) Language LAS ( max ) bxr 12.44( 32.24 ) hsb 14.19( 61.70 ) kmr 8.62( 47.53 ) sme 10.00 ( 48.96 )
Table 7 : 7
In UD version 2.0 datasets , Kazakh and Uyghur only contain development set , no training set .
