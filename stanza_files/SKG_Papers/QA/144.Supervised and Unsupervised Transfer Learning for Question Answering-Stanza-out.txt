title
Supervised and Unsupervised Transfer Learning for Question Answering
abstract
Although transfer learning has been shown to be successful for tasks like object and speech recognition , its applicability to question answering ( QA ) has yet to be well -studied .
In this paper , we conduct extensive experiments to investigate the transferability of knowledge learned from a source QA dataset to a target dataset using two QA models .
The performance of both models on a TOEFL listening comprehension test ( Tseng et al. , 2016 ) and MCTest ( Richardson et al. , 2013 ) is significantly improved via a simple transfer learning technique from MovieQA ( Tapaswi et al. , 2016 ) .
In particular , one of the models achieves the state - of - the - art on all target datasets ; for the TOEFL listening comprehension test , it outperforms the previous best model by 7 % .
Finally , we show that transfer learning is helpful even in unsupervised scenarios when correct answers for target QA dataset examples are not available .
Introduction 1 . Question Answering
One of the most important characteristics of an intelligent system is to understand stories like humans do .
A story is a sequence of sentences , and can be in the form of plain text ( Trischler et al. , 2017 ; Rajpurkar et al. , 2016 ; Weston et al. , 2016 ; Yang et al. , 2015 ) or spoken content ( Tseng et al. , 2016 ) , where the latter usually requires the spoken content to be first transcribed into text by automatic speech recognition ( ASR ) , and the model will subsequently process the ASR output .
To evaluate the extent of the model 's understanding of the story , it is asked to answer questions about the story .
Such a task is referred to as question answering ( QA ) , and has been a long-standing yet challenging problem in natural language processing ( NLP ) .
Several QA scenarios and datasets have been introduced over the past few years .
These scenarios differ from each other in various ways , including the length of the story , the format of the answer , and the size of the training set .
In this work , we focus on context - aware multi-choice QA , where the answer to each question can be obtained by referring to its accompanying story , and each question comes with a set of answer choices with only one correct answer .
The answer choices are in the form of open , natural language sentences .
To correctly answer the question , the model is required to understand and reason about the relationship between the sentences in the story .
Transfer Learning Transfer learning ( Pan and Yang , 2010 ) is a vital machine learning technique that aims to use the knowledge learned from one task and apply it to a different , but related , task in order to either reduce the necessary fine -tuning data size or improve performance .
Transfer learning , also known as domain adaptation 1 , has achieved success in numerous domains such as computer vision ( Sharif Razavian et al. , 2014 ) , ASR ( Doulaty et al. , 2015 ; Huang et al. , 2013 ) , and NLP ( Zhang et al. , 2017 ; Mou et al. , 2016 ) .
In computer vision , deep neural networks trained on a large-scale image classification dataset such as ImageNet ( Russakovsky et al. , 2015 ) have proven to be excellent feature extractors for a broad range of visual tasks such as image captioning ( Lu et al. , 2017 ; Karpathy and Fei-Fei , 2015 ; Fang et al. , 2015 ) and visual question answering ( Xu and Saenko , 2016 ; Fukui et al. , 2016 ; Antol et al. , 2015 ) , among others .
In NLP , transfer learning has also been successfully applied to tasks like sequence tagging ( Yang et al. , 2017 ) , syntactic parsing ( Mc - Closky et al. , 2010 ) and named entity recognition ( Chiticariu et al. , 2010 ) , among others .
Transfer Learning for QA
Although transfer learning has been successfully applied to various applications , its applicability to QA has yet to be well -studied .
In this paper , we tackle the TOEFL listening comprehension test ( Tseng et al. , 2016 ) and MCTest ( Richardson et al. , 2013 ) with transfer learning from MovieQA ( Tapaswi et al. , 2016 ) using two existing QA models .
Both models are pre-trained on MovieQA and then fine-tuned on each target dataset , so that their performance on the two target datasets are significantly improved .
In particular , one of the models achieves the state - of - the - art on all target datasets ; for the TOEFL listening comprehension test , it outperforms the previous best model by 7 % .
Transfer learning without any labeled data from the target domain is referred to as unsupervised transfer learning .
Motivated by the success of unsupervised transfer learning for speaker adaptation ( Chen et al. , 2011 ; Wallace et al. , 2009 ) and spoken document summarization ( Lee et al. , 2013 ) , we further investigate whether unsupervised transfer learning is feasible for QA .
Although not well studied in general , transfer Learning for QA has been explored recently .
To the best of our knowledge , Kadlec et al . ( 2016 ) is the first work that attempted to apply transfer learning for machine comprehension .
The authors showed only limited transfer between two QA tasks , but the transferred system was still significantly better than a random baseline .
Wiese et al. ( 2017 ) tackled a more specific task of biomedical QA with transfer learning from a large-scale dataset .
The work most similar to ours is by Min et al . ( 2017 ) , where the authors used a simple transfer learning technique and achieved significantly better performance .
However , none of these works study unsupervised transfer learning , which is especially crucial when the target dataset is small .
Golub et al. ( 2017 ) proposed a twostage synthesis network that can generate synthetic questions and answers to augment insuffi-cient training data without annotations .
In this work , we aim to handle the case that the questions from the target domain are available .
Task Descriptions and Approaches Among several existing QA settings , in this work we focus on multi-choice QA ( MCQA ) .
We are particularly interested in understanding whether a QA model can perform better on one MCQA dataset with knowledge transferred from another MCQA dataset .
In Section 2.1 , we first formalize the task of MCQA .
We then describe the procedures for transfer learning from one dataset to another in Section 2.2 .
We consider two kinds of settings for transfer learning in this paper , one is supervised and the other is unsupervised .
Multi-Choices QA
In MCQA , the inputs to the model are a story , a question , and several answer choices .
The story , denoted by S , is a list of sentences , where each of the sentences is a sequence of words from a vocabulary set V .
The question and each of the answer choices , denoted by Q and C , are both single sentences also composed of words from V .
The QA model aims to choose one correct answer from multiple answer choices based on the information provided in S and Q .
Transfer Learning
The procedure of transfer learning in this work is straightforward and includes two steps .
The first step is to pre-train the model on one MCQA dataset referred to as the source task , which usually contains abundant training data .
The second step is to fine- tune the same model on the other MCQA dataset , which is referred to as the target task , that we actually care about , but that usually contains much less training data .
The effectiveness of transfer learning is evaluated by the model 's performance on the target task .
Supervised Transfer Learning
In supervised transfer learning , both the source and target datasets provide the correct answer to each question during pre-training and fine-tuning , and the QA model is guided by the correct answer to optimize its objective function in a supervised manner in both stages .
Unsupervised Transfer Learning
We also consider unsupervised transfer learning where the correct answer to each question in the target dataset is not available .
In other words , the entire process is supervised during pre-training , but unsupervised during fine-tuning .
A selflabeling technique inspired by Lee et al . ( 2013 ) ; Chen et al . ( 2011 ) ; Wallace et al. ( 2009 ) is used during fine-tuning on the target dataset .
We present the proposed algorithm for unsupervised transfer learning in Algorithm 1 .
For each question in the target dataset , use M to predict its answer .
4 : For each question , assign the predicted answer to the question as the correct one .
5 : Fine-tune M on the target dataset as usual .
6 : until
Reach the number of training epochs .
Datasets
We used MovieQA ( Tapaswi et al. , 2016 ) as the source MCQA dataset , and TOEFL listening comprehension test ( Tseng et al. , 2016 ) and MCTest ( Richardson et al. , 2013 ) as two separate target datasets .
Examples of the three datasets are shown in Table 1 . MovieQA is a dataset that aims to evaluate automatic story comprehension from both video and text .
The dataset provides multiple sources of information such as plot synopses , scripts , subtitles , and video clips that can be used to infer answers .
We only used the plot synopses of the dataset , so our setting is the same as pure textual MCQA .
The dataset contains 9,848/1,958 train / dev examples ; each question comes with a set of five possible answer choices with only one correct answer .
TOEFL listening comprehension test is a recently published , very challenging MCQA dataset that contains 717/124/122 train / dev/test examples .
It aims to test knowledge and skills of academic English for global English learners whose native languages are not English .
There are only four answer choices for each question .
The stories in this dataset are in audio form .
Each story comes with two transcripts : manual and ASR transcriptions , where the latter is obtained by running the CMU Sphinx recognizer ( Walker et al. , 2004 ) on the original audio files .
We use TOEFL - manual and TOEFL - ASR to denote the two versions , respectively .
We highlight that the questions in this dataset are not easy because most of the answers cannot be found by simply matching the question and the choices without understanding the story .
For example , there are questions regarding the gist of the story or the conclusion for the conversation .
MCTest is a collection of 660 elementary - level children 's stories .
Each question comes with a set of four answer choices .
There are two variants in this dataset : MC160 and MC500 .
The former contains 280/120/240 train / dev/test examples , while the latter contains 1,200/200/600 train / dev/test examples and is considered more difficult .
The two chosen target datasets are challenging because the stories and questions are complicated , and only small training sets are available .
Therefore , it is difficult to train statistical models on only their training sets because the small size limits the number of parameters in the models , and prevents learning any complex language concepts simultaneously with the capacity to answer questions .
We demonstrate that we can effectively overcome these difficulties via transfer learning in Section 5 .
QA Neural Network Models Among numerous models proposed for multiplechoice QA ( Trischler et al. , 2016 ; Fang et al. , 2016 ; Tseng et al. , 2016 ) , we adopt the End-to - End Memory Network ( MemN2N ) 2 ( Sukhbaatar et al. , 2015 ) and Query - Based Attention CNN ( QACNN ) 3 ( Liu et al. , 2017 ) , both open-sourced , to conduct the experiments .
Below we briefly introduce the two models in Section 4.1 and Section 4.2 , respectively .
For the details of the models , please refer to the original papers .
End-to- End Memory Networks An End-to - End Memory Network ( MemN2N ) first transforms Q into a vector representation with an embedding layer B .
At the same time , all sentences in S are also transformed into two different sentence representations with two additional embedding layers A and C .
The first sentence representation is used in conjunction with the question representation to produce an attention - like mechanism that outputs the similarity between each sentence in S and Q .
The similarity is then used to weight the second sentence representation .
We then obtain the sum of the question representation and the weighted sentence representations over S as Q .
In the original MemN2N , Q is decoded to provide the estimation of the probability of being an answer for each word within a fixed set .
The word with the highest probability is then selected as the answer .
However , in multiple - choice QA , C is in the form of open , natural language sentences instead of a single word .
Hence we modify MemN2N by adding an embedding layer F to encode C as a vector representation C by averaging the embeddings of words in C .
We then compute the similarity between each choice representation C and Q .
The choice C with the highest probability is then selected as the answer .
Query - Based Attention CNN A Query - Based Attention CNN ( QACNN ) first uses an embedding layer E to transform S , Q , and C into a word embedding .
Then a compare layer generates a story -question similarity map SQ and a story - choice similarity map SC .
The two similarity maps are then passed into a two -stage CNN architecture , where a questionbased attention mechanism on the basis of SQ is applied to each of the two stages .
The first stage CNN generates a word-level attention map for each sentence in S , which is then fed into the second stage CNN to generate a sentence - level attention map , and yield choice - answer features for each of the choices .
Finally , a classifier that consists of two fully - connected layers collects the information from every choice answer feature and outputs the most likely answer .
The trainable parameters are the embedding layer E that transforms S , Q , and C into word embeddings , the two-stage CNN W ( 1 ) CN N and W ( 2 ) CN N that integrate information from the word to the sentence level , and from the sentence to the story level , and the two fully - connected layers W ( 1 ) F C and W ( 2 ) F C that make the final prediction .
We mention the trainable parameters here because in Section 5 we will conduct experiments to analyze the transferability of the QACNN by fine-tuning some parameters while keeping others fixed .
Since QACNN is a newly proposed QA model has a relatively complex structure , we illustrate its architecture in Figure 1 , which is enough for understanding the rest of the paper .
Please refer to the original paper ( Liu et al. , 2017 ) for more details .
Question Answering Experiments
Training Details
For pre-training MemN2N and QACNN on MovieQA , we followed the exact same procedure as in Tapaswi et al . ( 2016 ) and Liu et al . ( 2017 ) , respectively .
Each model was trained on the training set of the MovieQA task and tuned on the dev set , and the best performing models on the dev set were later fine-tuned on the target dataset .
During fine-tuning , the model was also trained on the training set of target datasets and tuned on the dev set , and the performance on the testing set of the target datasets was reported as the final result .
We use accuracy as the performance measurement .
Supervised Transfer Learning Experimental Results
Table 2 reports the results of our transfer learning on TOEFL - manual , TOEFL - ASR , MC160 , and MC500 , as well as the performance of the previous best models and several ablations that did not use pre-training or fine-tuning .
From Table 2 : Results of transfer learning on the target datasets .
The number in the parenthesis indicates the accuracy increased via transfer learning ( compared to rows ( a ) and ( g ) ) .
The best performance for each target dataset is marked in bold .
We also include the results of the previous best performing models on the target datasets in the last three rows . ) .
In addition , with transfer learning , QACNN outperforms the previous best models on TOEFL - manual by 7 % , TOEFL - ASR ( Fang et al. , 2016 ) by 6.5 % , MC160 ( Wang et al. , 2015 ) by 1.1 % , and MC500 ( Trischler et al. , 2016 ) by 1.3 % , and becomes the state - of - the - art on all target datasets .
Which QACNN parameters to transfer ?
For the QACNN , the training parameters are E , W CN N , W ( 2 ) CN N , W ( 1 ) F C , and W ( 2 ) F C ( Section 4.2 ) .
To better understand how transfer learning affects the performance of QACNN , we also report the results of keeping some parameters fixed and only fine-tuning other parameters .
We choose to fine- tune either only the last fully - connected layer W ( 2 ) F C while keeping other parameters fixed ( row ( d ) in Table 2 ) , the last two fully - connected layers W ( 1 ) F C and W ( 2 ) F C ( row ( e ) ) , and the entire QACNN ( row ( f ) ) .
For TOEFL - manual , TOEFL - ASR , and MC500 , QACNN performs the best when only the last two fully - connected layers were fine- tuned ; for MC160 , it performs the best when only the last fully - connected layer was fine-tuned .
Note that for training the QACNN , we followed the same procedure as in Liu et al . ( 2017 ) , whereby pre-trained GloVe word vectors ( Pennington et al. , 2014 ) were used to initialize the embedding layer , which were not updated during training .
Thus , the embedding layer does not depend on the training set , and the effective vocabularies are the same .
Fine-tuning the entire model is not always best .
It is interesting to see that fine-tuning the entire QACNN does n't necessarily produce the best result .
For MC500 , the accuracy of QACNN drops by 4.6 % compared to just fine-tuning the last two fully - connected layers ( rows ( f ) vs. ( e ) ) .
We conjecture that this is due to the amount of training data of the target datasets - when the training set of the target dataset is too small , finetuning all the parameters of a complex model like QACNN may result in overfitting .
This discovery aligns with other domains where transfer learning is well - studied such as object recognition ( Yosinski et al. , 2014 ) .
A large quantity of mismatched training examples is better than a small training set .
We expected to see that a MemN2N , when trained directly on the target dataset without pre-training on MovieQA , would outperform a MemN2N pretrained on MovieQA without fine-tuning on the target dataset ( rows ( g ) vs. ( h ) ) , since the model is evaluated on the target dataset .
However , for the QACNN this is surprisingly not the case - QACNN pre-trained on MovieQA without fine-tuning on the target dataset outperforms QACNN trained directly on the target dataset without pre-training on MovieQA ( rows ( b ) vs. ( a ) ) .
We attribute this to the limited size of the target dataset and the complex structure of the QACNN .
Table 3 : Results of varying sizes of the target datasets used for fine-tuning QACNN .
The number in the parenthesis indicates the accuracy increases from using the previous percentage for fine-tuning to the current percentage .
Varying the fine-tuning data size
We conducted experiments to study the relationship between the amount of training data from the target dataset for fine-tuning the model and the performance .
We first pre-train the models on MovieQA , then vary the training data size of the target dataset used to fine -tune them .
Note that for QACNN , we only fine - tune the last two fullyconnected layers instead of the entire model , since doing so usually produces the best performance according to Table 2 .
The results are shown in Table 3 4 .
As expected , the more training data is used for fine-tuning , the better the model 's performance is .
We also observe that the extent of improvement from using 0 % to 25 % of target training data is consistently larger than using from 25 % to 50 % , 50 % to 75 % , and 75 % to 100 % .
Using the QACNN fine-tuned on TOEFL - manual as an example , the accuracy of the QACNN improves by 2.7 % when varying the training size from 0 % to 25 % , but only improves by 0.9 % , 0.5 % , and 0.7 % when varying the training size from 25 % to 50 % , 50 % to 75 % , and 75 % to 100 % , respectively .
Varying the pre-training data size
We also vary the size of MovieQA for pre-training to study how large the source dataset should be to make transfer learning feasible .
The results are shown in Table 4 .
We find that even a small amount of source data can help .
For example , by using only 25 % of MovieQA for pre-training , the accuracy increases 6.3 % on MC160 .
We are interested in understanding what types of questions benefit the most from transfer learning .
According to the official guide to the TOEFL test , the questions in TOEFL can be divided into 3 types .
Type 1 questions are for basic comprehension of the story .
Type 2 questions go beyond basic comprehension , but test the understanding of the functions of utterances or the attitude the speaker expresses .
Type 3 questions further require the ability of making connections between different parts of the story , making inferences , drawing conclusions , or forming generalizations .
We used the split provided by Fang et al . ( 2016 ) , which contains 70/18/34 Type 1/2/3 questions .
We compare the performance of the QACNN and MemN2N on different types of questions in TOEFL - manual with and without pre-training on MovieQA , and show the results in Figure 2 . From Figure 2 we can observe that for both the QACNN and MemN2N , their performance on all three types of questions improves after pre-training , showing that the effectiveness of transfer learning is not limited to specific types of questions .
2 . The horizontal lines , where each line has the same color to its unsupervised counterpart , are the performances of QACNN with supervised transfer learning ( row ( e ) in Table 2 ) , and are the upperbounds for unsupervised transfer learning .
Unsupervised Transfer Learning
So far , we have studied the property of supervised transfer learning for QA , which means 1 . that during pre-training and fine-tuning , both the source and target datasets provide the correct answer for each question .
We now conduct unsupervised transfer learning experiments described in Section 2.2 ( Algorithm 1 ) , where the answers to the questions in the target dataset are not available .
We used QACNN as the QA model and all the parameters ( E , W 1 ) CN N , W ( 2 ) CN N , W ( F C , and W ( 2 ) F C ) were updated during fine -tuning in this experiment .
Since the range of the testing accuracy of the TOEFL - series ( TOEFL - manual and TOEFL - ASR ) is different from that of MCTest ( MC160 and MC500 ) , their results are displayed separately in Figure 3
Experimental Results From Figure 3 ( a ) and Figure 3 ( b ) we can observe that without ground truth in the target dataset for supervised fine-tuning , transfer learning from a source dataset can still improve the performance through a simple iterative self - labeling mechanism .
For TOEFL - manual and TOEFL - ASR , QACNN achieves the highest testing accuracy at Epoch 7 and 8 , outperforming its counterpart without fine-tuning by approximately 4 % and 5 % , respectively .
For MC160 and MC500 , the QACNN achieves the peak at Epoch 3 and 6 , outperforming its counterpart without fine- tuning by about 2 % and 6 % , respectively .
The results also show that the performance of unsupervised transfer learning is still worse than supervised transfer learning , which is not surprising , but the effectiveness of unsupervised transfer learning when no ground truth labels are provided is validated .
Attention Maps Visualization
To better understand the unsupervised transfer learning process of QACNN , we visualize the changes of the word-level attention map during training Epoch 1 , 4 , 7 , and 10 in Figure 4 .
We use the same question from TOEFL - manual as shown in Table 1 as an example .
From Figure 4 we can observe that as the training epochs increase , the QACNN focuses more on the context in the story that is related to the question and the correct answer choice .
For example , the correct answer is related to " class project " .
In Epoch 1 and 4 , the model does not focus on the phrase " class representation " , but the model attends on the phrase in Epoch 7 and 10 .
This demonstrates that even without ground truth , the iterative process in Algorithm 1 is still able to lead the QA model to gradually focus more on the important part of the story for answering the question .
Conclusion and Future Work
In this paper we demonstrate that a simple transfer learning technique can be very useful for the task of multi-choice question answering .
We use a QACNN and a MemN2N as QA models , with MovieQA as the source task and a TOEFL listening comprehension test and MCTest as the target tasks .
By pre-training on MovieQA , the performance of both models on the target datasets improves significantly .
The models also require much less training data from the target dataset to achieve similar performance to those without pretraining .
We also conduct experiments to study the influence of transfer learning on different types of questions , and show that the effectiveness of transfer learning is not limited to specific types of questions .
Finally , we show that by a simple iterative self- labeling technique , transfer learning is still useful , even when the correct answers for target QA dataset examples are not available , through quantitative results and visual analysis .
One area of future research will be generalizing the transfer learning results presented in this paper to other QA models and datasets .
In addition , since the original data format of the TOEFL listening comprehension test is audio instead of text , it is worth trying to initialize the embedding layer of the QACNN with semantic or acoustic word embeddings learned directly from speech Glass , 2018 , 2017 ; Chung et al. , 2016 ) instead of those learned from text ( Mikolov et al. , 2013 ; Pennington et al. , 2014 ) . Figure 1 : 1 Figure 1 : QACNN architecture overview .
QACNN consists of a similarity mapping layer , a query - based attention layer , and a prediction layer .
The two -stage attention mechanism takes place in the query - based attention layer , yielding word-level and sentence - level attention map , respectively .
The trainable parameters , including E , W ( 1 ) CN N , W ( 2 ) CN N , W ( 1 ) F C , and W ( 2 ) F C , are colored in light blue .
